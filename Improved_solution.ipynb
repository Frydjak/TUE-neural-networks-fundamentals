{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True # Used to display additional information during program execution\n",
    "TEST_SIZE = 1000\n",
    "VALIDATION_SIZE = 1000\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 785\n",
      "m = 70000\n",
      "labels_train.shape = (68000,)\n",
      "values_train.shape = (784, 68000)\n",
      "labels_test.shape = (1000,)\n",
      "values_test.shape = (784, 1000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 8\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from a file\n",
    "data = pd.read_csv('Datasets/MNIST_CSV/mnist.csv', header=None)\n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Split data into test, validation, and training sets\n",
    "data_test = data[0:TEST_SIZE].T\n",
    "labels_test = data_test[0]\n",
    "values_test = data_test[1:n].astype(np.float32) / 255.0 # converted and normalized\n",
    "\n",
    "data_validation = data[TEST_SIZE:(TEST_SIZE+VALIDATION_SIZE)].T\n",
    "labels_validation = data_validation[0]\n",
    "values_validation = data_validation[1:n].astype(np.float32) / 255.0 # converted and normalized\n",
    "\n",
    "data_train = data[(TEST_SIZE+VALIDATION_SIZE):m].T\n",
    "labels_train = data_train[0]\n",
    "values_train = data_train[1:n].astype(np.float32) / 255.0   # converted and normalized\n",
    "\n",
    "def show_image(values, index):\n",
    "    \"\"\"\n",
    "    Display image selected by index from given values matrix\n",
    "    \"\"\"\n",
    "    image = values[:, index, None]\n",
    "    image = image.reshape((28,28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "if DEBUG:\n",
    "    print(\"n =\", n)\n",
    "    print(\"m =\", m)\n",
    "    print(\"labels_train.shape =\", labels_train.shape)\n",
    "    print(\"values_train.shape =\", values_train.shape)\n",
    "    print(\"labels_test.shape =\", labels_test.shape)\n",
    "    print(\"values_test.shape =\", values_test.shape)\n",
    "    show_image(values_train, 0)\n",
    "    print(\"Label:\", labels_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Label: 8\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch tensors\n",
    "values_train = torch.tensor(values_train.T, dtype=torch.float32).view(-1, 1, 28, 28)\n",
    "labels_train = torch.tensor(labels_train, dtype=torch.long)\n",
    "dataset_train = TensorDataset(values_train, labels_train)\n",
    "loader_train = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "\n",
    "values_validation = torch.tensor(values_validation.T, dtype=torch.float32).view(-1, 1, 28, 28)\n",
    "labels_validation = torch.tensor(labels_validation, dtype=torch.long)\n",
    "dataset_validation = TensorDataset(values_validation, labels_validation)\n",
    "loader_validation = DataLoader(dataset_validation, batch_size=64, shuffle=False)\n",
    "\n",
    "values_test = torch.tensor(values_test.T, dtype=torch.float32).view(-1, 1, 28, 28)\n",
    "labels_test = torch.tensor(labels_test, dtype=torch.long)\n",
    "dataset_test = TensorDataset(values_test, labels_test)\n",
    "loader_test = DataLoader(dataset_test, batch_size=64, shuffle=False)\n",
    "\n",
    "# Option to print a sample to verify data correctness\n",
    "if DEBUG:\n",
    "    sample_idx = 0\n",
    "    plt.imshow(values_train[sample_idx].squeeze(), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(\"Sample Label:\", labels_train[sample_idx].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/1063], Loss: 2.2943\n",
      "Epoch [1/10], Step [2/1063], Loss: 2.2974\n",
      "Epoch [1/10], Step [3/1063], Loss: 2.3324\n",
      "Epoch [1/10], Step [4/1063], Loss: 2.2707\n",
      "Epoch [1/10], Step [5/1063], Loss: 2.2690\n",
      "Epoch [1/10], Step [6/1063], Loss: 2.2011\n",
      "Epoch [1/10], Step [7/1063], Loss: 2.1731\n",
      "Epoch [1/10], Step [8/1063], Loss: 2.1772\n",
      "Epoch [1/10], Step [9/1063], Loss: 2.1308\n",
      "Epoch [1/10], Step [10/1063], Loss: 2.0981\n",
      "Epoch [1/10], Step [11/1063], Loss: 2.0197\n",
      "Epoch [1/10], Step [12/1063], Loss: 1.9580\n",
      "Epoch [1/10], Step [13/1063], Loss: 1.9003\n",
      "Epoch [1/10], Step [14/1063], Loss: 1.9152\n",
      "Epoch [1/10], Step [15/1063], Loss: 1.8417\n",
      "Epoch [1/10], Step [16/1063], Loss: 1.5644\n",
      "Epoch [1/10], Step [17/1063], Loss: 1.5369\n",
      "Epoch [1/10], Step [18/1063], Loss: 1.5215\n",
      "Epoch [1/10], Step [19/1063], Loss: 1.4932\n",
      "Epoch [1/10], Step [20/1063], Loss: 1.5254\n",
      "Epoch [1/10], Step [21/1063], Loss: 1.4773\n",
      "Epoch [1/10], Step [22/1063], Loss: 1.3254\n",
      "Epoch [1/10], Step [23/1063], Loss: 1.0516\n",
      "Epoch [1/10], Step [24/1063], Loss: 1.2314\n",
      "Epoch [1/10], Step [25/1063], Loss: 1.1144\n",
      "Epoch [1/10], Step [26/1063], Loss: 1.0254\n",
      "Epoch [1/10], Step [27/1063], Loss: 1.1307\n",
      "Epoch [1/10], Step [28/1063], Loss: 0.8219\n",
      "Epoch [1/10], Step [29/1063], Loss: 0.8112\n",
      "Epoch [1/10], Step [30/1063], Loss: 0.8846\n",
      "Epoch [1/10], Step [31/1063], Loss: 0.8414\n",
      "Epoch [1/10], Step [32/1063], Loss: 0.6810\n",
      "Epoch [1/10], Step [33/1063], Loss: 1.0882\n",
      "Epoch [1/10], Step [34/1063], Loss: 0.8216\n",
      "Epoch [1/10], Step [35/1063], Loss: 0.7119\n",
      "Epoch [1/10], Step [36/1063], Loss: 0.6204\n",
      "Epoch [1/10], Step [37/1063], Loss: 0.6110\n",
      "Epoch [1/10], Step [38/1063], Loss: 0.4924\n",
      "Epoch [1/10], Step [39/1063], Loss: 0.7439\n",
      "Epoch [1/10], Step [40/1063], Loss: 0.7068\n",
      "Epoch [1/10], Step [41/1063], Loss: 0.4423\n",
      "Epoch [1/10], Step [42/1063], Loss: 0.5396\n",
      "Epoch [1/10], Step [43/1063], Loss: 0.4746\n",
      "Epoch [1/10], Step [44/1063], Loss: 0.5636\n",
      "Epoch [1/10], Step [45/1063], Loss: 0.6244\n",
      "Epoch [1/10], Step [46/1063], Loss: 0.6809\n",
      "Epoch [1/10], Step [47/1063], Loss: 0.7591\n",
      "Epoch [1/10], Step [48/1063], Loss: 0.4271\n",
      "Epoch [1/10], Step [49/1063], Loss: 0.4233\n",
      "Epoch [1/10], Step [50/1063], Loss: 0.6558\n",
      "Epoch [1/10], Step [51/1063], Loss: 0.5272\n",
      "Epoch [1/10], Step [52/1063], Loss: 0.4839\n",
      "Epoch [1/10], Step [53/1063], Loss: 0.4298\n",
      "Epoch [1/10], Step [54/1063], Loss: 0.4142\n",
      "Epoch [1/10], Step [55/1063], Loss: 0.6088\n",
      "Epoch [1/10], Step [56/1063], Loss: 0.4547\n",
      "Epoch [1/10], Step [57/1063], Loss: 0.5116\n",
      "Epoch [1/10], Step [58/1063], Loss: 0.4483\n",
      "Epoch [1/10], Step [59/1063], Loss: 0.6122\n",
      "Epoch [1/10], Step [60/1063], Loss: 0.5794\n",
      "Epoch [1/10], Step [61/1063], Loss: 0.4385\n",
      "Epoch [1/10], Step [62/1063], Loss: 0.5868\n",
      "Epoch [1/10], Step [63/1063], Loss: 0.2982\n",
      "Epoch [1/10], Step [64/1063], Loss: 0.4257\n",
      "Epoch [1/10], Step [65/1063], Loss: 0.4759\n",
      "Epoch [1/10], Step [66/1063], Loss: 0.5327\n",
      "Epoch [1/10], Step [67/1063], Loss: 0.5441\n",
      "Epoch [1/10], Step [68/1063], Loss: 0.4361\n",
      "Epoch [1/10], Step [69/1063], Loss: 0.5087\n",
      "Epoch [1/10], Step [70/1063], Loss: 0.3677\n",
      "Epoch [1/10], Step [71/1063], Loss: 0.4240\n",
      "Epoch [1/10], Step [72/1063], Loss: 0.3821\n",
      "Epoch [1/10], Step [73/1063], Loss: 0.2592\n",
      "Epoch [1/10], Step [74/1063], Loss: 0.2937\n",
      "Epoch [1/10], Step [75/1063], Loss: 0.2745\n",
      "Epoch [1/10], Step [76/1063], Loss: 0.2058\n",
      "Epoch [1/10], Step [77/1063], Loss: 0.3555\n",
      "Epoch [1/10], Step [78/1063], Loss: 0.3543\n",
      "Epoch [1/10], Step [79/1063], Loss: 0.4195\n",
      "Epoch [1/10], Step [80/1063], Loss: 0.4658\n",
      "Epoch [1/10], Step [81/1063], Loss: 0.3241\n",
      "Epoch [1/10], Step [82/1063], Loss: 0.2807\n",
      "Epoch [1/10], Step [83/1063], Loss: 0.5420\n",
      "Epoch [1/10], Step [84/1063], Loss: 0.3833\n",
      "Epoch [1/10], Step [85/1063], Loss: 0.4741\n",
      "Epoch [1/10], Step [86/1063], Loss: 0.4200\n",
      "Epoch [1/10], Step [87/1063], Loss: 0.6588\n",
      "Epoch [1/10], Step [88/1063], Loss: 0.4363\n",
      "Epoch [1/10], Step [89/1063], Loss: 0.2933\n",
      "Epoch [1/10], Step [90/1063], Loss: 0.3724\n",
      "Epoch [1/10], Step [91/1063], Loss: 0.4994\n",
      "Epoch [1/10], Step [92/1063], Loss: 0.4517\n",
      "Epoch [1/10], Step [93/1063], Loss: 0.4982\n",
      "Epoch [1/10], Step [94/1063], Loss: 0.3023\n",
      "Epoch [1/10], Step [95/1063], Loss: 0.4336\n",
      "Epoch [1/10], Step [96/1063], Loss: 0.2971\n",
      "Epoch [1/10], Step [97/1063], Loss: 0.2381\n",
      "Epoch [1/10], Step [98/1063], Loss: 0.3033\n",
      "Epoch [1/10], Step [99/1063], Loss: 0.3267\n",
      "Epoch [1/10], Step [100/1063], Loss: 0.4941\n",
      "Epoch [1/10], Step [101/1063], Loss: 0.3668\n",
      "Epoch [1/10], Step [102/1063], Loss: 0.4488\n",
      "Epoch [1/10], Step [103/1063], Loss: 0.2952\n",
      "Epoch [1/10], Step [104/1063], Loss: 0.3571\n",
      "Epoch [1/10], Step [105/1063], Loss: 0.2551\n",
      "Epoch [1/10], Step [106/1063], Loss: 0.1879\n",
      "Epoch [1/10], Step [107/1063], Loss: 0.3489\n",
      "Epoch [1/10], Step [108/1063], Loss: 0.3104\n",
      "Epoch [1/10], Step [109/1063], Loss: 0.3561\n",
      "Epoch [1/10], Step [110/1063], Loss: 0.2970\n",
      "Epoch [1/10], Step [111/1063], Loss: 0.3915\n",
      "Epoch [1/10], Step [112/1063], Loss: 0.1681\n",
      "Epoch [1/10], Step [113/1063], Loss: 0.2155\n",
      "Epoch [1/10], Step [114/1063], Loss: 0.2572\n",
      "Epoch [1/10], Step [115/1063], Loss: 0.2339\n",
      "Epoch [1/10], Step [116/1063], Loss: 0.2722\n",
      "Epoch [1/10], Step [117/1063], Loss: 0.1525\n",
      "Epoch [1/10], Step [118/1063], Loss: 0.4612\n",
      "Epoch [1/10], Step [119/1063], Loss: 0.2034\n",
      "Epoch [1/10], Step [120/1063], Loss: 0.4259\n",
      "Epoch [1/10], Step [121/1063], Loss: 0.1454\n",
      "Epoch [1/10], Step [122/1063], Loss: 0.2840\n",
      "Epoch [1/10], Step [123/1063], Loss: 0.1889\n",
      "Epoch [1/10], Step [124/1063], Loss: 0.1520\n",
      "Epoch [1/10], Step [125/1063], Loss: 0.2136\n",
      "Epoch [1/10], Step [126/1063], Loss: 0.1878\n",
      "Epoch [1/10], Step [127/1063], Loss: 0.4377\n",
      "Epoch [1/10], Step [128/1063], Loss: 0.1801\n",
      "Epoch [1/10], Step [129/1063], Loss: 0.1940\n",
      "Epoch [1/10], Step [130/1063], Loss: 0.1410\n",
      "Epoch [1/10], Step [131/1063], Loss: 0.1480\n",
      "Epoch [1/10], Step [132/1063], Loss: 0.1734\n",
      "Epoch [1/10], Step [133/1063], Loss: 0.1941\n",
      "Epoch [1/10], Step [134/1063], Loss: 0.2731\n",
      "Epoch [1/10], Step [135/1063], Loss: 0.1546\n",
      "Epoch [1/10], Step [136/1063], Loss: 0.3311\n",
      "Epoch [1/10], Step [137/1063], Loss: 0.4641\n",
      "Epoch [1/10], Step [138/1063], Loss: 0.1709\n",
      "Epoch [1/10], Step [139/1063], Loss: 0.3220\n",
      "Epoch [1/10], Step [140/1063], Loss: 0.2387\n",
      "Epoch [1/10], Step [141/1063], Loss: 0.1670\n",
      "Epoch [1/10], Step [142/1063], Loss: 0.1958\n",
      "Epoch [1/10], Step [143/1063], Loss: 0.1536\n",
      "Epoch [1/10], Step [144/1063], Loss: 0.3325\n",
      "Epoch [1/10], Step [145/1063], Loss: 0.3824\n",
      "Epoch [1/10], Step [146/1063], Loss: 0.2188\n",
      "Epoch [1/10], Step [147/1063], Loss: 0.1907\n",
      "Epoch [1/10], Step [148/1063], Loss: 0.1503\n",
      "Epoch [1/10], Step [149/1063], Loss: 0.5012\n",
      "Epoch [1/10], Step [150/1063], Loss: 0.1708\n",
      "Epoch [1/10], Step [151/1063], Loss: 0.2299\n",
      "Epoch [1/10], Step [152/1063], Loss: 0.1267\n",
      "Epoch [1/10], Step [153/1063], Loss: 0.2036\n",
      "Epoch [1/10], Step [154/1063], Loss: 0.2089\n",
      "Epoch [1/10], Step [155/1063], Loss: 0.1741\n",
      "Epoch [1/10], Step [156/1063], Loss: 0.2142\n",
      "Epoch [1/10], Step [157/1063], Loss: 0.1370\n",
      "Epoch [1/10], Step [158/1063], Loss: 0.1807\n",
      "Epoch [1/10], Step [159/1063], Loss: 0.1251\n",
      "Epoch [1/10], Step [160/1063], Loss: 0.0953\n",
      "Epoch [1/10], Step [161/1063], Loss: 0.1831\n",
      "Epoch [1/10], Step [162/1063], Loss: 0.1519\n",
      "Epoch [1/10], Step [163/1063], Loss: 0.1362\n",
      "Epoch [1/10], Step [164/1063], Loss: 0.3240\n",
      "Epoch [1/10], Step [165/1063], Loss: 0.1613\n",
      "Epoch [1/10], Step [166/1063], Loss: 0.1701\n",
      "Epoch [1/10], Step [167/1063], Loss: 0.2266\n",
      "Epoch [1/10], Step [168/1063], Loss: 0.3599\n",
      "Epoch [1/10], Step [169/1063], Loss: 0.1534\n",
      "Epoch [1/10], Step [170/1063], Loss: 0.1486\n",
      "Epoch [1/10], Step [171/1063], Loss: 0.0609\n",
      "Epoch [1/10], Step [172/1063], Loss: 0.1978\n",
      "Epoch [1/10], Step [173/1063], Loss: 0.2265\n",
      "Epoch [1/10], Step [174/1063], Loss: 0.2294\n",
      "Epoch [1/10], Step [175/1063], Loss: 0.0916\n",
      "Epoch [1/10], Step [176/1063], Loss: 0.1089\n",
      "Epoch [1/10], Step [177/1063], Loss: 0.1119\n",
      "Epoch [1/10], Step [178/1063], Loss: 0.3044\n",
      "Epoch [1/10], Step [179/1063], Loss: 0.1356\n",
      "Epoch [1/10], Step [180/1063], Loss: 0.0707\n",
      "Epoch [1/10], Step [181/1063], Loss: 0.2430\n",
      "Epoch [1/10], Step [182/1063], Loss: 0.1310\n",
      "Epoch [1/10], Step [183/1063], Loss: 0.2249\n",
      "Epoch [1/10], Step [184/1063], Loss: 0.1583\n",
      "Epoch [1/10], Step [185/1063], Loss: 0.2180\n",
      "Epoch [1/10], Step [186/1063], Loss: 0.1996\n",
      "Epoch [1/10], Step [187/1063], Loss: 0.0970\n",
      "Epoch [1/10], Step [188/1063], Loss: 0.1664\n",
      "Epoch [1/10], Step [189/1063], Loss: 0.2303\n",
      "Epoch [1/10], Step [190/1063], Loss: 0.4797\n",
      "Epoch [1/10], Step [191/1063], Loss: 0.0963\n",
      "Epoch [1/10], Step [192/1063], Loss: 0.2942\n",
      "Epoch [1/10], Step [193/1063], Loss: 0.1921\n",
      "Epoch [1/10], Step [194/1063], Loss: 0.1398\n",
      "Epoch [1/10], Step [195/1063], Loss: 0.1649\n",
      "Epoch [1/10], Step [196/1063], Loss: 0.1841\n",
      "Epoch [1/10], Step [197/1063], Loss: 0.2493\n",
      "Epoch [1/10], Step [198/1063], Loss: 0.1724\n",
      "Epoch [1/10], Step [199/1063], Loss: 0.1012\n",
      "Epoch [1/10], Step [200/1063], Loss: 0.2907\n",
      "Epoch [1/10], Step [201/1063], Loss: 0.1560\n",
      "Epoch [1/10], Step [202/1063], Loss: 0.1153\n",
      "Epoch [1/10], Step [203/1063], Loss: 0.1162\n",
      "Epoch [1/10], Step [204/1063], Loss: 0.2291\n",
      "Epoch [1/10], Step [205/1063], Loss: 0.1628\n",
      "Epoch [1/10], Step [206/1063], Loss: 0.1294\n",
      "Epoch [1/10], Step [207/1063], Loss: 0.1326\n",
      "Epoch [1/10], Step [208/1063], Loss: 0.2471\n",
      "Epoch [1/10], Step [209/1063], Loss: 0.1297\n",
      "Epoch [1/10], Step [210/1063], Loss: 0.2711\n",
      "Epoch [1/10], Step [211/1063], Loss: 0.3663\n",
      "Epoch [1/10], Step [212/1063], Loss: 0.3365\n",
      "Epoch [1/10], Step [213/1063], Loss: 0.2344\n",
      "Epoch [1/10], Step [214/1063], Loss: 0.0755\n",
      "Epoch [1/10], Step [215/1063], Loss: 0.1270\n",
      "Epoch [1/10], Step [216/1063], Loss: 0.2952\n",
      "Epoch [1/10], Step [217/1063], Loss: 0.1378\n",
      "Epoch [1/10], Step [218/1063], Loss: 0.2598\n",
      "Epoch [1/10], Step [219/1063], Loss: 0.2107\n",
      "Epoch [1/10], Step [220/1063], Loss: 0.1496\n",
      "Epoch [1/10], Step [221/1063], Loss: 0.1228\n",
      "Epoch [1/10], Step [222/1063], Loss: 0.1664\n",
      "Epoch [1/10], Step [223/1063], Loss: 0.0585\n",
      "Epoch [1/10], Step [224/1063], Loss: 0.1531\n",
      "Epoch [1/10], Step [225/1063], Loss: 0.3687\n",
      "Epoch [1/10], Step [226/1063], Loss: 0.2614\n",
      "Epoch [1/10], Step [227/1063], Loss: 0.0799\n",
      "Epoch [1/10], Step [228/1063], Loss: 0.1112\n",
      "Epoch [1/10], Step [229/1063], Loss: 0.1261\n",
      "Epoch [1/10], Step [230/1063], Loss: 0.1350\n",
      "Epoch [1/10], Step [231/1063], Loss: 0.1073\n",
      "Epoch [1/10], Step [232/1063], Loss: 0.0862\n",
      "Epoch [1/10], Step [233/1063], Loss: 0.2845\n",
      "Epoch [1/10], Step [234/1063], Loss: 0.1205\n",
      "Epoch [1/10], Step [235/1063], Loss: 0.1053\n",
      "Epoch [1/10], Step [236/1063], Loss: 0.3109\n",
      "Epoch [1/10], Step [237/1063], Loss: 0.2650\n",
      "Epoch [1/10], Step [238/1063], Loss: 0.0285\n",
      "Epoch [1/10], Step [239/1063], Loss: 0.1688\n",
      "Epoch [1/10], Step [240/1063], Loss: 0.2330\n",
      "Epoch [1/10], Step [241/1063], Loss: 0.0923\n",
      "Epoch [1/10], Step [242/1063], Loss: 0.0647\n",
      "Epoch [1/10], Step [243/1063], Loss: 0.1090\n",
      "Epoch [1/10], Step [244/1063], Loss: 0.1777\n",
      "Epoch [1/10], Step [245/1063], Loss: 0.1205\n",
      "Epoch [1/10], Step [246/1063], Loss: 0.1102\n",
      "Epoch [1/10], Step [247/1063], Loss: 0.1065\n",
      "Epoch [1/10], Step [248/1063], Loss: 0.1307\n",
      "Epoch [1/10], Step [249/1063], Loss: 0.3229\n",
      "Epoch [1/10], Step [250/1063], Loss: 0.1236\n",
      "Epoch [1/10], Step [251/1063], Loss: 0.0803\n",
      "Epoch [1/10], Step [252/1063], Loss: 0.1214\n",
      "Epoch [1/10], Step [253/1063], Loss: 0.0880\n",
      "Epoch [1/10], Step [254/1063], Loss: 0.3686\n",
      "Epoch [1/10], Step [255/1063], Loss: 0.2922\n",
      "Epoch [1/10], Step [256/1063], Loss: 0.0524\n",
      "Epoch [1/10], Step [257/1063], Loss: 0.0984\n",
      "Epoch [1/10], Step [258/1063], Loss: 0.2077\n",
      "Epoch [1/10], Step [259/1063], Loss: 0.1218\n",
      "Epoch [1/10], Step [260/1063], Loss: 0.1323\n",
      "Epoch [1/10], Step [261/1063], Loss: 0.2400\n",
      "Epoch [1/10], Step [262/1063], Loss: 0.1221\n",
      "Epoch [1/10], Step [263/1063], Loss: 0.0818\n",
      "Epoch [1/10], Step [264/1063], Loss: 0.1424\n",
      "Epoch [1/10], Step [265/1063], Loss: 0.0609\n",
      "Epoch [1/10], Step [266/1063], Loss: 0.1939\n",
      "Epoch [1/10], Step [267/1063], Loss: 0.2273\n",
      "Epoch [1/10], Step [268/1063], Loss: 0.1426\n",
      "Epoch [1/10], Step [269/1063], Loss: 0.2824\n",
      "Epoch [1/10], Step [270/1063], Loss: 0.0633\n",
      "Epoch [1/10], Step [271/1063], Loss: 0.1337\n",
      "Epoch [1/10], Step [272/1063], Loss: 0.0777\n",
      "Epoch [1/10], Step [273/1063], Loss: 0.1148\n",
      "Epoch [1/10], Step [274/1063], Loss: 0.0876\n",
      "Epoch [1/10], Step [275/1063], Loss: 0.1007\n",
      "Epoch [1/10], Step [276/1063], Loss: 0.1724\n",
      "Epoch [1/10], Step [277/1063], Loss: 0.0866\n",
      "Epoch [1/10], Step [278/1063], Loss: 0.1768\n",
      "Epoch [1/10], Step [279/1063], Loss: 0.0851\n",
      "Epoch [1/10], Step [280/1063], Loss: 0.1816\n",
      "Epoch [1/10], Step [281/1063], Loss: 0.2092\n",
      "Epoch [1/10], Step [282/1063], Loss: 0.2332\n",
      "Epoch [1/10], Step [283/1063], Loss: 0.0873\n",
      "Epoch [1/10], Step [284/1063], Loss: 0.1149\n",
      "Epoch [1/10], Step [285/1063], Loss: 0.1505\n",
      "Epoch [1/10], Step [286/1063], Loss: 0.2383\n",
      "Epoch [1/10], Step [287/1063], Loss: 0.0785\n",
      "Epoch [1/10], Step [288/1063], Loss: 0.0959\n",
      "Epoch [1/10], Step [289/1063], Loss: 0.0558\n",
      "Epoch [1/10], Step [290/1063], Loss: 0.0544\n",
      "Epoch [1/10], Step [291/1063], Loss: 0.0981\n",
      "Epoch [1/10], Step [292/1063], Loss: 0.1104\n",
      "Epoch [1/10], Step [293/1063], Loss: 0.0715\n",
      "Epoch [1/10], Step [294/1063], Loss: 0.1004\n",
      "Epoch [1/10], Step [295/1063], Loss: 0.1454\n",
      "Epoch [1/10], Step [296/1063], Loss: 0.0960\n",
      "Epoch [1/10], Step [297/1063], Loss: 0.1823\n",
      "Epoch [1/10], Step [298/1063], Loss: 0.0955\n",
      "Epoch [1/10], Step [299/1063], Loss: 0.2133\n",
      "Epoch [1/10], Step [300/1063], Loss: 0.1637\n",
      "Epoch [1/10], Step [301/1063], Loss: 0.0385\n",
      "Epoch [1/10], Step [302/1063], Loss: 0.1164\n",
      "Epoch [1/10], Step [303/1063], Loss: 0.0842\n",
      "Epoch [1/10], Step [304/1063], Loss: 0.1263\n",
      "Epoch [1/10], Step [305/1063], Loss: 0.0637\n",
      "Epoch [1/10], Step [306/1063], Loss: 0.1244\n",
      "Epoch [1/10], Step [307/1063], Loss: 0.0827\n",
      "Epoch [1/10], Step [308/1063], Loss: 0.0715\n",
      "Epoch [1/10], Step [309/1063], Loss: 0.0631\n",
      "Epoch [1/10], Step [310/1063], Loss: 0.0673\n",
      "Epoch [1/10], Step [311/1063], Loss: 0.0441\n",
      "Epoch [1/10], Step [312/1063], Loss: 0.0597\n",
      "Epoch [1/10], Step [313/1063], Loss: 0.1415\n",
      "Epoch [1/10], Step [314/1063], Loss: 0.1436\n",
      "Epoch [1/10], Step [315/1063], Loss: 0.0428\n",
      "Epoch [1/10], Step [316/1063], Loss: 0.1037\n",
      "Epoch [1/10], Step [317/1063], Loss: 0.0869\n",
      "Epoch [1/10], Step [318/1063], Loss: 0.0974\n",
      "Epoch [1/10], Step [319/1063], Loss: 0.1459\n",
      "Epoch [1/10], Step [320/1063], Loss: 0.1280\n",
      "Epoch [1/10], Step [321/1063], Loss: 0.0849\n",
      "Epoch [1/10], Step [322/1063], Loss: 0.2219\n",
      "Epoch [1/10], Step [323/1063], Loss: 0.0100\n",
      "Epoch [1/10], Step [324/1063], Loss: 0.0851\n",
      "Epoch [1/10], Step [325/1063], Loss: 0.1574\n",
      "Epoch [1/10], Step [326/1063], Loss: 0.1868\n",
      "Epoch [1/10], Step [327/1063], Loss: 0.0621\n",
      "Epoch [1/10], Step [328/1063], Loss: 0.0693\n",
      "Epoch [1/10], Step [329/1063], Loss: 0.0412\n",
      "Epoch [1/10], Step [330/1063], Loss: 0.0513\n",
      "Epoch [1/10], Step [331/1063], Loss: 0.1670\n",
      "Epoch [1/10], Step [332/1063], Loss: 0.0737\n",
      "Epoch [1/10], Step [333/1063], Loss: 0.1442\n",
      "Epoch [1/10], Step [334/1063], Loss: 0.2067\n",
      "Epoch [1/10], Step [335/1063], Loss: 0.1212\n",
      "Epoch [1/10], Step [336/1063], Loss: 0.0319\n",
      "Epoch [1/10], Step [337/1063], Loss: 0.0749\n",
      "Epoch [1/10], Step [338/1063], Loss: 0.0318\n",
      "Epoch [1/10], Step [339/1063], Loss: 0.0420\n",
      "Epoch [1/10], Step [340/1063], Loss: 0.1185\n",
      "Epoch [1/10], Step [341/1063], Loss: 0.0494\n",
      "Epoch [1/10], Step [342/1063], Loss: 0.1125\n",
      "Epoch [1/10], Step [343/1063], Loss: 0.1827\n",
      "Epoch [1/10], Step [344/1063], Loss: 0.0443\n",
      "Epoch [1/10], Step [345/1063], Loss: 0.1602\n",
      "Epoch [1/10], Step [346/1063], Loss: 0.1617\n",
      "Epoch [1/10], Step [347/1063], Loss: 0.0556\n",
      "Epoch [1/10], Step [348/1063], Loss: 0.1696\n",
      "Epoch [1/10], Step [349/1063], Loss: 0.0237\n",
      "Epoch [1/10], Step [350/1063], Loss: 0.0444\n",
      "Epoch [1/10], Step [351/1063], Loss: 0.1569\n",
      "Epoch [1/10], Step [352/1063], Loss: 0.0634\n",
      "Epoch [1/10], Step [353/1063], Loss: 0.2201\n",
      "Epoch [1/10], Step [354/1063], Loss: 0.0823\n",
      "Epoch [1/10], Step [355/1063], Loss: 0.0177\n",
      "Epoch [1/10], Step [356/1063], Loss: 0.0681\n",
      "Epoch [1/10], Step [357/1063], Loss: 0.0428\n",
      "Epoch [1/10], Step [358/1063], Loss: 0.0781\n",
      "Epoch [1/10], Step [359/1063], Loss: 0.1225\n",
      "Epoch [1/10], Step [360/1063], Loss: 0.1112\n",
      "Epoch [1/10], Step [361/1063], Loss: 0.0263\n",
      "Epoch [1/10], Step [362/1063], Loss: 0.2185\n",
      "Epoch [1/10], Step [363/1063], Loss: 0.1753\n",
      "Epoch [1/10], Step [364/1063], Loss: 0.1545\n",
      "Epoch [1/10], Step [365/1063], Loss: 0.0796\n",
      "Epoch [1/10], Step [366/1063], Loss: 0.1134\n",
      "Epoch [1/10], Step [367/1063], Loss: 0.1016\n",
      "Epoch [1/10], Step [368/1063], Loss: 0.1292\n",
      "Epoch [1/10], Step [369/1063], Loss: 0.0522\n",
      "Epoch [1/10], Step [370/1063], Loss: 0.1253\n",
      "Epoch [1/10], Step [371/1063], Loss: 0.0861\n",
      "Epoch [1/10], Step [372/1063], Loss: 0.0994\n",
      "Epoch [1/10], Step [373/1063], Loss: 0.1931\n",
      "Epoch [1/10], Step [374/1063], Loss: 0.1094\n",
      "Epoch [1/10], Step [375/1063], Loss: 0.1395\n",
      "Epoch [1/10], Step [376/1063], Loss: 0.1093\n",
      "Epoch [1/10], Step [377/1063], Loss: 0.0964\n",
      "Epoch [1/10], Step [378/1063], Loss: 0.0600\n",
      "Epoch [1/10], Step [379/1063], Loss: 0.0680\n",
      "Epoch [1/10], Step [380/1063], Loss: 0.1576\n",
      "Epoch [1/10], Step [381/1063], Loss: 0.0916\n",
      "Epoch [1/10], Step [382/1063], Loss: 0.0547\n",
      "Epoch [1/10], Step [383/1063], Loss: 0.1106\n",
      "Epoch [1/10], Step [384/1063], Loss: 0.1046\n",
      "Epoch [1/10], Step [385/1063], Loss: 0.1251\n",
      "Epoch [1/10], Step [386/1063], Loss: 0.1651\n",
      "Epoch [1/10], Step [387/1063], Loss: 0.1302\n",
      "Epoch [1/10], Step [388/1063], Loss: 0.1629\n",
      "Epoch [1/10], Step [389/1063], Loss: 0.0487\n",
      "Epoch [1/10], Step [390/1063], Loss: 0.0374\n",
      "Epoch [1/10], Step [391/1063], Loss: 0.0854\n",
      "Epoch [1/10], Step [392/1063], Loss: 0.0474\n",
      "Epoch [1/10], Step [393/1063], Loss: 0.0724\n",
      "Epoch [1/10], Step [394/1063], Loss: 0.0990\n",
      "Epoch [1/10], Step [395/1063], Loss: 0.0185\n",
      "Epoch [1/10], Step [396/1063], Loss: 0.0574\n",
      "Epoch [1/10], Step [397/1063], Loss: 0.0275\n",
      "Epoch [1/10], Step [398/1063], Loss: 0.2094\n",
      "Epoch [1/10], Step [399/1063], Loss: 0.0552\n",
      "Epoch [1/10], Step [400/1063], Loss: 0.0757\n",
      "Epoch [1/10], Step [401/1063], Loss: 0.1967\n",
      "Epoch [1/10], Step [402/1063], Loss: 0.0921\n",
      "Epoch [1/10], Step [403/1063], Loss: 0.0677\n",
      "Epoch [1/10], Step [404/1063], Loss: 0.1188\n",
      "Epoch [1/10], Step [405/1063], Loss: 0.1008\n",
      "Epoch [1/10], Step [406/1063], Loss: 0.0202\n",
      "Epoch [1/10], Step [407/1063], Loss: 0.0299\n",
      "Epoch [1/10], Step [408/1063], Loss: 0.1570\n",
      "Epoch [1/10], Step [409/1063], Loss: 0.1177\n",
      "Epoch [1/10], Step [410/1063], Loss: 0.0411\n",
      "Epoch [1/10], Step [411/1063], Loss: 0.0703\n",
      "Epoch [1/10], Step [412/1063], Loss: 0.1661\n",
      "Epoch [1/10], Step [413/1063], Loss: 0.0242\n",
      "Epoch [1/10], Step [414/1063], Loss: 0.1092\n",
      "Epoch [1/10], Step [415/1063], Loss: 0.0693\n",
      "Epoch [1/10], Step [416/1063], Loss: 0.0373\n",
      "Epoch [1/10], Step [417/1063], Loss: 0.0319\n",
      "Epoch [1/10], Step [418/1063], Loss: 0.1355\n",
      "Epoch [1/10], Step [419/1063], Loss: 0.1265\n",
      "Epoch [1/10], Step [420/1063], Loss: 0.1777\n",
      "Epoch [1/10], Step [421/1063], Loss: 0.0289\n",
      "Epoch [1/10], Step [422/1063], Loss: 0.0527\n",
      "Epoch [1/10], Step [423/1063], Loss: 0.0876\n",
      "Epoch [1/10], Step [424/1063], Loss: 0.1222\n",
      "Epoch [1/10], Step [425/1063], Loss: 0.0551\n",
      "Epoch [1/10], Step [426/1063], Loss: 0.0241\n",
      "Epoch [1/10], Step [427/1063], Loss: 0.0480\n",
      "Epoch [1/10], Step [428/1063], Loss: 0.1325\n",
      "Epoch [1/10], Step [429/1063], Loss: 0.1316\n",
      "Epoch [1/10], Step [430/1063], Loss: 0.0374\n",
      "Epoch [1/10], Step [431/1063], Loss: 0.0788\n",
      "Epoch [1/10], Step [432/1063], Loss: 0.0483\n",
      "Epoch [1/10], Step [433/1063], Loss: 0.1443\n",
      "Epoch [1/10], Step [434/1063], Loss: 0.1093\n",
      "Epoch [1/10], Step [435/1063], Loss: 0.0264\n",
      "Epoch [1/10], Step [436/1063], Loss: 0.0233\n",
      "Epoch [1/10], Step [437/1063], Loss: 0.0909\n",
      "Epoch [1/10], Step [438/1063], Loss: 0.1166\n",
      "Epoch [1/10], Step [439/1063], Loss: 0.1580\n",
      "Epoch [1/10], Step [440/1063], Loss: 0.0518\n",
      "Epoch [1/10], Step [441/1063], Loss: 0.0837\n",
      "Epoch [1/10], Step [442/1063], Loss: 0.0860\n",
      "Epoch [1/10], Step [443/1063], Loss: 0.0331\n",
      "Epoch [1/10], Step [444/1063], Loss: 0.0525\n",
      "Epoch [1/10], Step [445/1063], Loss: 0.0889\n",
      "Epoch [1/10], Step [446/1063], Loss: 0.0281\n",
      "Epoch [1/10], Step [447/1063], Loss: 0.1109\n",
      "Epoch [1/10], Step [448/1063], Loss: 0.1242\n",
      "Epoch [1/10], Step [449/1063], Loss: 0.0286\n",
      "Epoch [1/10], Step [450/1063], Loss: 0.1243\n",
      "Epoch [1/10], Step [451/1063], Loss: 0.0680\n",
      "Epoch [1/10], Step [452/1063], Loss: 0.0901\n",
      "Epoch [1/10], Step [453/1063], Loss: 0.1479\n",
      "Epoch [1/10], Step [454/1063], Loss: 0.1404\n",
      "Epoch [1/10], Step [455/1063], Loss: 0.0524\n",
      "Epoch [1/10], Step [456/1063], Loss: 0.1994\n",
      "Epoch [1/10], Step [457/1063], Loss: 0.3240\n",
      "Epoch [1/10], Step [458/1063], Loss: 0.0454\n",
      "Epoch [1/10], Step [459/1063], Loss: 0.0677\n",
      "Epoch [1/10], Step [460/1063], Loss: 0.1236\n",
      "Epoch [1/10], Step [461/1063], Loss: 0.1098\n",
      "Epoch [1/10], Step [462/1063], Loss: 0.1360\n",
      "Epoch [1/10], Step [463/1063], Loss: 0.0661\n",
      "Epoch [1/10], Step [464/1063], Loss: 0.1723\n",
      "Epoch [1/10], Step [465/1063], Loss: 0.0492\n",
      "Epoch [1/10], Step [466/1063], Loss: 0.0671\n",
      "Epoch [1/10], Step [467/1063], Loss: 0.1411\n",
      "Epoch [1/10], Step [468/1063], Loss: 0.1112\n",
      "Epoch [1/10], Step [469/1063], Loss: 0.2673\n",
      "Epoch [1/10], Step [470/1063], Loss: 0.1664\n",
      "Epoch [1/10], Step [471/1063], Loss: 0.0903\n",
      "Epoch [1/10], Step [472/1063], Loss: 0.0491\n",
      "Epoch [1/10], Step [473/1063], Loss: 0.1094\n",
      "Epoch [1/10], Step [474/1063], Loss: 0.1080\n",
      "Epoch [1/10], Step [475/1063], Loss: 0.0430\n",
      "Epoch [1/10], Step [476/1063], Loss: 0.0313\n",
      "Epoch [1/10], Step [477/1063], Loss: 0.0431\n",
      "Epoch [1/10], Step [478/1063], Loss: 0.0929\n",
      "Epoch [1/10], Step [479/1063], Loss: 0.0595\n",
      "Epoch [1/10], Step [480/1063], Loss: 0.0328\n",
      "Epoch [1/10], Step [481/1063], Loss: 0.0338\n",
      "Epoch [1/10], Step [482/1063], Loss: 0.0604\n",
      "Epoch [1/10], Step [483/1063], Loss: 0.0668\n",
      "Epoch [1/10], Step [484/1063], Loss: 0.0839\n",
      "Epoch [1/10], Step [485/1063], Loss: 0.0757\n",
      "Epoch [1/10], Step [486/1063], Loss: 0.0346\n",
      "Epoch [1/10], Step [487/1063], Loss: 0.0527\n",
      "Epoch [1/10], Step [488/1063], Loss: 0.0264\n",
      "Epoch [1/10], Step [489/1063], Loss: 0.0419\n",
      "Epoch [1/10], Step [490/1063], Loss: 0.0160\n",
      "Epoch [1/10], Step [491/1063], Loss: 0.0947\n",
      "Epoch [1/10], Step [492/1063], Loss: 0.2603\n",
      "Epoch [1/10], Step [493/1063], Loss: 0.0631\n",
      "Epoch [1/10], Step [494/1063], Loss: 0.0525\n",
      "Epoch [1/10], Step [495/1063], Loss: 0.1316\n",
      "Epoch [1/10], Step [496/1063], Loss: 0.2030\n",
      "Epoch [1/10], Step [497/1063], Loss: 0.2268\n",
      "Epoch [1/10], Step [498/1063], Loss: 0.0725\n",
      "Epoch [1/10], Step [499/1063], Loss: 0.1722\n",
      "Epoch [1/10], Step [500/1063], Loss: 0.0310\n",
      "Epoch [1/10], Step [501/1063], Loss: 0.1342\n",
      "Epoch [1/10], Step [502/1063], Loss: 0.1602\n",
      "Epoch [1/10], Step [503/1063], Loss: 0.1222\n",
      "Epoch [1/10], Step [504/1063], Loss: 0.0534\n",
      "Epoch [1/10], Step [505/1063], Loss: 0.1499\n",
      "Epoch [1/10], Step [506/1063], Loss: 0.2236\n",
      "Epoch [1/10], Step [507/1063], Loss: 0.0827\n",
      "Epoch [1/10], Step [508/1063], Loss: 0.0852\n",
      "Epoch [1/10], Step [509/1063], Loss: 0.2252\n",
      "Epoch [1/10], Step [510/1063], Loss: 0.0452\n",
      "Epoch [1/10], Step [511/1063], Loss: 0.0165\n",
      "Epoch [1/10], Step [512/1063], Loss: 0.0912\n",
      "Epoch [1/10], Step [513/1063], Loss: 0.1267\n",
      "Epoch [1/10], Step [514/1063], Loss: 0.0744\n",
      "Epoch [1/10], Step [515/1063], Loss: 0.0894\n",
      "Epoch [1/10], Step [516/1063], Loss: 0.1627\n",
      "Epoch [1/10], Step [517/1063], Loss: 0.0829\n",
      "Epoch [1/10], Step [518/1063], Loss: 0.0244\n",
      "Epoch [1/10], Step [519/1063], Loss: 0.1422\n",
      "Epoch [1/10], Step [520/1063], Loss: 0.0950\n",
      "Epoch [1/10], Step [521/1063], Loss: 0.0523\n",
      "Epoch [1/10], Step [522/1063], Loss: 0.0411\n",
      "Epoch [1/10], Step [523/1063], Loss: 0.1238\n",
      "Epoch [1/10], Step [524/1063], Loss: 0.0707\n",
      "Epoch [1/10], Step [525/1063], Loss: 0.0335\n",
      "Epoch [1/10], Step [526/1063], Loss: 0.0767\n",
      "Epoch [1/10], Step [527/1063], Loss: 0.0898\n",
      "Epoch [1/10], Step [528/1063], Loss: 0.0779\n",
      "Epoch [1/10], Step [529/1063], Loss: 0.0896\n",
      "Epoch [1/10], Step [530/1063], Loss: 0.0734\n",
      "Epoch [1/10], Step [531/1063], Loss: 0.0857\n",
      "Epoch [1/10], Step [532/1063], Loss: 0.1450\n",
      "Epoch [1/10], Step [533/1063], Loss: 0.0868\n",
      "Epoch [1/10], Step [534/1063], Loss: 0.0798\n",
      "Epoch [1/10], Step [535/1063], Loss: 0.0845\n",
      "Epoch [1/10], Step [536/1063], Loss: 0.0395\n",
      "Epoch [1/10], Step [537/1063], Loss: 0.1235\n",
      "Epoch [1/10], Step [538/1063], Loss: 0.0775\n",
      "Epoch [1/10], Step [539/1063], Loss: 0.0250\n",
      "Epoch [1/10], Step [540/1063], Loss: 0.0265\n",
      "Epoch [1/10], Step [541/1063], Loss: 0.0426\n",
      "Epoch [1/10], Step [542/1063], Loss: 0.0892\n",
      "Epoch [1/10], Step [543/1063], Loss: 0.0860\n",
      "Epoch [1/10], Step [544/1063], Loss: 0.0360\n",
      "Epoch [1/10], Step [545/1063], Loss: 0.0268\n",
      "Epoch [1/10], Step [546/1063], Loss: 0.0588\n",
      "Epoch [1/10], Step [547/1063], Loss: 0.1256\n",
      "Epoch [1/10], Step [548/1063], Loss: 0.0305\n",
      "Epoch [1/10], Step [549/1063], Loss: 0.1358\n",
      "Epoch [1/10], Step [550/1063], Loss: 0.1308\n",
      "Epoch [1/10], Step [551/1063], Loss: 0.0621\n",
      "Epoch [1/10], Step [552/1063], Loss: 0.0265\n",
      "Epoch [1/10], Step [553/1063], Loss: 0.1888\n",
      "Epoch [1/10], Step [554/1063], Loss: 0.1347\n",
      "Epoch [1/10], Step [555/1063], Loss: 0.1647\n",
      "Epoch [1/10], Step [556/1063], Loss: 0.0427\n",
      "Epoch [1/10], Step [557/1063], Loss: 0.0708\n",
      "Epoch [1/10], Step [558/1063], Loss: 0.0519\n",
      "Epoch [1/10], Step [559/1063], Loss: 0.0511\n",
      "Epoch [1/10], Step [560/1063], Loss: 0.0582\n",
      "Epoch [1/10], Step [561/1063], Loss: 0.0953\n",
      "Epoch [1/10], Step [562/1063], Loss: 0.1128\n",
      "Epoch [1/10], Step [563/1063], Loss: 0.0519\n",
      "Epoch [1/10], Step [564/1063], Loss: 0.0395\n",
      "Epoch [1/10], Step [565/1063], Loss: 0.0730\n",
      "Epoch [1/10], Step [566/1063], Loss: 0.0221\n",
      "Epoch [1/10], Step [567/1063], Loss: 0.0460\n",
      "Epoch [1/10], Step [568/1063], Loss: 0.0356\n",
      "Epoch [1/10], Step [569/1063], Loss: 0.0901\n",
      "Epoch [1/10], Step [570/1063], Loss: 0.0527\n",
      "Epoch [1/10], Step [571/1063], Loss: 0.0691\n",
      "Epoch [1/10], Step [572/1063], Loss: 0.0639\n",
      "Epoch [1/10], Step [573/1063], Loss: 0.0690\n",
      "Epoch [1/10], Step [574/1063], Loss: 0.0746\n",
      "Epoch [1/10], Step [575/1063], Loss: 0.0381\n",
      "Epoch [1/10], Step [576/1063], Loss: 0.0784\n",
      "Epoch [1/10], Step [577/1063], Loss: 0.0383\n",
      "Epoch [1/10], Step [578/1063], Loss: 0.0305\n",
      "Epoch [1/10], Step [579/1063], Loss: 0.1162\n",
      "Epoch [1/10], Step [580/1063], Loss: 0.0572\n",
      "Epoch [1/10], Step [581/1063], Loss: 0.1631\n",
      "Epoch [1/10], Step [582/1063], Loss: 0.0204\n",
      "Epoch [1/10], Step [583/1063], Loss: 0.0365\n",
      "Epoch [1/10], Step [584/1063], Loss: 0.0109\n",
      "Epoch [1/10], Step [585/1063], Loss: 0.0913\n",
      "Epoch [1/10], Step [586/1063], Loss: 0.0465\n",
      "Epoch [1/10], Step [587/1063], Loss: 0.2331\n",
      "Epoch [1/10], Step [588/1063], Loss: 0.1568\n",
      "Epoch [1/10], Step [589/1063], Loss: 0.0948\n",
      "Epoch [1/10], Step [590/1063], Loss: 0.0298\n",
      "Epoch [1/10], Step [591/1063], Loss: 0.0262\n",
      "Epoch [1/10], Step [592/1063], Loss: 0.0420\n",
      "Epoch [1/10], Step [593/1063], Loss: 0.0455\n",
      "Epoch [1/10], Step [594/1063], Loss: 0.0275\n",
      "Epoch [1/10], Step [595/1063], Loss: 0.0689\n",
      "Epoch [1/10], Step [596/1063], Loss: 0.1947\n",
      "Epoch [1/10], Step [597/1063], Loss: 0.1874\n",
      "Epoch [1/10], Step [598/1063], Loss: 0.0186\n",
      "Epoch [1/10], Step [599/1063], Loss: 0.1809\n",
      "Epoch [1/10], Step [600/1063], Loss: 0.0746\n",
      "Epoch [1/10], Step [601/1063], Loss: 0.0379\n",
      "Epoch [1/10], Step [602/1063], Loss: 0.2009\n",
      "Epoch [1/10], Step [603/1063], Loss: 0.0443\n",
      "Epoch [1/10], Step [604/1063], Loss: 0.0545\n",
      "Epoch [1/10], Step [605/1063], Loss: 0.0733\n",
      "Epoch [1/10], Step [606/1063], Loss: 0.2812\n",
      "Epoch [1/10], Step [607/1063], Loss: 0.0281\n",
      "Epoch [1/10], Step [608/1063], Loss: 0.1197\n",
      "Epoch [1/10], Step [609/1063], Loss: 0.0505\n",
      "Epoch [1/10], Step [610/1063], Loss: 0.0372\n",
      "Epoch [1/10], Step [611/1063], Loss: 0.0616\n",
      "Epoch [1/10], Step [612/1063], Loss: 0.0299\n",
      "Epoch [1/10], Step [613/1063], Loss: 0.0895\n",
      "Epoch [1/10], Step [614/1063], Loss: 0.0693\n",
      "Epoch [1/10], Step [615/1063], Loss: 0.0963\n",
      "Epoch [1/10], Step [616/1063], Loss: 0.0683\n",
      "Epoch [1/10], Step [617/1063], Loss: 0.0111\n",
      "Epoch [1/10], Step [618/1063], Loss: 0.0666\n",
      "Epoch [1/10], Step [619/1063], Loss: 0.0894\n",
      "Epoch [1/10], Step [620/1063], Loss: 0.0614\n",
      "Epoch [1/10], Step [621/1063], Loss: 0.1306\n",
      "Epoch [1/10], Step [622/1063], Loss: 0.0962\n",
      "Epoch [1/10], Step [623/1063], Loss: 0.2127\n",
      "Epoch [1/10], Step [624/1063], Loss: 0.0780\n",
      "Epoch [1/10], Step [625/1063], Loss: 0.0520\n",
      "Epoch [1/10], Step [626/1063], Loss: 0.0202\n",
      "Epoch [1/10], Step [627/1063], Loss: 0.0400\n",
      "Epoch [1/10], Step [628/1063], Loss: 0.0894\n",
      "Epoch [1/10], Step [629/1063], Loss: 0.1007\n",
      "Epoch [1/10], Step [630/1063], Loss: 0.1005\n",
      "Epoch [1/10], Step [631/1063], Loss: 0.0287\n",
      "Epoch [1/10], Step [632/1063], Loss: 0.0448\n",
      "Epoch [1/10], Step [633/1063], Loss: 0.0508\n",
      "Epoch [1/10], Step [634/1063], Loss: 0.0176\n",
      "Epoch [1/10], Step [635/1063], Loss: 0.0370\n",
      "Epoch [1/10], Step [636/1063], Loss: 0.0847\n",
      "Epoch [1/10], Step [637/1063], Loss: 0.1199\n",
      "Epoch [1/10], Step [638/1063], Loss: 0.1790\n",
      "Epoch [1/10], Step [639/1063], Loss: 0.0877\n",
      "Epoch [1/10], Step [640/1063], Loss: 0.0874\n",
      "Epoch [1/10], Step [641/1063], Loss: 0.0998\n",
      "Epoch [1/10], Step [642/1063], Loss: 0.0881\n",
      "Epoch [1/10], Step [643/1063], Loss: 0.0826\n",
      "Epoch [1/10], Step [644/1063], Loss: 0.1714\n",
      "Epoch [1/10], Step [645/1063], Loss: 0.0182\n",
      "Epoch [1/10], Step [646/1063], Loss: 0.0375\n",
      "Epoch [1/10], Step [647/1063], Loss: 0.0208\n",
      "Epoch [1/10], Step [648/1063], Loss: 0.2068\n",
      "Epoch [1/10], Step [649/1063], Loss: 0.1245\n",
      "Epoch [1/10], Step [650/1063], Loss: 0.1160\n",
      "Epoch [1/10], Step [651/1063], Loss: 0.0416\n",
      "Epoch [1/10], Step [652/1063], Loss: 0.0754\n",
      "Epoch [1/10], Step [653/1063], Loss: 0.1663\n",
      "Epoch [1/10], Step [654/1063], Loss: 0.0617\n",
      "Epoch [1/10], Step [655/1063], Loss: 0.0221\n",
      "Epoch [1/10], Step [656/1063], Loss: 0.0561\n",
      "Epoch [1/10], Step [657/1063], Loss: 0.0578\n",
      "Epoch [1/10], Step [658/1063], Loss: 0.0266\n",
      "Epoch [1/10], Step [659/1063], Loss: 0.0956\n",
      "Epoch [1/10], Step [660/1063], Loss: 0.0381\n",
      "Epoch [1/10], Step [661/1063], Loss: 0.0333\n",
      "Epoch [1/10], Step [662/1063], Loss: 0.2067\n",
      "Epoch [1/10], Step [663/1063], Loss: 0.0229\n",
      "Epoch [1/10], Step [664/1063], Loss: 0.0500\n",
      "Epoch [1/10], Step [665/1063], Loss: 0.0327\n",
      "Epoch [1/10], Step [666/1063], Loss: 0.1312\n",
      "Epoch [1/10], Step [667/1063], Loss: 0.0933\n",
      "Epoch [1/10], Step [668/1063], Loss: 0.0672\n",
      "Epoch [1/10], Step [669/1063], Loss: 0.0936\n",
      "Epoch [1/10], Step [670/1063], Loss: 0.0405\n",
      "Epoch [1/10], Step [671/1063], Loss: 0.0794\n",
      "Epoch [1/10], Step [672/1063], Loss: 0.0681\n",
      "Epoch [1/10], Step [673/1063], Loss: 0.1331\n",
      "Epoch [1/10], Step [674/1063], Loss: 0.1369\n",
      "Epoch [1/10], Step [675/1063], Loss: 0.0266\n",
      "Epoch [1/10], Step [676/1063], Loss: 0.0274\n",
      "Epoch [1/10], Step [677/1063], Loss: 0.0273\n",
      "Epoch [1/10], Step [678/1063], Loss: 0.0311\n",
      "Epoch [1/10], Step [679/1063], Loss: 0.2592\n",
      "Epoch [1/10], Step [680/1063], Loss: 0.1152\n",
      "Epoch [1/10], Step [681/1063], Loss: 0.0613\n",
      "Epoch [1/10], Step [682/1063], Loss: 0.0381\n",
      "Epoch [1/10], Step [683/1063], Loss: 0.0296\n",
      "Epoch [1/10], Step [684/1063], Loss: 0.1250\n",
      "Epoch [1/10], Step [685/1063], Loss: 0.0926\n",
      "Epoch [1/10], Step [686/1063], Loss: 0.0109\n",
      "Epoch [1/10], Step [687/1063], Loss: 0.1170\n",
      "Epoch [1/10], Step [688/1063], Loss: 0.0094\n",
      "Epoch [1/10], Step [689/1063], Loss: 0.0483\n",
      "Epoch [1/10], Step [690/1063], Loss: 0.0562\n",
      "Epoch [1/10], Step [691/1063], Loss: 0.0648\n",
      "Epoch [1/10], Step [692/1063], Loss: 0.0941\n",
      "Epoch [1/10], Step [693/1063], Loss: 0.1634\n",
      "Epoch [1/10], Step [694/1063], Loss: 0.0412\n",
      "Epoch [1/10], Step [695/1063], Loss: 0.0644\n",
      "Epoch [1/10], Step [696/1063], Loss: 0.1077\n",
      "Epoch [1/10], Step [697/1063], Loss: 0.0340\n",
      "Epoch [1/10], Step [698/1063], Loss: 0.0822\n",
      "Epoch [1/10], Step [699/1063], Loss: 0.1066\n",
      "Epoch [1/10], Step [700/1063], Loss: 0.1003\n",
      "Epoch [1/10], Step [701/1063], Loss: 0.1427\n",
      "Epoch [1/10], Step [702/1063], Loss: 0.0240\n",
      "Epoch [1/10], Step [703/1063], Loss: 0.1625\n",
      "Epoch [1/10], Step [704/1063], Loss: 0.0455\n",
      "Epoch [1/10], Step [705/1063], Loss: 0.0350\n",
      "Epoch [1/10], Step [706/1063], Loss: 0.1433\n",
      "Epoch [1/10], Step [707/1063], Loss: 0.0932\n",
      "Epoch [1/10], Step [708/1063], Loss: 0.0072\n",
      "Epoch [1/10], Step [709/1063], Loss: 0.0314\n",
      "Epoch [1/10], Step [710/1063], Loss: 0.0136\n",
      "Epoch [1/10], Step [711/1063], Loss: 0.0262\n",
      "Epoch [1/10], Step [712/1063], Loss: 0.0270\n",
      "Epoch [1/10], Step [713/1063], Loss: 0.0732\n",
      "Epoch [1/10], Step [714/1063], Loss: 0.0863\n",
      "Epoch [1/10], Step [715/1063], Loss: 0.0219\n",
      "Epoch [1/10], Step [716/1063], Loss: 0.1254\n",
      "Epoch [1/10], Step [717/1063], Loss: 0.0167\n",
      "Epoch [1/10], Step [718/1063], Loss: 0.0785\n",
      "Epoch [1/10], Step [719/1063], Loss: 0.1252\n",
      "Epoch [1/10], Step [720/1063], Loss: 0.2942\n",
      "Epoch [1/10], Step [721/1063], Loss: 0.1231\n",
      "Epoch [1/10], Step [722/1063], Loss: 0.0660\n",
      "Epoch [1/10], Step [723/1063], Loss: 0.1057\n",
      "Epoch [1/10], Step [724/1063], Loss: 0.1470\n",
      "Epoch [1/10], Step [725/1063], Loss: 0.0286\n",
      "Epoch [1/10], Step [726/1063], Loss: 0.0168\n",
      "Epoch [1/10], Step [727/1063], Loss: 0.0356\n",
      "Epoch [1/10], Step [728/1063], Loss: 0.1474\n",
      "Epoch [1/10], Step [729/1063], Loss: 0.0600\n",
      "Epoch [1/10], Step [730/1063], Loss: 0.0254\n",
      "Epoch [1/10], Step [731/1063], Loss: 0.0269\n",
      "Epoch [1/10], Step [732/1063], Loss: 0.1084\n",
      "Epoch [1/10], Step [733/1063], Loss: 0.1748\n",
      "Epoch [1/10], Step [734/1063], Loss: 0.0135\n",
      "Epoch [1/10], Step [735/1063], Loss: 0.0209\n",
      "Epoch [1/10], Step [736/1063], Loss: 0.0676\n",
      "Epoch [1/10], Step [737/1063], Loss: 0.1413\n",
      "Epoch [1/10], Step [738/1063], Loss: 0.0203\n",
      "Epoch [1/10], Step [739/1063], Loss: 0.0491\n",
      "Epoch [1/10], Step [740/1063], Loss: 0.1631\n",
      "Epoch [1/10], Step [741/1063], Loss: 0.0122\n",
      "Epoch [1/10], Step [742/1063], Loss: 0.1082\n",
      "Epoch [1/10], Step [743/1063], Loss: 0.0431\n",
      "Epoch [1/10], Step [744/1063], Loss: 0.0374\n",
      "Epoch [1/10], Step [745/1063], Loss: 0.0568\n",
      "Epoch [1/10], Step [746/1063], Loss: 0.0189\n",
      "Epoch [1/10], Step [747/1063], Loss: 0.0815\n",
      "Epoch [1/10], Step [748/1063], Loss: 0.0544\n",
      "Epoch [1/10], Step [749/1063], Loss: 0.0345\n",
      "Epoch [1/10], Step [750/1063], Loss: 0.0463\n",
      "Epoch [1/10], Step [751/1063], Loss: 0.1374\n",
      "Epoch [1/10], Step [752/1063], Loss: 0.0356\n",
      "Epoch [1/10], Step [753/1063], Loss: 0.0638\n",
      "Epoch [1/10], Step [754/1063], Loss: 0.0436\n",
      "Epoch [1/10], Step [755/1063], Loss: 0.0358\n",
      "Epoch [1/10], Step [756/1063], Loss: 0.1553\n",
      "Epoch [1/10], Step [757/1063], Loss: 0.0211\n",
      "Epoch [1/10], Step [758/1063], Loss: 0.1275\n",
      "Epoch [1/10], Step [759/1063], Loss: 0.0435\n",
      "Epoch [1/10], Step [760/1063], Loss: 0.0057\n",
      "Epoch [1/10], Step [761/1063], Loss: 0.1014\n",
      "Epoch [1/10], Step [762/1063], Loss: 0.0740\n",
      "Epoch [1/10], Step [763/1063], Loss: 0.0852\n",
      "Epoch [1/10], Step [764/1063], Loss: 0.0921\n",
      "Epoch [1/10], Step [765/1063], Loss: 0.0676\n",
      "Epoch [1/10], Step [766/1063], Loss: 0.0642\n",
      "Epoch [1/10], Step [767/1063], Loss: 0.0210\n",
      "Epoch [1/10], Step [768/1063], Loss: 0.0368\n",
      "Epoch [1/10], Step [769/1063], Loss: 0.0710\n",
      "Epoch [1/10], Step [770/1063], Loss: 0.0287\n",
      "Epoch [1/10], Step [771/1063], Loss: 0.0179\n",
      "Epoch [1/10], Step [772/1063], Loss: 0.0052\n",
      "Epoch [1/10], Step [773/1063], Loss: 0.0785\n",
      "Epoch [1/10], Step [774/1063], Loss: 0.1397\n",
      "Epoch [1/10], Step [775/1063], Loss: 0.0244\n",
      "Epoch [1/10], Step [776/1063], Loss: 0.0375\n",
      "Epoch [1/10], Step [777/1063], Loss: 0.1254\n",
      "Epoch [1/10], Step [778/1063], Loss: 0.0414\n",
      "Epoch [1/10], Step [779/1063], Loss: 0.1343\n",
      "Epoch [1/10], Step [780/1063], Loss: 0.1505\n",
      "Epoch [1/10], Step [781/1063], Loss: 0.2032\n",
      "Epoch [1/10], Step [782/1063], Loss: 0.0378\n",
      "Epoch [1/10], Step [783/1063], Loss: 0.0536\n",
      "Epoch [1/10], Step [784/1063], Loss: 0.0211\n",
      "Epoch [1/10], Step [785/1063], Loss: 0.0558\n",
      "Epoch [1/10], Step [786/1063], Loss: 0.0251\n",
      "Epoch [1/10], Step [787/1063], Loss: 0.0343\n",
      "Epoch [1/10], Step [788/1063], Loss: 0.0627\n",
      "Epoch [1/10], Step [789/1063], Loss: 0.0567\n",
      "Epoch [1/10], Step [790/1063], Loss: 0.0330\n",
      "Epoch [1/10], Step [791/1063], Loss: 0.0378\n",
      "Epoch [1/10], Step [792/1063], Loss: 0.0744\n",
      "Epoch [1/10], Step [793/1063], Loss: 0.1434\n",
      "Epoch [1/10], Step [794/1063], Loss: 0.0309\n",
      "Epoch [1/10], Step [795/1063], Loss: 0.0040\n",
      "Epoch [1/10], Step [796/1063], Loss: 0.0546\n",
      "Epoch [1/10], Step [797/1063], Loss: 0.0152\n",
      "Epoch [1/10], Step [798/1063], Loss: 0.0113\n",
      "Epoch [1/10], Step [799/1063], Loss: 0.0618\n",
      "Epoch [1/10], Step [800/1063], Loss: 0.0902\n",
      "Epoch [1/10], Step [801/1063], Loss: 0.0747\n",
      "Epoch [1/10], Step [802/1063], Loss: 0.0673\n",
      "Epoch [1/10], Step [803/1063], Loss: 0.0291\n",
      "Epoch [1/10], Step [804/1063], Loss: 0.0976\n",
      "Epoch [1/10], Step [805/1063], Loss: 0.0049\n",
      "Epoch [1/10], Step [806/1063], Loss: 0.0723\n",
      "Epoch [1/10], Step [807/1063], Loss: 0.0904\n",
      "Epoch [1/10], Step [808/1063], Loss: 0.0676\n",
      "Epoch [1/10], Step [809/1063], Loss: 0.0747\n",
      "Epoch [1/10], Step [810/1063], Loss: 0.0612\n",
      "Epoch [1/10], Step [811/1063], Loss: 0.0283\n",
      "Epoch [1/10], Step [812/1063], Loss: 0.0465\n",
      "Epoch [1/10], Step [813/1063], Loss: 0.0289\n",
      "Epoch [1/10], Step [814/1063], Loss: 0.0396\n",
      "Epoch [1/10], Step [815/1063], Loss: 0.0136\n",
      "Epoch [1/10], Step [816/1063], Loss: 0.0090\n",
      "Epoch [1/10], Step [817/1063], Loss: 0.0438\n",
      "Epoch [1/10], Step [818/1063], Loss: 0.1066\n",
      "Epoch [1/10], Step [819/1063], Loss: 0.1159\n",
      "Epoch [1/10], Step [820/1063], Loss: 0.0334\n",
      "Epoch [1/10], Step [821/1063], Loss: 0.0987\n",
      "Epoch [1/10], Step [822/1063], Loss: 0.0639\n",
      "Epoch [1/10], Step [823/1063], Loss: 0.0312\n",
      "Epoch [1/10], Step [824/1063], Loss: 0.0999\n",
      "Epoch [1/10], Step [825/1063], Loss: 0.0332\n",
      "Epoch [1/10], Step [826/1063], Loss: 0.0418\n",
      "Epoch [1/10], Step [827/1063], Loss: 0.0961\n",
      "Epoch [1/10], Step [828/1063], Loss: 0.1492\n",
      "Epoch [1/10], Step [829/1063], Loss: 0.0512\n",
      "Epoch [1/10], Step [830/1063], Loss: 0.0898\n",
      "Epoch [1/10], Step [831/1063], Loss: 0.1183\n",
      "Epoch [1/10], Step [832/1063], Loss: 0.0244\n",
      "Epoch [1/10], Step [833/1063], Loss: 0.0850\n",
      "Epoch [1/10], Step [834/1063], Loss: 0.0607\n",
      "Epoch [1/10], Step [835/1063], Loss: 0.0250\n",
      "Epoch [1/10], Step [836/1063], Loss: 0.0036\n",
      "Epoch [1/10], Step [837/1063], Loss: 0.0077\n",
      "Epoch [1/10], Step [838/1063], Loss: 0.0251\n",
      "Epoch [1/10], Step [839/1063], Loss: 0.1040\n",
      "Epoch [1/10], Step [840/1063], Loss: 0.0550\n",
      "Epoch [1/10], Step [841/1063], Loss: 0.0595\n",
      "Epoch [1/10], Step [842/1063], Loss: 0.0337\n",
      "Epoch [1/10], Step [843/1063], Loss: 0.0269\n",
      "Epoch [1/10], Step [844/1063], Loss: 0.0558\n",
      "Epoch [1/10], Step [845/1063], Loss: 0.0837\n",
      "Epoch [1/10], Step [846/1063], Loss: 0.1955\n",
      "Epoch [1/10], Step [847/1063], Loss: 0.0554\n",
      "Epoch [1/10], Step [848/1063], Loss: 0.1214\n",
      "Epoch [1/10], Step [849/1063], Loss: 0.0378\n",
      "Epoch [1/10], Step [850/1063], Loss: 0.0184\n",
      "Epoch [1/10], Step [851/1063], Loss: 0.0938\n",
      "Epoch [1/10], Step [852/1063], Loss: 0.1494\n",
      "Epoch [1/10], Step [853/1063], Loss: 0.1827\n",
      "Epoch [1/10], Step [854/1063], Loss: 0.0300\n",
      "Epoch [1/10], Step [855/1063], Loss: 0.0346\n",
      "Epoch [1/10], Step [856/1063], Loss: 0.1211\n",
      "Epoch [1/10], Step [857/1063], Loss: 0.0325\n",
      "Epoch [1/10], Step [858/1063], Loss: 0.0434\n",
      "Epoch [1/10], Step [859/1063], Loss: 0.0121\n",
      "Epoch [1/10], Step [860/1063], Loss: 0.0261\n",
      "Epoch [1/10], Step [861/1063], Loss: 0.0436\n",
      "Epoch [1/10], Step [862/1063], Loss: 0.0587\n",
      "Epoch [1/10], Step [863/1063], Loss: 0.1215\n",
      "Epoch [1/10], Step [864/1063], Loss: 0.0811\n",
      "Epoch [1/10], Step [865/1063], Loss: 0.0760\n",
      "Epoch [1/10], Step [866/1063], Loss: 0.1623\n",
      "Epoch [1/10], Step [867/1063], Loss: 0.2775\n",
      "Epoch [1/10], Step [868/1063], Loss: 0.0493\n",
      "Epoch [1/10], Step [869/1063], Loss: 0.0938\n",
      "Epoch [1/10], Step [870/1063], Loss: 0.0448\n",
      "Epoch [1/10], Step [871/1063], Loss: 0.0254\n",
      "Epoch [1/10], Step [872/1063], Loss: 0.0846\n",
      "Epoch [1/10], Step [873/1063], Loss: 0.0498\n",
      "Epoch [1/10], Step [874/1063], Loss: 0.0176\n",
      "Epoch [1/10], Step [875/1063], Loss: 0.0381\n",
      "Epoch [1/10], Step [876/1063], Loss: 0.2137\n",
      "Epoch [1/10], Step [877/1063], Loss: 0.0531\n",
      "Epoch [1/10], Step [878/1063], Loss: 0.0355\n",
      "Epoch [1/10], Step [879/1063], Loss: 0.0082\n",
      "Epoch [1/10], Step [880/1063], Loss: 0.2656\n",
      "Epoch [1/10], Step [881/1063], Loss: 0.1229\n",
      "Epoch [1/10], Step [882/1063], Loss: 0.0092\n",
      "Epoch [1/10], Step [883/1063], Loss: 0.1064\n",
      "Epoch [1/10], Step [884/1063], Loss: 0.0288\n",
      "Epoch [1/10], Step [885/1063], Loss: 0.0451\n",
      "Epoch [1/10], Step [886/1063], Loss: 0.1374\n",
      "Epoch [1/10], Step [887/1063], Loss: 0.0899\n",
      "Epoch [1/10], Step [888/1063], Loss: 0.0130\n",
      "Epoch [1/10], Step [889/1063], Loss: 0.0502\n",
      "Epoch [1/10], Step [890/1063], Loss: 0.1633\n",
      "Epoch [1/10], Step [891/1063], Loss: 0.0226\n",
      "Epoch [1/10], Step [892/1063], Loss: 0.0410\n",
      "Epoch [1/10], Step [893/1063], Loss: 0.1201\n",
      "Epoch [1/10], Step [894/1063], Loss: 0.0550\n",
      "Epoch [1/10], Step [895/1063], Loss: 0.0580\n",
      "Epoch [1/10], Step [896/1063], Loss: 0.0196\n",
      "Epoch [1/10], Step [897/1063], Loss: 0.0443\n",
      "Epoch [1/10], Step [898/1063], Loss: 0.0997\n",
      "Epoch [1/10], Step [899/1063], Loss: 0.1903\n",
      "Epoch [1/10], Step [900/1063], Loss: 0.0187\n",
      "Epoch [1/10], Step [901/1063], Loss: 0.0315\n",
      "Epoch [1/10], Step [902/1063], Loss: 0.0289\n",
      "Epoch [1/10], Step [903/1063], Loss: 0.0265\n",
      "Epoch [1/10], Step [904/1063], Loss: 0.0480\n",
      "Epoch [1/10], Step [905/1063], Loss: 0.0220\n",
      "Epoch [1/10], Step [906/1063], Loss: 0.0622\n",
      "Epoch [1/10], Step [907/1063], Loss: 0.1298\n",
      "Epoch [1/10], Step [908/1063], Loss: 0.0598\n",
      "Epoch [1/10], Step [909/1063], Loss: 0.0392\n",
      "Epoch [1/10], Step [910/1063], Loss: 0.0925\n",
      "Epoch [1/10], Step [911/1063], Loss: 0.2004\n",
      "Epoch [1/10], Step [912/1063], Loss: 0.0731\n",
      "Epoch [1/10], Step [913/1063], Loss: 0.0728\n",
      "Epoch [1/10], Step [914/1063], Loss: 0.1400\n",
      "Epoch [1/10], Step [915/1063], Loss: 0.0484\n",
      "Epoch [1/10], Step [916/1063], Loss: 0.0239\n",
      "Epoch [1/10], Step [917/1063], Loss: 0.0130\n",
      "Epoch [1/10], Step [918/1063], Loss: 0.0738\n",
      "Epoch [1/10], Step [919/1063], Loss: 0.0816\n",
      "Epoch [1/10], Step [920/1063], Loss: 0.2820\n",
      "Epoch [1/10], Step [921/1063], Loss: 0.0666\n",
      "Epoch [1/10], Step [922/1063], Loss: 0.0180\n",
      "Epoch [1/10], Step [923/1063], Loss: 0.1202\n",
      "Epoch [1/10], Step [924/1063], Loss: 0.0292\n",
      "Epoch [1/10], Step [925/1063], Loss: 0.0215\n",
      "Epoch [1/10], Step [926/1063], Loss: 0.1820\n",
      "Epoch [1/10], Step [927/1063], Loss: 0.0771\n",
      "Epoch [1/10], Step [928/1063], Loss: 0.0410\n",
      "Epoch [1/10], Step [929/1063], Loss: 0.0375\n",
      "Epoch [1/10], Step [930/1063], Loss: 0.0237\n",
      "Epoch [1/10], Step [931/1063], Loss: 0.0320\n",
      "Epoch [1/10], Step [932/1063], Loss: 0.2343\n",
      "Epoch [1/10], Step [933/1063], Loss: 0.0206\n",
      "Epoch [1/10], Step [934/1063], Loss: 0.0256\n",
      "Epoch [1/10], Step [935/1063], Loss: 0.0237\n",
      "Epoch [1/10], Step [936/1063], Loss: 0.1727\n",
      "Epoch [1/10], Step [937/1063], Loss: 0.0533\n",
      "Epoch [1/10], Step [938/1063], Loss: 0.0397\n",
      "Epoch [1/10], Step [939/1063], Loss: 0.0836\n",
      "Epoch [1/10], Step [940/1063], Loss: 0.0464\n",
      "Epoch [1/10], Step [941/1063], Loss: 0.0673\n",
      "Epoch [1/10], Step [942/1063], Loss: 0.1215\n",
      "Epoch [1/10], Step [943/1063], Loss: 0.1456\n",
      "Epoch [1/10], Step [944/1063], Loss: 0.0779\n",
      "Epoch [1/10], Step [945/1063], Loss: 0.0514\n",
      "Epoch [1/10], Step [946/1063], Loss: 0.0247\n",
      "Epoch [1/10], Step [947/1063], Loss: 0.1410\n",
      "Epoch [1/10], Step [948/1063], Loss: 0.0610\n",
      "Epoch [1/10], Step [949/1063], Loss: 0.0158\n",
      "Epoch [1/10], Step [950/1063], Loss: 0.0545\n",
      "Epoch [1/10], Step [951/1063], Loss: 0.0228\n",
      "Epoch [1/10], Step [952/1063], Loss: 0.0693\n",
      "Epoch [1/10], Step [953/1063], Loss: 0.0219\n",
      "Epoch [1/10], Step [954/1063], Loss: 0.0276\n",
      "Epoch [1/10], Step [955/1063], Loss: 0.0855\n",
      "Epoch [1/10], Step [956/1063], Loss: 0.1024\n",
      "Epoch [1/10], Step [957/1063], Loss: 0.0435\n",
      "Epoch [1/10], Step [958/1063], Loss: 0.0131\n",
      "Epoch [1/10], Step [959/1063], Loss: 0.0298\n",
      "Epoch [1/10], Step [960/1063], Loss: 0.0341\n",
      "Epoch [1/10], Step [961/1063], Loss: 0.0593\n",
      "Epoch [1/10], Step [962/1063], Loss: 0.0905\n",
      "Epoch [1/10], Step [963/1063], Loss: 0.1085\n",
      "Epoch [1/10], Step [964/1063], Loss: 0.0306\n",
      "Epoch [1/10], Step [965/1063], Loss: 0.0176\n",
      "Epoch [1/10], Step [966/1063], Loss: 0.1790\n",
      "Epoch [1/10], Step [967/1063], Loss: 0.0116\n",
      "Epoch [1/10], Step [968/1063], Loss: 0.0240\n",
      "Epoch [1/10], Step [969/1063], Loss: 0.0296\n",
      "Epoch [1/10], Step [970/1063], Loss: 0.0114\n",
      "Epoch [1/10], Step [971/1063], Loss: 0.0254\n",
      "Epoch [1/10], Step [972/1063], Loss: 0.0716\n",
      "Epoch [1/10], Step [973/1063], Loss: 0.0068\n",
      "Epoch [1/10], Step [974/1063], Loss: 0.1443\n",
      "Epoch [1/10], Step [975/1063], Loss: 0.0122\n",
      "Epoch [1/10], Step [976/1063], Loss: 0.0568\n",
      "Epoch [1/10], Step [977/1063], Loss: 0.1663\n",
      "Epoch [1/10], Step [978/1063], Loss: 0.0255\n",
      "Epoch [1/10], Step [979/1063], Loss: 0.0252\n",
      "Epoch [1/10], Step [980/1063], Loss: 0.0341\n",
      "Epoch [1/10], Step [981/1063], Loss: 0.0464\n",
      "Epoch [1/10], Step [982/1063], Loss: 0.2223\n",
      "Epoch [1/10], Step [983/1063], Loss: 0.0231\n",
      "Epoch [1/10], Step [984/1063], Loss: 0.0242\n",
      "Epoch [1/10], Step [985/1063], Loss: 0.0355\n",
      "Epoch [1/10], Step [986/1063], Loss: 0.0130\n",
      "Epoch [1/10], Step [987/1063], Loss: 0.0660\n",
      "Epoch [1/10], Step [988/1063], Loss: 0.0883\n",
      "Epoch [1/10], Step [989/1063], Loss: 0.0549\n",
      "Epoch [1/10], Step [990/1063], Loss: 0.1237\n",
      "Epoch [1/10], Step [991/1063], Loss: 0.0705\n",
      "Epoch [1/10], Step [992/1063], Loss: 0.1320\n",
      "Epoch [1/10], Step [993/1063], Loss: 0.0666\n",
      "Epoch [1/10], Step [994/1063], Loss: 0.0488\n",
      "Epoch [1/10], Step [995/1063], Loss: 0.0565\n",
      "Epoch [1/10], Step [996/1063], Loss: 0.0136\n",
      "Epoch [1/10], Step [997/1063], Loss: 0.0541\n",
      "Epoch [1/10], Step [998/1063], Loss: 0.0337\n",
      "Epoch [1/10], Step [999/1063], Loss: 0.1285\n",
      "Epoch [1/10], Step [1000/1063], Loss: 0.0872\n",
      "Epoch [1/10], Step [1001/1063], Loss: 0.0827\n",
      "Epoch [1/10], Step [1002/1063], Loss: 0.0111\n",
      "Epoch [1/10], Step [1003/1063], Loss: 0.0418\n",
      "Epoch [1/10], Step [1004/1063], Loss: 0.0313\n",
      "Epoch [1/10], Step [1005/1063], Loss: 0.0150\n",
      "Epoch [1/10], Step [1006/1063], Loss: 0.0672\n",
      "Epoch [1/10], Step [1007/1063], Loss: 0.1241\n",
      "Epoch [1/10], Step [1008/1063], Loss: 0.1018\n",
      "Epoch [1/10], Step [1009/1063], Loss: 0.0268\n",
      "Epoch [1/10], Step [1010/1063], Loss: 0.0107\n",
      "Epoch [1/10], Step [1011/1063], Loss: 0.0365\n",
      "Epoch [1/10], Step [1012/1063], Loss: 0.0148\n",
      "Epoch [1/10], Step [1013/1063], Loss: 0.0120\n",
      "Epoch [1/10], Step [1014/1063], Loss: 0.0134\n",
      "Epoch [1/10], Step [1015/1063], Loss: 0.0113\n",
      "Epoch [1/10], Step [1016/1063], Loss: 0.0398\n",
      "Epoch [1/10], Step [1017/1063], Loss: 0.0962\n",
      "Epoch [1/10], Step [1018/1063], Loss: 0.1779\n",
      "Epoch [1/10], Step [1019/1063], Loss: 0.0513\n",
      "Epoch [1/10], Step [1020/1063], Loss: 0.0211\n",
      "Epoch [1/10], Step [1021/1063], Loss: 0.0760\n",
      "Epoch [1/10], Step [1022/1063], Loss: 0.0110\n",
      "Epoch [1/10], Step [1023/1063], Loss: 0.0425\n",
      "Epoch [1/10], Step [1024/1063], Loss: 0.0305\n",
      "Epoch [1/10], Step [1025/1063], Loss: 0.0212\n",
      "Epoch [1/10], Step [1026/1063], Loss: 0.1595\n",
      "Epoch [1/10], Step [1027/1063], Loss: 0.0226\n",
      "Epoch [1/10], Step [1028/1063], Loss: 0.0215\n",
      "Epoch [1/10], Step [1029/1063], Loss: 0.0891\n",
      "Epoch [1/10], Step [1030/1063], Loss: 0.1624\n",
      "Epoch [1/10], Step [1031/1063], Loss: 0.0459\n",
      "Epoch [1/10], Step [1032/1063], Loss: 0.0623\n",
      "Epoch [1/10], Step [1033/1063], Loss: 0.1092\n",
      "Epoch [1/10], Step [1034/1063], Loss: 0.0826\n",
      "Epoch [1/10], Step [1035/1063], Loss: 0.0543\n",
      "Epoch [1/10], Step [1036/1063], Loss: 0.0165\n",
      "Epoch [1/10], Step [1037/1063], Loss: 0.2029\n",
      "Epoch [1/10], Step [1038/1063], Loss: 0.2101\n",
      "Epoch [1/10], Step [1039/1063], Loss: 0.0316\n",
      "Epoch [1/10], Step [1040/1063], Loss: 0.0171\n",
      "Epoch [1/10], Step [1041/1063], Loss: 0.0244\n",
      "Epoch [1/10], Step [1042/1063], Loss: 0.0655\n",
      "Epoch [1/10], Step [1043/1063], Loss: 0.0490\n",
      "Epoch [1/10], Step [1044/1063], Loss: 0.0215\n",
      "Epoch [1/10], Step [1045/1063], Loss: 0.0071\n",
      "Epoch [1/10], Step [1046/1063], Loss: 0.0248\n",
      "Epoch [1/10], Step [1047/1063], Loss: 0.1785\n",
      "Epoch [1/10], Step [1048/1063], Loss: 0.0485\n",
      "Epoch [1/10], Step [1049/1063], Loss: 0.0445\n",
      "Epoch [1/10], Step [1050/1063], Loss: 0.1182\n",
      "Epoch [1/10], Step [1051/1063], Loss: 0.0159\n",
      "Epoch [1/10], Step [1052/1063], Loss: 0.1400\n",
      "Epoch [1/10], Step [1053/1063], Loss: 0.1148\n",
      "Epoch [1/10], Step [1054/1063], Loss: 0.0456\n",
      "Epoch [1/10], Step [1055/1063], Loss: 0.0401\n",
      "Epoch [1/10], Step [1056/1063], Loss: 0.0503\n",
      "Epoch [1/10], Step [1057/1063], Loss: 0.0166\n",
      "Epoch [1/10], Step [1058/1063], Loss: 0.0613\n",
      "Epoch [1/10], Step [1059/1063], Loss: 0.0324\n",
      "Epoch [1/10], Step [1060/1063], Loss: 0.1295\n",
      "Epoch [1/10], Step [1061/1063], Loss: 0.0157\n",
      "Epoch [1/10], Step [1062/1063], Loss: 0.0117\n",
      "Epoch [1/10], Step [1063/1063], Loss: 0.0224\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [1/1063], Loss: 0.0269\n",
      "Epoch [2/10], Step [2/1063], Loss: 0.0582\n",
      "Epoch [2/10], Step [3/1063], Loss: 0.0239\n",
      "Epoch [2/10], Step [4/1063], Loss: 0.0796\n",
      "Epoch [2/10], Step [5/1063], Loss: 0.0567\n",
      "Epoch [2/10], Step [6/1063], Loss: 0.0196\n",
      "Epoch [2/10], Step [7/1063], Loss: 0.0298\n",
      "Epoch [2/10], Step [8/1063], Loss: 0.1567\n",
      "Epoch [2/10], Step [9/1063], Loss: 0.1141\n",
      "Epoch [2/10], Step [10/1063], Loss: 0.0678\n",
      "Epoch [2/10], Step [11/1063], Loss: 0.0076\n",
      "Epoch [2/10], Step [12/1063], Loss: 0.0514\n",
      "Epoch [2/10], Step [13/1063], Loss: 0.0240\n",
      "Epoch [2/10], Step [14/1063], Loss: 0.0985\n",
      "Epoch [2/10], Step [15/1063], Loss: 0.1274\n",
      "Epoch [2/10], Step [16/1063], Loss: 0.1708\n",
      "Epoch [2/10], Step [17/1063], Loss: 0.0273\n",
      "Epoch [2/10], Step [18/1063], Loss: 0.0620\n",
      "Epoch [2/10], Step [19/1063], Loss: 0.0132\n",
      "Epoch [2/10], Step [20/1063], Loss: 0.0050\n",
      "Epoch [2/10], Step [21/1063], Loss: 0.0599\n",
      "Epoch [2/10], Step [22/1063], Loss: 0.0151\n",
      "Epoch [2/10], Step [23/1063], Loss: 0.0345\n",
      "Epoch [2/10], Step [24/1063], Loss: 0.0305\n",
      "Epoch [2/10], Step [25/1063], Loss: 0.0414\n",
      "Epoch [2/10], Step [26/1063], Loss: 0.1551\n",
      "Epoch [2/10], Step [27/1063], Loss: 0.0955\n",
      "Epoch [2/10], Step [28/1063], Loss: 0.0260\n",
      "Epoch [2/10], Step [29/1063], Loss: 0.0938\n",
      "Epoch [2/10], Step [30/1063], Loss: 0.0374\n",
      "Epoch [2/10], Step [31/1063], Loss: 0.0086\n",
      "Epoch [2/10], Step [32/1063], Loss: 0.0303\n",
      "Epoch [2/10], Step [33/1063], Loss: 0.0069\n",
      "Epoch [2/10], Step [34/1063], Loss: 0.0236\n",
      "Epoch [2/10], Step [35/1063], Loss: 0.0261\n",
      "Epoch [2/10], Step [36/1063], Loss: 0.0480\n",
      "Epoch [2/10], Step [37/1063], Loss: 0.1478\n",
      "Epoch [2/10], Step [38/1063], Loss: 0.0344\n",
      "Epoch [2/10], Step [39/1063], Loss: 0.1164\n",
      "Epoch [2/10], Step [40/1063], Loss: 0.0379\n",
      "Epoch [2/10], Step [41/1063], Loss: 0.0148\n",
      "Epoch [2/10], Step [42/1063], Loss: 0.0633\n",
      "Epoch [2/10], Step [43/1063], Loss: 0.0352\n",
      "Epoch [2/10], Step [44/1063], Loss: 0.0290\n",
      "Epoch [2/10], Step [45/1063], Loss: 0.0400\n",
      "Epoch [2/10], Step [46/1063], Loss: 0.0107\n",
      "Epoch [2/10], Step [47/1063], Loss: 0.0518\n",
      "Epoch [2/10], Step [48/1063], Loss: 0.0100\n",
      "Epoch [2/10], Step [49/1063], Loss: 0.2291\n",
      "Epoch [2/10], Step [50/1063], Loss: 0.0299\n",
      "Epoch [2/10], Step [51/1063], Loss: 0.0447\n",
      "Epoch [2/10], Step [52/1063], Loss: 0.0169\n",
      "Epoch [2/10], Step [53/1063], Loss: 0.0078\n",
      "Epoch [2/10], Step [54/1063], Loss: 0.0193\n",
      "Epoch [2/10], Step [55/1063], Loss: 0.0169\n",
      "Epoch [2/10], Step [56/1063], Loss: 0.0262\n",
      "Epoch [2/10], Step [57/1063], Loss: 0.0075\n",
      "Epoch [2/10], Step [58/1063], Loss: 0.0729\n",
      "Epoch [2/10], Step [59/1063], Loss: 0.0232\n",
      "Epoch [2/10], Step [60/1063], Loss: 0.0881\n",
      "Epoch [2/10], Step [61/1063], Loss: 0.0169\n",
      "Epoch [2/10], Step [62/1063], Loss: 0.0137\n",
      "Epoch [2/10], Step [63/1063], Loss: 0.0132\n",
      "Epoch [2/10], Step [64/1063], Loss: 0.1065\n",
      "Epoch [2/10], Step [65/1063], Loss: 0.0311\n",
      "Epoch [2/10], Step [66/1063], Loss: 0.0135\n",
      "Epoch [2/10], Step [67/1063], Loss: 0.0162\n",
      "Epoch [2/10], Step [68/1063], Loss: 0.0049\n",
      "Epoch [2/10], Step [69/1063], Loss: 0.0649\n",
      "Epoch [2/10], Step [70/1063], Loss: 0.1002\n",
      "Epoch [2/10], Step [71/1063], Loss: 0.0975\n",
      "Epoch [2/10], Step [72/1063], Loss: 0.1085\n",
      "Epoch [2/10], Step [73/1063], Loss: 0.1485\n",
      "Epoch [2/10], Step [74/1063], Loss: 0.0731\n",
      "Epoch [2/10], Step [75/1063], Loss: 0.0272\n",
      "Epoch [2/10], Step [76/1063], Loss: 0.0284\n",
      "Epoch [2/10], Step [77/1063], Loss: 0.0807\n",
      "Epoch [2/10], Step [78/1063], Loss: 0.0507\n",
      "Epoch [2/10], Step [79/1063], Loss: 0.0335\n",
      "Epoch [2/10], Step [80/1063], Loss: 0.0210\n",
      "Epoch [2/10], Step [81/1063], Loss: 0.0739\n",
      "Epoch [2/10], Step [82/1063], Loss: 0.0308\n",
      "Epoch [2/10], Step [83/1063], Loss: 0.0675\n",
      "Epoch [2/10], Step [84/1063], Loss: 0.0386\n",
      "Epoch [2/10], Step [85/1063], Loss: 0.0688\n",
      "Epoch [2/10], Step [86/1063], Loss: 0.0323\n",
      "Epoch [2/10], Step [87/1063], Loss: 0.0152\n",
      "Epoch [2/10], Step [88/1063], Loss: 0.0942\n",
      "Epoch [2/10], Step [89/1063], Loss: 0.0404\n",
      "Epoch [2/10], Step [90/1063], Loss: 0.0670\n",
      "Epoch [2/10], Step [91/1063], Loss: 0.0836\n",
      "Epoch [2/10], Step [92/1063], Loss: 0.0456\n",
      "Epoch [2/10], Step [93/1063], Loss: 0.1749\n",
      "Epoch [2/10], Step [94/1063], Loss: 0.0236\n",
      "Epoch [2/10], Step [95/1063], Loss: 0.0111\n",
      "Epoch [2/10], Step [96/1063], Loss: 0.1383\n",
      "Epoch [2/10], Step [97/1063], Loss: 0.0510\n",
      "Epoch [2/10], Step [98/1063], Loss: 0.1075\n",
      "Epoch [2/10], Step [99/1063], Loss: 0.0678\n",
      "Epoch [2/10], Step [100/1063], Loss: 0.1249\n",
      "Epoch [2/10], Step [101/1063], Loss: 0.0313\n",
      "Epoch [2/10], Step [102/1063], Loss: 0.0183\n",
      "Epoch [2/10], Step [103/1063], Loss: 0.0973\n",
      "Epoch [2/10], Step [104/1063], Loss: 0.0114\n",
      "Epoch [2/10], Step [105/1063], Loss: 0.0385\n",
      "Epoch [2/10], Step [106/1063], Loss: 0.0436\n",
      "Epoch [2/10], Step [107/1063], Loss: 0.0575\n",
      "Epoch [2/10], Step [108/1063], Loss: 0.0441\n",
      "Epoch [2/10], Step [109/1063], Loss: 0.0244\n",
      "Epoch [2/10], Step [110/1063], Loss: 0.0303\n",
      "Epoch [2/10], Step [111/1063], Loss: 0.0423\n",
      "Epoch [2/10], Step [112/1063], Loss: 0.0323\n",
      "Epoch [2/10], Step [113/1063], Loss: 0.0318\n",
      "Epoch [2/10], Step [114/1063], Loss: 0.0523\n",
      "Epoch [2/10], Step [115/1063], Loss: 0.0051\n",
      "Epoch [2/10], Step [116/1063], Loss: 0.0844\n",
      "Epoch [2/10], Step [117/1063], Loss: 0.0810\n",
      "Epoch [2/10], Step [118/1063], Loss: 0.0277\n",
      "Epoch [2/10], Step [119/1063], Loss: 0.0852\n",
      "Epoch [2/10], Step [120/1063], Loss: 0.0879\n",
      "Epoch [2/10], Step [121/1063], Loss: 0.0412\n",
      "Epoch [2/10], Step [122/1063], Loss: 0.0574\n",
      "Epoch [2/10], Step [123/1063], Loss: 0.0182\n",
      "Epoch [2/10], Step [124/1063], Loss: 0.1359\n",
      "Epoch [2/10], Step [125/1063], Loss: 0.0100\n",
      "Epoch [2/10], Step [126/1063], Loss: 0.1725\n",
      "Epoch [2/10], Step [127/1063], Loss: 0.0505\n",
      "Epoch [2/10], Step [128/1063], Loss: 0.0097\n",
      "Epoch [2/10], Step [129/1063], Loss: 0.0846\n",
      "Epoch [2/10], Step [130/1063], Loss: 0.0185\n",
      "Epoch [2/10], Step [131/1063], Loss: 0.0286\n",
      "Epoch [2/10], Step [132/1063], Loss: 0.0340\n",
      "Epoch [2/10], Step [133/1063], Loss: 0.0302\n",
      "Epoch [2/10], Step [134/1063], Loss: 0.0069\n",
      "Epoch [2/10], Step [135/1063], Loss: 0.0137\n",
      "Epoch [2/10], Step [136/1063], Loss: 0.0152\n",
      "Epoch [2/10], Step [137/1063], Loss: 0.2589\n",
      "Epoch [2/10], Step [138/1063], Loss: 0.0134\n",
      "Epoch [2/10], Step [139/1063], Loss: 0.0565\n",
      "Epoch [2/10], Step [140/1063], Loss: 0.0095\n",
      "Epoch [2/10], Step [141/1063], Loss: 0.0083\n",
      "Epoch [2/10], Step [142/1063], Loss: 0.0778\n",
      "Epoch [2/10], Step [143/1063], Loss: 0.0108\n",
      "Epoch [2/10], Step [144/1063], Loss: 0.0037\n",
      "Epoch [2/10], Step [145/1063], Loss: 0.0348\n",
      "Epoch [2/10], Step [146/1063], Loss: 0.0016\n",
      "Epoch [2/10], Step [147/1063], Loss: 0.0014\n",
      "Epoch [2/10], Step [148/1063], Loss: 0.1153\n",
      "Epoch [2/10], Step [149/1063], Loss: 0.0965\n",
      "Epoch [2/10], Step [150/1063], Loss: 0.0028\n",
      "Epoch [2/10], Step [151/1063], Loss: 0.1644\n",
      "Epoch [2/10], Step [152/1063], Loss: 0.0761\n",
      "Epoch [2/10], Step [153/1063], Loss: 0.0071\n",
      "Epoch [2/10], Step [154/1063], Loss: 0.0320\n",
      "Epoch [2/10], Step [155/1063], Loss: 0.1495\n",
      "Epoch [2/10], Step [156/1063], Loss: 0.0035\n",
      "Epoch [2/10], Step [157/1063], Loss: 0.0085\n",
      "Epoch [2/10], Step [158/1063], Loss: 0.1369\n",
      "Epoch [2/10], Step [159/1063], Loss: 0.0178\n",
      "Epoch [2/10], Step [160/1063], Loss: 0.0124\n",
      "Epoch [2/10], Step [161/1063], Loss: 0.0256\n",
      "Epoch [2/10], Step [162/1063], Loss: 0.0228\n",
      "Epoch [2/10], Step [163/1063], Loss: 0.0051\n",
      "Epoch [2/10], Step [164/1063], Loss: 0.0048\n",
      "Epoch [2/10], Step [165/1063], Loss: 0.0136\n",
      "Epoch [2/10], Step [166/1063], Loss: 0.0046\n",
      "Epoch [2/10], Step [167/1063], Loss: 0.0760\n",
      "Epoch [2/10], Step [168/1063], Loss: 0.0075\n",
      "Epoch [2/10], Step [169/1063], Loss: 0.0244\n",
      "Epoch [2/10], Step [170/1063], Loss: 0.0100\n",
      "Epoch [2/10], Step [171/1063], Loss: 0.0623\n",
      "Epoch [2/10], Step [172/1063], Loss: 0.0080\n",
      "Epoch [2/10], Step [173/1063], Loss: 0.0260\n",
      "Epoch [2/10], Step [174/1063], Loss: 0.0225\n",
      "Epoch [2/10], Step [175/1063], Loss: 0.0497\n",
      "Epoch [2/10], Step [176/1063], Loss: 0.0076\n",
      "Epoch [2/10], Step [177/1063], Loss: 0.0285\n",
      "Epoch [2/10], Step [178/1063], Loss: 0.0129\n",
      "Epoch [2/10], Step [179/1063], Loss: 0.0358\n",
      "Epoch [2/10], Step [180/1063], Loss: 0.1926\n",
      "Epoch [2/10], Step [181/1063], Loss: 0.0261\n",
      "Epoch [2/10], Step [182/1063], Loss: 0.0053\n",
      "Epoch [2/10], Step [183/1063], Loss: 0.0215\n",
      "Epoch [2/10], Step [184/1063], Loss: 0.0049\n",
      "Epoch [2/10], Step [185/1063], Loss: 0.0837\n",
      "Epoch [2/10], Step [186/1063], Loss: 0.0290\n",
      "Epoch [2/10], Step [187/1063], Loss: 0.0423\n",
      "Epoch [2/10], Step [188/1063], Loss: 0.1001\n",
      "Epoch [2/10], Step [189/1063], Loss: 0.1435\n",
      "Epoch [2/10], Step [190/1063], Loss: 0.1046\n",
      "Epoch [2/10], Step [191/1063], Loss: 0.0536\n",
      "Epoch [2/10], Step [192/1063], Loss: 0.0791\n",
      "Epoch [2/10], Step [193/1063], Loss: 0.0269\n",
      "Epoch [2/10], Step [194/1063], Loss: 0.1146\n",
      "Epoch [2/10], Step [195/1063], Loss: 0.0067\n",
      "Epoch [2/10], Step [196/1063], Loss: 0.0821\n",
      "Epoch [2/10], Step [197/1063], Loss: 0.0380\n",
      "Epoch [2/10], Step [198/1063], Loss: 0.0362\n",
      "Epoch [2/10], Step [199/1063], Loss: 0.0044\n",
      "Epoch [2/10], Step [200/1063], Loss: 0.0173\n",
      "Epoch [2/10], Step [201/1063], Loss: 0.0193\n",
      "Epoch [2/10], Step [202/1063], Loss: 0.0105\n",
      "Epoch [2/10], Step [203/1063], Loss: 0.0305\n",
      "Epoch [2/10], Step [204/1063], Loss: 0.0042\n",
      "Epoch [2/10], Step [205/1063], Loss: 0.0482\n",
      "Epoch [2/10], Step [206/1063], Loss: 0.0226\n",
      "Epoch [2/10], Step [207/1063], Loss: 0.0182\n",
      "Epoch [2/10], Step [208/1063], Loss: 0.0144\n",
      "Epoch [2/10], Step [209/1063], Loss: 0.0245\n",
      "Epoch [2/10], Step [210/1063], Loss: 0.0103\n",
      "Epoch [2/10], Step [211/1063], Loss: 0.0901\n",
      "Epoch [2/10], Step [212/1063], Loss: 0.0490\n",
      "Epoch [2/10], Step [213/1063], Loss: 0.0286\n",
      "Epoch [2/10], Step [214/1063], Loss: 0.0440\n",
      "Epoch [2/10], Step [215/1063], Loss: 0.0532\n",
      "Epoch [2/10], Step [216/1063], Loss: 0.0691\n",
      "Epoch [2/10], Step [217/1063], Loss: 0.0279\n",
      "Epoch [2/10], Step [218/1063], Loss: 0.0760\n",
      "Epoch [2/10], Step [219/1063], Loss: 0.0153\n",
      "Epoch [2/10], Step [220/1063], Loss: 0.0098\n",
      "Epoch [2/10], Step [221/1063], Loss: 0.0583\n",
      "Epoch [2/10], Step [222/1063], Loss: 0.0225\n",
      "Epoch [2/10], Step [223/1063], Loss: 0.0299\n",
      "Epoch [2/10], Step [224/1063], Loss: 0.0096\n",
      "Epoch [2/10], Step [225/1063], Loss: 0.0159\n",
      "Epoch [2/10], Step [226/1063], Loss: 0.0329\n",
      "Epoch [2/10], Step [227/1063], Loss: 0.1335\n",
      "Epoch [2/10], Step [228/1063], Loss: 0.0085\n",
      "Epoch [2/10], Step [229/1063], Loss: 0.0043\n",
      "Epoch [2/10], Step [230/1063], Loss: 0.0918\n",
      "Epoch [2/10], Step [231/1063], Loss: 0.0684\n",
      "Epoch [2/10], Step [232/1063], Loss: 0.0349\n",
      "Epoch [2/10], Step [233/1063], Loss: 0.0692\n",
      "Epoch [2/10], Step [234/1063], Loss: 0.0230\n",
      "Epoch [2/10], Step [235/1063], Loss: 0.0890\n",
      "Epoch [2/10], Step [236/1063], Loss: 0.0105\n",
      "Epoch [2/10], Step [237/1063], Loss: 0.0563\n",
      "Epoch [2/10], Step [238/1063], Loss: 0.0737\n",
      "Epoch [2/10], Step [239/1063], Loss: 0.0220\n",
      "Epoch [2/10], Step [240/1063], Loss: 0.0187\n",
      "Epoch [2/10], Step [241/1063], Loss: 0.0338\n",
      "Epoch [2/10], Step [242/1063], Loss: 0.0345\n",
      "Epoch [2/10], Step [243/1063], Loss: 0.0023\n",
      "Epoch [2/10], Step [244/1063], Loss: 0.1311\n",
      "Epoch [2/10], Step [245/1063], Loss: 0.0197\n",
      "Epoch [2/10], Step [246/1063], Loss: 0.0014\n",
      "Epoch [2/10], Step [247/1063], Loss: 0.0482\n",
      "Epoch [2/10], Step [248/1063], Loss: 0.0291\n",
      "Epoch [2/10], Step [249/1063], Loss: 0.0491\n",
      "Epoch [2/10], Step [250/1063], Loss: 0.0266\n",
      "Epoch [2/10], Step [251/1063], Loss: 0.0070\n",
      "Epoch [2/10], Step [252/1063], Loss: 0.0909\n",
      "Epoch [2/10], Step [253/1063], Loss: 0.0424\n",
      "Epoch [2/10], Step [254/1063], Loss: 0.0103\n",
      "Epoch [2/10], Step [255/1063], Loss: 0.0370\n",
      "Epoch [2/10], Step [256/1063], Loss: 0.0238\n",
      "Epoch [2/10], Step [257/1063], Loss: 0.0040\n",
      "Epoch [2/10], Step [258/1063], Loss: 0.0168\n",
      "Epoch [2/10], Step [259/1063], Loss: 0.0398\n",
      "Epoch [2/10], Step [260/1063], Loss: 0.0325\n",
      "Epoch [2/10], Step [261/1063], Loss: 0.0189\n",
      "Epoch [2/10], Step [262/1063], Loss: 0.0358\n",
      "Epoch [2/10], Step [263/1063], Loss: 0.0289\n",
      "Epoch [2/10], Step [264/1063], Loss: 0.0494\n",
      "Epoch [2/10], Step [265/1063], Loss: 0.0444\n",
      "Epoch [2/10], Step [266/1063], Loss: 0.1163\n",
      "Epoch [2/10], Step [267/1063], Loss: 0.0272\n",
      "Epoch [2/10], Step [268/1063], Loss: 0.0883\n",
      "Epoch [2/10], Step [269/1063], Loss: 0.0107\n",
      "Epoch [2/10], Step [270/1063], Loss: 0.0585\n",
      "Epoch [2/10], Step [271/1063], Loss: 0.0613\n",
      "Epoch [2/10], Step [272/1063], Loss: 0.1374\n",
      "Epoch [2/10], Step [273/1063], Loss: 0.0352\n",
      "Epoch [2/10], Step [274/1063], Loss: 0.0159\n",
      "Epoch [2/10], Step [275/1063], Loss: 0.0290\n",
      "Epoch [2/10], Step [276/1063], Loss: 0.0217\n",
      "Epoch [2/10], Step [277/1063], Loss: 0.0844\n",
      "Epoch [2/10], Step [278/1063], Loss: 0.0218\n",
      "Epoch [2/10], Step [279/1063], Loss: 0.0362\n",
      "Epoch [2/10], Step [280/1063], Loss: 0.0303\n",
      "Epoch [2/10], Step [281/1063], Loss: 0.0351\n",
      "Epoch [2/10], Step [282/1063], Loss: 0.0675\n",
      "Epoch [2/10], Step [283/1063], Loss: 0.0934\n",
      "Epoch [2/10], Step [284/1063], Loss: 0.0365\n",
      "Epoch [2/10], Step [285/1063], Loss: 0.0407\n",
      "Epoch [2/10], Step [286/1063], Loss: 0.0233\n",
      "Epoch [2/10], Step [287/1063], Loss: 0.0709\n",
      "Epoch [2/10], Step [288/1063], Loss: 0.0109\n",
      "Epoch [2/10], Step [289/1063], Loss: 0.0307\n",
      "Epoch [2/10], Step [290/1063], Loss: 0.0746\n",
      "Epoch [2/10], Step [291/1063], Loss: 0.0069\n",
      "Epoch [2/10], Step [292/1063], Loss: 0.0237\n",
      "Epoch [2/10], Step [293/1063], Loss: 0.0428\n",
      "Epoch [2/10], Step [294/1063], Loss: 0.0284\n",
      "Epoch [2/10], Step [295/1063], Loss: 0.1409\n",
      "Epoch [2/10], Step [296/1063], Loss: 0.0058\n",
      "Epoch [2/10], Step [297/1063], Loss: 0.0527\n",
      "Epoch [2/10], Step [298/1063], Loss: 0.0858\n",
      "Epoch [2/10], Step [299/1063], Loss: 0.0037\n",
      "Epoch [2/10], Step [300/1063], Loss: 0.0073\n",
      "Epoch [2/10], Step [301/1063], Loss: 0.0179\n",
      "Epoch [2/10], Step [302/1063], Loss: 0.0097\n",
      "Epoch [2/10], Step [303/1063], Loss: 0.0427\n",
      "Epoch [2/10], Step [304/1063], Loss: 0.0416\n",
      "Epoch [2/10], Step [305/1063], Loss: 0.0115\n",
      "Epoch [2/10], Step [306/1063], Loss: 0.0122\n",
      "Epoch [2/10], Step [307/1063], Loss: 0.0074\n",
      "Epoch [2/10], Step [308/1063], Loss: 0.0788\n",
      "Epoch [2/10], Step [309/1063], Loss: 0.2121\n",
      "Epoch [2/10], Step [310/1063], Loss: 0.0134\n",
      "Epoch [2/10], Step [311/1063], Loss: 0.0244\n",
      "Epoch [2/10], Step [312/1063], Loss: 0.0065\n",
      "Epoch [2/10], Step [313/1063], Loss: 0.0340\n",
      "Epoch [2/10], Step [314/1063], Loss: 0.0022\n",
      "Epoch [2/10], Step [315/1063], Loss: 0.0384\n",
      "Epoch [2/10], Step [316/1063], Loss: 0.0569\n",
      "Epoch [2/10], Step [317/1063], Loss: 0.0158\n",
      "Epoch [2/10], Step [318/1063], Loss: 0.0394\n",
      "Epoch [2/10], Step [319/1063], Loss: 0.0368\n",
      "Epoch [2/10], Step [320/1063], Loss: 0.0654\n",
      "Epoch [2/10], Step [321/1063], Loss: 0.0132\n",
      "Epoch [2/10], Step [322/1063], Loss: 0.0165\n",
      "Epoch [2/10], Step [323/1063], Loss: 0.0163\n",
      "Epoch [2/10], Step [324/1063], Loss: 0.0053\n",
      "Epoch [2/10], Step [325/1063], Loss: 0.0697\n",
      "Epoch [2/10], Step [326/1063], Loss: 0.0466\n",
      "Epoch [2/10], Step [327/1063], Loss: 0.0591\n",
      "Epoch [2/10], Step [328/1063], Loss: 0.0314\n",
      "Epoch [2/10], Step [329/1063], Loss: 0.0312\n",
      "Epoch [2/10], Step [330/1063], Loss: 0.0019\n",
      "Epoch [2/10], Step [331/1063], Loss: 0.0145\n",
      "Epoch [2/10], Step [332/1063], Loss: 0.1237\n",
      "Epoch [2/10], Step [333/1063], Loss: 0.0074\n",
      "Epoch [2/10], Step [334/1063], Loss: 0.0048\n",
      "Epoch [2/10], Step [335/1063], Loss: 0.0739\n",
      "Epoch [2/10], Step [336/1063], Loss: 0.0064\n",
      "Epoch [2/10], Step [337/1063], Loss: 0.0168\n",
      "Epoch [2/10], Step [338/1063], Loss: 0.0620\n",
      "Epoch [2/10], Step [339/1063], Loss: 0.0702\n",
      "Epoch [2/10], Step [340/1063], Loss: 0.0117\n",
      "Epoch [2/10], Step [341/1063], Loss: 0.0338\n",
      "Epoch [2/10], Step [342/1063], Loss: 0.0025\n",
      "Epoch [2/10], Step [343/1063], Loss: 0.0528\n",
      "Epoch [2/10], Step [344/1063], Loss: 0.0132\n",
      "Epoch [2/10], Step [345/1063], Loss: 0.1285\n",
      "Epoch [2/10], Step [346/1063], Loss: 0.0364\n",
      "Epoch [2/10], Step [347/1063], Loss: 0.0244\n",
      "Epoch [2/10], Step [348/1063], Loss: 0.0164\n",
      "Epoch [2/10], Step [349/1063], Loss: 0.0674\n",
      "Epoch [2/10], Step [350/1063], Loss: 0.0036\n",
      "Epoch [2/10], Step [351/1063], Loss: 0.0779\n",
      "Epoch [2/10], Step [352/1063], Loss: 0.0989\n",
      "Epoch [2/10], Step [353/1063], Loss: 0.0790\n",
      "Epoch [2/10], Step [354/1063], Loss: 0.0089\n",
      "Epoch [2/10], Step [355/1063], Loss: 0.0341\n",
      "Epoch [2/10], Step [356/1063], Loss: 0.0366\n",
      "Epoch [2/10], Step [357/1063], Loss: 0.0257\n",
      "Epoch [2/10], Step [358/1063], Loss: 0.2321\n",
      "Epoch [2/10], Step [359/1063], Loss: 0.0523\n",
      "Epoch [2/10], Step [360/1063], Loss: 0.0209\n",
      "Epoch [2/10], Step [361/1063], Loss: 0.0166\n",
      "Epoch [2/10], Step [362/1063], Loss: 0.0128\n",
      "Epoch [2/10], Step [363/1063], Loss: 0.0056\n",
      "Epoch [2/10], Step [364/1063], Loss: 0.0073\n",
      "Epoch [2/10], Step [365/1063], Loss: 0.1630\n",
      "Epoch [2/10], Step [366/1063], Loss: 0.1335\n",
      "Epoch [2/10], Step [367/1063], Loss: 0.0056\n",
      "Epoch [2/10], Step [368/1063], Loss: 0.0168\n",
      "Epoch [2/10], Step [369/1063], Loss: 0.0403\n",
      "Epoch [2/10], Step [370/1063], Loss: 0.0316\n",
      "Epoch [2/10], Step [371/1063], Loss: 0.0234\n",
      "Epoch [2/10], Step [372/1063], Loss: 0.0390\n",
      "Epoch [2/10], Step [373/1063], Loss: 0.0075\n",
      "Epoch [2/10], Step [374/1063], Loss: 0.0422\n",
      "Epoch [2/10], Step [375/1063], Loss: 0.1572\n",
      "Epoch [2/10], Step [376/1063], Loss: 0.0836\n",
      "Epoch [2/10], Step [377/1063], Loss: 0.0314\n",
      "Epoch [2/10], Step [378/1063], Loss: 0.0597\n",
      "Epoch [2/10], Step [379/1063], Loss: 0.0917\n",
      "Epoch [2/10], Step [380/1063], Loss: 0.0220\n",
      "Epoch [2/10], Step [381/1063], Loss: 0.0750\n",
      "Epoch [2/10], Step [382/1063], Loss: 0.0322\n",
      "Epoch [2/10], Step [383/1063], Loss: 0.1005\n",
      "Epoch [2/10], Step [384/1063], Loss: 0.0969\n",
      "Epoch [2/10], Step [385/1063], Loss: 0.0205\n",
      "Epoch [2/10], Step [386/1063], Loss: 0.0164\n",
      "Epoch [2/10], Step [387/1063], Loss: 0.0213\n",
      "Epoch [2/10], Step [388/1063], Loss: 0.0562\n",
      "Epoch [2/10], Step [389/1063], Loss: 0.0335\n",
      "Epoch [2/10], Step [390/1063], Loss: 0.1141\n",
      "Epoch [2/10], Step [391/1063], Loss: 0.0248\n",
      "Epoch [2/10], Step [392/1063], Loss: 0.0291\n",
      "Epoch [2/10], Step [393/1063], Loss: 0.0057\n",
      "Epoch [2/10], Step [394/1063], Loss: 0.0071\n",
      "Epoch [2/10], Step [395/1063], Loss: 0.0071\n",
      "Epoch [2/10], Step [396/1063], Loss: 0.0044\n",
      "Epoch [2/10], Step [397/1063], Loss: 0.0470\n",
      "Epoch [2/10], Step [398/1063], Loss: 0.0311\n",
      "Epoch [2/10], Step [399/1063], Loss: 0.0248\n",
      "Epoch [2/10], Step [400/1063], Loss: 0.0235\n",
      "Epoch [2/10], Step [401/1063], Loss: 0.0168\n",
      "Epoch [2/10], Step [402/1063], Loss: 0.0197\n",
      "Epoch [2/10], Step [403/1063], Loss: 0.0122\n",
      "Epoch [2/10], Step [404/1063], Loss: 0.0463\n",
      "Epoch [2/10], Step [405/1063], Loss: 0.0166\n",
      "Epoch [2/10], Step [406/1063], Loss: 0.0732\n",
      "Epoch [2/10], Step [407/1063], Loss: 0.0436\n",
      "Epoch [2/10], Step [408/1063], Loss: 0.0253\n",
      "Epoch [2/10], Step [409/1063], Loss: 0.0301\n",
      "Epoch [2/10], Step [410/1063], Loss: 0.1678\n",
      "Epoch [2/10], Step [411/1063], Loss: 0.1145\n",
      "Epoch [2/10], Step [412/1063], Loss: 0.0037\n",
      "Epoch [2/10], Step [413/1063], Loss: 0.0086\n",
      "Epoch [2/10], Step [414/1063], Loss: 0.0118\n",
      "Epoch [2/10], Step [415/1063], Loss: 0.0170\n",
      "Epoch [2/10], Step [416/1063], Loss: 0.0778\n",
      "Epoch [2/10], Step [417/1063], Loss: 0.0114\n",
      "Epoch [2/10], Step [418/1063], Loss: 0.0466\n",
      "Epoch [2/10], Step [419/1063], Loss: 0.0129\n",
      "Epoch [2/10], Step [420/1063], Loss: 0.0290\n",
      "Epoch [2/10], Step [421/1063], Loss: 0.0103\n",
      "Epoch [2/10], Step [422/1063], Loss: 0.0086\n",
      "Epoch [2/10], Step [423/1063], Loss: 0.0425\n",
      "Epoch [2/10], Step [424/1063], Loss: 0.0476\n",
      "Epoch [2/10], Step [425/1063], Loss: 0.0198\n",
      "Epoch [2/10], Step [426/1063], Loss: 0.0405\n",
      "Epoch [2/10], Step [427/1063], Loss: 0.0266\n",
      "Epoch [2/10], Step [428/1063], Loss: 0.0522\n",
      "Epoch [2/10], Step [429/1063], Loss: 0.0067\n",
      "Epoch [2/10], Step [430/1063], Loss: 0.0108\n",
      "Epoch [2/10], Step [431/1063], Loss: 0.0075\n",
      "Epoch [2/10], Step [432/1063], Loss: 0.0420\n",
      "Epoch [2/10], Step [433/1063], Loss: 0.0039\n",
      "Epoch [2/10], Step [434/1063], Loss: 0.0467\n",
      "Epoch [2/10], Step [435/1063], Loss: 0.0698\n",
      "Epoch [2/10], Step [436/1063], Loss: 0.0131\n",
      "Epoch [2/10], Step [437/1063], Loss: 0.0446\n",
      "Epoch [2/10], Step [438/1063], Loss: 0.0033\n",
      "Epoch [2/10], Step [439/1063], Loss: 0.0728\n",
      "Epoch [2/10], Step [440/1063], Loss: 0.0336\n",
      "Epoch [2/10], Step [441/1063], Loss: 0.0210\n",
      "Epoch [2/10], Step [442/1063], Loss: 0.0037\n",
      "Epoch [2/10], Step [443/1063], Loss: 0.2237\n",
      "Epoch [2/10], Step [444/1063], Loss: 0.0114\n",
      "Epoch [2/10], Step [445/1063], Loss: 0.0659\n",
      "Epoch [2/10], Step [446/1063], Loss: 0.0095\n",
      "Epoch [2/10], Step [447/1063], Loss: 0.0079\n",
      "Epoch [2/10], Step [448/1063], Loss: 0.0437\n",
      "Epoch [2/10], Step [449/1063], Loss: 0.0182\n",
      "Epoch [2/10], Step [450/1063], Loss: 0.0136\n",
      "Epoch [2/10], Step [451/1063], Loss: 0.0630\n",
      "Epoch [2/10], Step [452/1063], Loss: 0.0039\n",
      "Epoch [2/10], Step [453/1063], Loss: 0.0823\n",
      "Epoch [2/10], Step [454/1063], Loss: 0.0594\n",
      "Epoch [2/10], Step [455/1063], Loss: 0.0087\n",
      "Epoch [2/10], Step [456/1063], Loss: 0.0213\n",
      "Epoch [2/10], Step [457/1063], Loss: 0.0047\n",
      "Epoch [2/10], Step [458/1063], Loss: 0.0537\n",
      "Epoch [2/10], Step [459/1063], Loss: 0.0676\n",
      "Epoch [2/10], Step [460/1063], Loss: 0.1688\n",
      "Epoch [2/10], Step [461/1063], Loss: 0.1256\n",
      "Epoch [2/10], Step [462/1063], Loss: 0.0145\n",
      "Epoch [2/10], Step [463/1063], Loss: 0.0486\n",
      "Epoch [2/10], Step [464/1063], Loss: 0.1432\n",
      "Epoch [2/10], Step [465/1063], Loss: 0.0424\n",
      "Epoch [2/10], Step [466/1063], Loss: 0.0267\n",
      "Epoch [2/10], Step [467/1063], Loss: 0.0333\n",
      "Epoch [2/10], Step [468/1063], Loss: 0.0320\n",
      "Epoch [2/10], Step [469/1063], Loss: 0.0149\n",
      "Epoch [2/10], Step [470/1063], Loss: 0.0802\n",
      "Epoch [2/10], Step [471/1063], Loss: 0.0087\n",
      "Epoch [2/10], Step [472/1063], Loss: 0.0039\n",
      "Epoch [2/10], Step [473/1063], Loss: 0.0252\n",
      "Epoch [2/10], Step [474/1063], Loss: 0.0295\n",
      "Epoch [2/10], Step [475/1063], Loss: 0.0156\n",
      "Epoch [2/10], Step [476/1063], Loss: 0.0779\n",
      "Epoch [2/10], Step [477/1063], Loss: 0.0366\n",
      "Epoch [2/10], Step [478/1063], Loss: 0.0166\n",
      "Epoch [2/10], Step [479/1063], Loss: 0.1300\n",
      "Epoch [2/10], Step [480/1063], Loss: 0.0887\n",
      "Epoch [2/10], Step [481/1063], Loss: 0.0197\n",
      "Epoch [2/10], Step [482/1063], Loss: 0.1119\n",
      "Epoch [2/10], Step [483/1063], Loss: 0.0520\n",
      "Epoch [2/10], Step [484/1063], Loss: 0.0029\n",
      "Epoch [2/10], Step [485/1063], Loss: 0.0228\n",
      "Epoch [2/10], Step [486/1063], Loss: 0.0177\n",
      "Epoch [2/10], Step [487/1063], Loss: 0.0436\n",
      "Epoch [2/10], Step [488/1063], Loss: 0.0370\n",
      "Epoch [2/10], Step [489/1063], Loss: 0.0142\n",
      "Epoch [2/10], Step [490/1063], Loss: 0.0420\n",
      "Epoch [2/10], Step [491/1063], Loss: 0.0262\n",
      "Epoch [2/10], Step [492/1063], Loss: 0.0195\n",
      "Epoch [2/10], Step [493/1063], Loss: 0.0110\n",
      "Epoch [2/10], Step [494/1063], Loss: 0.0469\n",
      "Epoch [2/10], Step [495/1063], Loss: 0.0217\n",
      "Epoch [2/10], Step [496/1063], Loss: 0.0431\n",
      "Epoch [2/10], Step [497/1063], Loss: 0.0850\n",
      "Epoch [2/10], Step [498/1063], Loss: 0.1011\n",
      "Epoch [2/10], Step [499/1063], Loss: 0.1565\n",
      "Epoch [2/10], Step [500/1063], Loss: 0.0367\n",
      "Epoch [2/10], Step [501/1063], Loss: 0.0583\n",
      "Epoch [2/10], Step [502/1063], Loss: 0.0271\n",
      "Epoch [2/10], Step [503/1063], Loss: 0.0202\n",
      "Epoch [2/10], Step [504/1063], Loss: 0.1999\n",
      "Epoch [2/10], Step [505/1063], Loss: 0.0072\n",
      "Epoch [2/10], Step [506/1063], Loss: 0.0380\n",
      "Epoch [2/10], Step [507/1063], Loss: 0.0153\n",
      "Epoch [2/10], Step [508/1063], Loss: 0.0138\n",
      "Epoch [2/10], Step [509/1063], Loss: 0.1474\n",
      "Epoch [2/10], Step [510/1063], Loss: 0.0197\n",
      "Epoch [2/10], Step [511/1063], Loss: 0.0462\n",
      "Epoch [2/10], Step [512/1063], Loss: 0.0154\n",
      "Epoch [2/10], Step [513/1063], Loss: 0.0414\n",
      "Epoch [2/10], Step [514/1063], Loss: 0.0785\n",
      "Epoch [2/10], Step [515/1063], Loss: 0.1578\n",
      "Epoch [2/10], Step [516/1063], Loss: 0.0033\n",
      "Epoch [2/10], Step [517/1063], Loss: 0.0368\n",
      "Epoch [2/10], Step [518/1063], Loss: 0.0413\n",
      "Epoch [2/10], Step [519/1063], Loss: 0.1021\n",
      "Epoch [2/10], Step [520/1063], Loss: 0.0142\n",
      "Epoch [2/10], Step [521/1063], Loss: 0.0093\n",
      "Epoch [2/10], Step [522/1063], Loss: 0.1282\n",
      "Epoch [2/10], Step [523/1063], Loss: 0.0102\n",
      "Epoch [2/10], Step [524/1063], Loss: 0.0166\n",
      "Epoch [2/10], Step [525/1063], Loss: 0.0149\n",
      "Epoch [2/10], Step [526/1063], Loss: 0.0359\n",
      "Epoch [2/10], Step [527/1063], Loss: 0.0615\n",
      "Epoch [2/10], Step [528/1063], Loss: 0.0572\n",
      "Epoch [2/10], Step [529/1063], Loss: 0.0093\n",
      "Epoch [2/10], Step [530/1063], Loss: 0.0144\n",
      "Epoch [2/10], Step [531/1063], Loss: 0.0274\n",
      "Epoch [2/10], Step [532/1063], Loss: 0.0067\n",
      "Epoch [2/10], Step [533/1063], Loss: 0.1275\n",
      "Epoch [2/10], Step [534/1063], Loss: 0.1405\n",
      "Epoch [2/10], Step [535/1063], Loss: 0.0092\n",
      "Epoch [2/10], Step [536/1063], Loss: 0.0290\n",
      "Epoch [2/10], Step [537/1063], Loss: 0.0035\n",
      "Epoch [2/10], Step [538/1063], Loss: 0.0206\n",
      "Epoch [2/10], Step [539/1063], Loss: 0.0467\n",
      "Epoch [2/10], Step [540/1063], Loss: 0.0170\n",
      "Epoch [2/10], Step [541/1063], Loss: 0.0275\n",
      "Epoch [2/10], Step [542/1063], Loss: 0.0179\n",
      "Epoch [2/10], Step [543/1063], Loss: 0.0472\n",
      "Epoch [2/10], Step [544/1063], Loss: 0.3244\n",
      "Epoch [2/10], Step [545/1063], Loss: 0.0026\n",
      "Epoch [2/10], Step [546/1063], Loss: 0.0398\n",
      "Epoch [2/10], Step [547/1063], Loss: 0.0870\n",
      "Epoch [2/10], Step [548/1063], Loss: 0.0218\n",
      "Epoch [2/10], Step [549/1063], Loss: 0.0216\n",
      "Epoch [2/10], Step [550/1063], Loss: 0.0195\n",
      "Epoch [2/10], Step [551/1063], Loss: 0.0056\n",
      "Epoch [2/10], Step [552/1063], Loss: 0.0424\n",
      "Epoch [2/10], Step [553/1063], Loss: 0.0028\n",
      "Epoch [2/10], Step [554/1063], Loss: 0.0829\n",
      "Epoch [2/10], Step [555/1063], Loss: 0.0669\n",
      "Epoch [2/10], Step [556/1063], Loss: 0.0234\n",
      "Epoch [2/10], Step [557/1063], Loss: 0.0182\n",
      "Epoch [2/10], Step [558/1063], Loss: 0.0115\n",
      "Epoch [2/10], Step [559/1063], Loss: 0.0307\n",
      "Epoch [2/10], Step [560/1063], Loss: 0.0091\n",
      "Epoch [2/10], Step [561/1063], Loss: 0.0276\n",
      "Epoch [2/10], Step [562/1063], Loss: 0.0151\n",
      "Epoch [2/10], Step [563/1063], Loss: 0.0314\n",
      "Epoch [2/10], Step [564/1063], Loss: 0.0242\n",
      "Epoch [2/10], Step [565/1063], Loss: 0.0554\n",
      "Epoch [2/10], Step [566/1063], Loss: 0.0768\n",
      "Epoch [2/10], Step [567/1063], Loss: 0.0816\n",
      "Epoch [2/10], Step [568/1063], Loss: 0.1321\n",
      "Epoch [2/10], Step [569/1063], Loss: 0.0156\n",
      "Epoch [2/10], Step [570/1063], Loss: 0.0281\n",
      "Epoch [2/10], Step [571/1063], Loss: 0.0062\n",
      "Epoch [2/10], Step [572/1063], Loss: 0.0190\n",
      "Epoch [2/10], Step [573/1063], Loss: 0.0936\n",
      "Epoch [2/10], Step [574/1063], Loss: 0.0805\n",
      "Epoch [2/10], Step [575/1063], Loss: 0.0944\n",
      "Epoch [2/10], Step [576/1063], Loss: 0.0284\n",
      "Epoch [2/10], Step [577/1063], Loss: 0.0564\n",
      "Epoch [2/10], Step [578/1063], Loss: 0.0350\n",
      "Epoch [2/10], Step [579/1063], Loss: 0.0338\n",
      "Epoch [2/10], Step [580/1063], Loss: 0.0499\n",
      "Epoch [2/10], Step [581/1063], Loss: 0.0299\n",
      "Epoch [2/10], Step [582/1063], Loss: 0.0240\n",
      "Epoch [2/10], Step [583/1063], Loss: 0.0050\n",
      "Epoch [2/10], Step [584/1063], Loss: 0.0752\n",
      "Epoch [2/10], Step [585/1063], Loss: 0.0240\n",
      "Epoch [2/10], Step [586/1063], Loss: 0.0025\n",
      "Epoch [2/10], Step [587/1063], Loss: 0.0040\n",
      "Epoch [2/10], Step [588/1063], Loss: 0.0657\n",
      "Epoch [2/10], Step [589/1063], Loss: 0.0592\n",
      "Epoch [2/10], Step [590/1063], Loss: 0.0121\n",
      "Epoch [2/10], Step [591/1063], Loss: 0.0695\n",
      "Epoch [2/10], Step [592/1063], Loss: 0.0904\n",
      "Epoch [2/10], Step [593/1063], Loss: 0.1403\n",
      "Epoch [2/10], Step [594/1063], Loss: 0.0650\n",
      "Epoch [2/10], Step [595/1063], Loss: 0.0178\n",
      "Epoch [2/10], Step [596/1063], Loss: 0.0378\n",
      "Epoch [2/10], Step [597/1063], Loss: 0.0491\n",
      "Epoch [2/10], Step [598/1063], Loss: 0.0236\n",
      "Epoch [2/10], Step [599/1063], Loss: 0.0124\n",
      "Epoch [2/10], Step [600/1063], Loss: 0.0423\n",
      "Epoch [2/10], Step [601/1063], Loss: 0.0073\n",
      "Epoch [2/10], Step [602/1063], Loss: 0.0627\n",
      "Epoch [2/10], Step [603/1063], Loss: 0.0518\n",
      "Epoch [2/10], Step [604/1063], Loss: 0.0220\n",
      "Epoch [2/10], Step [605/1063], Loss: 0.0135\n",
      "Epoch [2/10], Step [606/1063], Loss: 0.0265\n",
      "Epoch [2/10], Step [607/1063], Loss: 0.0854\n",
      "Epoch [2/10], Step [608/1063], Loss: 0.1450\n",
      "Epoch [2/10], Step [609/1063], Loss: 0.0228\n",
      "Epoch [2/10], Step [610/1063], Loss: 0.0369\n",
      "Epoch [2/10], Step [611/1063], Loss: 0.0105\n",
      "Epoch [2/10], Step [612/1063], Loss: 0.0279\n",
      "Epoch [2/10], Step [613/1063], Loss: 0.0512\n",
      "Epoch [2/10], Step [614/1063], Loss: 0.0406\n",
      "Epoch [2/10], Step [615/1063], Loss: 0.0689\n",
      "Epoch [2/10], Step [616/1063], Loss: 0.0528\n",
      "Epoch [2/10], Step [617/1063], Loss: 0.0377\n",
      "Epoch [2/10], Step [618/1063], Loss: 0.0076\n",
      "Epoch [2/10], Step [619/1063], Loss: 0.0495\n",
      "Epoch [2/10], Step [620/1063], Loss: 0.0268\n",
      "Epoch [2/10], Step [621/1063], Loss: 0.0045\n",
      "Epoch [2/10], Step [622/1063], Loss: 0.0153\n",
      "Epoch [2/10], Step [623/1063], Loss: 0.1401\n",
      "Epoch [2/10], Step [624/1063], Loss: 0.0586\n",
      "Epoch [2/10], Step [625/1063], Loss: 0.0310\n",
      "Epoch [2/10], Step [626/1063], Loss: 0.0486\n",
      "Epoch [2/10], Step [627/1063], Loss: 0.0968\n",
      "Epoch [2/10], Step [628/1063], Loss: 0.0532\n",
      "Epoch [2/10], Step [629/1063], Loss: 0.0774\n",
      "Epoch [2/10], Step [630/1063], Loss: 0.1450\n",
      "Epoch [2/10], Step [631/1063], Loss: 0.0886\n",
      "Epoch [2/10], Step [632/1063], Loss: 0.0145\n",
      "Epoch [2/10], Step [633/1063], Loss: 0.0266\n",
      "Epoch [2/10], Step [634/1063], Loss: 0.0238\n",
      "Epoch [2/10], Step [635/1063], Loss: 0.0233\n",
      "Epoch [2/10], Step [636/1063], Loss: 0.0527\n",
      "Epoch [2/10], Step [637/1063], Loss: 0.0111\n",
      "Epoch [2/10], Step [638/1063], Loss: 0.0802\n",
      "Epoch [2/10], Step [639/1063], Loss: 0.1260\n",
      "Epoch [2/10], Step [640/1063], Loss: 0.0175\n",
      "Epoch [2/10], Step [641/1063], Loss: 0.0942\n",
      "Epoch [2/10], Step [642/1063], Loss: 0.0252\n",
      "Epoch [2/10], Step [643/1063], Loss: 0.0733\n",
      "Epoch [2/10], Step [644/1063], Loss: 0.0102\n",
      "Epoch [2/10], Step [645/1063], Loss: 0.0208\n",
      "Epoch [2/10], Step [646/1063], Loss: 0.0745\n",
      "Epoch [2/10], Step [647/1063], Loss: 0.0397\n",
      "Epoch [2/10], Step [648/1063], Loss: 0.0109\n",
      "Epoch [2/10], Step [649/1063], Loss: 0.1325\n",
      "Epoch [2/10], Step [650/1063], Loss: 0.0898\n",
      "Epoch [2/10], Step [651/1063], Loss: 0.0179\n",
      "Epoch [2/10], Step [652/1063], Loss: 0.1368\n",
      "Epoch [2/10], Step [653/1063], Loss: 0.0241\n",
      "Epoch [2/10], Step [654/1063], Loss: 0.0348\n",
      "Epoch [2/10], Step [655/1063], Loss: 0.0730\n",
      "Epoch [2/10], Step [656/1063], Loss: 0.0514\n",
      "Epoch [2/10], Step [657/1063], Loss: 0.0276\n",
      "Epoch [2/10], Step [658/1063], Loss: 0.0243\n",
      "Epoch [2/10], Step [659/1063], Loss: 0.0172\n",
      "Epoch [2/10], Step [660/1063], Loss: 0.1009\n",
      "Epoch [2/10], Step [661/1063], Loss: 0.0561\n",
      "Epoch [2/10], Step [662/1063], Loss: 0.0520\n",
      "Epoch [2/10], Step [663/1063], Loss: 0.0254\n",
      "Epoch [2/10], Step [664/1063], Loss: 0.2322\n",
      "Epoch [2/10], Step [665/1063], Loss: 0.0677\n",
      "Epoch [2/10], Step [666/1063], Loss: 0.0086\n",
      "Epoch [2/10], Step [667/1063], Loss: 0.0276\n",
      "Epoch [2/10], Step [668/1063], Loss: 0.0232\n",
      "Epoch [2/10], Step [669/1063], Loss: 0.0180\n",
      "Epoch [2/10], Step [670/1063], Loss: 0.0491\n",
      "Epoch [2/10], Step [671/1063], Loss: 0.0149\n",
      "Epoch [2/10], Step [672/1063], Loss: 0.0512\n",
      "Epoch [2/10], Step [673/1063], Loss: 0.0321\n",
      "Epoch [2/10], Step [674/1063], Loss: 0.0444\n",
      "Epoch [2/10], Step [675/1063], Loss: 0.0328\n",
      "Epoch [2/10], Step [676/1063], Loss: 0.0938\n",
      "Epoch [2/10], Step [677/1063], Loss: 0.0623\n",
      "Epoch [2/10], Step [678/1063], Loss: 0.1224\n",
      "Epoch [2/10], Step [679/1063], Loss: 0.0738\n",
      "Epoch [2/10], Step [680/1063], Loss: 0.0088\n",
      "Epoch [2/10], Step [681/1063], Loss: 0.0241\n",
      "Epoch [2/10], Step [682/1063], Loss: 0.0544\n",
      "Epoch [2/10], Step [683/1063], Loss: 0.0246\n",
      "Epoch [2/10], Step [684/1063], Loss: 0.0258\n",
      "Epoch [2/10], Step [685/1063], Loss: 0.0032\n",
      "Epoch [2/10], Step [686/1063], Loss: 0.0223\n",
      "Epoch [2/10], Step [687/1063], Loss: 0.0080\n",
      "Epoch [2/10], Step [688/1063], Loss: 0.0749\n",
      "Epoch [2/10], Step [689/1063], Loss: 0.0017\n",
      "Epoch [2/10], Step [690/1063], Loss: 0.0859\n",
      "Epoch [2/10], Step [691/1063], Loss: 0.0383\n",
      "Epoch [2/10], Step [692/1063], Loss: 0.0042\n",
      "Epoch [2/10], Step [693/1063], Loss: 0.0148\n",
      "Epoch [2/10], Step [694/1063], Loss: 0.1219\n",
      "Epoch [2/10], Step [695/1063], Loss: 0.0026\n",
      "Epoch [2/10], Step [696/1063], Loss: 0.0095\n",
      "Epoch [2/10], Step [697/1063], Loss: 0.0303\n",
      "Epoch [2/10], Step [698/1063], Loss: 0.0467\n",
      "Epoch [2/10], Step [699/1063], Loss: 0.0176\n",
      "Epoch [2/10], Step [700/1063], Loss: 0.0210\n",
      "Epoch [2/10], Step [701/1063], Loss: 0.0997\n",
      "Epoch [2/10], Step [702/1063], Loss: 0.0261\n",
      "Epoch [2/10], Step [703/1063], Loss: 0.1729\n",
      "Epoch [2/10], Step [704/1063], Loss: 0.0103\n",
      "Epoch [2/10], Step [705/1063], Loss: 0.0398\n",
      "Epoch [2/10], Step [706/1063], Loss: 0.0430\n",
      "Epoch [2/10], Step [707/1063], Loss: 0.0246\n",
      "Epoch [2/10], Step [708/1063], Loss: 0.0521\n",
      "Epoch [2/10], Step [709/1063], Loss: 0.0085\n",
      "Epoch [2/10], Step [710/1063], Loss: 0.0797\n",
      "Epoch [2/10], Step [711/1063], Loss: 0.0551\n",
      "Epoch [2/10], Step [712/1063], Loss: 0.0897\n",
      "Epoch [2/10], Step [713/1063], Loss: 0.0395\n",
      "Epoch [2/10], Step [714/1063], Loss: 0.0817\n",
      "Epoch [2/10], Step [715/1063], Loss: 0.0360\n",
      "Epoch [2/10], Step [716/1063], Loss: 0.0605\n",
      "Epoch [2/10], Step [717/1063], Loss: 0.0159\n",
      "Epoch [2/10], Step [718/1063], Loss: 0.0695\n",
      "Epoch [2/10], Step [719/1063], Loss: 0.0288\n",
      "Epoch [2/10], Step [720/1063], Loss: 0.0277\n",
      "Epoch [2/10], Step [721/1063], Loss: 0.0799\n",
      "Epoch [2/10], Step [722/1063], Loss: 0.0018\n",
      "Epoch [2/10], Step [723/1063], Loss: 0.0098\n",
      "Epoch [2/10], Step [724/1063], Loss: 0.0379\n",
      "Epoch [2/10], Step [725/1063], Loss: 0.0276\n",
      "Epoch [2/10], Step [726/1063], Loss: 0.0999\n",
      "Epoch [2/10], Step [727/1063], Loss: 0.0110\n",
      "Epoch [2/10], Step [728/1063], Loss: 0.0075\n",
      "Epoch [2/10], Step [729/1063], Loss: 0.0098\n",
      "Epoch [2/10], Step [730/1063], Loss: 0.1216\n",
      "Epoch [2/10], Step [731/1063], Loss: 0.0487\n",
      "Epoch [2/10], Step [732/1063], Loss: 0.2356\n",
      "Epoch [2/10], Step [733/1063], Loss: 0.0110\n",
      "Epoch [2/10], Step [734/1063], Loss: 0.0089\n",
      "Epoch [2/10], Step [735/1063], Loss: 0.0062\n",
      "Epoch [2/10], Step [736/1063], Loss: 0.0219\n",
      "Epoch [2/10], Step [737/1063], Loss: 0.1199\n",
      "Epoch [2/10], Step [738/1063], Loss: 0.0109\n",
      "Epoch [2/10], Step [739/1063], Loss: 0.0497\n",
      "Epoch [2/10], Step [740/1063], Loss: 0.1605\n",
      "Epoch [2/10], Step [741/1063], Loss: 0.0516\n",
      "Epoch [2/10], Step [742/1063], Loss: 0.0365\n",
      "Epoch [2/10], Step [743/1063], Loss: 0.0603\n",
      "Epoch [2/10], Step [744/1063], Loss: 0.0677\n",
      "Epoch [2/10], Step [745/1063], Loss: 0.0082\n",
      "Epoch [2/10], Step [746/1063], Loss: 0.0479\n",
      "Epoch [2/10], Step [747/1063], Loss: 0.0105\n",
      "Epoch [2/10], Step [748/1063], Loss: 0.0649\n",
      "Epoch [2/10], Step [749/1063], Loss: 0.0519\n",
      "Epoch [2/10], Step [750/1063], Loss: 0.0267\n",
      "Epoch [2/10], Step [751/1063], Loss: 0.0344\n",
      "Epoch [2/10], Step [752/1063], Loss: 0.0750\n",
      "Epoch [2/10], Step [753/1063], Loss: 0.0168\n",
      "Epoch [2/10], Step [754/1063], Loss: 0.1033\n",
      "Epoch [2/10], Step [755/1063], Loss: 0.0084\n",
      "Epoch [2/10], Step [756/1063], Loss: 0.0064\n",
      "Epoch [2/10], Step [757/1063], Loss: 0.0141\n",
      "Epoch [2/10], Step [758/1063], Loss: 0.0431\n",
      "Epoch [2/10], Step [759/1063], Loss: 0.0076\n",
      "Epoch [2/10], Step [760/1063], Loss: 0.0079\n",
      "Epoch [2/10], Step [761/1063], Loss: 0.1030\n",
      "Epoch [2/10], Step [762/1063], Loss: 0.0986\n",
      "Epoch [2/10], Step [763/1063], Loss: 0.0406\n",
      "Epoch [2/10], Step [764/1063], Loss: 0.0110\n",
      "Epoch [2/10], Step [765/1063], Loss: 0.0334\n",
      "Epoch [2/10], Step [766/1063], Loss: 0.1466\n",
      "Epoch [2/10], Step [767/1063], Loss: 0.0664\n",
      "Epoch [2/10], Step [768/1063], Loss: 0.0555\n",
      "Epoch [2/10], Step [769/1063], Loss: 0.0035\n",
      "Epoch [2/10], Step [770/1063], Loss: 0.0708\n",
      "Epoch [2/10], Step [771/1063], Loss: 0.0116\n",
      "Epoch [2/10], Step [772/1063], Loss: 0.0077\n",
      "Epoch [2/10], Step [773/1063], Loss: 0.1357\n",
      "Epoch [2/10], Step [774/1063], Loss: 0.0154\n",
      "Epoch [2/10], Step [775/1063], Loss: 0.0595\n",
      "Epoch [2/10], Step [776/1063], Loss: 0.0187\n",
      "Epoch [2/10], Step [777/1063], Loss: 0.0091\n",
      "Epoch [2/10], Step [778/1063], Loss: 0.0221\n",
      "Epoch [2/10], Step [779/1063], Loss: 0.0398\n",
      "Epoch [2/10], Step [780/1063], Loss: 0.0037\n",
      "Epoch [2/10], Step [781/1063], Loss: 0.0480\n",
      "Epoch [2/10], Step [782/1063], Loss: 0.0667\n",
      "Epoch [2/10], Step [783/1063], Loss: 0.0452\n",
      "Epoch [2/10], Step [784/1063], Loss: 0.0495\n",
      "Epoch [2/10], Step [785/1063], Loss: 0.0305\n",
      "Epoch [2/10], Step [786/1063], Loss: 0.1132\n",
      "Epoch [2/10], Step [787/1063], Loss: 0.1097\n",
      "Epoch [2/10], Step [788/1063], Loss: 0.0144\n",
      "Epoch [2/10], Step [789/1063], Loss: 0.0931\n",
      "Epoch [2/10], Step [790/1063], Loss: 0.0018\n",
      "Epoch [2/10], Step [791/1063], Loss: 0.1409\n",
      "Epoch [2/10], Step [792/1063], Loss: 0.0414\n",
      "Epoch [2/10], Step [793/1063], Loss: 0.0153\n",
      "Epoch [2/10], Step [794/1063], Loss: 0.0218\n",
      "Epoch [2/10], Step [795/1063], Loss: 0.0586\n",
      "Epoch [2/10], Step [796/1063], Loss: 0.0133\n",
      "Epoch [2/10], Step [797/1063], Loss: 0.0152\n",
      "Epoch [2/10], Step [798/1063], Loss: 0.0041\n",
      "Epoch [2/10], Step [799/1063], Loss: 0.0202\n",
      "Epoch [2/10], Step [800/1063], Loss: 0.0124\n",
      "Epoch [2/10], Step [801/1063], Loss: 0.0221\n",
      "Epoch [2/10], Step [802/1063], Loss: 0.0157\n",
      "Epoch [2/10], Step [803/1063], Loss: 0.0058\n",
      "Epoch [2/10], Step [804/1063], Loss: 0.0255\n",
      "Epoch [2/10], Step [805/1063], Loss: 0.0747\n",
      "Epoch [2/10], Step [806/1063], Loss: 0.0520\n",
      "Epoch [2/10], Step [807/1063], Loss: 0.0524\n",
      "Epoch [2/10], Step [808/1063], Loss: 0.0145\n",
      "Epoch [2/10], Step [809/1063], Loss: 0.0467\n",
      "Epoch [2/10], Step [810/1063], Loss: 0.0048\n",
      "Epoch [2/10], Step [811/1063], Loss: 0.0162\n",
      "Epoch [2/10], Step [812/1063], Loss: 0.0049\n",
      "Epoch [2/10], Step [813/1063], Loss: 0.1855\n",
      "Epoch [2/10], Step [814/1063], Loss: 0.0257\n",
      "Epoch [2/10], Step [815/1063], Loss: 0.0139\n",
      "Epoch [2/10], Step [816/1063], Loss: 0.0280\n",
      "Epoch [2/10], Step [817/1063], Loss: 0.0009\n",
      "Epoch [2/10], Step [818/1063], Loss: 0.0281\n",
      "Epoch [2/10], Step [819/1063], Loss: 0.0293\n",
      "Epoch [2/10], Step [820/1063], Loss: 0.0035\n",
      "Epoch [2/10], Step [821/1063], Loss: 0.0460\n",
      "Epoch [2/10], Step [822/1063], Loss: 0.0153\n",
      "Epoch [2/10], Step [823/1063], Loss: 0.1690\n",
      "Epoch [2/10], Step [824/1063], Loss: 0.0938\n",
      "Epoch [2/10], Step [825/1063], Loss: 0.0514\n",
      "Epoch [2/10], Step [826/1063], Loss: 0.0204\n",
      "Epoch [2/10], Step [827/1063], Loss: 0.0445\n",
      "Epoch [2/10], Step [828/1063], Loss: 0.0096\n",
      "Epoch [2/10], Step [829/1063], Loss: 0.0121\n",
      "Epoch [2/10], Step [830/1063], Loss: 0.0029\n",
      "Epoch [2/10], Step [831/1063], Loss: 0.0644\n",
      "Epoch [2/10], Step [832/1063], Loss: 0.1267\n",
      "Epoch [2/10], Step [833/1063], Loss: 0.0793\n",
      "Epoch [2/10], Step [834/1063], Loss: 0.0075\n",
      "Epoch [2/10], Step [835/1063], Loss: 0.0282\n",
      "Epoch [2/10], Step [836/1063], Loss: 0.0344\n",
      "Epoch [2/10], Step [837/1063], Loss: 0.1128\n",
      "Epoch [2/10], Step [838/1063], Loss: 0.0287\n",
      "Epoch [2/10], Step [839/1063], Loss: 0.0199\n",
      "Epoch [2/10], Step [840/1063], Loss: 0.0082\n",
      "Epoch [2/10], Step [841/1063], Loss: 0.0151\n",
      "Epoch [2/10], Step [842/1063], Loss: 0.0195\n",
      "Epoch [2/10], Step [843/1063], Loss: 0.0168\n",
      "Epoch [2/10], Step [844/1063], Loss: 0.0147\n",
      "Epoch [2/10], Step [845/1063], Loss: 0.0046\n",
      "Epoch [2/10], Step [846/1063], Loss: 0.0248\n",
      "Epoch [2/10], Step [847/1063], Loss: 0.0166\n",
      "Epoch [2/10], Step [848/1063], Loss: 0.0334\n",
      "Epoch [2/10], Step [849/1063], Loss: 0.0281\n",
      "Epoch [2/10], Step [850/1063], Loss: 0.0042\n",
      "Epoch [2/10], Step [851/1063], Loss: 0.0473\n",
      "Epoch [2/10], Step [852/1063], Loss: 0.0364\n",
      "Epoch [2/10], Step [853/1063], Loss: 0.0574\n",
      "Epoch [2/10], Step [854/1063], Loss: 0.0810\n",
      "Epoch [2/10], Step [855/1063], Loss: 0.0061\n",
      "Epoch [2/10], Step [856/1063], Loss: 0.0101\n",
      "Epoch [2/10], Step [857/1063], Loss: 0.0948\n",
      "Epoch [2/10], Step [858/1063], Loss: 0.1867\n",
      "Epoch [2/10], Step [859/1063], Loss: 0.1246\n",
      "Epoch [2/10], Step [860/1063], Loss: 0.0380\n",
      "Epoch [2/10], Step [861/1063], Loss: 0.0097\n",
      "Epoch [2/10], Step [862/1063], Loss: 0.0280\n",
      "Epoch [2/10], Step [863/1063], Loss: 0.0080\n",
      "Epoch [2/10], Step [864/1063], Loss: 0.0043\n",
      "Epoch [2/10], Step [865/1063], Loss: 0.0144\n",
      "Epoch [2/10], Step [866/1063], Loss: 0.1264\n",
      "Epoch [2/10], Step [867/1063], Loss: 0.1006\n",
      "Epoch [2/10], Step [868/1063], Loss: 0.0352\n",
      "Epoch [2/10], Step [869/1063], Loss: 0.0200\n",
      "Epoch [2/10], Step [870/1063], Loss: 0.0746\n",
      "Epoch [2/10], Step [871/1063], Loss: 0.0562\n",
      "Epoch [2/10], Step [872/1063], Loss: 0.0240\n",
      "Epoch [2/10], Step [873/1063], Loss: 0.0064\n",
      "Epoch [2/10], Step [874/1063], Loss: 0.0675\n",
      "Epoch [2/10], Step [875/1063], Loss: 0.0263\n",
      "Epoch [2/10], Step [876/1063], Loss: 0.0374\n",
      "Epoch [2/10], Step [877/1063], Loss: 0.0126\n",
      "Epoch [2/10], Step [878/1063], Loss: 0.1233\n",
      "Epoch [2/10], Step [879/1063], Loss: 0.0403\n",
      "Epoch [2/10], Step [880/1063], Loss: 0.0024\n",
      "Epoch [2/10], Step [881/1063], Loss: 0.0426\n",
      "Epoch [2/10], Step [882/1063], Loss: 0.0058\n",
      "Epoch [2/10], Step [883/1063], Loss: 0.0093\n",
      "Epoch [2/10], Step [884/1063], Loss: 0.0749\n",
      "Epoch [2/10], Step [885/1063], Loss: 0.1116\n",
      "Epoch [2/10], Step [886/1063], Loss: 0.1035\n",
      "Epoch [2/10], Step [887/1063], Loss: 0.0527\n",
      "Epoch [2/10], Step [888/1063], Loss: 0.0719\n",
      "Epoch [2/10], Step [889/1063], Loss: 0.0168\n",
      "Epoch [2/10], Step [890/1063], Loss: 0.0135\n",
      "Epoch [2/10], Step [891/1063], Loss: 0.1399\n",
      "Epoch [2/10], Step [892/1063], Loss: 0.0688\n",
      "Epoch [2/10], Step [893/1063], Loss: 0.0023\n",
      "Epoch [2/10], Step [894/1063], Loss: 0.0324\n",
      "Epoch [2/10], Step [895/1063], Loss: 0.0066\n",
      "Epoch [2/10], Step [896/1063], Loss: 0.0263\n",
      "Epoch [2/10], Step [897/1063], Loss: 0.0059\n",
      "Epoch [2/10], Step [898/1063], Loss: 0.0046\n",
      "Epoch [2/10], Step [899/1063], Loss: 0.0075\n",
      "Epoch [2/10], Step [900/1063], Loss: 0.1474\n",
      "Epoch [2/10], Step [901/1063], Loss: 0.0498\n",
      "Epoch [2/10], Step [902/1063], Loss: 0.0723\n",
      "Epoch [2/10], Step [903/1063], Loss: 0.0167\n",
      "Epoch [2/10], Step [904/1063], Loss: 0.0080\n",
      "Epoch [2/10], Step [905/1063], Loss: 0.0129\n",
      "Epoch [2/10], Step [906/1063], Loss: 0.0310\n",
      "Epoch [2/10], Step [907/1063], Loss: 0.0307\n",
      "Epoch [2/10], Step [908/1063], Loss: 0.1278\n",
      "Epoch [2/10], Step [909/1063], Loss: 0.0571\n",
      "Epoch [2/10], Step [910/1063], Loss: 0.0741\n",
      "Epoch [2/10], Step [911/1063], Loss: 0.0243\n",
      "Epoch [2/10], Step [912/1063], Loss: 0.0401\n",
      "Epoch [2/10], Step [913/1063], Loss: 0.0341\n",
      "Epoch [2/10], Step [914/1063], Loss: 0.0190\n",
      "Epoch [2/10], Step [915/1063], Loss: 0.0386\n",
      "Epoch [2/10], Step [916/1063], Loss: 0.0213\n",
      "Epoch [2/10], Step [917/1063], Loss: 0.1449\n",
      "Epoch [2/10], Step [918/1063], Loss: 0.0095\n",
      "Epoch [2/10], Step [919/1063], Loss: 0.0117\n",
      "Epoch [2/10], Step [920/1063], Loss: 0.0967\n",
      "Epoch [2/10], Step [921/1063], Loss: 0.0133\n",
      "Epoch [2/10], Step [922/1063], Loss: 0.0315\n",
      "Epoch [2/10], Step [923/1063], Loss: 0.0692\n",
      "Epoch [2/10], Step [924/1063], Loss: 0.0236\n",
      "Epoch [2/10], Step [925/1063], Loss: 0.0039\n",
      "Epoch [2/10], Step [926/1063], Loss: 0.0257\n",
      "Epoch [2/10], Step [927/1063], Loss: 0.0139\n",
      "Epoch [2/10], Step [928/1063], Loss: 0.0362\n",
      "Epoch [2/10], Step [929/1063], Loss: 0.0205\n",
      "Epoch [2/10], Step [930/1063], Loss: 0.0028\n",
      "Epoch [2/10], Step [931/1063], Loss: 0.0530\n",
      "Epoch [2/10], Step [932/1063], Loss: 0.0125\n",
      "Epoch [2/10], Step [933/1063], Loss: 0.0131\n",
      "Epoch [2/10], Step [934/1063], Loss: 0.1308\n",
      "Epoch [2/10], Step [935/1063], Loss: 0.0102\n",
      "Epoch [2/10], Step [936/1063], Loss: 0.0162\n",
      "Epoch [2/10], Step [937/1063], Loss: 0.0059\n",
      "Epoch [2/10], Step [938/1063], Loss: 0.0080\n",
      "Epoch [2/10], Step [939/1063], Loss: 0.0166\n",
      "Epoch [2/10], Step [940/1063], Loss: 0.0944\n",
      "Epoch [2/10], Step [941/1063], Loss: 0.0156\n",
      "Epoch [2/10], Step [942/1063], Loss: 0.0442\n",
      "Epoch [2/10], Step [943/1063], Loss: 0.0165\n",
      "Epoch [2/10], Step [944/1063], Loss: 0.0185\n",
      "Epoch [2/10], Step [945/1063], Loss: 0.0714\n",
      "Epoch [2/10], Step [946/1063], Loss: 0.0461\n",
      "Epoch [2/10], Step [947/1063], Loss: 0.1051\n",
      "Epoch [2/10], Step [948/1063], Loss: 0.0469\n",
      "Epoch [2/10], Step [949/1063], Loss: 0.0386\n",
      "Epoch [2/10], Step [950/1063], Loss: 0.0623\n",
      "Epoch [2/10], Step [951/1063], Loss: 0.0420\n",
      "Epoch [2/10], Step [952/1063], Loss: 0.0095\n",
      "Epoch [2/10], Step [953/1063], Loss: 0.0097\n",
      "Epoch [2/10], Step [954/1063], Loss: 0.0662\n",
      "Epoch [2/10], Step [955/1063], Loss: 0.0552\n",
      "Epoch [2/10], Step [956/1063], Loss: 0.0864\n",
      "Epoch [2/10], Step [957/1063], Loss: 0.0183\n",
      "Epoch [2/10], Step [958/1063], Loss: 0.1625\n",
      "Epoch [2/10], Step [959/1063], Loss: 0.0222\n",
      "Epoch [2/10], Step [960/1063], Loss: 0.0712\n",
      "Epoch [2/10], Step [961/1063], Loss: 0.0238\n",
      "Epoch [2/10], Step [962/1063], Loss: 0.0225\n",
      "Epoch [2/10], Step [963/1063], Loss: 0.0066\n",
      "Epoch [2/10], Step [964/1063], Loss: 0.0059\n",
      "Epoch [2/10], Step [965/1063], Loss: 0.0075\n",
      "Epoch [2/10], Step [966/1063], Loss: 0.0673\n",
      "Epoch [2/10], Step [967/1063], Loss: 0.0363\n",
      "Epoch [2/10], Step [968/1063], Loss: 0.0275\n",
      "Epoch [2/10], Step [969/1063], Loss: 0.0199\n",
      "Epoch [2/10], Step [970/1063], Loss: 0.0168\n",
      "Epoch [2/10], Step [971/1063], Loss: 0.1165\n",
      "Epoch [2/10], Step [972/1063], Loss: 0.0048\n",
      "Epoch [2/10], Step [973/1063], Loss: 0.0209\n",
      "Epoch [2/10], Step [974/1063], Loss: 0.0032\n",
      "Epoch [2/10], Step [975/1063], Loss: 0.0751\n",
      "Epoch [2/10], Step [976/1063], Loss: 0.0101\n",
      "Epoch [2/10], Step [977/1063], Loss: 0.0116\n",
      "Epoch [2/10], Step [978/1063], Loss: 0.2140\n",
      "Epoch [2/10], Step [979/1063], Loss: 0.0181\n",
      "Epoch [2/10], Step [980/1063], Loss: 0.0647\n",
      "Epoch [2/10], Step [981/1063], Loss: 0.0507\n",
      "Epoch [2/10], Step [982/1063], Loss: 0.0033\n",
      "Epoch [2/10], Step [983/1063], Loss: 0.0029\n",
      "Epoch [2/10], Step [984/1063], Loss: 0.0155\n",
      "Epoch [2/10], Step [985/1063], Loss: 0.0321\n",
      "Epoch [2/10], Step [986/1063], Loss: 0.1568\n",
      "Epoch [2/10], Step [987/1063], Loss: 0.0274\n",
      "Epoch [2/10], Step [988/1063], Loss: 0.0524\n",
      "Epoch [2/10], Step [989/1063], Loss: 0.0051\n",
      "Epoch [2/10], Step [990/1063], Loss: 0.1352\n",
      "Epoch [2/10], Step [991/1063], Loss: 0.0070\n",
      "Epoch [2/10], Step [992/1063], Loss: 0.0319\n",
      "Epoch [2/10], Step [993/1063], Loss: 0.0777\n",
      "Epoch [2/10], Step [994/1063], Loss: 0.0648\n",
      "Epoch [2/10], Step [995/1063], Loss: 0.0447\n",
      "Epoch [2/10], Step [996/1063], Loss: 0.0052\n",
      "Epoch [2/10], Step [997/1063], Loss: 0.0056\n",
      "Epoch [2/10], Step [998/1063], Loss: 0.0051\n",
      "Epoch [2/10], Step [999/1063], Loss: 0.0218\n",
      "Epoch [2/10], Step [1000/1063], Loss: 0.0773\n",
      "Epoch [2/10], Step [1001/1063], Loss: 0.0156\n",
      "Epoch [2/10], Step [1002/1063], Loss: 0.0709\n",
      "Epoch [2/10], Step [1003/1063], Loss: 0.0364\n",
      "Epoch [2/10], Step [1004/1063], Loss: 0.0384\n",
      "Epoch [2/10], Step [1005/1063], Loss: 0.0421\n",
      "Epoch [2/10], Step [1006/1063], Loss: 0.0680\n",
      "Epoch [2/10], Step [1007/1063], Loss: 0.0525\n",
      "Epoch [2/10], Step [1008/1063], Loss: 0.0242\n",
      "Epoch [2/10], Step [1009/1063], Loss: 0.0058\n",
      "Epoch [2/10], Step [1010/1063], Loss: 0.0158\n",
      "Epoch [2/10], Step [1011/1063], Loss: 0.0495\n",
      "Epoch [2/10], Step [1012/1063], Loss: 0.0101\n",
      "Epoch [2/10], Step [1013/1063], Loss: 0.0096\n",
      "Epoch [2/10], Step [1014/1063], Loss: 0.1998\n",
      "Epoch [2/10], Step [1015/1063], Loss: 0.0901\n",
      "Epoch [2/10], Step [1016/1063], Loss: 0.0465\n",
      "Epoch [2/10], Step [1017/1063], Loss: 0.1153\n",
      "Epoch [2/10], Step [1018/1063], Loss: 0.0787\n",
      "Epoch [2/10], Step [1019/1063], Loss: 0.0699\n",
      "Epoch [2/10], Step [1020/1063], Loss: 0.0615\n",
      "Epoch [2/10], Step [1021/1063], Loss: 0.0890\n",
      "Epoch [2/10], Step [1022/1063], Loss: 0.0823\n",
      "Epoch [2/10], Step [1023/1063], Loss: 0.0151\n",
      "Epoch [2/10], Step [1024/1063], Loss: 0.0343\n",
      "Epoch [2/10], Step [1025/1063], Loss: 0.1068\n",
      "Epoch [2/10], Step [1026/1063], Loss: 0.0274\n",
      "Epoch [2/10], Step [1027/1063], Loss: 0.0509\n",
      "Epoch [2/10], Step [1028/1063], Loss: 0.0198\n",
      "Epoch [2/10], Step [1029/1063], Loss: 0.0883\n",
      "Epoch [2/10], Step [1030/1063], Loss: 0.0137\n",
      "Epoch [2/10], Step [1031/1063], Loss: 0.0246\n",
      "Epoch [2/10], Step [1032/1063], Loss: 0.0124\n",
      "Epoch [2/10], Step [1033/1063], Loss: 0.0103\n",
      "Epoch [2/10], Step [1034/1063], Loss: 0.0777\n",
      "Epoch [2/10], Step [1035/1063], Loss: 0.0584\n",
      "Epoch [2/10], Step [1036/1063], Loss: 0.0109\n",
      "Epoch [2/10], Step [1037/1063], Loss: 0.0333\n",
      "Epoch [2/10], Step [1038/1063], Loss: 0.0201\n",
      "Epoch [2/10], Step [1039/1063], Loss: 0.0263\n",
      "Epoch [2/10], Step [1040/1063], Loss: 0.0346\n",
      "Epoch [2/10], Step [1041/1063], Loss: 0.0251\n",
      "Epoch [2/10], Step [1042/1063], Loss: 0.0484\n",
      "Epoch [2/10], Step [1043/1063], Loss: 0.0098\n",
      "Epoch [2/10], Step [1044/1063], Loss: 0.0084\n",
      "Epoch [2/10], Step [1045/1063], Loss: 0.0458\n",
      "Epoch [2/10], Step [1046/1063], Loss: 0.0117\n",
      "Epoch [2/10], Step [1047/1063], Loss: 0.0462\n",
      "Epoch [2/10], Step [1048/1063], Loss: 0.0579\n",
      "Epoch [2/10], Step [1049/1063], Loss: 0.1753\n",
      "Epoch [2/10], Step [1050/1063], Loss: 0.0264\n",
      "Epoch [2/10], Step [1051/1063], Loss: 0.0361\n",
      "Epoch [2/10], Step [1052/1063], Loss: 0.0099\n",
      "Epoch [2/10], Step [1053/1063], Loss: 0.0480\n",
      "Epoch [2/10], Step [1054/1063], Loss: 0.0233\n",
      "Epoch [2/10], Step [1055/1063], Loss: 0.0212\n",
      "Epoch [2/10], Step [1056/1063], Loss: 0.0945\n",
      "Epoch [2/10], Step [1057/1063], Loss: 0.0301\n",
      "Epoch [2/10], Step [1058/1063], Loss: 0.0236\n",
      "Epoch [2/10], Step [1059/1063], Loss: 0.0224\n",
      "Epoch [2/10], Step [1060/1063], Loss: 0.0463\n",
      "Epoch [2/10], Step [1061/1063], Loss: 0.0307\n",
      "Epoch [2/10], Step [1062/1063], Loss: 0.0063\n",
      "Epoch [2/10], Step [1063/1063], Loss: 0.0067\n",
      "Epoch [3/10], Step [1/1063], Loss: 0.0089\n",
      "Epoch [3/10], Step [2/1063], Loss: 0.0184\n",
      "Epoch [3/10], Step [3/1063], Loss: 0.0674\n",
      "Epoch [3/10], Step [4/1063], Loss: 0.0064\n",
      "Epoch [3/10], Step [5/1063], Loss: 0.0496\n",
      "Epoch [3/10], Step [6/1063], Loss: 0.0078\n",
      "Epoch [3/10], Step [7/1063], Loss: 0.0048\n",
      "Epoch [3/10], Step [8/1063], Loss: 0.0195\n",
      "Epoch [3/10], Step [9/1063], Loss: 0.0193\n",
      "Epoch [3/10], Step [10/1063], Loss: 0.0614\n",
      "Epoch [3/10], Step [11/1063], Loss: 0.0162\n",
      "Epoch [3/10], Step [12/1063], Loss: 0.0034\n",
      "Epoch [3/10], Step [13/1063], Loss: 0.0169\n",
      "Epoch [3/10], Step [14/1063], Loss: 0.0044\n",
      "Epoch [3/10], Step [15/1063], Loss: 0.1033\n",
      "Epoch [3/10], Step [16/1063], Loss: 0.0520\n",
      "Epoch [3/10], Step [17/1063], Loss: 0.0678\n",
      "Epoch [3/10], Step [18/1063], Loss: 0.0051\n",
      "Epoch [3/10], Step [19/1063], Loss: 0.0074\n",
      "Epoch [3/10], Step [20/1063], Loss: 0.0075\n",
      "Epoch [3/10], Step [21/1063], Loss: 0.0345\n",
      "Epoch [3/10], Step [22/1063], Loss: 0.0192\n",
      "Epoch [3/10], Step [23/1063], Loss: 0.0446\n",
      "Epoch [3/10], Step [24/1063], Loss: 0.1171\n",
      "Epoch [3/10], Step [25/1063], Loss: 0.0093\n",
      "Epoch [3/10], Step [26/1063], Loss: 0.0432\n",
      "Epoch [3/10], Step [27/1063], Loss: 0.0366\n",
      "Epoch [3/10], Step [28/1063], Loss: 0.0191\n",
      "Epoch [3/10], Step [29/1063], Loss: 0.0080\n",
      "Epoch [3/10], Step [30/1063], Loss: 0.0117\n",
      "Epoch [3/10], Step [31/1063], Loss: 0.0367\n",
      "Epoch [3/10], Step [32/1063], Loss: 0.0129\n",
      "Epoch [3/10], Step [33/1063], Loss: 0.0112\n",
      "Epoch [3/10], Step [34/1063], Loss: 0.1207\n",
      "Epoch [3/10], Step [35/1063], Loss: 0.0369\n",
      "Epoch [3/10], Step [36/1063], Loss: 0.0358\n",
      "Epoch [3/10], Step [37/1063], Loss: 0.0663\n",
      "Epoch [3/10], Step [38/1063], Loss: 0.0838\n",
      "Epoch [3/10], Step [39/1063], Loss: 0.0272\n",
      "Epoch [3/10], Step [40/1063], Loss: 0.0393\n",
      "Epoch [3/10], Step [41/1063], Loss: 0.0245\n",
      "Epoch [3/10], Step [42/1063], Loss: 0.0058\n",
      "Epoch [3/10], Step [43/1063], Loss: 0.0671\n",
      "Epoch [3/10], Step [44/1063], Loss: 0.0858\n",
      "Epoch [3/10], Step [45/1063], Loss: 0.0771\n",
      "Epoch [3/10], Step [46/1063], Loss: 0.0117\n",
      "Epoch [3/10], Step [47/1063], Loss: 0.0459\n",
      "Epoch [3/10], Step [48/1063], Loss: 0.0603\n",
      "Epoch [3/10], Step [49/1063], Loss: 0.0428\n",
      "Epoch [3/10], Step [50/1063], Loss: 0.0125\n",
      "Epoch [3/10], Step [51/1063], Loss: 0.0168\n",
      "Epoch [3/10], Step [52/1063], Loss: 0.0403\n",
      "Epoch [3/10], Step [53/1063], Loss: 0.0198\n",
      "Epoch [3/10], Step [54/1063], Loss: 0.0062\n",
      "Epoch [3/10], Step [55/1063], Loss: 0.0027\n",
      "Epoch [3/10], Step [56/1063], Loss: 0.0383\n",
      "Epoch [3/10], Step [57/1063], Loss: 0.0230\n",
      "Epoch [3/10], Step [58/1063], Loss: 0.0175\n",
      "Epoch [3/10], Step [59/1063], Loss: 0.0537\n",
      "Epoch [3/10], Step [60/1063], Loss: 0.0022\n",
      "Epoch [3/10], Step [61/1063], Loss: 0.0184\n",
      "Epoch [3/10], Step [62/1063], Loss: 0.0202\n",
      "Epoch [3/10], Step [63/1063], Loss: 0.0125\n",
      "Epoch [3/10], Step [64/1063], Loss: 0.0099\n",
      "Epoch [3/10], Step [65/1063], Loss: 0.0197\n",
      "Epoch [3/10], Step [66/1063], Loss: 0.0087\n",
      "Epoch [3/10], Step [67/1063], Loss: 0.0349\n",
      "Epoch [3/10], Step [68/1063], Loss: 0.0440\n",
      "Epoch [3/10], Step [69/1063], Loss: 0.0151\n",
      "Epoch [3/10], Step [70/1063], Loss: 0.0296\n",
      "Epoch [3/10], Step [71/1063], Loss: 0.0078\n",
      "Epoch [3/10], Step [72/1063], Loss: 0.0370\n",
      "Epoch [3/10], Step [73/1063], Loss: 0.0082\n",
      "Epoch [3/10], Step [74/1063], Loss: 0.0496\n",
      "Epoch [3/10], Step [75/1063], Loss: 0.0029\n",
      "Epoch [3/10], Step [76/1063], Loss: 0.0149\n",
      "Epoch [3/10], Step [77/1063], Loss: 0.0299\n",
      "Epoch [3/10], Step [78/1063], Loss: 0.0036\n",
      "Epoch [3/10], Step [79/1063], Loss: 0.0193\n",
      "Epoch [3/10], Step [80/1063], Loss: 0.0137\n",
      "Epoch [3/10], Step [81/1063], Loss: 0.0040\n",
      "Epoch [3/10], Step [82/1063], Loss: 0.0454\n",
      "Epoch [3/10], Step [83/1063], Loss: 0.0102\n",
      "Epoch [3/10], Step [84/1063], Loss: 0.0928\n",
      "Epoch [3/10], Step [85/1063], Loss: 0.0300\n",
      "Epoch [3/10], Step [86/1063], Loss: 0.1209\n",
      "Epoch [3/10], Step [87/1063], Loss: 0.0054\n",
      "Epoch [3/10], Step [88/1063], Loss: 0.0327\n",
      "Epoch [3/10], Step [89/1063], Loss: 0.0014\n",
      "Epoch [3/10], Step [90/1063], Loss: 0.0137\n",
      "Epoch [3/10], Step [91/1063], Loss: 0.0114\n",
      "Epoch [3/10], Step [92/1063], Loss: 0.0469\n",
      "Epoch [3/10], Step [93/1063], Loss: 0.0160\n",
      "Epoch [3/10], Step [94/1063], Loss: 0.0014\n",
      "Epoch [3/10], Step [95/1063], Loss: 0.0334\n",
      "Epoch [3/10], Step [96/1063], Loss: 0.0060\n",
      "Epoch [3/10], Step [97/1063], Loss: 0.1205\n",
      "Epoch [3/10], Step [98/1063], Loss: 0.0150\n",
      "Epoch [3/10], Step [99/1063], Loss: 0.0028\n",
      "Epoch [3/10], Step [100/1063], Loss: 0.0035\n",
      "Epoch [3/10], Step [101/1063], Loss: 0.0053\n",
      "Epoch [3/10], Step [102/1063], Loss: 0.0102\n",
      "Epoch [3/10], Step [103/1063], Loss: 0.0025\n",
      "Epoch [3/10], Step [104/1063], Loss: 0.0614\n",
      "Epoch [3/10], Step [105/1063], Loss: 0.2773\n",
      "Epoch [3/10], Step [106/1063], Loss: 0.0033\n",
      "Epoch [3/10], Step [107/1063], Loss: 0.0801\n",
      "Epoch [3/10], Step [108/1063], Loss: 0.0405\n",
      "Epoch [3/10], Step [109/1063], Loss: 0.0362\n",
      "Epoch [3/10], Step [110/1063], Loss: 0.0375\n",
      "Epoch [3/10], Step [111/1063], Loss: 0.0605\n",
      "Epoch [3/10], Step [112/1063], Loss: 0.0122\n",
      "Epoch [3/10], Step [113/1063], Loss: 0.0344\n",
      "Epoch [3/10], Step [114/1063], Loss: 0.0649\n",
      "Epoch [3/10], Step [115/1063], Loss: 0.0200\n",
      "Epoch [3/10], Step [116/1063], Loss: 0.0059\n",
      "Epoch [3/10], Step [117/1063], Loss: 0.0119\n",
      "Epoch [3/10], Step [118/1063], Loss: 0.0120\n",
      "Epoch [3/10], Step [119/1063], Loss: 0.0081\n",
      "Epoch [3/10], Step [120/1063], Loss: 0.0735\n",
      "Epoch [3/10], Step [121/1063], Loss: 0.0184\n",
      "Epoch [3/10], Step [122/1063], Loss: 0.0061\n",
      "Epoch [3/10], Step [123/1063], Loss: 0.0371\n",
      "Epoch [3/10], Step [124/1063], Loss: 0.0061\n",
      "Epoch [3/10], Step [125/1063], Loss: 0.0105\n",
      "Epoch [3/10], Step [126/1063], Loss: 0.0595\n",
      "Epoch [3/10], Step [127/1063], Loss: 0.0071\n",
      "Epoch [3/10], Step [128/1063], Loss: 0.0051\n",
      "Epoch [3/10], Step [129/1063], Loss: 0.0532\n",
      "Epoch [3/10], Step [130/1063], Loss: 0.0267\n",
      "Epoch [3/10], Step [131/1063], Loss: 0.0090\n",
      "Epoch [3/10], Step [132/1063], Loss: 0.0167\n",
      "Epoch [3/10], Step [133/1063], Loss: 0.0036\n",
      "Epoch [3/10], Step [134/1063], Loss: 0.0051\n",
      "Epoch [3/10], Step [135/1063], Loss: 0.0760\n",
      "Epoch [3/10], Step [136/1063], Loss: 0.0410\n",
      "Epoch [3/10], Step [137/1063], Loss: 0.0043\n",
      "Epoch [3/10], Step [138/1063], Loss: 0.0928\n",
      "Epoch [3/10], Step [139/1063], Loss: 0.0166\n",
      "Epoch [3/10], Step [140/1063], Loss: 0.0147\n",
      "Epoch [3/10], Step [141/1063], Loss: 0.0577\n",
      "Epoch [3/10], Step [142/1063], Loss: 0.0236\n",
      "Epoch [3/10], Step [143/1063], Loss: 0.0041\n",
      "Epoch [3/10], Step [144/1063], Loss: 0.0285\n",
      "Epoch [3/10], Step [145/1063], Loss: 0.0154\n",
      "Epoch [3/10], Step [146/1063], Loss: 0.0186\n",
      "Epoch [3/10], Step [147/1063], Loss: 0.0031\n",
      "Epoch [3/10], Step [148/1063], Loss: 0.0563\n",
      "Epoch [3/10], Step [149/1063], Loss: 0.0108\n",
      "Epoch [3/10], Step [150/1063], Loss: 0.0021\n",
      "Epoch [3/10], Step [151/1063], Loss: 0.0093\n",
      "Epoch [3/10], Step [152/1063], Loss: 0.0019\n",
      "Epoch [3/10], Step [153/1063], Loss: 0.0237\n",
      "Epoch [3/10], Step [154/1063], Loss: 0.0572\n",
      "Epoch [3/10], Step [155/1063], Loss: 0.1254\n",
      "Epoch [3/10], Step [156/1063], Loss: 0.0084\n",
      "Epoch [3/10], Step [157/1063], Loss: 0.0064\n",
      "Epoch [3/10], Step [158/1063], Loss: 0.0363\n",
      "Epoch [3/10], Step [159/1063], Loss: 0.0102\n",
      "Epoch [3/10], Step [160/1063], Loss: 0.0702\n",
      "Epoch [3/10], Step [161/1063], Loss: 0.0136\n",
      "Epoch [3/10], Step [162/1063], Loss: 0.0261\n",
      "Epoch [3/10], Step [163/1063], Loss: 0.2037\n",
      "Epoch [3/10], Step [164/1063], Loss: 0.0109\n",
      "Epoch [3/10], Step [165/1063], Loss: 0.0560\n",
      "Epoch [3/10], Step [166/1063], Loss: 0.0018\n",
      "Epoch [3/10], Step [167/1063], Loss: 0.0123\n",
      "Epoch [3/10], Step [168/1063], Loss: 0.0175\n",
      "Epoch [3/10], Step [169/1063], Loss: 0.0428\n",
      "Epoch [3/10], Step [170/1063], Loss: 0.0249\n",
      "Epoch [3/10], Step [171/1063], Loss: 0.0088\n",
      "Epoch [3/10], Step [172/1063], Loss: 0.0240\n",
      "Epoch [3/10], Step [173/1063], Loss: 0.0192\n",
      "Epoch [3/10], Step [174/1063], Loss: 0.0098\n",
      "Epoch [3/10], Step [175/1063], Loss: 0.0523\n",
      "Epoch [3/10], Step [176/1063], Loss: 0.0281\n",
      "Epoch [3/10], Step [177/1063], Loss: 0.0263\n",
      "Epoch [3/10], Step [178/1063], Loss: 0.0218\n",
      "Epoch [3/10], Step [179/1063], Loss: 0.0368\n",
      "Epoch [3/10], Step [180/1063], Loss: 0.0057\n",
      "Epoch [3/10], Step [181/1063], Loss: 0.0332\n",
      "Epoch [3/10], Step [182/1063], Loss: 0.0299\n",
      "Epoch [3/10], Step [183/1063], Loss: 0.0073\n",
      "Epoch [3/10], Step [184/1063], Loss: 0.0087\n",
      "Epoch [3/10], Step [185/1063], Loss: 0.0434\n",
      "Epoch [3/10], Step [186/1063], Loss: 0.0042\n",
      "Epoch [3/10], Step [187/1063], Loss: 0.0039\n",
      "Epoch [3/10], Step [188/1063], Loss: 0.0118\n",
      "Epoch [3/10], Step [189/1063], Loss: 0.0177\n",
      "Epoch [3/10], Step [190/1063], Loss: 0.0038\n",
      "Epoch [3/10], Step [191/1063], Loss: 0.0280\n",
      "Epoch [3/10], Step [192/1063], Loss: 0.0425\n",
      "Epoch [3/10], Step [193/1063], Loss: 0.0352\n",
      "Epoch [3/10], Step [194/1063], Loss: 0.0163\n",
      "Epoch [3/10], Step [195/1063], Loss: 0.0086\n",
      "Epoch [3/10], Step [196/1063], Loss: 0.1290\n",
      "Epoch [3/10], Step [197/1063], Loss: 0.0027\n",
      "Epoch [3/10], Step [198/1063], Loss: 0.0494\n",
      "Epoch [3/10], Step [199/1063], Loss: 0.0048\n",
      "Epoch [3/10], Step [200/1063], Loss: 0.0156\n",
      "Epoch [3/10], Step [201/1063], Loss: 0.0057\n",
      "Epoch [3/10], Step [202/1063], Loss: 0.0389\n",
      "Epoch [3/10], Step [203/1063], Loss: 0.0132\n",
      "Epoch [3/10], Step [204/1063], Loss: 0.0076\n",
      "Epoch [3/10], Step [205/1063], Loss: 0.1232\n",
      "Epoch [3/10], Step [206/1063], Loss: 0.0057\n",
      "Epoch [3/10], Step [207/1063], Loss: 0.0184\n",
      "Epoch [3/10], Step [208/1063], Loss: 0.0003\n",
      "Epoch [3/10], Step [209/1063], Loss: 0.0063\n",
      "Epoch [3/10], Step [210/1063], Loss: 0.0032\n",
      "Epoch [3/10], Step [211/1063], Loss: 0.0107\n",
      "Epoch [3/10], Step [212/1063], Loss: 0.0761\n",
      "Epoch [3/10], Step [213/1063], Loss: 0.0056\n",
      "Epoch [3/10], Step [214/1063], Loss: 0.0542\n",
      "Epoch [3/10], Step [215/1063], Loss: 0.1023\n",
      "Epoch [3/10], Step [216/1063], Loss: 0.0016\n",
      "Epoch [3/10], Step [217/1063], Loss: 0.0068\n",
      "Epoch [3/10], Step [218/1063], Loss: 0.0077\n",
      "Epoch [3/10], Step [219/1063], Loss: 0.0831\n",
      "Epoch [3/10], Step [220/1063], Loss: 0.0168\n",
      "Epoch [3/10], Step [221/1063], Loss: 0.0295\n",
      "Epoch [3/10], Step [222/1063], Loss: 0.0049\n",
      "Epoch [3/10], Step [223/1063], Loss: 0.0292\n",
      "Epoch [3/10], Step [224/1063], Loss: 0.0575\n",
      "Epoch [3/10], Step [225/1063], Loss: 0.0207\n",
      "Epoch [3/10], Step [226/1063], Loss: 0.0665\n",
      "Epoch [3/10], Step [227/1063], Loss: 0.0048\n",
      "Epoch [3/10], Step [228/1063], Loss: 0.0177\n",
      "Epoch [3/10], Step [229/1063], Loss: 0.1047\n",
      "Epoch [3/10], Step [230/1063], Loss: 0.0216\n",
      "Epoch [3/10], Step [231/1063], Loss: 0.0268\n",
      "Epoch [3/10], Step [232/1063], Loss: 0.0052\n",
      "Epoch [3/10], Step [233/1063], Loss: 0.0750\n",
      "Epoch [3/10], Step [234/1063], Loss: 0.0197\n",
      "Epoch [3/10], Step [235/1063], Loss: 0.0984\n",
      "Epoch [3/10], Step [236/1063], Loss: 0.0190\n",
      "Epoch [3/10], Step [237/1063], Loss: 0.0893\n",
      "Epoch [3/10], Step [238/1063], Loss: 0.0778\n",
      "Epoch [3/10], Step [239/1063], Loss: 0.0063\n",
      "Epoch [3/10], Step [240/1063], Loss: 0.0092\n",
      "Epoch [3/10], Step [241/1063], Loss: 0.0319\n",
      "Epoch [3/10], Step [242/1063], Loss: 0.0282\n",
      "Epoch [3/10], Step [243/1063], Loss: 0.0121\n",
      "Epoch [3/10], Step [244/1063], Loss: 0.0140\n",
      "Epoch [3/10], Step [245/1063], Loss: 0.0211\n",
      "Epoch [3/10], Step [246/1063], Loss: 0.0114\n",
      "Epoch [3/10], Step [247/1063], Loss: 0.0066\n",
      "Epoch [3/10], Step [248/1063], Loss: 0.0416\n",
      "Epoch [3/10], Step [249/1063], Loss: 0.0560\n",
      "Epoch [3/10], Step [250/1063], Loss: 0.0103\n",
      "Epoch [3/10], Step [251/1063], Loss: 0.0228\n",
      "Epoch [3/10], Step [252/1063], Loss: 0.0118\n",
      "Epoch [3/10], Step [253/1063], Loss: 0.0262\n",
      "Epoch [3/10], Step [254/1063], Loss: 0.0158\n",
      "Epoch [3/10], Step [255/1063], Loss: 0.0640\n",
      "Epoch [3/10], Step [256/1063], Loss: 0.0131\n",
      "Epoch [3/10], Step [257/1063], Loss: 0.0732\n",
      "Epoch [3/10], Step [258/1063], Loss: 0.0347\n",
      "Epoch [3/10], Step [259/1063], Loss: 0.1190\n",
      "Epoch [3/10], Step [260/1063], Loss: 0.0035\n",
      "Epoch [3/10], Step [261/1063], Loss: 0.0503\n",
      "Epoch [3/10], Step [262/1063], Loss: 0.0558\n",
      "Epoch [3/10], Step [263/1063], Loss: 0.0510\n",
      "Epoch [3/10], Step [264/1063], Loss: 0.0059\n",
      "Epoch [3/10], Step [265/1063], Loss: 0.0193\n",
      "Epoch [3/10], Step [266/1063], Loss: 0.0562\n",
      "Epoch [3/10], Step [267/1063], Loss: 0.0065\n",
      "Epoch [3/10], Step [268/1063], Loss: 0.0767\n",
      "Epoch [3/10], Step [269/1063], Loss: 0.0044\n",
      "Epoch [3/10], Step [270/1063], Loss: 0.0355\n",
      "Epoch [3/10], Step [271/1063], Loss: 0.1347\n",
      "Epoch [3/10], Step [272/1063], Loss: 0.0511\n",
      "Epoch [3/10], Step [273/1063], Loss: 0.0383\n",
      "Epoch [3/10], Step [274/1063], Loss: 0.0623\n",
      "Epoch [3/10], Step [275/1063], Loss: 0.0123\n",
      "Epoch [3/10], Step [276/1063], Loss: 0.0237\n",
      "Epoch [3/10], Step [277/1063], Loss: 0.0094\n",
      "Epoch [3/10], Step [278/1063], Loss: 0.0057\n",
      "Epoch [3/10], Step [279/1063], Loss: 0.0439\n",
      "Epoch [3/10], Step [280/1063], Loss: 0.0878\n",
      "Epoch [3/10], Step [281/1063], Loss: 0.0322\n",
      "Epoch [3/10], Step [282/1063], Loss: 0.0157\n",
      "Epoch [3/10], Step [283/1063], Loss: 0.0068\n",
      "Epoch [3/10], Step [284/1063], Loss: 0.0042\n",
      "Epoch [3/10], Step [285/1063], Loss: 0.0146\n",
      "Epoch [3/10], Step [286/1063], Loss: 0.1777\n",
      "Epoch [3/10], Step [287/1063], Loss: 0.0399\n",
      "Epoch [3/10], Step [288/1063], Loss: 0.0598\n",
      "Epoch [3/10], Step [289/1063], Loss: 0.0280\n",
      "Epoch [3/10], Step [290/1063], Loss: 0.0045\n",
      "Epoch [3/10], Step [291/1063], Loss: 0.0684\n",
      "Epoch [3/10], Step [292/1063], Loss: 0.1106\n",
      "Epoch [3/10], Step [293/1063], Loss: 0.0339\n",
      "Epoch [3/10], Step [294/1063], Loss: 0.0054\n",
      "Epoch [3/10], Step [295/1063], Loss: 0.0476\n",
      "Epoch [3/10], Step [296/1063], Loss: 0.0066\n",
      "Epoch [3/10], Step [297/1063], Loss: 0.0044\n",
      "Epoch [3/10], Step [298/1063], Loss: 0.0867\n",
      "Epoch [3/10], Step [299/1063], Loss: 0.0035\n",
      "Epoch [3/10], Step [300/1063], Loss: 0.0211\n",
      "Epoch [3/10], Step [301/1063], Loss: 0.0607\n",
      "Epoch [3/10], Step [302/1063], Loss: 0.0118\n",
      "Epoch [3/10], Step [303/1063], Loss: 0.0084\n",
      "Epoch [3/10], Step [304/1063], Loss: 0.0731\n",
      "Epoch [3/10], Step [305/1063], Loss: 0.0120\n",
      "Epoch [3/10], Step [306/1063], Loss: 0.0027\n",
      "Epoch [3/10], Step [307/1063], Loss: 0.0147\n",
      "Epoch [3/10], Step [308/1063], Loss: 0.0204\n",
      "Epoch [3/10], Step [309/1063], Loss: 0.0341\n",
      "Epoch [3/10], Step [310/1063], Loss: 0.0534\n",
      "Epoch [3/10], Step [311/1063], Loss: 0.0452\n",
      "Epoch [3/10], Step [312/1063], Loss: 0.1345\n",
      "Epoch [3/10], Step [313/1063], Loss: 0.0283\n",
      "Epoch [3/10], Step [314/1063], Loss: 0.0314\n",
      "Epoch [3/10], Step [315/1063], Loss: 0.0323\n",
      "Epoch [3/10], Step [316/1063], Loss: 0.0589\n",
      "Epoch [3/10], Step [317/1063], Loss: 0.0443\n",
      "Epoch [3/10], Step [318/1063], Loss: 0.0119\n",
      "Epoch [3/10], Step [319/1063], Loss: 0.0182\n",
      "Epoch [3/10], Step [320/1063], Loss: 0.0208\n",
      "Epoch [3/10], Step [321/1063], Loss: 0.0104\n",
      "Epoch [3/10], Step [322/1063], Loss: 0.0377\n",
      "Epoch [3/10], Step [323/1063], Loss: 0.0546\n",
      "Epoch [3/10], Step [324/1063], Loss: 0.0957\n",
      "Epoch [3/10], Step [325/1063], Loss: 0.0860\n",
      "Epoch [3/10], Step [326/1063], Loss: 0.0049\n",
      "Epoch [3/10], Step [327/1063], Loss: 0.0037\n",
      "Epoch [3/10], Step [328/1063], Loss: 0.0320\n",
      "Epoch [3/10], Step [329/1063], Loss: 0.0988\n",
      "Epoch [3/10], Step [330/1063], Loss: 0.0738\n",
      "Epoch [3/10], Step [331/1063], Loss: 0.0805\n",
      "Epoch [3/10], Step [332/1063], Loss: 0.0337\n",
      "Epoch [3/10], Step [333/1063], Loss: 0.1081\n",
      "Epoch [3/10], Step [334/1063], Loss: 0.0230\n",
      "Epoch [3/10], Step [335/1063], Loss: 0.0533\n",
      "Epoch [3/10], Step [336/1063], Loss: 0.0441\n",
      "Epoch [3/10], Step [337/1063], Loss: 0.0037\n",
      "Epoch [3/10], Step [338/1063], Loss: 0.0090\n",
      "Epoch [3/10], Step [339/1063], Loss: 0.0138\n",
      "Epoch [3/10], Step [340/1063], Loss: 0.0082\n",
      "Epoch [3/10], Step [341/1063], Loss: 0.0223\n",
      "Epoch [3/10], Step [342/1063], Loss: 0.0048\n",
      "Epoch [3/10], Step [343/1063], Loss: 0.0188\n",
      "Epoch [3/10], Step [344/1063], Loss: 0.0222\n",
      "Epoch [3/10], Step [345/1063], Loss: 0.0162\n",
      "Epoch [3/10], Step [346/1063], Loss: 0.0136\n",
      "Epoch [3/10], Step [347/1063], Loss: 0.0928\n",
      "Epoch [3/10], Step [348/1063], Loss: 0.0040\n",
      "Epoch [3/10], Step [349/1063], Loss: 0.0222\n",
      "Epoch [3/10], Step [350/1063], Loss: 0.0029\n",
      "Epoch [3/10], Step [351/1063], Loss: 0.0315\n",
      "Epoch [3/10], Step [352/1063], Loss: 0.0304\n",
      "Epoch [3/10], Step [353/1063], Loss: 0.0348\n",
      "Epoch [3/10], Step [354/1063], Loss: 0.0146\n",
      "Epoch [3/10], Step [355/1063], Loss: 0.0140\n",
      "Epoch [3/10], Step [356/1063], Loss: 0.0084\n",
      "Epoch [3/10], Step [357/1063], Loss: 0.0686\n",
      "Epoch [3/10], Step [358/1063], Loss: 0.0054\n",
      "Epoch [3/10], Step [359/1063], Loss: 0.0016\n",
      "Epoch [3/10], Step [360/1063], Loss: 0.0480\n",
      "Epoch [3/10], Step [361/1063], Loss: 0.0024\n",
      "Epoch [3/10], Step [362/1063], Loss: 0.0745\n",
      "Epoch [3/10], Step [363/1063], Loss: 0.0061\n",
      "Epoch [3/10], Step [364/1063], Loss: 0.0075\n",
      "Epoch [3/10], Step [365/1063], Loss: 0.0016\n",
      "Epoch [3/10], Step [366/1063], Loss: 0.0011\n",
      "Epoch [3/10], Step [367/1063], Loss: 0.0378\n",
      "Epoch [3/10], Step [368/1063], Loss: 0.0041\n",
      "Epoch [3/10], Step [369/1063], Loss: 0.0060\n",
      "Epoch [3/10], Step [370/1063], Loss: 0.0088\n",
      "Epoch [3/10], Step [371/1063], Loss: 0.0024\n",
      "Epoch [3/10], Step [372/1063], Loss: 0.0282\n",
      "Epoch [3/10], Step [373/1063], Loss: 0.0419\n",
      "Epoch [3/10], Step [374/1063], Loss: 0.0213\n",
      "Epoch [3/10], Step [375/1063], Loss: 0.0278\n",
      "Epoch [3/10], Step [376/1063], Loss: 0.0728\n",
      "Epoch [3/10], Step [377/1063], Loss: 0.0123\n",
      "Epoch [3/10], Step [378/1063], Loss: 0.0508\n",
      "Epoch [3/10], Step [379/1063], Loss: 0.0194\n",
      "Epoch [3/10], Step [380/1063], Loss: 0.0404\n",
      "Epoch [3/10], Step [381/1063], Loss: 0.0021\n",
      "Epoch [3/10], Step [382/1063], Loss: 0.0703\n",
      "Epoch [3/10], Step [383/1063], Loss: 0.0065\n",
      "Epoch [3/10], Step [384/1063], Loss: 0.0232\n",
      "Epoch [3/10], Step [385/1063], Loss: 0.0024\n",
      "Epoch [3/10], Step [386/1063], Loss: 0.1345\n",
      "Epoch [3/10], Step [387/1063], Loss: 0.0452\n",
      "Epoch [3/10], Step [388/1063], Loss: 0.0415\n",
      "Epoch [3/10], Step [389/1063], Loss: 0.0050\n",
      "Epoch [3/10], Step [390/1063], Loss: 0.0517\n",
      "Epoch [3/10], Step [391/1063], Loss: 0.0103\n",
      "Epoch [3/10], Step [392/1063], Loss: 0.0260\n",
      "Epoch [3/10], Step [393/1063], Loss: 0.0282\n",
      "Epoch [3/10], Step [394/1063], Loss: 0.0232\n",
      "Epoch [3/10], Step [395/1063], Loss: 0.0125\n",
      "Epoch [3/10], Step [396/1063], Loss: 0.0832\n",
      "Epoch [3/10], Step [397/1063], Loss: 0.0024\n",
      "Epoch [3/10], Step [398/1063], Loss: 0.0156\n",
      "Epoch [3/10], Step [399/1063], Loss: 0.1233\n",
      "Epoch [3/10], Step [400/1063], Loss: 0.0365\n",
      "Epoch [3/10], Step [401/1063], Loss: 0.0619\n",
      "Epoch [3/10], Step [402/1063], Loss: 0.0023\n",
      "Epoch [3/10], Step [403/1063], Loss: 0.0117\n",
      "Epoch [3/10], Step [404/1063], Loss: 0.0161\n",
      "Epoch [3/10], Step [405/1063], Loss: 0.0090\n",
      "Epoch [3/10], Step [406/1063], Loss: 0.1094\n",
      "Epoch [3/10], Step [407/1063], Loss: 0.0032\n",
      "Epoch [3/10], Step [408/1063], Loss: 0.0056\n",
      "Epoch [3/10], Step [409/1063], Loss: 0.0605\n",
      "Epoch [3/10], Step [410/1063], Loss: 0.0552\n",
      "Epoch [3/10], Step [411/1063], Loss: 0.0091\n",
      "Epoch [3/10], Step [412/1063], Loss: 0.0090\n",
      "Epoch [3/10], Step [413/1063], Loss: 0.1236\n",
      "Epoch [3/10], Step [414/1063], Loss: 0.0074\n",
      "Epoch [3/10], Step [415/1063], Loss: 0.0475\n",
      "Epoch [3/10], Step [416/1063], Loss: 0.0120\n",
      "Epoch [3/10], Step [417/1063], Loss: 0.0776\n",
      "Epoch [3/10], Step [418/1063], Loss: 0.0339\n",
      "Epoch [3/10], Step [419/1063], Loss: 0.0233\n",
      "Epoch [3/10], Step [420/1063], Loss: 0.0059\n",
      "Epoch [3/10], Step [421/1063], Loss: 0.0160\n",
      "Epoch [3/10], Step [422/1063], Loss: 0.0993\n",
      "Epoch [3/10], Step [423/1063], Loss: 0.0154\n",
      "Epoch [3/10], Step [424/1063], Loss: 0.0026\n",
      "Epoch [3/10], Step [425/1063], Loss: 0.0013\n",
      "Epoch [3/10], Step [426/1063], Loss: 0.0019\n",
      "Epoch [3/10], Step [427/1063], Loss: 0.0256\n",
      "Epoch [3/10], Step [428/1063], Loss: 0.0303\n",
      "Epoch [3/10], Step [429/1063], Loss: 0.0095\n",
      "Epoch [3/10], Step [430/1063], Loss: 0.0567\n",
      "Epoch [3/10], Step [431/1063], Loss: 0.0188\n",
      "Epoch [3/10], Step [432/1063], Loss: 0.0097\n",
      "Epoch [3/10], Step [433/1063], Loss: 0.0014\n",
      "Epoch [3/10], Step [434/1063], Loss: 0.1101\n",
      "Epoch [3/10], Step [435/1063], Loss: 0.0031\n",
      "Epoch [3/10], Step [436/1063], Loss: 0.0047\n",
      "Epoch [3/10], Step [437/1063], Loss: 0.0133\n",
      "Epoch [3/10], Step [438/1063], Loss: 0.0412\n",
      "Epoch [3/10], Step [439/1063], Loss: 0.0518\n",
      "Epoch [3/10], Step [440/1063], Loss: 0.0189\n",
      "Epoch [3/10], Step [441/1063], Loss: 0.0032\n",
      "Epoch [3/10], Step [442/1063], Loss: 0.0152\n",
      "Epoch [3/10], Step [443/1063], Loss: 0.0065\n",
      "Epoch [3/10], Step [444/1063], Loss: 0.0015\n",
      "Epoch [3/10], Step [445/1063], Loss: 0.0443\n",
      "Epoch [3/10], Step [446/1063], Loss: 0.0518\n",
      "Epoch [3/10], Step [447/1063], Loss: 0.0664\n",
      "Epoch [3/10], Step [448/1063], Loss: 0.1218\n",
      "Epoch [3/10], Step [449/1063], Loss: 0.0009\n",
      "Epoch [3/10], Step [450/1063], Loss: 0.0036\n",
      "Epoch [3/10], Step [451/1063], Loss: 0.0353\n",
      "Epoch [3/10], Step [452/1063], Loss: 0.0642\n",
      "Epoch [3/10], Step [453/1063], Loss: 0.0312\n",
      "Epoch [3/10], Step [454/1063], Loss: 0.0031\n",
      "Epoch [3/10], Step [455/1063], Loss: 0.0113\n",
      "Epoch [3/10], Step [456/1063], Loss: 0.0347\n",
      "Epoch [3/10], Step [457/1063], Loss: 0.0025\n",
      "Epoch [3/10], Step [458/1063], Loss: 0.0361\n",
      "Epoch [3/10], Step [459/1063], Loss: 0.0062\n",
      "Epoch [3/10], Step [460/1063], Loss: 0.0698\n",
      "Epoch [3/10], Step [461/1063], Loss: 0.0755\n",
      "Epoch [3/10], Step [462/1063], Loss: 0.0165\n",
      "Epoch [3/10], Step [463/1063], Loss: 0.0412\n",
      "Epoch [3/10], Step [464/1063], Loss: 0.0029\n",
      "Epoch [3/10], Step [465/1063], Loss: 0.0132\n",
      "Epoch [3/10], Step [466/1063], Loss: 0.0021\n",
      "Epoch [3/10], Step [467/1063], Loss: 0.0052\n",
      "Epoch [3/10], Step [468/1063], Loss: 0.0919\n",
      "Epoch [3/10], Step [469/1063], Loss: 0.0094\n",
      "Epoch [3/10], Step [470/1063], Loss: 0.0818\n",
      "Epoch [3/10], Step [471/1063], Loss: 0.0350\n",
      "Epoch [3/10], Step [472/1063], Loss: 0.0128\n",
      "Epoch [3/10], Step [473/1063], Loss: 0.1225\n",
      "Epoch [3/10], Step [474/1063], Loss: 0.0138\n",
      "Epoch [3/10], Step [475/1063], Loss: 0.0336\n",
      "Epoch [3/10], Step [476/1063], Loss: 0.0189\n",
      "Epoch [3/10], Step [477/1063], Loss: 0.0264\n",
      "Epoch [3/10], Step [478/1063], Loss: 0.0032\n",
      "Epoch [3/10], Step [479/1063], Loss: 0.0189\n",
      "Epoch [3/10], Step [480/1063], Loss: 0.0431\n",
      "Epoch [3/10], Step [481/1063], Loss: 0.0010\n",
      "Epoch [3/10], Step [482/1063], Loss: 0.0481\n",
      "Epoch [3/10], Step [483/1063], Loss: 0.0254\n",
      "Epoch [3/10], Step [484/1063], Loss: 0.0344\n",
      "Epoch [3/10], Step [485/1063], Loss: 0.0087\n",
      "Epoch [3/10], Step [486/1063], Loss: 0.0221\n",
      "Epoch [3/10], Step [487/1063], Loss: 0.0155\n",
      "Epoch [3/10], Step [488/1063], Loss: 0.1791\n",
      "Epoch [3/10], Step [489/1063], Loss: 0.0554\n",
      "Epoch [3/10], Step [490/1063], Loss: 0.0274\n",
      "Epoch [3/10], Step [491/1063], Loss: 0.0120\n",
      "Epoch [3/10], Step [492/1063], Loss: 0.0140\n",
      "Epoch [3/10], Step [493/1063], Loss: 0.0574\n",
      "Epoch [3/10], Step [494/1063], Loss: 0.0385\n",
      "Epoch [3/10], Step [495/1063], Loss: 0.0844\n",
      "Epoch [3/10], Step [496/1063], Loss: 0.1032\n",
      "Epoch [3/10], Step [497/1063], Loss: 0.0124\n",
      "Epoch [3/10], Step [498/1063], Loss: 0.0169\n",
      "Epoch [3/10], Step [499/1063], Loss: 0.1540\n",
      "Epoch [3/10], Step [500/1063], Loss: 0.0108\n",
      "Epoch [3/10], Step [501/1063], Loss: 0.0046\n",
      "Epoch [3/10], Step [502/1063], Loss: 0.0137\n",
      "Epoch [3/10], Step [503/1063], Loss: 0.0173\n",
      "Epoch [3/10], Step [504/1063], Loss: 0.1153\n",
      "Epoch [3/10], Step [505/1063], Loss: 0.0273\n",
      "Epoch [3/10], Step [506/1063], Loss: 0.0212\n",
      "Epoch [3/10], Step [507/1063], Loss: 0.0319\n",
      "Epoch [3/10], Step [508/1063], Loss: 0.0239\n",
      "Epoch [3/10], Step [509/1063], Loss: 0.0412\n",
      "Epoch [3/10], Step [510/1063], Loss: 0.0085\n",
      "Epoch [3/10], Step [511/1063], Loss: 0.0026\n",
      "Epoch [3/10], Step [512/1063], Loss: 0.0058\n",
      "Epoch [3/10], Step [513/1063], Loss: 0.0887\n",
      "Epoch [3/10], Step [514/1063], Loss: 0.0439\n",
      "Epoch [3/10], Step [515/1063], Loss: 0.0019\n",
      "Epoch [3/10], Step [516/1063], Loss: 0.0050\n",
      "Epoch [3/10], Step [517/1063], Loss: 0.0570\n",
      "Epoch [3/10], Step [518/1063], Loss: 0.0259\n",
      "Epoch [3/10], Step [519/1063], Loss: 0.0032\n",
      "Epoch [3/10], Step [520/1063], Loss: 0.0071\n",
      "Epoch [3/10], Step [521/1063], Loss: 0.0308\n",
      "Epoch [3/10], Step [522/1063], Loss: 0.0196\n",
      "Epoch [3/10], Step [523/1063], Loss: 0.0537\n",
      "Epoch [3/10], Step [524/1063], Loss: 0.0263\n",
      "Epoch [3/10], Step [525/1063], Loss: 0.0132\n",
      "Epoch [3/10], Step [526/1063], Loss: 0.0136\n",
      "Epoch [3/10], Step [527/1063], Loss: 0.0342\n",
      "Epoch [3/10], Step [528/1063], Loss: 0.0026\n",
      "Epoch [3/10], Step [529/1063], Loss: 0.0227\n",
      "Epoch [3/10], Step [530/1063], Loss: 0.0290\n",
      "Epoch [3/10], Step [531/1063], Loss: 0.0036\n",
      "Epoch [3/10], Step [532/1063], Loss: 0.0035\n",
      "Epoch [3/10], Step [533/1063], Loss: 0.0554\n",
      "Epoch [3/10], Step [534/1063], Loss: 0.0913\n",
      "Epoch [3/10], Step [535/1063], Loss: 0.0251\n",
      "Epoch [3/10], Step [536/1063], Loss: 0.0097\n",
      "Epoch [3/10], Step [537/1063], Loss: 0.0631\n",
      "Epoch [3/10], Step [538/1063], Loss: 0.0904\n",
      "Epoch [3/10], Step [539/1063], Loss: 0.0438\n",
      "Epoch [3/10], Step [540/1063], Loss: 0.0043\n",
      "Epoch [3/10], Step [541/1063], Loss: 0.0057\n",
      "Epoch [3/10], Step [542/1063], Loss: 0.0137\n",
      "Epoch [3/10], Step [543/1063], Loss: 0.0024\n",
      "Epoch [3/10], Step [544/1063], Loss: 0.0101\n",
      "Epoch [3/10], Step [545/1063], Loss: 0.0347\n",
      "Epoch [3/10], Step [546/1063], Loss: 0.0043\n",
      "Epoch [3/10], Step [547/1063], Loss: 0.0032\n",
      "Epoch [3/10], Step [548/1063], Loss: 0.0171\n",
      "Epoch [3/10], Step [549/1063], Loss: 0.0204\n",
      "Epoch [3/10], Step [550/1063], Loss: 0.0100\n",
      "Epoch [3/10], Step [551/1063], Loss: 0.0306\n",
      "Epoch [3/10], Step [552/1063], Loss: 0.0124\n",
      "Epoch [3/10], Step [553/1063], Loss: 0.0984\n",
      "Epoch [3/10], Step [554/1063], Loss: 0.0209\n",
      "Epoch [3/10], Step [555/1063], Loss: 0.0424\n",
      "Epoch [3/10], Step [556/1063], Loss: 0.0376\n",
      "Epoch [3/10], Step [557/1063], Loss: 0.1012\n",
      "Epoch [3/10], Step [558/1063], Loss: 0.0020\n",
      "Epoch [3/10], Step [559/1063], Loss: 0.0026\n",
      "Epoch [3/10], Step [560/1063], Loss: 0.0730\n",
      "Epoch [3/10], Step [561/1063], Loss: 0.0010\n",
      "Epoch [3/10], Step [562/1063], Loss: 0.0442\n",
      "Epoch [3/10], Step [563/1063], Loss: 0.0049\n",
      "Epoch [3/10], Step [564/1063], Loss: 0.0144\n",
      "Epoch [3/10], Step [565/1063], Loss: 0.1722\n",
      "Epoch [3/10], Step [566/1063], Loss: 0.0423\n",
      "Epoch [3/10], Step [567/1063], Loss: 0.0174\n",
      "Epoch [3/10], Step [568/1063], Loss: 0.0030\n",
      "Epoch [3/10], Step [569/1063], Loss: 0.0685\n",
      "Epoch [3/10], Step [570/1063], Loss: 0.0070\n",
      "Epoch [3/10], Step [571/1063], Loss: 0.0097\n",
      "Epoch [3/10], Step [572/1063], Loss: 0.0102\n",
      "Epoch [3/10], Step [573/1063], Loss: 0.0114\n",
      "Epoch [3/10], Step [574/1063], Loss: 0.0930\n",
      "Epoch [3/10], Step [575/1063], Loss: 0.0362\n",
      "Epoch [3/10], Step [576/1063], Loss: 0.0511\n",
      "Epoch [3/10], Step [577/1063], Loss: 0.0014\n",
      "Epoch [3/10], Step [578/1063], Loss: 0.0582\n",
      "Epoch [3/10], Step [579/1063], Loss: 0.0041\n",
      "Epoch [3/10], Step [580/1063], Loss: 0.0076\n",
      "Epoch [3/10], Step [581/1063], Loss: 0.1392\n",
      "Epoch [3/10], Step [582/1063], Loss: 0.0324\n",
      "Epoch [3/10], Step [583/1063], Loss: 0.0192\n",
      "Epoch [3/10], Step [584/1063], Loss: 0.0066\n",
      "Epoch [3/10], Step [585/1063], Loss: 0.0736\n",
      "Epoch [3/10], Step [586/1063], Loss: 0.0465\n",
      "Epoch [3/10], Step [587/1063], Loss: 0.0673\n",
      "Epoch [3/10], Step [588/1063], Loss: 0.0405\n",
      "Epoch [3/10], Step [589/1063], Loss: 0.0720\n",
      "Epoch [3/10], Step [590/1063], Loss: 0.0165\n",
      "Epoch [3/10], Step [591/1063], Loss: 0.0036\n",
      "Epoch [3/10], Step [592/1063], Loss: 0.0046\n",
      "Epoch [3/10], Step [593/1063], Loss: 0.0118\n",
      "Epoch [3/10], Step [594/1063], Loss: 0.0098\n",
      "Epoch [3/10], Step [595/1063], Loss: 0.0059\n",
      "Epoch [3/10], Step [596/1063], Loss: 0.0086\n",
      "Epoch [3/10], Step [597/1063], Loss: 0.0040\n",
      "Epoch [3/10], Step [598/1063], Loss: 0.0201\n",
      "Epoch [3/10], Step [599/1063], Loss: 0.1226\n",
      "Epoch [3/10], Step [600/1063], Loss: 0.0274\n",
      "Epoch [3/10], Step [601/1063], Loss: 0.0467\n",
      "Epoch [3/10], Step [602/1063], Loss: 0.0141\n",
      "Epoch [3/10], Step [603/1063], Loss: 0.0167\n",
      "Epoch [3/10], Step [604/1063], Loss: 0.0037\n",
      "Epoch [3/10], Step [605/1063], Loss: 0.0731\n",
      "Epoch [3/10], Step [606/1063], Loss: 0.0320\n",
      "Epoch [3/10], Step [607/1063], Loss: 0.0734\n",
      "Epoch [3/10], Step [608/1063], Loss: 0.1384\n",
      "Epoch [3/10], Step [609/1063], Loss: 0.0044\n",
      "Epoch [3/10], Step [610/1063], Loss: 0.0756\n",
      "Epoch [3/10], Step [611/1063], Loss: 0.0035\n",
      "Epoch [3/10], Step [612/1063], Loss: 0.0049\n",
      "Epoch [3/10], Step [613/1063], Loss: 0.0135\n",
      "Epoch [3/10], Step [614/1063], Loss: 0.0282\n",
      "Epoch [3/10], Step [615/1063], Loss: 0.0585\n",
      "Epoch [3/10], Step [616/1063], Loss: 0.0075\n",
      "Epoch [3/10], Step [617/1063], Loss: 0.0879\n",
      "Epoch [3/10], Step [618/1063], Loss: 0.0110\n",
      "Epoch [3/10], Step [619/1063], Loss: 0.0016\n",
      "Epoch [3/10], Step [620/1063], Loss: 0.1601\n",
      "Epoch [3/10], Step [621/1063], Loss: 0.0029\n",
      "Epoch [3/10], Step [622/1063], Loss: 0.1019\n",
      "Epoch [3/10], Step [623/1063], Loss: 0.0157\n",
      "Epoch [3/10], Step [624/1063], Loss: 0.0318\n",
      "Epoch [3/10], Step [625/1063], Loss: 0.0139\n",
      "Epoch [3/10], Step [626/1063], Loss: 0.0107\n",
      "Epoch [3/10], Step [627/1063], Loss: 0.0432\n",
      "Epoch [3/10], Step [628/1063], Loss: 0.0277\n",
      "Epoch [3/10], Step [629/1063], Loss: 0.0090\n",
      "Epoch [3/10], Step [630/1063], Loss: 0.0748\n",
      "Epoch [3/10], Step [631/1063], Loss: 0.0294\n",
      "Epoch [3/10], Step [632/1063], Loss: 0.0121\n",
      "Epoch [3/10], Step [633/1063], Loss: 0.0431\n",
      "Epoch [3/10], Step [634/1063], Loss: 0.0296\n",
      "Epoch [3/10], Step [635/1063], Loss: 0.0389\n",
      "Epoch [3/10], Step [636/1063], Loss: 0.0261\n",
      "Epoch [3/10], Step [637/1063], Loss: 0.0528\n",
      "Epoch [3/10], Step [638/1063], Loss: 0.0169\n",
      "Epoch [3/10], Step [639/1063], Loss: 0.0351\n",
      "Epoch [3/10], Step [640/1063], Loss: 0.0244\n",
      "Epoch [3/10], Step [641/1063], Loss: 0.0111\n",
      "Epoch [3/10], Step [642/1063], Loss: 0.0230\n",
      "Epoch [3/10], Step [643/1063], Loss: 0.0168\n",
      "Epoch [3/10], Step [644/1063], Loss: 0.0049\n",
      "Epoch [3/10], Step [645/1063], Loss: 0.0343\n",
      "Epoch [3/10], Step [646/1063], Loss: 0.0203\n",
      "Epoch [3/10], Step [647/1063], Loss: 0.0118\n",
      "Epoch [3/10], Step [648/1063], Loss: 0.0487\n",
      "Epoch [3/10], Step [649/1063], Loss: 0.0119\n",
      "Epoch [3/10], Step [650/1063], Loss: 0.0053\n",
      "Epoch [3/10], Step [651/1063], Loss: 0.0021\n",
      "Epoch [3/10], Step [652/1063], Loss: 0.0129\n",
      "Epoch [3/10], Step [653/1063], Loss: 0.0109\n",
      "Epoch [3/10], Step [654/1063], Loss: 0.0048\n",
      "Epoch [3/10], Step [655/1063], Loss: 0.0026\n",
      "Epoch [3/10], Step [656/1063], Loss: 0.0340\n",
      "Epoch [3/10], Step [657/1063], Loss: 0.0023\n",
      "Epoch [3/10], Step [658/1063], Loss: 0.0120\n",
      "Epoch [3/10], Step [659/1063], Loss: 0.0113\n",
      "Epoch [3/10], Step [660/1063], Loss: 0.0078\n",
      "Epoch [3/10], Step [661/1063], Loss: 0.0143\n",
      "Epoch [3/10], Step [662/1063], Loss: 0.0172\n",
      "Epoch [3/10], Step [663/1063], Loss: 0.0123\n",
      "Epoch [3/10], Step [664/1063], Loss: 0.0114\n",
      "Epoch [3/10], Step [665/1063], Loss: 0.0098\n",
      "Epoch [3/10], Step [666/1063], Loss: 0.0327\n",
      "Epoch [3/10], Step [667/1063], Loss: 0.0179\n",
      "Epoch [3/10], Step [668/1063], Loss: 0.0292\n",
      "Epoch [3/10], Step [669/1063], Loss: 0.0154\n",
      "Epoch [3/10], Step [670/1063], Loss: 0.1361\n",
      "Epoch [3/10], Step [671/1063], Loss: 0.0552\n",
      "Epoch [3/10], Step [672/1063], Loss: 0.0315\n",
      "Epoch [3/10], Step [673/1063], Loss: 0.0089\n",
      "Epoch [3/10], Step [674/1063], Loss: 0.0024\n",
      "Epoch [3/10], Step [675/1063], Loss: 0.0100\n",
      "Epoch [3/10], Step [676/1063], Loss: 0.0851\n",
      "Epoch [3/10], Step [677/1063], Loss: 0.0023\n",
      "Epoch [3/10], Step [678/1063], Loss: 0.0050\n",
      "Epoch [3/10], Step [679/1063], Loss: 0.0525\n",
      "Epoch [3/10], Step [680/1063], Loss: 0.0074\n",
      "Epoch [3/10], Step [681/1063], Loss: 0.0198\n",
      "Epoch [3/10], Step [682/1063], Loss: 0.0266\n",
      "Epoch [3/10], Step [683/1063], Loss: 0.0164\n",
      "Epoch [3/10], Step [684/1063], Loss: 0.0013\n",
      "Epoch [3/10], Step [685/1063], Loss: 0.0024\n",
      "Epoch [3/10], Step [686/1063], Loss: 0.0628\n",
      "Epoch [3/10], Step [687/1063], Loss: 0.0188\n",
      "Epoch [3/10], Step [688/1063], Loss: 0.0020\n",
      "Epoch [3/10], Step [689/1063], Loss: 0.0511\n",
      "Epoch [3/10], Step [690/1063], Loss: 0.0059\n",
      "Epoch [3/10], Step [691/1063], Loss: 0.0022\n",
      "Epoch [3/10], Step [692/1063], Loss: 0.1125\n",
      "Epoch [3/10], Step [693/1063], Loss: 0.0075\n",
      "Epoch [3/10], Step [694/1063], Loss: 0.0031\n",
      "Epoch [3/10], Step [695/1063], Loss: 0.0264\n",
      "Epoch [3/10], Step [696/1063], Loss: 0.0180\n",
      "Epoch [3/10], Step [697/1063], Loss: 0.0248\n",
      "Epoch [3/10], Step [698/1063], Loss: 0.0009\n",
      "Epoch [3/10], Step [699/1063], Loss: 0.0145\n",
      "Epoch [3/10], Step [700/1063], Loss: 0.0998\n",
      "Epoch [3/10], Step [701/1063], Loss: 0.0156\n",
      "Epoch [3/10], Step [702/1063], Loss: 0.0255\n",
      "Epoch [3/10], Step [703/1063], Loss: 0.0158\n",
      "Epoch [3/10], Step [704/1063], Loss: 0.0278\n",
      "Epoch [3/10], Step [705/1063], Loss: 0.0806\n",
      "Epoch [3/10], Step [706/1063], Loss: 0.0424\n",
      "Epoch [3/10], Step [707/1063], Loss: 0.0402\n",
      "Epoch [3/10], Step [708/1063], Loss: 0.0208\n",
      "Epoch [3/10], Step [709/1063], Loss: 0.0080\n",
      "Epoch [3/10], Step [710/1063], Loss: 0.0028\n",
      "Epoch [3/10], Step [711/1063], Loss: 0.0139\n",
      "Epoch [3/10], Step [712/1063], Loss: 0.0638\n",
      "Epoch [3/10], Step [713/1063], Loss: 0.0122\n",
      "Epoch [3/10], Step [714/1063], Loss: 0.0233\n",
      "Epoch [3/10], Step [715/1063], Loss: 0.0022\n",
      "Epoch [3/10], Step [716/1063], Loss: 0.0233\n",
      "Epoch [3/10], Step [717/1063], Loss: 0.0242\n",
      "Epoch [3/10], Step [718/1063], Loss: 0.1772\n",
      "Epoch [3/10], Step [719/1063], Loss: 0.0197\n",
      "Epoch [3/10], Step [720/1063], Loss: 0.0431\n",
      "Epoch [3/10], Step [721/1063], Loss: 0.0647\n",
      "Epoch [3/10], Step [722/1063], Loss: 0.0055\n",
      "Epoch [3/10], Step [723/1063], Loss: 0.0138\n",
      "Epoch [3/10], Step [724/1063], Loss: 0.0435\n",
      "Epoch [3/10], Step [725/1063], Loss: 0.0489\n",
      "Epoch [3/10], Step [726/1063], Loss: 0.0739\n",
      "Epoch [3/10], Step [727/1063], Loss: 0.0139\n",
      "Epoch [3/10], Step [728/1063], Loss: 0.0048\n",
      "Epoch [3/10], Step [729/1063], Loss: 0.0877\n",
      "Epoch [3/10], Step [730/1063], Loss: 0.0124\n",
      "Epoch [3/10], Step [731/1063], Loss: 0.0050\n",
      "Epoch [3/10], Step [732/1063], Loss: 0.0622\n",
      "Epoch [3/10], Step [733/1063], Loss: 0.0114\n",
      "Epoch [3/10], Step [734/1063], Loss: 0.0132\n",
      "Epoch [3/10], Step [735/1063], Loss: 0.1020\n",
      "Epoch [3/10], Step [736/1063], Loss: 0.0259\n",
      "Epoch [3/10], Step [737/1063], Loss: 0.0188\n",
      "Epoch [3/10], Step [738/1063], Loss: 0.0109\n",
      "Epoch [3/10], Step [739/1063], Loss: 0.0388\n",
      "Epoch [3/10], Step [740/1063], Loss: 0.0115\n",
      "Epoch [3/10], Step [741/1063], Loss: 0.0901\n",
      "Epoch [3/10], Step [742/1063], Loss: 0.0059\n",
      "Epoch [3/10], Step [743/1063], Loss: 0.0214\n",
      "Epoch [3/10], Step [744/1063], Loss: 0.0266\n",
      "Epoch [3/10], Step [745/1063], Loss: 0.0041\n",
      "Epoch [3/10], Step [746/1063], Loss: 0.0134\n",
      "Epoch [3/10], Step [747/1063], Loss: 0.0049\n",
      "Epoch [3/10], Step [748/1063], Loss: 0.0086\n",
      "Epoch [3/10], Step [749/1063], Loss: 0.0099\n",
      "Epoch [3/10], Step [750/1063], Loss: 0.0098\n",
      "Epoch [3/10], Step [751/1063], Loss: 0.0261\n",
      "Epoch [3/10], Step [752/1063], Loss: 0.0256\n",
      "Epoch [3/10], Step [753/1063], Loss: 0.0151\n",
      "Epoch [3/10], Step [754/1063], Loss: 0.0046\n",
      "Epoch [3/10], Step [755/1063], Loss: 0.0603\n",
      "Epoch [3/10], Step [756/1063], Loss: 0.1632\n",
      "Epoch [3/10], Step [757/1063], Loss: 0.0566\n",
      "Epoch [3/10], Step [758/1063], Loss: 0.0311\n",
      "Epoch [3/10], Step [759/1063], Loss: 0.0138\n",
      "Epoch [3/10], Step [760/1063], Loss: 0.0191\n",
      "Epoch [3/10], Step [761/1063], Loss: 0.0890\n",
      "Epoch [3/10], Step [762/1063], Loss: 0.0130\n",
      "Epoch [3/10], Step [763/1063], Loss: 0.0041\n",
      "Epoch [3/10], Step [764/1063], Loss: 0.0097\n",
      "Epoch [3/10], Step [765/1063], Loss: 0.0448\n",
      "Epoch [3/10], Step [766/1063], Loss: 0.0015\n",
      "Epoch [3/10], Step [767/1063], Loss: 0.1045\n",
      "Epoch [3/10], Step [768/1063], Loss: 0.0104\n",
      "Epoch [3/10], Step [769/1063], Loss: 0.0870\n",
      "Epoch [3/10], Step [770/1063], Loss: 0.0124\n",
      "Epoch [3/10], Step [771/1063], Loss: 0.0407\n",
      "Epoch [3/10], Step [772/1063], Loss: 0.0034\n",
      "Epoch [3/10], Step [773/1063], Loss: 0.0120\n",
      "Epoch [3/10], Step [774/1063], Loss: 0.0022\n",
      "Epoch [3/10], Step [775/1063], Loss: 0.0191\n",
      "Epoch [3/10], Step [776/1063], Loss: 0.0331\n",
      "Epoch [3/10], Step [777/1063], Loss: 0.0157\n",
      "Epoch [3/10], Step [778/1063], Loss: 0.0532\n",
      "Epoch [3/10], Step [779/1063], Loss: 0.0190\n",
      "Epoch [3/10], Step [780/1063], Loss: 0.0880\n",
      "Epoch [3/10], Step [781/1063], Loss: 0.0271\n",
      "Epoch [3/10], Step [782/1063], Loss: 0.0106\n",
      "Epoch [3/10], Step [783/1063], Loss: 0.0109\n",
      "Epoch [3/10], Step [784/1063], Loss: 0.0106\n",
      "Epoch [3/10], Step [785/1063], Loss: 0.0067\n",
      "Epoch [3/10], Step [786/1063], Loss: 0.0180\n",
      "Epoch [3/10], Step [787/1063], Loss: 0.0152\n",
      "Epoch [3/10], Step [788/1063], Loss: 0.0189\n",
      "Epoch [3/10], Step [789/1063], Loss: 0.0354\n",
      "Epoch [3/10], Step [790/1063], Loss: 0.1271\n",
      "Epoch [3/10], Step [791/1063], Loss: 0.0436\n",
      "Epoch [3/10], Step [792/1063], Loss: 0.0048\n",
      "Epoch [3/10], Step [793/1063], Loss: 0.0321\n",
      "Epoch [3/10], Step [794/1063], Loss: 0.0229\n",
      "Epoch [3/10], Step [795/1063], Loss: 0.0017\n",
      "Epoch [3/10], Step [796/1063], Loss: 0.0631\n",
      "Epoch [3/10], Step [797/1063], Loss: 0.0055\n",
      "Epoch [3/10], Step [798/1063], Loss: 0.0095\n",
      "Epoch [3/10], Step [799/1063], Loss: 0.0018\n",
      "Epoch [3/10], Step [800/1063], Loss: 0.0468\n",
      "Epoch [3/10], Step [801/1063], Loss: 0.0596\n",
      "Epoch [3/10], Step [802/1063], Loss: 0.0050\n",
      "Epoch [3/10], Step [803/1063], Loss: 0.0411\n",
      "Epoch [3/10], Step [804/1063], Loss: 0.0316\n",
      "Epoch [3/10], Step [805/1063], Loss: 0.0410\n",
      "Epoch [3/10], Step [806/1063], Loss: 0.0222\n",
      "Epoch [3/10], Step [807/1063], Loss: 0.0164\n",
      "Epoch [3/10], Step [808/1063], Loss: 0.0481\n",
      "Epoch [3/10], Step [809/1063], Loss: 0.0148\n",
      "Epoch [3/10], Step [810/1063], Loss: 0.0181\n",
      "Epoch [3/10], Step [811/1063], Loss: 0.0348\n",
      "Epoch [3/10], Step [812/1063], Loss: 0.2105\n",
      "Epoch [3/10], Step [813/1063], Loss: 0.0346\n",
      "Epoch [3/10], Step [814/1063], Loss: 0.0039\n",
      "Epoch [3/10], Step [815/1063], Loss: 0.0054\n",
      "Epoch [3/10], Step [816/1063], Loss: 0.0135\n",
      "Epoch [3/10], Step [817/1063], Loss: 0.0174\n",
      "Epoch [3/10], Step [818/1063], Loss: 0.0052\n",
      "Epoch [3/10], Step [819/1063], Loss: 0.0078\n",
      "Epoch [3/10], Step [820/1063], Loss: 0.0424\n",
      "Epoch [3/10], Step [821/1063], Loss: 0.1068\n",
      "Epoch [3/10], Step [822/1063], Loss: 0.0949\n",
      "Epoch [3/10], Step [823/1063], Loss: 0.0436\n",
      "Epoch [3/10], Step [824/1063], Loss: 0.1016\n",
      "Epoch [3/10], Step [825/1063], Loss: 0.0663\n",
      "Epoch [3/10], Step [826/1063], Loss: 0.0025\n",
      "Epoch [3/10], Step [827/1063], Loss: 0.0315\n",
      "Epoch [3/10], Step [828/1063], Loss: 0.0109\n",
      "Epoch [3/10], Step [829/1063], Loss: 0.0369\n",
      "Epoch [3/10], Step [830/1063], Loss: 0.0090\n",
      "Epoch [3/10], Step [831/1063], Loss: 0.0500\n",
      "Epoch [3/10], Step [832/1063], Loss: 0.0062\n",
      "Epoch [3/10], Step [833/1063], Loss: 0.0034\n",
      "Epoch [3/10], Step [834/1063], Loss: 0.0511\n",
      "Epoch [3/10], Step [835/1063], Loss: 0.0453\n",
      "Epoch [3/10], Step [836/1063], Loss: 0.0437\n",
      "Epoch [3/10], Step [837/1063], Loss: 0.0033\n",
      "Epoch [3/10], Step [838/1063], Loss: 0.0047\n",
      "Epoch [3/10], Step [839/1063], Loss: 0.0134\n",
      "Epoch [3/10], Step [840/1063], Loss: 0.0487\n",
      "Epoch [3/10], Step [841/1063], Loss: 0.0485\n",
      "Epoch [3/10], Step [842/1063], Loss: 0.0575\n",
      "Epoch [3/10], Step [843/1063], Loss: 0.0079\n",
      "Epoch [3/10], Step [844/1063], Loss: 0.0029\n",
      "Epoch [3/10], Step [845/1063], Loss: 0.0229\n",
      "Epoch [3/10], Step [846/1063], Loss: 0.0375\n",
      "Epoch [3/10], Step [847/1063], Loss: 0.0062\n",
      "Epoch [3/10], Step [848/1063], Loss: 0.0074\n",
      "Epoch [3/10], Step [849/1063], Loss: 0.0658\n",
      "Epoch [3/10], Step [850/1063], Loss: 0.0080\n",
      "Epoch [3/10], Step [851/1063], Loss: 0.0233\n",
      "Epoch [3/10], Step [852/1063], Loss: 0.0109\n",
      "Epoch [3/10], Step [853/1063], Loss: 0.0031\n",
      "Epoch [3/10], Step [854/1063], Loss: 0.0136\n",
      "Epoch [3/10], Step [855/1063], Loss: 0.0674\n",
      "Epoch [3/10], Step [856/1063], Loss: 0.0440\n",
      "Epoch [3/10], Step [857/1063], Loss: 0.0396\n",
      "Epoch [3/10], Step [858/1063], Loss: 0.0047\n",
      "Epoch [3/10], Step [859/1063], Loss: 0.0219\n",
      "Epoch [3/10], Step [860/1063], Loss: 0.0199\n",
      "Epoch [3/10], Step [861/1063], Loss: 0.0092\n",
      "Epoch [3/10], Step [862/1063], Loss: 0.0501\n",
      "Epoch [3/10], Step [863/1063], Loss: 0.0010\n",
      "Epoch [3/10], Step [864/1063], Loss: 0.0531\n",
      "Epoch [3/10], Step [865/1063], Loss: 0.0038\n",
      "Epoch [3/10], Step [866/1063], Loss: 0.0044\n",
      "Epoch [3/10], Step [867/1063], Loss: 0.0181\n",
      "Epoch [3/10], Step [868/1063], Loss: 0.0181\n",
      "Epoch [3/10], Step [869/1063], Loss: 0.0159\n",
      "Epoch [3/10], Step [870/1063], Loss: 0.0107\n",
      "Epoch [3/10], Step [871/1063], Loss: 0.0121\n",
      "Epoch [3/10], Step [872/1063], Loss: 0.0327\n",
      "Epoch [3/10], Step [873/1063], Loss: 0.0213\n",
      "Epoch [3/10], Step [874/1063], Loss: 0.0241\n",
      "Epoch [3/10], Step [875/1063], Loss: 0.0657\n",
      "Epoch [3/10], Step [876/1063], Loss: 0.0010\n",
      "Epoch [3/10], Step [877/1063], Loss: 0.0434\n",
      "Epoch [3/10], Step [878/1063], Loss: 0.0549\n",
      "Epoch [3/10], Step [879/1063], Loss: 0.0255\n",
      "Epoch [3/10], Step [880/1063], Loss: 0.0048\n",
      "Epoch [3/10], Step [881/1063], Loss: 0.0235\n",
      "Epoch [3/10], Step [882/1063], Loss: 0.0023\n",
      "Epoch [3/10], Step [883/1063], Loss: 0.0825\n",
      "Epoch [3/10], Step [884/1063], Loss: 0.0036\n",
      "Epoch [3/10], Step [885/1063], Loss: 0.0228\n",
      "Epoch [3/10], Step [886/1063], Loss: 0.0044\n",
      "Epoch [3/10], Step [887/1063], Loss: 0.0241\n",
      "Epoch [3/10], Step [888/1063], Loss: 0.0255\n",
      "Epoch [3/10], Step [889/1063], Loss: 0.0730\n",
      "Epoch [3/10], Step [890/1063], Loss: 0.0038\n",
      "Epoch [3/10], Step [891/1063], Loss: 0.0186\n",
      "Epoch [3/10], Step [892/1063], Loss: 0.0004\n",
      "Epoch [3/10], Step [893/1063], Loss: 0.0039\n",
      "Epoch [3/10], Step [894/1063], Loss: 0.0049\n",
      "Epoch [3/10], Step [895/1063], Loss: 0.0379\n",
      "Epoch [3/10], Step [896/1063], Loss: 0.0043\n",
      "Epoch [3/10], Step [897/1063], Loss: 0.0141\n",
      "Epoch [3/10], Step [898/1063], Loss: 0.1293\n",
      "Epoch [3/10], Step [899/1063], Loss: 0.0089\n",
      "Epoch [3/10], Step [900/1063], Loss: 0.0049\n",
      "Epoch [3/10], Step [901/1063], Loss: 0.0594\n",
      "Epoch [3/10], Step [902/1063], Loss: 0.0459\n",
      "Epoch [3/10], Step [903/1063], Loss: 0.0041\n",
      "Epoch [3/10], Step [904/1063], Loss: 0.0028\n",
      "Epoch [3/10], Step [905/1063], Loss: 0.0220\n",
      "Epoch [3/10], Step [906/1063], Loss: 0.0165\n",
      "Epoch [3/10], Step [907/1063], Loss: 0.0069\n",
      "Epoch [3/10], Step [908/1063], Loss: 0.0302\n",
      "Epoch [3/10], Step [909/1063], Loss: 0.0156\n",
      "Epoch [3/10], Step [910/1063], Loss: 0.0077\n",
      "Epoch [3/10], Step [911/1063], Loss: 0.0181\n",
      "Epoch [3/10], Step [912/1063], Loss: 0.0207\n",
      "Epoch [3/10], Step [913/1063], Loss: 0.0047\n",
      "Epoch [3/10], Step [914/1063], Loss: 0.0024\n",
      "Epoch [3/10], Step [915/1063], Loss: 0.1237\n",
      "Epoch [3/10], Step [916/1063], Loss: 0.0468\n",
      "Epoch [3/10], Step [917/1063], Loss: 0.0056\n",
      "Epoch [3/10], Step [918/1063], Loss: 0.0219\n",
      "Epoch [3/10], Step [919/1063], Loss: 0.0123\n",
      "Epoch [3/10], Step [920/1063], Loss: 0.0092\n",
      "Epoch [3/10], Step [921/1063], Loss: 0.0045\n",
      "Epoch [3/10], Step [922/1063], Loss: 0.0268\n",
      "Epoch [3/10], Step [923/1063], Loss: 0.1365\n",
      "Epoch [3/10], Step [924/1063], Loss: 0.0057\n",
      "Epoch [3/10], Step [925/1063], Loss: 0.0033\n",
      "Epoch [3/10], Step [926/1063], Loss: 0.0046\n",
      "Epoch [3/10], Step [927/1063], Loss: 0.0427\n",
      "Epoch [3/10], Step [928/1063], Loss: 0.0017\n",
      "Epoch [3/10], Step [929/1063], Loss: 0.0034\n",
      "Epoch [3/10], Step [930/1063], Loss: 0.0378\n",
      "Epoch [3/10], Step [931/1063], Loss: 0.0251\n",
      "Epoch [3/10], Step [932/1063], Loss: 0.0513\n",
      "Epoch [3/10], Step [933/1063], Loss: 0.0070\n",
      "Epoch [3/10], Step [934/1063], Loss: 0.1115\n",
      "Epoch [3/10], Step [935/1063], Loss: 0.0073\n",
      "Epoch [3/10], Step [936/1063], Loss: 0.0142\n",
      "Epoch [3/10], Step [937/1063], Loss: 0.0022\n",
      "Epoch [3/10], Step [938/1063], Loss: 0.0557\n",
      "Epoch [3/10], Step [939/1063], Loss: 0.0194\n",
      "Epoch [3/10], Step [940/1063], Loss: 0.0165\n",
      "Epoch [3/10], Step [941/1063], Loss: 0.0117\n",
      "Epoch [3/10], Step [942/1063], Loss: 0.1357\n",
      "Epoch [3/10], Step [943/1063], Loss: 0.0171\n",
      "Epoch [3/10], Step [944/1063], Loss: 0.0235\n",
      "Epoch [3/10], Step [945/1063], Loss: 0.0093\n",
      "Epoch [3/10], Step [946/1063], Loss: 0.0147\n",
      "Epoch [3/10], Step [947/1063], Loss: 0.0558\n",
      "Epoch [3/10], Step [948/1063], Loss: 0.0031\n",
      "Epoch [3/10], Step [949/1063], Loss: 0.0095\n",
      "Epoch [3/10], Step [950/1063], Loss: 0.0594\n",
      "Epoch [3/10], Step [951/1063], Loss: 0.0202\n",
      "Epoch [3/10], Step [952/1063], Loss: 0.0040\n",
      "Epoch [3/10], Step [953/1063], Loss: 0.0149\n",
      "Epoch [3/10], Step [954/1063], Loss: 0.0018\n",
      "Epoch [3/10], Step [955/1063], Loss: 0.0771\n",
      "Epoch [3/10], Step [956/1063], Loss: 0.0021\n",
      "Epoch [3/10], Step [957/1063], Loss: 0.0168\n",
      "Epoch [3/10], Step [958/1063], Loss: 0.0463\n",
      "Epoch [3/10], Step [959/1063], Loss: 0.0049\n",
      "Epoch [3/10], Step [960/1063], Loss: 0.0003\n",
      "Epoch [3/10], Step [961/1063], Loss: 0.0029\n",
      "Epoch [3/10], Step [962/1063], Loss: 0.0106\n",
      "Epoch [3/10], Step [963/1063], Loss: 0.0027\n",
      "Epoch [3/10], Step [964/1063], Loss: 0.0068\n",
      "Epoch [3/10], Step [965/1063], Loss: 0.1207\n",
      "Epoch [3/10], Step [966/1063], Loss: 0.0835\n",
      "Epoch [3/10], Step [967/1063], Loss: 0.0100\n",
      "Epoch [3/10], Step [968/1063], Loss: 0.0066\n",
      "Epoch [3/10], Step [969/1063], Loss: 0.0088\n",
      "Epoch [3/10], Step [970/1063], Loss: 0.0034\n",
      "Epoch [3/10], Step [971/1063], Loss: 0.0830\n",
      "Epoch [3/10], Step [972/1063], Loss: 0.0038\n",
      "Epoch [3/10], Step [973/1063], Loss: 0.1536\n",
      "Epoch [3/10], Step [974/1063], Loss: 0.0004\n",
      "Epoch [3/10], Step [975/1063], Loss: 0.0121\n",
      "Epoch [3/10], Step [976/1063], Loss: 0.0312\n",
      "Epoch [3/10], Step [977/1063], Loss: 0.0100\n",
      "Epoch [3/10], Step [978/1063], Loss: 0.0057\n",
      "Epoch [3/10], Step [979/1063], Loss: 0.1481\n",
      "Epoch [3/10], Step [980/1063], Loss: 0.0122\n",
      "Epoch [3/10], Step [981/1063], Loss: 0.0124\n",
      "Epoch [3/10], Step [982/1063], Loss: 0.1334\n",
      "Epoch [3/10], Step [983/1063], Loss: 0.0071\n",
      "Epoch [3/10], Step [984/1063], Loss: 0.0414\n",
      "Epoch [3/10], Step [985/1063], Loss: 0.0386\n",
      "Epoch [3/10], Step [986/1063], Loss: 0.0056\n",
      "Epoch [3/10], Step [987/1063], Loss: 0.0742\n",
      "Epoch [3/10], Step [988/1063], Loss: 0.0157\n",
      "Epoch [3/10], Step [989/1063], Loss: 0.0112\n",
      "Epoch [3/10], Step [990/1063], Loss: 0.0347\n",
      "Epoch [3/10], Step [991/1063], Loss: 0.1022\n",
      "Epoch [3/10], Step [992/1063], Loss: 0.1230\n",
      "Epoch [3/10], Step [993/1063], Loss: 0.0020\n",
      "Epoch [3/10], Step [994/1063], Loss: 0.0051\n",
      "Epoch [3/10], Step [995/1063], Loss: 0.0227\n",
      "Epoch [3/10], Step [996/1063], Loss: 0.0249\n",
      "Epoch [3/10], Step [997/1063], Loss: 0.0671\n",
      "Epoch [3/10], Step [998/1063], Loss: 0.0122\n",
      "Epoch [3/10], Step [999/1063], Loss: 0.0954\n",
      "Epoch [3/10], Step [1000/1063], Loss: 0.0067\n",
      "Epoch [3/10], Step [1001/1063], Loss: 0.0679\n",
      "Epoch [3/10], Step [1002/1063], Loss: 0.0202\n",
      "Epoch [3/10], Step [1003/1063], Loss: 0.0260\n",
      "Epoch [3/10], Step [1004/1063], Loss: 0.0140\n",
      "Epoch [3/10], Step [1005/1063], Loss: 0.0167\n",
      "Epoch [3/10], Step [1006/1063], Loss: 0.1048\n",
      "Epoch [3/10], Step [1007/1063], Loss: 0.0075\n",
      "Epoch [3/10], Step [1008/1063], Loss: 0.0032\n",
      "Epoch [3/10], Step [1009/1063], Loss: 0.0680\n",
      "Epoch [3/10], Step [1010/1063], Loss: 0.0094\n",
      "Epoch [3/10], Step [1011/1063], Loss: 0.0414\n",
      "Epoch [3/10], Step [1012/1063], Loss: 0.0139\n",
      "Epoch [3/10], Step [1013/1063], Loss: 0.0105\n",
      "Epoch [3/10], Step [1014/1063], Loss: 0.0025\n",
      "Epoch [3/10], Step [1015/1063], Loss: 0.0258\n",
      "Epoch [3/10], Step [1016/1063], Loss: 0.0768\n",
      "Epoch [3/10], Step [1017/1063], Loss: 0.0015\n",
      "Epoch [3/10], Step [1018/1063], Loss: 0.0030\n",
      "Epoch [3/10], Step [1019/1063], Loss: 0.0534\n",
      "Epoch [3/10], Step [1020/1063], Loss: 0.0023\n",
      "Epoch [3/10], Step [1021/1063], Loss: 0.0402\n",
      "Epoch [3/10], Step [1022/1063], Loss: 0.0018\n",
      "Epoch [3/10], Step [1023/1063], Loss: 0.0652\n",
      "Epoch [3/10], Step [1024/1063], Loss: 0.0116\n",
      "Epoch [3/10], Step [1025/1063], Loss: 0.0167\n",
      "Epoch [3/10], Step [1026/1063], Loss: 0.0055\n",
      "Epoch [3/10], Step [1027/1063], Loss: 0.1463\n",
      "Epoch [3/10], Step [1028/1063], Loss: 0.0020\n",
      "Epoch [3/10], Step [1029/1063], Loss: 0.0016\n",
      "Epoch [3/10], Step [1030/1063], Loss: 0.0061\n",
      "Epoch [3/10], Step [1031/1063], Loss: 0.0247\n",
      "Epoch [3/10], Step [1032/1063], Loss: 0.0594\n",
      "Epoch [3/10], Step [1033/1063], Loss: 0.1191\n",
      "Epoch [3/10], Step [1034/1063], Loss: 0.0092\n",
      "Epoch [3/10], Step [1035/1063], Loss: 0.0067\n",
      "Epoch [3/10], Step [1036/1063], Loss: 0.0203\n",
      "Epoch [3/10], Step [1037/1063], Loss: 0.0115\n",
      "Epoch [3/10], Step [1038/1063], Loss: 0.0703\n",
      "Epoch [3/10], Step [1039/1063], Loss: 0.0923\n",
      "Epoch [3/10], Step [1040/1063], Loss: 0.0028\n",
      "Epoch [3/10], Step [1041/1063], Loss: 0.0551\n",
      "Epoch [3/10], Step [1042/1063], Loss: 0.0103\n",
      "Epoch [3/10], Step [1043/1063], Loss: 0.0060\n",
      "Epoch [3/10], Step [1044/1063], Loss: 0.0081\n",
      "Epoch [3/10], Step [1045/1063], Loss: 0.0461\n",
      "Epoch [3/10], Step [1046/1063], Loss: 0.0022\n",
      "Epoch [3/10], Step [1047/1063], Loss: 0.0406\n",
      "Epoch [3/10], Step [1048/1063], Loss: 0.0196\n",
      "Epoch [3/10], Step [1049/1063], Loss: 0.0193\n",
      "Epoch [3/10], Step [1050/1063], Loss: 0.0540\n",
      "Epoch [3/10], Step [1051/1063], Loss: 0.0437\n",
      "Epoch [3/10], Step [1052/1063], Loss: 0.0009\n",
      "Epoch [3/10], Step [1053/1063], Loss: 0.0546\n",
      "Epoch [3/10], Step [1054/1063], Loss: 0.0620\n",
      "Epoch [3/10], Step [1055/1063], Loss: 0.0164\n",
      "Epoch [3/10], Step [1056/1063], Loss: 0.0025\n",
      "Epoch [3/10], Step [1057/1063], Loss: 0.0078\n",
      "Epoch [3/10], Step [1058/1063], Loss: 0.0065\n",
      "Epoch [3/10], Step [1059/1063], Loss: 0.1458\n",
      "Epoch [3/10], Step [1060/1063], Loss: 0.0363\n",
      "Epoch [3/10], Step [1061/1063], Loss: 0.0078\n",
      "Epoch [3/10], Step [1062/1063], Loss: 0.0622\n",
      "Epoch [3/10], Step [1063/1063], Loss: 0.0031\n",
      "Epoch [4/10], Step [1/1063], Loss: 0.0061\n",
      "Epoch [4/10], Step [2/1063], Loss: 0.0711\n",
      "Epoch [4/10], Step [3/1063], Loss: 0.0083\n",
      "Epoch [4/10], Step [4/1063], Loss: 0.0234\n",
      "Epoch [4/10], Step [5/1063], Loss: 0.0114\n",
      "Epoch [4/10], Step [6/1063], Loss: 0.0023\n",
      "Epoch [4/10], Step [7/1063], Loss: 0.0061\n",
      "Epoch [4/10], Step [8/1063], Loss: 0.0059\n",
      "Epoch [4/10], Step [9/1063], Loss: 0.0301\n",
      "Epoch [4/10], Step [10/1063], Loss: 0.0131\n",
      "Epoch [4/10], Step [11/1063], Loss: 0.0058\n",
      "Epoch [4/10], Step [12/1063], Loss: 0.0261\n",
      "Epoch [4/10], Step [13/1063], Loss: 0.0061\n",
      "Epoch [4/10], Step [14/1063], Loss: 0.0562\n",
      "Epoch [4/10], Step [15/1063], Loss: 0.0096\n",
      "Epoch [4/10], Step [16/1063], Loss: 0.0067\n",
      "Epoch [4/10], Step [17/1063], Loss: 0.0180\n",
      "Epoch [4/10], Step [18/1063], Loss: 0.0155\n",
      "Epoch [4/10], Step [19/1063], Loss: 0.0170\n",
      "Epoch [4/10], Step [20/1063], Loss: 0.0087\n",
      "Epoch [4/10], Step [21/1063], Loss: 0.0100\n",
      "Epoch [4/10], Step [22/1063], Loss: 0.0032\n",
      "Epoch [4/10], Step [23/1063], Loss: 0.0131\n",
      "Epoch [4/10], Step [24/1063], Loss: 0.0084\n",
      "Epoch [4/10], Step [25/1063], Loss: 0.0397\n",
      "Epoch [4/10], Step [26/1063], Loss: 0.0135\n",
      "Epoch [4/10], Step [27/1063], Loss: 0.0522\n",
      "Epoch [4/10], Step [28/1063], Loss: 0.0149\n",
      "Epoch [4/10], Step [29/1063], Loss: 0.0161\n",
      "Epoch [4/10], Step [30/1063], Loss: 0.0046\n",
      "Epoch [4/10], Step [31/1063], Loss: 0.0101\n",
      "Epoch [4/10], Step [32/1063], Loss: 0.0163\n",
      "Epoch [4/10], Step [33/1063], Loss: 0.0085\n",
      "Epoch [4/10], Step [34/1063], Loss: 0.0022\n",
      "Epoch [4/10], Step [35/1063], Loss: 0.0019\n",
      "Epoch [4/10], Step [36/1063], Loss: 0.0012\n",
      "Epoch [4/10], Step [37/1063], Loss: 0.0054\n",
      "Epoch [4/10], Step [38/1063], Loss: 0.0043\n",
      "Epoch [4/10], Step [39/1063], Loss: 0.0121\n",
      "Epoch [4/10], Step [40/1063], Loss: 0.0104\n",
      "Epoch [4/10], Step [41/1063], Loss: 0.0077\n",
      "Epoch [4/10], Step [42/1063], Loss: 0.0165\n",
      "Epoch [4/10], Step [43/1063], Loss: 0.0010\n",
      "Epoch [4/10], Step [44/1063], Loss: 0.0115\n",
      "Epoch [4/10], Step [45/1063], Loss: 0.0184\n",
      "Epoch [4/10], Step [46/1063], Loss: 0.0017\n",
      "Epoch [4/10], Step [47/1063], Loss: 0.0067\n",
      "Epoch [4/10], Step [48/1063], Loss: 0.0009\n",
      "Epoch [4/10], Step [49/1063], Loss: 0.0167\n",
      "Epoch [4/10], Step [50/1063], Loss: 0.0002\n",
      "Epoch [4/10], Step [51/1063], Loss: 0.0032\n",
      "Epoch [4/10], Step [52/1063], Loss: 0.0027\n",
      "Epoch [4/10], Step [53/1063], Loss: 0.0016\n",
      "Epoch [4/10], Step [54/1063], Loss: 0.0183\n",
      "Epoch [4/10], Step [55/1063], Loss: 0.0023\n",
      "Epoch [4/10], Step [56/1063], Loss: 0.0122\n",
      "Epoch [4/10], Step [57/1063], Loss: 0.0992\n",
      "Epoch [4/10], Step [58/1063], Loss: 0.0575\n",
      "Epoch [4/10], Step [59/1063], Loss: 0.1077\n",
      "Epoch [4/10], Step [60/1063], Loss: 0.0015\n",
      "Epoch [4/10], Step [61/1063], Loss: 0.0004\n",
      "Epoch [4/10], Step [62/1063], Loss: 0.0030\n",
      "Epoch [4/10], Step [63/1063], Loss: 0.0125\n",
      "Epoch [4/10], Step [64/1063], Loss: 0.0084\n",
      "Epoch [4/10], Step [65/1063], Loss: 0.0016\n",
      "Epoch [4/10], Step [66/1063], Loss: 0.0130\n",
      "Epoch [4/10], Step [67/1063], Loss: 0.0472\n",
      "Epoch [4/10], Step [68/1063], Loss: 0.1008\n",
      "Epoch [4/10], Step [69/1063], Loss: 0.0007\n",
      "Epoch [4/10], Step [70/1063], Loss: 0.0190\n",
      "Epoch [4/10], Step [71/1063], Loss: 0.0163\n",
      "Epoch [4/10], Step [72/1063], Loss: 0.1138\n",
      "Epoch [4/10], Step [73/1063], Loss: 0.0124\n",
      "Epoch [4/10], Step [74/1063], Loss: 0.0064\n",
      "Epoch [4/10], Step [75/1063], Loss: 0.0179\n",
      "Epoch [4/10], Step [76/1063], Loss: 0.0410\n",
      "Epoch [4/10], Step [77/1063], Loss: 0.0177\n",
      "Epoch [4/10], Step [78/1063], Loss: 0.0729\n",
      "Epoch [4/10], Step [79/1063], Loss: 0.0027\n",
      "Epoch [4/10], Step [80/1063], Loss: 0.0024\n",
      "Epoch [4/10], Step [81/1063], Loss: 0.0599\n",
      "Epoch [4/10], Step [82/1063], Loss: 0.0262\n",
      "Epoch [4/10], Step [83/1063], Loss: 0.1196\n",
      "Epoch [4/10], Step [84/1063], Loss: 0.0007\n",
      "Epoch [4/10], Step [85/1063], Loss: 0.0028\n",
      "Epoch [4/10], Step [86/1063], Loss: 0.0195\n",
      "Epoch [4/10], Step [87/1063], Loss: 0.0012\n",
      "Epoch [4/10], Step [88/1063], Loss: 0.0124\n",
      "Epoch [4/10], Step [89/1063], Loss: 0.0209\n",
      "Epoch [4/10], Step [90/1063], Loss: 0.0178\n",
      "Epoch [4/10], Step [91/1063], Loss: 0.0009\n",
      "Epoch [4/10], Step [92/1063], Loss: 0.0163\n",
      "Epoch [4/10], Step [93/1063], Loss: 0.0429\n",
      "Epoch [4/10], Step [94/1063], Loss: 0.0048\n",
      "Epoch [4/10], Step [95/1063], Loss: 0.0015\n",
      "Epoch [4/10], Step [96/1063], Loss: 0.0012\n",
      "Epoch [4/10], Step [97/1063], Loss: 0.0017\n",
      "Epoch [4/10], Step [98/1063], Loss: 0.0025\n",
      "Epoch [4/10], Step [99/1063], Loss: 0.0025\n",
      "Epoch [4/10], Step [100/1063], Loss: 0.0164\n",
      "Epoch [4/10], Step [101/1063], Loss: 0.0274\n",
      "Epoch [4/10], Step [102/1063], Loss: 0.0050\n",
      "Epoch [4/10], Step [103/1063], Loss: 0.0258\n",
      "Epoch [4/10], Step [104/1063], Loss: 0.0092\n",
      "Epoch [4/10], Step [105/1063], Loss: 0.0436\n",
      "Epoch [4/10], Step [106/1063], Loss: 0.0470\n",
      "Epoch [4/10], Step [107/1063], Loss: 0.0239\n",
      "Epoch [4/10], Step [108/1063], Loss: 0.0591\n",
      "Epoch [4/10], Step [109/1063], Loss: 0.0379\n",
      "Epoch [4/10], Step [110/1063], Loss: 0.0091\n",
      "Epoch [4/10], Step [111/1063], Loss: 0.0283\n",
      "Epoch [4/10], Step [112/1063], Loss: 0.0013\n",
      "Epoch [4/10], Step [113/1063], Loss: 0.0298\n",
      "Epoch [4/10], Step [114/1063], Loss: 0.0013\n",
      "Epoch [4/10], Step [115/1063], Loss: 0.0084\n",
      "Epoch [4/10], Step [116/1063], Loss: 0.0302\n",
      "Epoch [4/10], Step [117/1063], Loss: 0.0035\n",
      "Epoch [4/10], Step [118/1063], Loss: 0.0516\n",
      "Epoch [4/10], Step [119/1063], Loss: 0.0670\n",
      "Epoch [4/10], Step [120/1063], Loss: 0.0211\n",
      "Epoch [4/10], Step [121/1063], Loss: 0.1260\n",
      "Epoch [4/10], Step [122/1063], Loss: 0.0236\n",
      "Epoch [4/10], Step [123/1063], Loss: 0.0030\n",
      "Epoch [4/10], Step [124/1063], Loss: 0.0316\n",
      "Epoch [4/10], Step [125/1063], Loss: 0.0015\n",
      "Epoch [4/10], Step [126/1063], Loss: 0.0970\n",
      "Epoch [4/10], Step [127/1063], Loss: 0.0105\n",
      "Epoch [4/10], Step [128/1063], Loss: 0.0104\n",
      "Epoch [4/10], Step [129/1063], Loss: 0.1190\n",
      "Epoch [4/10], Step [130/1063], Loss: 0.0787\n",
      "Epoch [4/10], Step [131/1063], Loss: 0.0034\n",
      "Epoch [4/10], Step [132/1063], Loss: 0.0712\n",
      "Epoch [4/10], Step [133/1063], Loss: 0.0402\n",
      "Epoch [4/10], Step [134/1063], Loss: 0.0270\n",
      "Epoch [4/10], Step [135/1063], Loss: 0.0147\n",
      "Epoch [4/10], Step [136/1063], Loss: 0.0073\n",
      "Epoch [4/10], Step [137/1063], Loss: 0.0227\n",
      "Epoch [4/10], Step [138/1063], Loss: 0.0184\n",
      "Epoch [4/10], Step [139/1063], Loss: 0.0163\n",
      "Epoch [4/10], Step [140/1063], Loss: 0.0027\n",
      "Epoch [4/10], Step [141/1063], Loss: 0.0125\n",
      "Epoch [4/10], Step [142/1063], Loss: 0.0183\n",
      "Epoch [4/10], Step [143/1063], Loss: 0.0157\n",
      "Epoch [4/10], Step [144/1063], Loss: 0.0014\n",
      "Epoch [4/10], Step [145/1063], Loss: 0.0284\n",
      "Epoch [4/10], Step [146/1063], Loss: 0.0152\n",
      "Epoch [4/10], Step [147/1063], Loss: 0.0438\n",
      "Epoch [4/10], Step [148/1063], Loss: 0.0081\n",
      "Epoch [4/10], Step [149/1063], Loss: 0.0563\n",
      "Epoch [4/10], Step [150/1063], Loss: 0.0200\n",
      "Epoch [4/10], Step [151/1063], Loss: 0.0216\n",
      "Epoch [4/10], Step [152/1063], Loss: 0.0077\n",
      "Epoch [4/10], Step [153/1063], Loss: 0.0018\n",
      "Epoch [4/10], Step [154/1063], Loss: 0.1103\n",
      "Epoch [4/10], Step [155/1063], Loss: 0.0178\n",
      "Epoch [4/10], Step [156/1063], Loss: 0.0092\n",
      "Epoch [4/10], Step [157/1063], Loss: 0.0150\n",
      "Epoch [4/10], Step [158/1063], Loss: 0.0201\n",
      "Epoch [4/10], Step [159/1063], Loss: 0.0060\n",
      "Epoch [4/10], Step [160/1063], Loss: 0.0433\n",
      "Epoch [4/10], Step [161/1063], Loss: 0.0006\n",
      "Epoch [4/10], Step [162/1063], Loss: 0.0668\n",
      "Epoch [4/10], Step [163/1063], Loss: 0.0368\n",
      "Epoch [4/10], Step [164/1063], Loss: 0.0105\n",
      "Epoch [4/10], Step [165/1063], Loss: 0.0148\n",
      "Epoch [4/10], Step [166/1063], Loss: 0.1430\n",
      "Epoch [4/10], Step [167/1063], Loss: 0.0046\n",
      "Epoch [4/10], Step [168/1063], Loss: 0.0030\n",
      "Epoch [4/10], Step [169/1063], Loss: 0.0595\n",
      "Epoch [4/10], Step [170/1063], Loss: 0.0243\n",
      "Epoch [4/10], Step [171/1063], Loss: 0.0082\n",
      "Epoch [4/10], Step [172/1063], Loss: 0.0020\n",
      "Epoch [4/10], Step [173/1063], Loss: 0.0076\n",
      "Epoch [4/10], Step [174/1063], Loss: 0.0026\n",
      "Epoch [4/10], Step [175/1063], Loss: 0.0010\n",
      "Epoch [4/10], Step [176/1063], Loss: 0.0100\n",
      "Epoch [4/10], Step [177/1063], Loss: 0.0583\n",
      "Epoch [4/10], Step [178/1063], Loss: 0.0152\n",
      "Epoch [4/10], Step [179/1063], Loss: 0.0079\n",
      "Epoch [4/10], Step [180/1063], Loss: 0.0432\n",
      "Epoch [4/10], Step [181/1063], Loss: 0.0433\n",
      "Epoch [4/10], Step [182/1063], Loss: 0.0066\n",
      "Epoch [4/10], Step [183/1063], Loss: 0.0040\n",
      "Epoch [4/10], Step [184/1063], Loss: 0.0048\n",
      "Epoch [4/10], Step [185/1063], Loss: 0.0073\n",
      "Epoch [4/10], Step [186/1063], Loss: 0.0050\n",
      "Epoch [4/10], Step [187/1063], Loss: 0.0214\n",
      "Epoch [4/10], Step [188/1063], Loss: 0.0113\n",
      "Epoch [4/10], Step [189/1063], Loss: 0.0151\n",
      "Epoch [4/10], Step [190/1063], Loss: 0.0038\n",
      "Epoch [4/10], Step [191/1063], Loss: 0.0530\n",
      "Epoch [4/10], Step [192/1063], Loss: 0.0082\n",
      "Epoch [4/10], Step [193/1063], Loss: 0.0114\n",
      "Epoch [4/10], Step [194/1063], Loss: 0.0149\n",
      "Epoch [4/10], Step [195/1063], Loss: 0.0180\n",
      "Epoch [4/10], Step [196/1063], Loss: 0.0183\n",
      "Epoch [4/10], Step [197/1063], Loss: 0.0096\n",
      "Epoch [4/10], Step [198/1063], Loss: 0.0138\n",
      "Epoch [4/10], Step [199/1063], Loss: 0.0537\n",
      "Epoch [4/10], Step [200/1063], Loss: 0.0703\n",
      "Epoch [4/10], Step [201/1063], Loss: 0.1163\n",
      "Epoch [4/10], Step [202/1063], Loss: 0.0322\n",
      "Epoch [4/10], Step [203/1063], Loss: 0.0056\n",
      "Epoch [4/10], Step [204/1063], Loss: 0.0083\n",
      "Epoch [4/10], Step [205/1063], Loss: 0.0410\n",
      "Epoch [4/10], Step [206/1063], Loss: 0.0096\n",
      "Epoch [4/10], Step [207/1063], Loss: 0.0045\n",
      "Epoch [4/10], Step [208/1063], Loss: 0.0429\n",
      "Epoch [4/10], Step [209/1063], Loss: 0.0090\n",
      "Epoch [4/10], Step [210/1063], Loss: 0.0022\n",
      "Epoch [4/10], Step [211/1063], Loss: 0.0026\n",
      "Epoch [4/10], Step [212/1063], Loss: 0.0336\n",
      "Epoch [4/10], Step [213/1063], Loss: 0.0127\n",
      "Epoch [4/10], Step [214/1063], Loss: 0.0075\n",
      "Epoch [4/10], Step [215/1063], Loss: 0.0229\n",
      "Epoch [4/10], Step [216/1063], Loss: 0.0108\n",
      "Epoch [4/10], Step [217/1063], Loss: 0.0218\n",
      "Epoch [4/10], Step [218/1063], Loss: 0.0178\n",
      "Epoch [4/10], Step [219/1063], Loss: 0.0111\n",
      "Epoch [4/10], Step [220/1063], Loss: 0.0949\n",
      "Epoch [4/10], Step [221/1063], Loss: 0.0009\n",
      "Epoch [4/10], Step [222/1063], Loss: 0.0152\n",
      "Epoch [4/10], Step [223/1063], Loss: 0.0321\n",
      "Epoch [4/10], Step [224/1063], Loss: 0.0213\n",
      "Epoch [4/10], Step [225/1063], Loss: 0.0087\n",
      "Epoch [4/10], Step [226/1063], Loss: 0.0439\n",
      "Epoch [4/10], Step [227/1063], Loss: 0.0325\n",
      "Epoch [4/10], Step [228/1063], Loss: 0.0179\n",
      "Epoch [4/10], Step [229/1063], Loss: 0.0008\n",
      "Epoch [4/10], Step [230/1063], Loss: 0.0136\n",
      "Epoch [4/10], Step [231/1063], Loss: 0.0017\n",
      "Epoch [4/10], Step [232/1063], Loss: 0.0344\n",
      "Epoch [4/10], Step [233/1063], Loss: 0.0219\n",
      "Epoch [4/10], Step [234/1063], Loss: 0.0048\n",
      "Epoch [4/10], Step [235/1063], Loss: 0.0058\n",
      "Epoch [4/10], Step [236/1063], Loss: 0.0966\n",
      "Epoch [4/10], Step [237/1063], Loss: 0.0213\n",
      "Epoch [4/10], Step [238/1063], Loss: 0.0178\n",
      "Epoch [4/10], Step [239/1063], Loss: 0.0120\n",
      "Epoch [4/10], Step [240/1063], Loss: 0.0148\n",
      "Epoch [4/10], Step [241/1063], Loss: 0.0478\n",
      "Epoch [4/10], Step [242/1063], Loss: 0.0072\n",
      "Epoch [4/10], Step [243/1063], Loss: 0.0051\n",
      "Epoch [4/10], Step [244/1063], Loss: 0.0231\n",
      "Epoch [4/10], Step [245/1063], Loss: 0.0322\n",
      "Epoch [4/10], Step [246/1063], Loss: 0.0206\n",
      "Epoch [4/10], Step [247/1063], Loss: 0.0037\n",
      "Epoch [4/10], Step [248/1063], Loss: 0.0026\n",
      "Epoch [4/10], Step [249/1063], Loss: 0.0288\n",
      "Epoch [4/10], Step [250/1063], Loss: 0.0223\n",
      "Epoch [4/10], Step [251/1063], Loss: 0.0134\n",
      "Epoch [4/10], Step [252/1063], Loss: 0.0104\n",
      "Epoch [4/10], Step [253/1063], Loss: 0.0045\n",
      "Epoch [4/10], Step [254/1063], Loss: 0.0157\n",
      "Epoch [4/10], Step [255/1063], Loss: 0.0087\n",
      "Epoch [4/10], Step [256/1063], Loss: 0.0521\n",
      "Epoch [4/10], Step [257/1063], Loss: 0.0007\n",
      "Epoch [4/10], Step [258/1063], Loss: 0.0040\n",
      "Epoch [4/10], Step [259/1063], Loss: 0.0141\n",
      "Epoch [4/10], Step [260/1063], Loss: 0.0011\n",
      "Epoch [4/10], Step [261/1063], Loss: 0.0249\n",
      "Epoch [4/10], Step [262/1063], Loss: 0.0123\n",
      "Epoch [4/10], Step [263/1063], Loss: 0.0103\n",
      "Epoch [4/10], Step [264/1063], Loss: 0.0048\n",
      "Epoch [4/10], Step [265/1063], Loss: 0.0035\n",
      "Epoch [4/10], Step [266/1063], Loss: 0.0049\n",
      "Epoch [4/10], Step [267/1063], Loss: 0.0048\n",
      "Epoch [4/10], Step [268/1063], Loss: 0.0399\n",
      "Epoch [4/10], Step [269/1063], Loss: 0.0034\n",
      "Epoch [4/10], Step [270/1063], Loss: 0.0079\n",
      "Epoch [4/10], Step [271/1063], Loss: 0.0228\n",
      "Epoch [4/10], Step [272/1063], Loss: 0.0090\n",
      "Epoch [4/10], Step [273/1063], Loss: 0.0153\n",
      "Epoch [4/10], Step [274/1063], Loss: 0.0351\n",
      "Epoch [4/10], Step [275/1063], Loss: 0.0175\n",
      "Epoch [4/10], Step [276/1063], Loss: 0.0701\n",
      "Epoch [4/10], Step [277/1063], Loss: 0.0164\n",
      "Epoch [4/10], Step [278/1063], Loss: 0.0151\n",
      "Epoch [4/10], Step [279/1063], Loss: 0.0128\n",
      "Epoch [4/10], Step [280/1063], Loss: 0.0007\n",
      "Epoch [4/10], Step [281/1063], Loss: 0.0015\n",
      "Epoch [4/10], Step [282/1063], Loss: 0.0032\n",
      "Epoch [4/10], Step [283/1063], Loss: 0.0474\n",
      "Epoch [4/10], Step [284/1063], Loss: 0.0706\n",
      "Epoch [4/10], Step [285/1063], Loss: 0.0017\n",
      "Epoch [4/10], Step [286/1063], Loss: 0.0037\n",
      "Epoch [4/10], Step [287/1063], Loss: 0.0161\n",
      "Epoch [4/10], Step [288/1063], Loss: 0.0009\n",
      "Epoch [4/10], Step [289/1063], Loss: 0.0080\n",
      "Epoch [4/10], Step [290/1063], Loss: 0.0142\n",
      "Epoch [4/10], Step [291/1063], Loss: 0.0020\n",
      "Epoch [4/10], Step [292/1063], Loss: 0.0108\n",
      "Epoch [4/10], Step [293/1063], Loss: 0.0220\n",
      "Epoch [4/10], Step [294/1063], Loss: 0.0021\n",
      "Epoch [4/10], Step [295/1063], Loss: 0.0100\n",
      "Epoch [4/10], Step [296/1063], Loss: 0.0214\n",
      "Epoch [4/10], Step [297/1063], Loss: 0.0380\n",
      "Epoch [4/10], Step [298/1063], Loss: 0.0020\n",
      "Epoch [4/10], Step [299/1063], Loss: 0.0422\n",
      "Epoch [4/10], Step [300/1063], Loss: 0.0002\n",
      "Epoch [4/10], Step [301/1063], Loss: 0.0259\n",
      "Epoch [4/10], Step [302/1063], Loss: 0.0080\n",
      "Epoch [4/10], Step [303/1063], Loss: 0.0092\n",
      "Epoch [4/10], Step [304/1063], Loss: 0.0204\n",
      "Epoch [4/10], Step [305/1063], Loss: 0.0297\n",
      "Epoch [4/10], Step [306/1063], Loss: 0.0051\n",
      "Epoch [4/10], Step [307/1063], Loss: 0.0877\n",
      "Epoch [4/10], Step [308/1063], Loss: 0.0379\n",
      "Epoch [4/10], Step [309/1063], Loss: 0.0027\n",
      "Epoch [4/10], Step [310/1063], Loss: 0.1536\n",
      "Epoch [4/10], Step [311/1063], Loss: 0.0017\n",
      "Epoch [4/10], Step [312/1063], Loss: 0.0763\n",
      "Epoch [4/10], Step [313/1063], Loss: 0.0215\n",
      "Epoch [4/10], Step [314/1063], Loss: 0.0107\n",
      "Epoch [4/10], Step [315/1063], Loss: 0.0575\n",
      "Epoch [4/10], Step [316/1063], Loss: 0.0153\n",
      "Epoch [4/10], Step [317/1063], Loss: 0.1121\n",
      "Epoch [4/10], Step [318/1063], Loss: 0.0307\n",
      "Epoch [4/10], Step [319/1063], Loss: 0.0034\n",
      "Epoch [4/10], Step [320/1063], Loss: 0.0024\n",
      "Epoch [4/10], Step [321/1063], Loss: 0.0180\n",
      "Epoch [4/10], Step [322/1063], Loss: 0.0280\n",
      "Epoch [4/10], Step [323/1063], Loss: 0.0375\n",
      "Epoch [4/10], Step [324/1063], Loss: 0.0616\n",
      "Epoch [4/10], Step [325/1063], Loss: 0.0034\n",
      "Epoch [4/10], Step [326/1063], Loss: 0.0121\n",
      "Epoch [4/10], Step [327/1063], Loss: 0.0212\n",
      "Epoch [4/10], Step [328/1063], Loss: 0.0024\n",
      "Epoch [4/10], Step [329/1063], Loss: 0.0746\n",
      "Epoch [4/10], Step [330/1063], Loss: 0.0088\n",
      "Epoch [4/10], Step [331/1063], Loss: 0.0023\n",
      "Epoch [4/10], Step [332/1063], Loss: 0.0241\n",
      "Epoch [4/10], Step [333/1063], Loss: 0.0046\n",
      "Epoch [4/10], Step [334/1063], Loss: 0.0078\n",
      "Epoch [4/10], Step [335/1063], Loss: 0.0150\n",
      "Epoch [4/10], Step [336/1063], Loss: 0.0390\n",
      "Epoch [4/10], Step [337/1063], Loss: 0.0367\n",
      "Epoch [4/10], Step [338/1063], Loss: 0.0218\n",
      "Epoch [4/10], Step [339/1063], Loss: 0.0161\n",
      "Epoch [4/10], Step [340/1063], Loss: 0.0032\n",
      "Epoch [4/10], Step [341/1063], Loss: 0.0200\n",
      "Epoch [4/10], Step [342/1063], Loss: 0.0768\n",
      "Epoch [4/10], Step [343/1063], Loss: 0.0332\n",
      "Epoch [4/10], Step [344/1063], Loss: 0.0264\n",
      "Epoch [4/10], Step [345/1063], Loss: 0.0017\n",
      "Epoch [4/10], Step [346/1063], Loss: 0.0060\n",
      "Epoch [4/10], Step [347/1063], Loss: 0.0177\n",
      "Epoch [4/10], Step [348/1063], Loss: 0.0396\n",
      "Epoch [4/10], Step [349/1063], Loss: 0.0225\n",
      "Epoch [4/10], Step [350/1063], Loss: 0.0272\n",
      "Epoch [4/10], Step [351/1063], Loss: 0.0009\n",
      "Epoch [4/10], Step [352/1063], Loss: 0.0304\n",
      "Epoch [4/10], Step [353/1063], Loss: 0.0054\n",
      "Epoch [4/10], Step [354/1063], Loss: 0.0226\n",
      "Epoch [4/10], Step [355/1063], Loss: 0.0027\n",
      "Epoch [4/10], Step [356/1063], Loss: 0.0044\n",
      "Epoch [4/10], Step [357/1063], Loss: 0.0026\n",
      "Epoch [4/10], Step [358/1063], Loss: 0.0824\n",
      "Epoch [4/10], Step [359/1063], Loss: 0.0066\n",
      "Epoch [4/10], Step [360/1063], Loss: 0.0040\n",
      "Epoch [4/10], Step [361/1063], Loss: 0.0167\n",
      "Epoch [4/10], Step [362/1063], Loss: 0.0036\n",
      "Epoch [4/10], Step [363/1063], Loss: 0.0008\n",
      "Epoch [4/10], Step [364/1063], Loss: 0.0137\n",
      "Epoch [4/10], Step [365/1063], Loss: 0.0054\n",
      "Epoch [4/10], Step [366/1063], Loss: 0.0710\n",
      "Epoch [4/10], Step [367/1063], Loss: 0.0603\n",
      "Epoch [4/10], Step [368/1063], Loss: 0.0027\n",
      "Epoch [4/10], Step [369/1063], Loss: 0.0043\n",
      "Epoch [4/10], Step [370/1063], Loss: 0.0014\n",
      "Epoch [4/10], Step [371/1063], Loss: 0.0298\n",
      "Epoch [4/10], Step [372/1063], Loss: 0.0084\n",
      "Epoch [4/10], Step [373/1063], Loss: 0.0289\n",
      "Epoch [4/10], Step [374/1063], Loss: 0.0051\n",
      "Epoch [4/10], Step [375/1063], Loss: 0.0466\n",
      "Epoch [4/10], Step [376/1063], Loss: 0.0055\n",
      "Epoch [4/10], Step [377/1063], Loss: 0.0255\n",
      "Epoch [4/10], Step [378/1063], Loss: 0.0127\n",
      "Epoch [4/10], Step [379/1063], Loss: 0.0115\n",
      "Epoch [4/10], Step [380/1063], Loss: 0.0273\n",
      "Epoch [4/10], Step [381/1063], Loss: 0.0087\n",
      "Epoch [4/10], Step [382/1063], Loss: 0.0120\n",
      "Epoch [4/10], Step [383/1063], Loss: 0.0081\n",
      "Epoch [4/10], Step [384/1063], Loss: 0.0290\n",
      "Epoch [4/10], Step [385/1063], Loss: 0.0053\n",
      "Epoch [4/10], Step [386/1063], Loss: 0.0426\n",
      "Epoch [4/10], Step [387/1063], Loss: 0.0079\n",
      "Epoch [4/10], Step [388/1063], Loss: 0.0031\n",
      "Epoch [4/10], Step [389/1063], Loss: 0.0058\n",
      "Epoch [4/10], Step [390/1063], Loss: 0.0078\n",
      "Epoch [4/10], Step [391/1063], Loss: 0.0141\n",
      "Epoch [4/10], Step [392/1063], Loss: 0.0126\n",
      "Epoch [4/10], Step [393/1063], Loss: 0.0266\n",
      "Epoch [4/10], Step [394/1063], Loss: 0.1163\n",
      "Epoch [4/10], Step [395/1063], Loss: 0.0029\n",
      "Epoch [4/10], Step [396/1063], Loss: 0.0050\n",
      "Epoch [4/10], Step [397/1063], Loss: 0.0116\n",
      "Epoch [4/10], Step [398/1063], Loss: 0.0600\n",
      "Epoch [4/10], Step [399/1063], Loss: 0.0004\n",
      "Epoch [4/10], Step [400/1063], Loss: 0.0016\n",
      "Epoch [4/10], Step [401/1063], Loss: 0.0031\n",
      "Epoch [4/10], Step [402/1063], Loss: 0.0064\n",
      "Epoch [4/10], Step [403/1063], Loss: 0.0262\n",
      "Epoch [4/10], Step [404/1063], Loss: 0.0283\n",
      "Epoch [4/10], Step [405/1063], Loss: 0.0152\n",
      "Epoch [4/10], Step [406/1063], Loss: 0.0005\n",
      "Epoch [4/10], Step [407/1063], Loss: 0.0612\n",
      "Epoch [4/10], Step [408/1063], Loss: 0.0421\n",
      "Epoch [4/10], Step [409/1063], Loss: 0.0002\n",
      "Epoch [4/10], Step [410/1063], Loss: 0.0244\n",
      "Epoch [4/10], Step [411/1063], Loss: 0.1098\n",
      "Epoch [4/10], Step [412/1063], Loss: 0.0540\n",
      "Epoch [4/10], Step [413/1063], Loss: 0.1003\n",
      "Epoch [4/10], Step [414/1063], Loss: 0.0019\n",
      "Epoch [4/10], Step [415/1063], Loss: 0.0138\n",
      "Epoch [4/10], Step [416/1063], Loss: 0.0228\n",
      "Epoch [4/10], Step [417/1063], Loss: 0.0125\n",
      "Epoch [4/10], Step [418/1063], Loss: 0.0280\n",
      "Epoch [4/10], Step [419/1063], Loss: 0.0011\n",
      "Epoch [4/10], Step [420/1063], Loss: 0.0024\n",
      "Epoch [4/10], Step [421/1063], Loss: 0.0504\n",
      "Epoch [4/10], Step [422/1063], Loss: 0.0508\n",
      "Epoch [4/10], Step [423/1063], Loss: 0.0803\n",
      "Epoch [4/10], Step [424/1063], Loss: 0.0048\n",
      "Epoch [4/10], Step [425/1063], Loss: 0.0076\n",
      "Epoch [4/10], Step [426/1063], Loss: 0.0035\n",
      "Epoch [4/10], Step [427/1063], Loss: 0.0013\n",
      "Epoch [4/10], Step [428/1063], Loss: 0.1066\n",
      "Epoch [4/10], Step [429/1063], Loss: 0.0243\n",
      "Epoch [4/10], Step [430/1063], Loss: 0.0211\n",
      "Epoch [4/10], Step [431/1063], Loss: 0.0372\n",
      "Epoch [4/10], Step [432/1063], Loss: 0.0497\n",
      "Epoch [4/10], Step [433/1063], Loss: 0.0370\n",
      "Epoch [4/10], Step [434/1063], Loss: 0.0444\n",
      "Epoch [4/10], Step [435/1063], Loss: 0.0087\n",
      "Epoch [4/10], Step [436/1063], Loss: 0.0270\n",
      "Epoch [4/10], Step [437/1063], Loss: 0.0067\n",
      "Epoch [4/10], Step [438/1063], Loss: 0.0032\n",
      "Epoch [4/10], Step [439/1063], Loss: 0.0068\n",
      "Epoch [4/10], Step [440/1063], Loss: 0.0539\n",
      "Epoch [4/10], Step [441/1063], Loss: 0.0249\n",
      "Epoch [4/10], Step [442/1063], Loss: 0.0431\n",
      "Epoch [4/10], Step [443/1063], Loss: 0.0090\n",
      "Epoch [4/10], Step [444/1063], Loss: 0.0241\n",
      "Epoch [4/10], Step [445/1063], Loss: 0.0136\n",
      "Epoch [4/10], Step [446/1063], Loss: 0.0018\n",
      "Epoch [4/10], Step [447/1063], Loss: 0.0023\n",
      "Epoch [4/10], Step [448/1063], Loss: 0.0779\n",
      "Epoch [4/10], Step [449/1063], Loss: 0.0682\n",
      "Epoch [4/10], Step [450/1063], Loss: 0.0547\n",
      "Epoch [4/10], Step [451/1063], Loss: 0.0320\n",
      "Epoch [4/10], Step [452/1063], Loss: 0.0055\n",
      "Epoch [4/10], Step [453/1063], Loss: 0.0139\n",
      "Epoch [4/10], Step [454/1063], Loss: 0.0543\n",
      "Epoch [4/10], Step [455/1063], Loss: 0.0162\n",
      "Epoch [4/10], Step [456/1063], Loss: 0.0046\n",
      "Epoch [4/10], Step [457/1063], Loss: 0.0065\n",
      "Epoch [4/10], Step [458/1063], Loss: 0.0194\n",
      "Epoch [4/10], Step [459/1063], Loss: 0.0040\n",
      "Epoch [4/10], Step [460/1063], Loss: 0.0098\n",
      "Epoch [4/10], Step [461/1063], Loss: 0.0104\n",
      "Epoch [4/10], Step [462/1063], Loss: 0.0876\n",
      "Epoch [4/10], Step [463/1063], Loss: 0.0725\n",
      "Epoch [4/10], Step [464/1063], Loss: 0.0084\n",
      "Epoch [4/10], Step [465/1063], Loss: 0.0483\n",
      "Epoch [4/10], Step [466/1063], Loss: 0.0137\n",
      "Epoch [4/10], Step [467/1063], Loss: 0.0311\n",
      "Epoch [4/10], Step [468/1063], Loss: 0.0117\n",
      "Epoch [4/10], Step [469/1063], Loss: 0.1934\n",
      "Epoch [4/10], Step [470/1063], Loss: 0.0025\n",
      "Epoch [4/10], Step [471/1063], Loss: 0.0176\n",
      "Epoch [4/10], Step [472/1063], Loss: 0.0072\n",
      "Epoch [4/10], Step [473/1063], Loss: 0.0093\n",
      "Epoch [4/10], Step [474/1063], Loss: 0.0061\n",
      "Epoch [4/10], Step [475/1063], Loss: 0.0179\n",
      "Epoch [4/10], Step [476/1063], Loss: 0.0205\n",
      "Epoch [4/10], Step [477/1063], Loss: 0.0028\n",
      "Epoch [4/10], Step [478/1063], Loss: 0.0024\n",
      "Epoch [4/10], Step [479/1063], Loss: 0.0017\n",
      "Epoch [4/10], Step [480/1063], Loss: 0.0066\n",
      "Epoch [4/10], Step [481/1063], Loss: 0.0568\n",
      "Epoch [4/10], Step [482/1063], Loss: 0.0956\n",
      "Epoch [4/10], Step [483/1063], Loss: 0.0524\n",
      "Epoch [4/10], Step [484/1063], Loss: 0.0388\n",
      "Epoch [4/10], Step [485/1063], Loss: 0.0438\n",
      "Epoch [4/10], Step [486/1063], Loss: 0.0205\n",
      "Epoch [4/10], Step [487/1063], Loss: 0.0097\n",
      "Epoch [4/10], Step [488/1063], Loss: 0.0417\n",
      "Epoch [4/10], Step [489/1063], Loss: 0.0151\n",
      "Epoch [4/10], Step [490/1063], Loss: 0.0325\n",
      "Epoch [4/10], Step [491/1063], Loss: 0.0048\n",
      "Epoch [4/10], Step [492/1063], Loss: 0.0047\n",
      "Epoch [4/10], Step [493/1063], Loss: 0.0262\n",
      "Epoch [4/10], Step [494/1063], Loss: 0.0237\n",
      "Epoch [4/10], Step [495/1063], Loss: 0.0716\n",
      "Epoch [4/10], Step [496/1063], Loss: 0.0466\n",
      "Epoch [4/10], Step [497/1063], Loss: 0.0044\n",
      "Epoch [4/10], Step [498/1063], Loss: 0.0088\n",
      "Epoch [4/10], Step [499/1063], Loss: 0.0041\n",
      "Epoch [4/10], Step [500/1063], Loss: 0.0176\n",
      "Epoch [4/10], Step [501/1063], Loss: 0.0078\n",
      "Epoch [4/10], Step [502/1063], Loss: 0.0018\n",
      "Epoch [4/10], Step [503/1063], Loss: 0.0155\n",
      "Epoch [4/10], Step [504/1063], Loss: 0.0157\n",
      "Epoch [4/10], Step [505/1063], Loss: 0.0446\n",
      "Epoch [4/10], Step [506/1063], Loss: 0.0043\n",
      "Epoch [4/10], Step [507/1063], Loss: 0.0005\n",
      "Epoch [4/10], Step [508/1063], Loss: 0.0506\n",
      "Epoch [4/10], Step [509/1063], Loss: 0.0139\n",
      "Epoch [4/10], Step [510/1063], Loss: 0.0060\n",
      "Epoch [4/10], Step [511/1063], Loss: 0.0116\n",
      "Epoch [4/10], Step [512/1063], Loss: 0.0124\n",
      "Epoch [4/10], Step [513/1063], Loss: 0.0178\n",
      "Epoch [4/10], Step [514/1063], Loss: 0.1058\n",
      "Epoch [4/10], Step [515/1063], Loss: 0.0441\n",
      "Epoch [4/10], Step [516/1063], Loss: 0.0121\n",
      "Epoch [4/10], Step [517/1063], Loss: 0.0113\n",
      "Epoch [4/10], Step [518/1063], Loss: 0.0014\n",
      "Epoch [4/10], Step [519/1063], Loss: 0.0092\n",
      "Epoch [4/10], Step [520/1063], Loss: 0.0278\n",
      "Epoch [4/10], Step [521/1063], Loss: 0.0015\n",
      "Epoch [4/10], Step [522/1063], Loss: 0.0009\n",
      "Epoch [4/10], Step [523/1063], Loss: 0.0755\n",
      "Epoch [4/10], Step [524/1063], Loss: 0.0237\n",
      "Epoch [4/10], Step [525/1063], Loss: 0.0103\n",
      "Epoch [4/10], Step [526/1063], Loss: 0.0035\n",
      "Epoch [4/10], Step [527/1063], Loss: 0.0088\n",
      "Epoch [4/10], Step [528/1063], Loss: 0.0003\n",
      "Epoch [4/10], Step [529/1063], Loss: 0.0194\n",
      "Epoch [4/10], Step [530/1063], Loss: 0.0214\n",
      "Epoch [4/10], Step [531/1063], Loss: 0.0026\n",
      "Epoch [4/10], Step [532/1063], Loss: 0.0059\n",
      "Epoch [4/10], Step [533/1063], Loss: 0.0031\n",
      "Epoch [4/10], Step [534/1063], Loss: 0.0041\n",
      "Epoch [4/10], Step [535/1063], Loss: 0.0250\n",
      "Epoch [4/10], Step [536/1063], Loss: 0.0954\n",
      "Epoch [4/10], Step [537/1063], Loss: 0.0607\n",
      "Epoch [4/10], Step [538/1063], Loss: 0.0222\n",
      "Epoch [4/10], Step [539/1063], Loss: 0.0020\n",
      "Epoch [4/10], Step [540/1063], Loss: 0.0102\n",
      "Epoch [4/10], Step [541/1063], Loss: 0.0006\n",
      "Epoch [4/10], Step [542/1063], Loss: 0.0094\n",
      "Epoch [4/10], Step [543/1063], Loss: 0.0240\n",
      "Epoch [4/10], Step [544/1063], Loss: 0.0068\n",
      "Epoch [4/10], Step [545/1063], Loss: 0.0197\n",
      "Epoch [4/10], Step [546/1063], Loss: 0.0012\n",
      "Epoch [4/10], Step [547/1063], Loss: 0.0044\n",
      "Epoch [4/10], Step [548/1063], Loss: 0.0009\n",
      "Epoch [4/10], Step [549/1063], Loss: 0.0038\n",
      "Epoch [4/10], Step [550/1063], Loss: 0.0369\n",
      "Epoch [4/10], Step [551/1063], Loss: 0.0101\n",
      "Epoch [4/10], Step [552/1063], Loss: 0.0246\n",
      "Epoch [4/10], Step [553/1063], Loss: 0.0836\n",
      "Epoch [4/10], Step [554/1063], Loss: 0.2289\n",
      "Epoch [4/10], Step [555/1063], Loss: 0.0083\n",
      "Epoch [4/10], Step [556/1063], Loss: 0.0025\n",
      "Epoch [4/10], Step [557/1063], Loss: 0.0033\n",
      "Epoch [4/10], Step [558/1063], Loss: 0.0172\n",
      "Epoch [4/10], Step [559/1063], Loss: 0.0561\n",
      "Epoch [4/10], Step [560/1063], Loss: 0.0086\n",
      "Epoch [4/10], Step [561/1063], Loss: 0.0422\n",
      "Epoch [4/10], Step [562/1063], Loss: 0.0107\n",
      "Epoch [4/10], Step [563/1063], Loss: 0.0005\n",
      "Epoch [4/10], Step [564/1063], Loss: 0.0465\n",
      "Epoch [4/10], Step [565/1063], Loss: 0.0515\n",
      "Epoch [4/10], Step [566/1063], Loss: 0.0047\n",
      "Epoch [4/10], Step [567/1063], Loss: 0.0071\n",
      "Epoch [4/10], Step [568/1063], Loss: 0.2063\n",
      "Epoch [4/10], Step [569/1063], Loss: 0.0068\n",
      "Epoch [4/10], Step [570/1063], Loss: 0.0011\n",
      "Epoch [4/10], Step [571/1063], Loss: 0.0307\n",
      "Epoch [4/10], Step [572/1063], Loss: 0.0041\n",
      "Epoch [4/10], Step [573/1063], Loss: 0.0383\n",
      "Epoch [4/10], Step [574/1063], Loss: 0.0304\n",
      "Epoch [4/10], Step [575/1063], Loss: 0.0218\n",
      "Epoch [4/10], Step [576/1063], Loss: 0.0065\n",
      "Epoch [4/10], Step [577/1063], Loss: 0.0050\n",
      "Epoch [4/10], Step [578/1063], Loss: 0.0350\n",
      "Epoch [4/10], Step [579/1063], Loss: 0.0187\n",
      "Epoch [4/10], Step [580/1063], Loss: 0.0774\n",
      "Epoch [4/10], Step [581/1063], Loss: 0.0025\n",
      "Epoch [4/10], Step [582/1063], Loss: 0.0065\n",
      "Epoch [4/10], Step [583/1063], Loss: 0.0183\n",
      "Epoch [4/10], Step [584/1063], Loss: 0.0082\n",
      "Epoch [4/10], Step [585/1063], Loss: 0.0040\n",
      "Epoch [4/10], Step [586/1063], Loss: 0.0065\n",
      "Epoch [4/10], Step [587/1063], Loss: 0.0855\n",
      "Epoch [4/10], Step [588/1063], Loss: 0.0046\n",
      "Epoch [4/10], Step [589/1063], Loss: 0.0362\n",
      "Epoch [4/10], Step [590/1063], Loss: 0.0074\n",
      "Epoch [4/10], Step [591/1063], Loss: 0.0821\n",
      "Epoch [4/10], Step [592/1063], Loss: 0.0120\n",
      "Epoch [4/10], Step [593/1063], Loss: 0.0015\n",
      "Epoch [4/10], Step [594/1063], Loss: 0.0273\n",
      "Epoch [4/10], Step [595/1063], Loss: 0.0596\n",
      "Epoch [4/10], Step [596/1063], Loss: 0.0009\n",
      "Epoch [4/10], Step [597/1063], Loss: 0.0385\n",
      "Epoch [4/10], Step [598/1063], Loss: 0.0969\n",
      "Epoch [4/10], Step [599/1063], Loss: 0.0145\n",
      "Epoch [4/10], Step [600/1063], Loss: 0.1028\n",
      "Epoch [4/10], Step [601/1063], Loss: 0.0070\n",
      "Epoch [4/10], Step [602/1063], Loss: 0.0023\n",
      "Epoch [4/10], Step [603/1063], Loss: 0.0300\n",
      "Epoch [4/10], Step [604/1063], Loss: 0.0032\n",
      "Epoch [4/10], Step [605/1063], Loss: 0.0239\n",
      "Epoch [4/10], Step [606/1063], Loss: 0.0357\n",
      "Epoch [4/10], Step [607/1063], Loss: 0.0598\n",
      "Epoch [4/10], Step [608/1063], Loss: 0.0750\n",
      "Epoch [4/10], Step [609/1063], Loss: 0.0056\n",
      "Epoch [4/10], Step [610/1063], Loss: 0.0326\n",
      "Epoch [4/10], Step [611/1063], Loss: 0.0561\n",
      "Epoch [4/10], Step [612/1063], Loss: 0.0093\n",
      "Epoch [4/10], Step [613/1063], Loss: 0.0111\n",
      "Epoch [4/10], Step [614/1063], Loss: 0.0391\n",
      "Epoch [4/10], Step [615/1063], Loss: 0.0056\n",
      "Epoch [4/10], Step [616/1063], Loss: 0.0311\n",
      "Epoch [4/10], Step [617/1063], Loss: 0.0120\n",
      "Epoch [4/10], Step [618/1063], Loss: 0.2693\n",
      "Epoch [4/10], Step [619/1063], Loss: 0.0397\n",
      "Epoch [4/10], Step [620/1063], Loss: 0.0388\n",
      "Epoch [4/10], Step [621/1063], Loss: 0.0457\n",
      "Epoch [4/10], Step [622/1063], Loss: 0.0046\n",
      "Epoch [4/10], Step [623/1063], Loss: 0.0093\n",
      "Epoch [4/10], Step [624/1063], Loss: 0.0149\n",
      "Epoch [4/10], Step [625/1063], Loss: 0.0946\n",
      "Epoch [4/10], Step [626/1063], Loss: 0.0984\n",
      "Epoch [4/10], Step [627/1063], Loss: 0.0564\n",
      "Epoch [4/10], Step [628/1063], Loss: 0.0040\n",
      "Epoch [4/10], Step [629/1063], Loss: 0.0383\n",
      "Epoch [4/10], Step [630/1063], Loss: 0.0602\n",
      "Epoch [4/10], Step [631/1063], Loss: 0.0621\n",
      "Epoch [4/10], Step [632/1063], Loss: 0.0871\n",
      "Epoch [4/10], Step [633/1063], Loss: 0.0080\n",
      "Epoch [4/10], Step [634/1063], Loss: 0.0550\n",
      "Epoch [4/10], Step [635/1063], Loss: 0.1421\n",
      "Epoch [4/10], Step [636/1063], Loss: 0.0058\n",
      "Epoch [4/10], Step [637/1063], Loss: 0.0172\n",
      "Epoch [4/10], Step [638/1063], Loss: 0.0112\n",
      "Epoch [4/10], Step [639/1063], Loss: 0.0033\n",
      "Epoch [4/10], Step [640/1063], Loss: 0.0098\n",
      "Epoch [4/10], Step [641/1063], Loss: 0.0020\n",
      "Epoch [4/10], Step [642/1063], Loss: 0.0068\n",
      "Epoch [4/10], Step [643/1063], Loss: 0.0294\n",
      "Epoch [4/10], Step [644/1063], Loss: 0.1000\n",
      "Epoch [4/10], Step [645/1063], Loss: 0.0151\n",
      "Epoch [4/10], Step [646/1063], Loss: 0.0363\n",
      "Epoch [4/10], Step [647/1063], Loss: 0.0232\n",
      "Epoch [4/10], Step [648/1063], Loss: 0.0652\n",
      "Epoch [4/10], Step [649/1063], Loss: 0.0106\n",
      "Epoch [4/10], Step [650/1063], Loss: 0.0300\n",
      "Epoch [4/10], Step [651/1063], Loss: 0.0165\n",
      "Epoch [4/10], Step [652/1063], Loss: 0.0088\n",
      "Epoch [4/10], Step [653/1063], Loss: 0.1165\n",
      "Epoch [4/10], Step [654/1063], Loss: 0.0211\n",
      "Epoch [4/10], Step [655/1063], Loss: 0.0027\n",
      "Epoch [4/10], Step [656/1063], Loss: 0.0448\n",
      "Epoch [4/10], Step [657/1063], Loss: 0.0012\n",
      "Epoch [4/10], Step [658/1063], Loss: 0.0417\n",
      "Epoch [4/10], Step [659/1063], Loss: 0.0250\n",
      "Epoch [4/10], Step [660/1063], Loss: 0.0055\n",
      "Epoch [4/10], Step [661/1063], Loss: 0.0382\n",
      "Epoch [4/10], Step [662/1063], Loss: 0.0033\n",
      "Epoch [4/10], Step [663/1063], Loss: 0.0022\n",
      "Epoch [4/10], Step [664/1063], Loss: 0.0198\n",
      "Epoch [4/10], Step [665/1063], Loss: 0.0024\n",
      "Epoch [4/10], Step [666/1063], Loss: 0.0078\n",
      "Epoch [4/10], Step [667/1063], Loss: 0.0046\n",
      "Epoch [4/10], Step [668/1063], Loss: 0.0053\n",
      "Epoch [4/10], Step [669/1063], Loss: 0.0072\n",
      "Epoch [4/10], Step [670/1063], Loss: 0.0050\n",
      "Epoch [4/10], Step [671/1063], Loss: 0.0106\n",
      "Epoch [4/10], Step [672/1063], Loss: 0.0450\n",
      "Epoch [4/10], Step [673/1063], Loss: 0.0098\n",
      "Epoch [4/10], Step [674/1063], Loss: 0.1410\n",
      "Epoch [4/10], Step [675/1063], Loss: 0.0089\n",
      "Epoch [4/10], Step [676/1063], Loss: 0.0394\n",
      "Epoch [4/10], Step [677/1063], Loss: 0.0049\n",
      "Epoch [4/10], Step [678/1063], Loss: 0.0285\n",
      "Epoch [4/10], Step [679/1063], Loss: 0.0029\n",
      "Epoch [4/10], Step [680/1063], Loss: 0.0108\n",
      "Epoch [4/10], Step [681/1063], Loss: 0.0421\n",
      "Epoch [4/10], Step [682/1063], Loss: 0.0035\n",
      "Epoch [4/10], Step [683/1063], Loss: 0.0099\n",
      "Epoch [4/10], Step [684/1063], Loss: 0.0058\n",
      "Epoch [4/10], Step [685/1063], Loss: 0.0040\n",
      "Epoch [4/10], Step [686/1063], Loss: 0.0064\n",
      "Epoch [4/10], Step [687/1063], Loss: 0.0194\n",
      "Epoch [4/10], Step [688/1063], Loss: 0.0022\n",
      "Epoch [4/10], Step [689/1063], Loss: 0.0976\n",
      "Epoch [4/10], Step [690/1063], Loss: 0.0136\n",
      "Epoch [4/10], Step [691/1063], Loss: 0.0014\n",
      "Epoch [4/10], Step [692/1063], Loss: 0.0586\n",
      "Epoch [4/10], Step [693/1063], Loss: 0.0034\n",
      "Epoch [4/10], Step [694/1063], Loss: 0.0032\n",
      "Epoch [4/10], Step [695/1063], Loss: 0.0263\n",
      "Epoch [4/10], Step [696/1063], Loss: 0.0136\n",
      "Epoch [4/10], Step [697/1063], Loss: 0.0032\n",
      "Epoch [4/10], Step [698/1063], Loss: 0.0047\n",
      "Epoch [4/10], Step [699/1063], Loss: 0.0020\n",
      "Epoch [4/10], Step [700/1063], Loss: 0.0055\n",
      "Epoch [4/10], Step [701/1063], Loss: 0.0613\n",
      "Epoch [4/10], Step [702/1063], Loss: 0.0078\n",
      "Epoch [4/10], Step [703/1063], Loss: 0.0246\n",
      "Epoch [4/10], Step [704/1063], Loss: 0.0727\n",
      "Epoch [4/10], Step [705/1063], Loss: 0.0013\n",
      "Epoch [4/10], Step [706/1063], Loss: 0.0255\n",
      "Epoch [4/10], Step [707/1063], Loss: 0.1180\n",
      "Epoch [4/10], Step [708/1063], Loss: 0.0013\n",
      "Epoch [4/10], Step [709/1063], Loss: 0.0032\n",
      "Epoch [4/10], Step [710/1063], Loss: 0.0129\n",
      "Epoch [4/10], Step [711/1063], Loss: 0.0032\n",
      "Epoch [4/10], Step [712/1063], Loss: 0.0095\n",
      "Epoch [4/10], Step [713/1063], Loss: 0.0037\n",
      "Epoch [4/10], Step [714/1063], Loss: 0.0505\n",
      "Epoch [4/10], Step [715/1063], Loss: 0.0075\n",
      "Epoch [4/10], Step [716/1063], Loss: 0.0192\n",
      "Epoch [4/10], Step [717/1063], Loss: 0.0086\n",
      "Epoch [4/10], Step [718/1063], Loss: 0.0014\n",
      "Epoch [4/10], Step [719/1063], Loss: 0.0023\n",
      "Epoch [4/10], Step [720/1063], Loss: 0.0457\n",
      "Epoch [4/10], Step [721/1063], Loss: 0.0027\n",
      "Epoch [4/10], Step [722/1063], Loss: 0.0463\n",
      "Epoch [4/10], Step [723/1063], Loss: 0.0003\n",
      "Epoch [4/10], Step [724/1063], Loss: 0.0184\n",
      "Epoch [4/10], Step [725/1063], Loss: 0.0449\n",
      "Epoch [4/10], Step [726/1063], Loss: 0.0082\n",
      "Epoch [4/10], Step [727/1063], Loss: 0.0786\n",
      "Epoch [4/10], Step [728/1063], Loss: 0.0105\n",
      "Epoch [4/10], Step [729/1063], Loss: 0.0073\n",
      "Epoch [4/10], Step [730/1063], Loss: 0.0075\n",
      "Epoch [4/10], Step [731/1063], Loss: 0.0049\n",
      "Epoch [4/10], Step [732/1063], Loss: 0.0047\n",
      "Epoch [4/10], Step [733/1063], Loss: 0.0060\n",
      "Epoch [4/10], Step [734/1063], Loss: 0.0043\n",
      "Epoch [4/10], Step [735/1063], Loss: 0.0023\n",
      "Epoch [4/10], Step [736/1063], Loss: 0.0132\n",
      "Epoch [4/10], Step [737/1063], Loss: 0.0143\n",
      "Epoch [4/10], Step [738/1063], Loss: 0.0283\n",
      "Epoch [4/10], Step [739/1063], Loss: 0.0245\n",
      "Epoch [4/10], Step [740/1063], Loss: 0.0133\n",
      "Epoch [4/10], Step [741/1063], Loss: 0.0123\n",
      "Epoch [4/10], Step [742/1063], Loss: 0.0021\n",
      "Epoch [4/10], Step [743/1063], Loss: 0.0005\n",
      "Epoch [4/10], Step [744/1063], Loss: 0.0424\n",
      "Epoch [4/10], Step [745/1063], Loss: 0.0280\n",
      "Epoch [4/10], Step [746/1063], Loss: 0.0283\n",
      "Epoch [4/10], Step [747/1063], Loss: 0.0020\n",
      "Epoch [4/10], Step [748/1063], Loss: 0.0102\n",
      "Epoch [4/10], Step [749/1063], Loss: 0.0258\n",
      "Epoch [4/10], Step [750/1063], Loss: 0.0184\n",
      "Epoch [4/10], Step [751/1063], Loss: 0.0338\n",
      "Epoch [4/10], Step [752/1063], Loss: 0.0012\n",
      "Epoch [4/10], Step [753/1063], Loss: 0.1429\n",
      "Epoch [4/10], Step [754/1063], Loss: 0.0343\n",
      "Epoch [4/10], Step [755/1063], Loss: 0.0458\n",
      "Epoch [4/10], Step [756/1063], Loss: 0.0017\n",
      "Epoch [4/10], Step [757/1063], Loss: 0.0016\n",
      "Epoch [4/10], Step [758/1063], Loss: 0.0150\n",
      "Epoch [4/10], Step [759/1063], Loss: 0.0025\n",
      "Epoch [4/10], Step [760/1063], Loss: 0.0013\n",
      "Epoch [4/10], Step [761/1063], Loss: 0.0437\n",
      "Epoch [4/10], Step [762/1063], Loss: 0.2432\n",
      "Epoch [4/10], Step [763/1063], Loss: 0.0040\n",
      "Epoch [4/10], Step [764/1063], Loss: 0.0836\n",
      "Epoch [4/10], Step [765/1063], Loss: 0.0073\n",
      "Epoch [4/10], Step [766/1063], Loss: 0.0666\n",
      "Epoch [4/10], Step [767/1063], Loss: 0.0434\n",
      "Epoch [4/10], Step [768/1063], Loss: 0.0101\n",
      "Epoch [4/10], Step [769/1063], Loss: 0.0329\n",
      "Epoch [4/10], Step [770/1063], Loss: 0.0338\n",
      "Epoch [4/10], Step [771/1063], Loss: 0.0212\n",
      "Epoch [4/10], Step [772/1063], Loss: 0.0143\n",
      "Epoch [4/10], Step [773/1063], Loss: 0.0366\n",
      "Epoch [4/10], Step [774/1063], Loss: 0.1095\n",
      "Epoch [4/10], Step [775/1063], Loss: 0.0306\n",
      "Epoch [4/10], Step [776/1063], Loss: 0.0017\n",
      "Epoch [4/10], Step [777/1063], Loss: 0.0274\n",
      "Epoch [4/10], Step [778/1063], Loss: 0.0011\n",
      "Epoch [4/10], Step [779/1063], Loss: 0.0203\n",
      "Epoch [4/10], Step [780/1063], Loss: 0.0072\n",
      "Epoch [4/10], Step [781/1063], Loss: 0.0014\n",
      "Epoch [4/10], Step [782/1063], Loss: 0.0021\n",
      "Epoch [4/10], Step [783/1063], Loss: 0.0015\n",
      "Epoch [4/10], Step [784/1063], Loss: 0.0013\n",
      "Epoch [4/10], Step [785/1063], Loss: 0.0558\n",
      "Epoch [4/10], Step [786/1063], Loss: 0.0453\n",
      "Epoch [4/10], Step [787/1063], Loss: 0.0313\n",
      "Epoch [4/10], Step [788/1063], Loss: 0.0115\n",
      "Epoch [4/10], Step [789/1063], Loss: 0.0010\n",
      "Epoch [4/10], Step [790/1063], Loss: 0.0507\n",
      "Epoch [4/10], Step [791/1063], Loss: 0.0073\n",
      "Epoch [4/10], Step [792/1063], Loss: 0.0446\n",
      "Epoch [4/10], Step [793/1063], Loss: 0.0093\n",
      "Epoch [4/10], Step [794/1063], Loss: 0.0023\n",
      "Epoch [4/10], Step [795/1063], Loss: 0.0008\n",
      "Epoch [4/10], Step [796/1063], Loss: 0.0218\n",
      "Epoch [4/10], Step [797/1063], Loss: 0.0042\n",
      "Epoch [4/10], Step [798/1063], Loss: 0.0073\n",
      "Epoch [4/10], Step [799/1063], Loss: 0.0169\n",
      "Epoch [4/10], Step [800/1063], Loss: 0.0037\n",
      "Epoch [4/10], Step [801/1063], Loss: 0.0051\n",
      "Epoch [4/10], Step [802/1063], Loss: 0.0222\n",
      "Epoch [4/10], Step [803/1063], Loss: 0.0527\n",
      "Epoch [4/10], Step [804/1063], Loss: 0.0076\n",
      "Epoch [4/10], Step [805/1063], Loss: 0.0299\n",
      "Epoch [4/10], Step [806/1063], Loss: 0.0377\n",
      "Epoch [4/10], Step [807/1063], Loss: 0.0048\n",
      "Epoch [4/10], Step [808/1063], Loss: 0.0319\n",
      "Epoch [4/10], Step [809/1063], Loss: 0.0192\n",
      "Epoch [4/10], Step [810/1063], Loss: 0.0025\n",
      "Epoch [4/10], Step [811/1063], Loss: 0.0292\n",
      "Epoch [4/10], Step [812/1063], Loss: 0.0421\n",
      "Epoch [4/10], Step [813/1063], Loss: 0.0101\n",
      "Epoch [4/10], Step [814/1063], Loss: 0.0416\n",
      "Epoch [4/10], Step [815/1063], Loss: 0.0087\n",
      "Epoch [4/10], Step [816/1063], Loss: 0.0313\n",
      "Epoch [4/10], Step [817/1063], Loss: 0.0023\n",
      "Epoch [4/10], Step [818/1063], Loss: 0.0020\n",
      "Epoch [4/10], Step [819/1063], Loss: 0.0233\n",
      "Epoch [4/10], Step [820/1063], Loss: 0.0177\n",
      "Epoch [4/10], Step [821/1063], Loss: 0.0144\n",
      "Epoch [4/10], Step [822/1063], Loss: 0.0254\n",
      "Epoch [4/10], Step [823/1063], Loss: 0.0030\n",
      "Epoch [4/10], Step [824/1063], Loss: 0.0205\n",
      "Epoch [4/10], Step [825/1063], Loss: 0.0089\n",
      "Epoch [4/10], Step [826/1063], Loss: 0.0076\n",
      "Epoch [4/10], Step [827/1063], Loss: 0.0060\n",
      "Epoch [4/10], Step [828/1063], Loss: 0.0402\n",
      "Epoch [4/10], Step [829/1063], Loss: 0.0889\n",
      "Epoch [4/10], Step [830/1063], Loss: 0.0220\n",
      "Epoch [4/10], Step [831/1063], Loss: 0.0990\n",
      "Epoch [4/10], Step [832/1063], Loss: 0.0059\n",
      "Epoch [4/10], Step [833/1063], Loss: 0.0249\n",
      "Epoch [4/10], Step [834/1063], Loss: 0.0830\n",
      "Epoch [4/10], Step [835/1063], Loss: 0.0358\n",
      "Epoch [4/10], Step [836/1063], Loss: 0.0075\n",
      "Epoch [4/10], Step [837/1063], Loss: 0.0010\n",
      "Epoch [4/10], Step [838/1063], Loss: 0.0115\n",
      "Epoch [4/10], Step [839/1063], Loss: 0.0617\n",
      "Epoch [4/10], Step [840/1063], Loss: 0.0127\n",
      "Epoch [4/10], Step [841/1063], Loss: 0.0042\n",
      "Epoch [4/10], Step [842/1063], Loss: 0.0022\n",
      "Epoch [4/10], Step [843/1063], Loss: 0.0140\n",
      "Epoch [4/10], Step [844/1063], Loss: 0.0181\n",
      "Epoch [4/10], Step [845/1063], Loss: 0.0005\n",
      "Epoch [4/10], Step [846/1063], Loss: 0.0423\n",
      "Epoch [4/10], Step [847/1063], Loss: 0.0167\n",
      "Epoch [4/10], Step [848/1063], Loss: 0.0134\n",
      "Epoch [4/10], Step [849/1063], Loss: 0.0069\n",
      "Epoch [4/10], Step [850/1063], Loss: 0.0155\n",
      "Epoch [4/10], Step [851/1063], Loss: 0.0134\n",
      "Epoch [4/10], Step [852/1063], Loss: 0.0362\n",
      "Epoch [4/10], Step [853/1063], Loss: 0.1206\n",
      "Epoch [4/10], Step [854/1063], Loss: 0.0036\n",
      "Epoch [4/10], Step [855/1063], Loss: 0.0003\n",
      "Epoch [4/10], Step [856/1063], Loss: 0.0033\n",
      "Epoch [4/10], Step [857/1063], Loss: 0.0005\n",
      "Epoch [4/10], Step [858/1063], Loss: 0.0132\n",
      "Epoch [4/10], Step [859/1063], Loss: 0.0929\n",
      "Epoch [4/10], Step [860/1063], Loss: 0.0033\n",
      "Epoch [4/10], Step [861/1063], Loss: 0.0263\n",
      "Epoch [4/10], Step [862/1063], Loss: 0.0247\n",
      "Epoch [4/10], Step [863/1063], Loss: 0.0114\n",
      "Epoch [4/10], Step [864/1063], Loss: 0.0176\n",
      "Epoch [4/10], Step [865/1063], Loss: 0.1391\n",
      "Epoch [4/10], Step [866/1063], Loss: 0.0173\n",
      "Epoch [4/10], Step [867/1063], Loss: 0.0075\n",
      "Epoch [4/10], Step [868/1063], Loss: 0.0191\n",
      "Epoch [4/10], Step [869/1063], Loss: 0.0622\n",
      "Epoch [4/10], Step [870/1063], Loss: 0.0622\n",
      "Epoch [4/10], Step [871/1063], Loss: 0.0056\n",
      "Epoch [4/10], Step [872/1063], Loss: 0.0063\n",
      "Epoch [4/10], Step [873/1063], Loss: 0.0030\n",
      "Epoch [4/10], Step [874/1063], Loss: 0.0469\n",
      "Epoch [4/10], Step [875/1063], Loss: 0.0020\n",
      "Epoch [4/10], Step [876/1063], Loss: 0.0039\n",
      "Epoch [4/10], Step [877/1063], Loss: 0.0049\n",
      "Epoch [4/10], Step [878/1063], Loss: 0.0157\n",
      "Epoch [4/10], Step [879/1063], Loss: 0.0002\n",
      "Epoch [4/10], Step [880/1063], Loss: 0.0213\n",
      "Epoch [4/10], Step [881/1063], Loss: 0.0059\n",
      "Epoch [4/10], Step [882/1063], Loss: 0.0801\n",
      "Epoch [4/10], Step [883/1063], Loss: 0.0020\n",
      "Epoch [4/10], Step [884/1063], Loss: 0.0143\n",
      "Epoch [4/10], Step [885/1063], Loss: 0.0069\n",
      "Epoch [4/10], Step [886/1063], Loss: 0.0007\n",
      "Epoch [4/10], Step [887/1063], Loss: 0.0021\n",
      "Epoch [4/10], Step [888/1063], Loss: 0.0132\n",
      "Epoch [4/10], Step [889/1063], Loss: 0.0784\n",
      "Epoch [4/10], Step [890/1063], Loss: 0.1067\n",
      "Epoch [4/10], Step [891/1063], Loss: 0.0096\n",
      "Epoch [4/10], Step [892/1063], Loss: 0.0043\n",
      "Epoch [4/10], Step [893/1063], Loss: 0.0038\n",
      "Epoch [4/10], Step [894/1063], Loss: 0.0105\n",
      "Epoch [4/10], Step [895/1063], Loss: 0.0136\n",
      "Epoch [4/10], Step [896/1063], Loss: 0.0051\n",
      "Epoch [4/10], Step [897/1063], Loss: 0.0096\n",
      "Epoch [4/10], Step [898/1063], Loss: 0.0023\n",
      "Epoch [4/10], Step [899/1063], Loss: 0.0155\n",
      "Epoch [4/10], Step [900/1063], Loss: 0.0010\n",
      "Epoch [4/10], Step [901/1063], Loss: 0.0237\n",
      "Epoch [4/10], Step [902/1063], Loss: 0.0018\n",
      "Epoch [4/10], Step [903/1063], Loss: 0.0777\n",
      "Epoch [4/10], Step [904/1063], Loss: 0.0023\n",
      "Epoch [4/10], Step [905/1063], Loss: 0.0056\n",
      "Epoch [4/10], Step [906/1063], Loss: 0.0034\n",
      "Epoch [4/10], Step [907/1063], Loss: 0.0100\n",
      "Epoch [4/10], Step [908/1063], Loss: 0.0029\n",
      "Epoch [4/10], Step [909/1063], Loss: 0.0019\n",
      "Epoch [4/10], Step [910/1063], Loss: 0.0084\n",
      "Epoch [4/10], Step [911/1063], Loss: 0.0063\n",
      "Epoch [4/10], Step [912/1063], Loss: 0.0084\n",
      "Epoch [4/10], Step [913/1063], Loss: 0.0495\n",
      "Epoch [4/10], Step [914/1063], Loss: 0.0039\n",
      "Epoch [4/10], Step [915/1063], Loss: 0.0072\n",
      "Epoch [4/10], Step [916/1063], Loss: 0.0028\n",
      "Epoch [4/10], Step [917/1063], Loss: 0.0039\n",
      "Epoch [4/10], Step [918/1063], Loss: 0.0396\n",
      "Epoch [4/10], Step [919/1063], Loss: 0.0060\n",
      "Epoch [4/10], Step [920/1063], Loss: 0.0031\n",
      "Epoch [4/10], Step [921/1063], Loss: 0.0038\n",
      "Epoch [4/10], Step [922/1063], Loss: 0.0063\n",
      "Epoch [4/10], Step [923/1063], Loss: 0.0024\n",
      "Epoch [4/10], Step [924/1063], Loss: 0.0055\n",
      "Epoch [4/10], Step [925/1063], Loss: 0.0043\n",
      "Epoch [4/10], Step [926/1063], Loss: 0.0034\n",
      "Epoch [4/10], Step [927/1063], Loss: 0.0007\n",
      "Epoch [4/10], Step [928/1063], Loss: 0.0989\n",
      "Epoch [4/10], Step [929/1063], Loss: 0.0214\n",
      "Epoch [4/10], Step [930/1063], Loss: 0.0089\n",
      "Epoch [4/10], Step [931/1063], Loss: 0.0398\n",
      "Epoch [4/10], Step [932/1063], Loss: 0.0074\n",
      "Epoch [4/10], Step [933/1063], Loss: 0.0136\n",
      "Epoch [4/10], Step [934/1063], Loss: 0.0071\n",
      "Epoch [4/10], Step [935/1063], Loss: 0.0042\n",
      "Epoch [4/10], Step [936/1063], Loss: 0.0210\n",
      "Epoch [4/10], Step [937/1063], Loss: 0.0166\n",
      "Epoch [4/10], Step [938/1063], Loss: 0.0007\n",
      "Epoch [4/10], Step [939/1063], Loss: 0.0163\n",
      "Epoch [4/10], Step [940/1063], Loss: 0.0100\n",
      "Epoch [4/10], Step [941/1063], Loss: 0.0053\n",
      "Epoch [4/10], Step [942/1063], Loss: 0.0079\n",
      "Epoch [4/10], Step [943/1063], Loss: 0.0090\n",
      "Epoch [4/10], Step [944/1063], Loss: 0.0094\n",
      "Epoch [4/10], Step [945/1063], Loss: 0.0270\n",
      "Epoch [4/10], Step [946/1063], Loss: 0.0222\n",
      "Epoch [4/10], Step [947/1063], Loss: 0.0374\n",
      "Epoch [4/10], Step [948/1063], Loss: 0.0428\n",
      "Epoch [4/10], Step [949/1063], Loss: 0.0066\n",
      "Epoch [4/10], Step [950/1063], Loss: 0.0065\n",
      "Epoch [4/10], Step [951/1063], Loss: 0.0081\n",
      "Epoch [4/10], Step [952/1063], Loss: 0.0036\n",
      "Epoch [4/10], Step [953/1063], Loss: 0.0061\n",
      "Epoch [4/10], Step [954/1063], Loss: 0.0571\n",
      "Epoch [4/10], Step [955/1063], Loss: 0.0614\n",
      "Epoch [4/10], Step [956/1063], Loss: 0.0051\n",
      "Epoch [4/10], Step [957/1063], Loss: 0.0073\n",
      "Epoch [4/10], Step [958/1063], Loss: 0.0173\n",
      "Epoch [4/10], Step [959/1063], Loss: 0.1108\n",
      "Epoch [4/10], Step [960/1063], Loss: 0.0273\n",
      "Epoch [4/10], Step [961/1063], Loss: 0.0041\n",
      "Epoch [4/10], Step [962/1063], Loss: 0.0018\n",
      "Epoch [4/10], Step [963/1063], Loss: 0.0088\n",
      "Epoch [4/10], Step [964/1063], Loss: 0.0247\n",
      "Epoch [4/10], Step [965/1063], Loss: 0.0039\n",
      "Epoch [4/10], Step [966/1063], Loss: 0.0019\n",
      "Epoch [4/10], Step [967/1063], Loss: 0.0044\n",
      "Epoch [4/10], Step [968/1063], Loss: 0.0069\n",
      "Epoch [4/10], Step [969/1063], Loss: 0.0259\n",
      "Epoch [4/10], Step [970/1063], Loss: 0.0046\n",
      "Epoch [4/10], Step [971/1063], Loss: 0.0367\n",
      "Epoch [4/10], Step [972/1063], Loss: 0.0197\n",
      "Epoch [4/10], Step [973/1063], Loss: 0.0876\n",
      "Epoch [4/10], Step [974/1063], Loss: 0.0916\n",
      "Epoch [4/10], Step [975/1063], Loss: 0.0009\n",
      "Epoch [4/10], Step [976/1063], Loss: 0.0123\n",
      "Epoch [4/10], Step [977/1063], Loss: 0.0024\n",
      "Epoch [4/10], Step [978/1063], Loss: 0.0249\n",
      "Epoch [4/10], Step [979/1063], Loss: 0.0032\n",
      "Epoch [4/10], Step [980/1063], Loss: 0.0022\n",
      "Epoch [4/10], Step [981/1063], Loss: 0.0197\n",
      "Epoch [4/10], Step [982/1063], Loss: 0.0025\n",
      "Epoch [4/10], Step [983/1063], Loss: 0.0529\n",
      "Epoch [4/10], Step [984/1063], Loss: 0.0057\n",
      "Epoch [4/10], Step [985/1063], Loss: 0.0220\n",
      "Epoch [4/10], Step [986/1063], Loss: 0.0525\n",
      "Epoch [4/10], Step [987/1063], Loss: 0.0129\n",
      "Epoch [4/10], Step [988/1063], Loss: 0.0033\n",
      "Epoch [4/10], Step [989/1063], Loss: 0.0431\n",
      "Epoch [4/10], Step [990/1063], Loss: 0.0182\n",
      "Epoch [4/10], Step [991/1063], Loss: 0.0079\n",
      "Epoch [4/10], Step [992/1063], Loss: 0.0022\n",
      "Epoch [4/10], Step [993/1063], Loss: 0.0038\n",
      "Epoch [4/10], Step [994/1063], Loss: 0.0124\n",
      "Epoch [4/10], Step [995/1063], Loss: 0.0038\n",
      "Epoch [4/10], Step [996/1063], Loss: 0.0109\n",
      "Epoch [4/10], Step [997/1063], Loss: 0.0010\n",
      "Epoch [4/10], Step [998/1063], Loss: 0.0151\n",
      "Epoch [4/10], Step [999/1063], Loss: 0.0163\n",
      "Epoch [4/10], Step [1000/1063], Loss: 0.0630\n",
      "Epoch [4/10], Step [1001/1063], Loss: 0.0208\n",
      "Epoch [4/10], Step [1002/1063], Loss: 0.0012\n",
      "Epoch [4/10], Step [1003/1063], Loss: 0.0022\n",
      "Epoch [4/10], Step [1004/1063], Loss: 0.0699\n",
      "Epoch [4/10], Step [1005/1063], Loss: 0.0129\n",
      "Epoch [4/10], Step [1006/1063], Loss: 0.0138\n",
      "Epoch [4/10], Step [1007/1063], Loss: 0.0021\n",
      "Epoch [4/10], Step [1008/1063], Loss: 0.0024\n",
      "Epoch [4/10], Step [1009/1063], Loss: 0.0536\n",
      "Epoch [4/10], Step [1010/1063], Loss: 0.0007\n",
      "Epoch [4/10], Step [1011/1063], Loss: 0.1092\n",
      "Epoch [4/10], Step [1012/1063], Loss: 0.0603\n",
      "Epoch [4/10], Step [1013/1063], Loss: 0.0126\n",
      "Epoch [4/10], Step [1014/1063], Loss: 0.0044\n",
      "Epoch [4/10], Step [1015/1063], Loss: 0.0302\n",
      "Epoch [4/10], Step [1016/1063], Loss: 0.0198\n",
      "Epoch [4/10], Step [1017/1063], Loss: 0.0023\n",
      "Epoch [4/10], Step [1018/1063], Loss: 0.0485\n",
      "Epoch [4/10], Step [1019/1063], Loss: 0.0015\n",
      "Epoch [4/10], Step [1020/1063], Loss: 0.0224\n",
      "Epoch [4/10], Step [1021/1063], Loss: 0.0634\n",
      "Epoch [4/10], Step [1022/1063], Loss: 0.0626\n",
      "Epoch [4/10], Step [1023/1063], Loss: 0.0005\n",
      "Epoch [4/10], Step [1024/1063], Loss: 0.0170\n",
      "Epoch [4/10], Step [1025/1063], Loss: 0.0102\n",
      "Epoch [4/10], Step [1026/1063], Loss: 0.0110\n",
      "Epoch [4/10], Step [1027/1063], Loss: 0.0205\n",
      "Epoch [4/10], Step [1028/1063], Loss: 0.0017\n",
      "Epoch [4/10], Step [1029/1063], Loss: 0.0423\n",
      "Epoch [4/10], Step [1030/1063], Loss: 0.0024\n",
      "Epoch [4/10], Step [1031/1063], Loss: 0.0061\n",
      "Epoch [4/10], Step [1032/1063], Loss: 0.0085\n",
      "Epoch [4/10], Step [1033/1063], Loss: 0.0303\n",
      "Epoch [4/10], Step [1034/1063], Loss: 0.1515\n",
      "Epoch [4/10], Step [1035/1063], Loss: 0.0225\n",
      "Epoch [4/10], Step [1036/1063], Loss: 0.0037\n",
      "Epoch [4/10], Step [1037/1063], Loss: 0.0020\n",
      "Epoch [4/10], Step [1038/1063], Loss: 0.0686\n",
      "Epoch [4/10], Step [1039/1063], Loss: 0.0342\n",
      "Epoch [4/10], Step [1040/1063], Loss: 0.0027\n",
      "Epoch [4/10], Step [1041/1063], Loss: 0.0077\n",
      "Epoch [4/10], Step [1042/1063], Loss: 0.0309\n",
      "Epoch [4/10], Step [1043/1063], Loss: 0.0110\n",
      "Epoch [4/10], Step [1044/1063], Loss: 0.0051\n",
      "Epoch [4/10], Step [1045/1063], Loss: 0.2063\n",
      "Epoch [4/10], Step [1046/1063], Loss: 0.0019\n",
      "Epoch [4/10], Step [1047/1063], Loss: 0.0292\n",
      "Epoch [4/10], Step [1048/1063], Loss: 0.0063\n",
      "Epoch [4/10], Step [1049/1063], Loss: 0.0043\n",
      "Epoch [4/10], Step [1050/1063], Loss: 0.0405\n",
      "Epoch [4/10], Step [1051/1063], Loss: 0.0068\n",
      "Epoch [4/10], Step [1052/1063], Loss: 0.1067\n",
      "Epoch [4/10], Step [1053/1063], Loss: 0.0110\n",
      "Epoch [4/10], Step [1054/1063], Loss: 0.0725\n",
      "Epoch [4/10], Step [1055/1063], Loss: 0.0012\n",
      "Epoch [4/10], Step [1056/1063], Loss: 0.0424\n",
      "Epoch [4/10], Step [1057/1063], Loss: 0.0485\n",
      "Epoch [4/10], Step [1058/1063], Loss: 0.0900\n",
      "Epoch [4/10], Step [1059/1063], Loss: 0.0045\n",
      "Epoch [4/10], Step [1060/1063], Loss: 0.0083\n",
      "Epoch [4/10], Step [1061/1063], Loss: 0.0027\n",
      "Epoch [4/10], Step [1062/1063], Loss: 0.0204\n",
      "Epoch [4/10], Step [1063/1063], Loss: 0.0443\n",
      "Epoch [5/10], Step [1/1063], Loss: 0.0385\n",
      "Epoch [5/10], Step [2/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [3/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [4/1063], Loss: 0.0100\n",
      "Epoch [5/10], Step [5/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [6/1063], Loss: 0.0109\n",
      "Epoch [5/10], Step [7/1063], Loss: 0.0062\n",
      "Epoch [5/10], Step [8/1063], Loss: 0.0285\n",
      "Epoch [5/10], Step [9/1063], Loss: 0.0079\n",
      "Epoch [5/10], Step [10/1063], Loss: 0.0880\n",
      "Epoch [5/10], Step [11/1063], Loss: 0.0045\n",
      "Epoch [5/10], Step [12/1063], Loss: 0.0023\n",
      "Epoch [5/10], Step [13/1063], Loss: 0.0008\n",
      "Epoch [5/10], Step [14/1063], Loss: 0.0177\n",
      "Epoch [5/10], Step [15/1063], Loss: 0.1160\n",
      "Epoch [5/10], Step [16/1063], Loss: 0.0078\n",
      "Epoch [5/10], Step [17/1063], Loss: 0.0053\n",
      "Epoch [5/10], Step [18/1063], Loss: 0.0227\n",
      "Epoch [5/10], Step [19/1063], Loss: 0.0044\n",
      "Epoch [5/10], Step [20/1063], Loss: 0.0052\n",
      "Epoch [5/10], Step [21/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [22/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [23/1063], Loss: 0.0145\n",
      "Epoch [5/10], Step [24/1063], Loss: 0.0087\n",
      "Epoch [5/10], Step [25/1063], Loss: 0.0094\n",
      "Epoch [5/10], Step [26/1063], Loss: 0.0046\n",
      "Epoch [5/10], Step [27/1063], Loss: 0.0127\n",
      "Epoch [5/10], Step [28/1063], Loss: 0.0055\n",
      "Epoch [5/10], Step [29/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [30/1063], Loss: 0.0019\n",
      "Epoch [5/10], Step [31/1063], Loss: 0.0055\n",
      "Epoch [5/10], Step [32/1063], Loss: 0.0007\n",
      "Epoch [5/10], Step [33/1063], Loss: 0.0034\n",
      "Epoch [5/10], Step [34/1063], Loss: 0.0024\n",
      "Epoch [5/10], Step [35/1063], Loss: 0.0089\n",
      "Epoch [5/10], Step [36/1063], Loss: 0.0021\n",
      "Epoch [5/10], Step [37/1063], Loss: 0.0117\n",
      "Epoch [5/10], Step [38/1063], Loss: 0.0171\n",
      "Epoch [5/10], Step [39/1063], Loss: 0.0416\n",
      "Epoch [5/10], Step [40/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [41/1063], Loss: 0.0035\n",
      "Epoch [5/10], Step [42/1063], Loss: 0.0074\n",
      "Epoch [5/10], Step [43/1063], Loss: 0.0371\n",
      "Epoch [5/10], Step [44/1063], Loss: 0.0019\n",
      "Epoch [5/10], Step [45/1063], Loss: 0.0639\n",
      "Epoch [5/10], Step [46/1063], Loss: 0.0042\n",
      "Epoch [5/10], Step [47/1063], Loss: 0.0779\n",
      "Epoch [5/10], Step [48/1063], Loss: 0.0091\n",
      "Epoch [5/10], Step [49/1063], Loss: 0.0030\n",
      "Epoch [5/10], Step [50/1063], Loss: 0.0087\n",
      "Epoch [5/10], Step [51/1063], Loss: 0.0024\n",
      "Epoch [5/10], Step [52/1063], Loss: 0.0005\n",
      "Epoch [5/10], Step [53/1063], Loss: 0.0019\n",
      "Epoch [5/10], Step [54/1063], Loss: 0.0214\n",
      "Epoch [5/10], Step [55/1063], Loss: 0.0454\n",
      "Epoch [5/10], Step [56/1063], Loss: 0.0005\n",
      "Epoch [5/10], Step [57/1063], Loss: 0.0023\n",
      "Epoch [5/10], Step [58/1063], Loss: 0.0197\n",
      "Epoch [5/10], Step [59/1063], Loss: 0.0097\n",
      "Epoch [5/10], Step [60/1063], Loss: 0.0184\n",
      "Epoch [5/10], Step [61/1063], Loss: 0.0337\n",
      "Epoch [5/10], Step [62/1063], Loss: 0.0033\n",
      "Epoch [5/10], Step [63/1063], Loss: 0.0054\n",
      "Epoch [5/10], Step [64/1063], Loss: 0.0156\n",
      "Epoch [5/10], Step [65/1063], Loss: 0.0272\n",
      "Epoch [5/10], Step [66/1063], Loss: 0.0041\n",
      "Epoch [5/10], Step [67/1063], Loss: 0.0001\n",
      "Epoch [5/10], Step [68/1063], Loss: 0.0393\n",
      "Epoch [5/10], Step [69/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [70/1063], Loss: 0.0065\n",
      "Epoch [5/10], Step [71/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [72/1063], Loss: 0.0137\n",
      "Epoch [5/10], Step [73/1063], Loss: 0.0017\n",
      "Epoch [5/10], Step [74/1063], Loss: 0.0027\n",
      "Epoch [5/10], Step [75/1063], Loss: 0.0887\n",
      "Epoch [5/10], Step [76/1063], Loss: 0.0029\n",
      "Epoch [5/10], Step [77/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [78/1063], Loss: 0.0060\n",
      "Epoch [5/10], Step [79/1063], Loss: 0.0012\n",
      "Epoch [5/10], Step [80/1063], Loss: 0.0101\n",
      "Epoch [5/10], Step [81/1063], Loss: 0.0266\n",
      "Epoch [5/10], Step [82/1063], Loss: 0.0027\n",
      "Epoch [5/10], Step [83/1063], Loss: 0.0029\n",
      "Epoch [5/10], Step [84/1063], Loss: 0.0022\n",
      "Epoch [5/10], Step [85/1063], Loss: 0.0399\n",
      "Epoch [5/10], Step [86/1063], Loss: 0.0753\n",
      "Epoch [5/10], Step [87/1063], Loss: 0.0020\n",
      "Epoch [5/10], Step [88/1063], Loss: 0.0025\n",
      "Epoch [5/10], Step [89/1063], Loss: 0.0164\n",
      "Epoch [5/10], Step [90/1063], Loss: 0.0089\n",
      "Epoch [5/10], Step [91/1063], Loss: 0.0008\n",
      "Epoch [5/10], Step [92/1063], Loss: 0.0045\n",
      "Epoch [5/10], Step [93/1063], Loss: 0.0020\n",
      "Epoch [5/10], Step [94/1063], Loss: 0.0351\n",
      "Epoch [5/10], Step [95/1063], Loss: 0.0038\n",
      "Epoch [5/10], Step [96/1063], Loss: 0.0364\n",
      "Epoch [5/10], Step [97/1063], Loss: 0.0175\n",
      "Epoch [5/10], Step [98/1063], Loss: 0.0047\n",
      "Epoch [5/10], Step [99/1063], Loss: 0.0039\n",
      "Epoch [5/10], Step [100/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [101/1063], Loss: 0.0044\n",
      "Epoch [5/10], Step [102/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [103/1063], Loss: 0.0032\n",
      "Epoch [5/10], Step [104/1063], Loss: 0.0341\n",
      "Epoch [5/10], Step [105/1063], Loss: 0.0021\n",
      "Epoch [5/10], Step [106/1063], Loss: 0.0063\n",
      "Epoch [5/10], Step [107/1063], Loss: 0.1265\n",
      "Epoch [5/10], Step [108/1063], Loss: 0.0035\n",
      "Epoch [5/10], Step [109/1063], Loss: 0.0024\n",
      "Epoch [5/10], Step [110/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [111/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [112/1063], Loss: 0.0012\n",
      "Epoch [5/10], Step [113/1063], Loss: 0.0005\n",
      "Epoch [5/10], Step [114/1063], Loss: 0.0114\n",
      "Epoch [5/10], Step [115/1063], Loss: 0.0708\n",
      "Epoch [5/10], Step [116/1063], Loss: 0.0023\n",
      "Epoch [5/10], Step [117/1063], Loss: 0.0218\n",
      "Epoch [5/10], Step [118/1063], Loss: 0.0139\n",
      "Epoch [5/10], Step [119/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [120/1063], Loss: 0.0427\n",
      "Epoch [5/10], Step [121/1063], Loss: 0.0019\n",
      "Epoch [5/10], Step [122/1063], Loss: 0.0139\n",
      "Epoch [5/10], Step [123/1063], Loss: 0.0247\n",
      "Epoch [5/10], Step [124/1063], Loss: 0.0051\n",
      "Epoch [5/10], Step [125/1063], Loss: 0.0117\n",
      "Epoch [5/10], Step [126/1063], Loss: 0.0069\n",
      "Epoch [5/10], Step [127/1063], Loss: 0.0839\n",
      "Epoch [5/10], Step [128/1063], Loss: 0.0021\n",
      "Epoch [5/10], Step [129/1063], Loss: 0.0032\n",
      "Epoch [5/10], Step [130/1063], Loss: 0.0644\n",
      "Epoch [5/10], Step [131/1063], Loss: 0.0014\n",
      "Epoch [5/10], Step [132/1063], Loss: 0.0161\n",
      "Epoch [5/10], Step [133/1063], Loss: 0.0079\n",
      "Epoch [5/10], Step [134/1063], Loss: 0.0115\n",
      "Epoch [5/10], Step [135/1063], Loss: 0.0116\n",
      "Epoch [5/10], Step [136/1063], Loss: 0.0065\n",
      "Epoch [5/10], Step [137/1063], Loss: 0.0087\n",
      "Epoch [5/10], Step [138/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [139/1063], Loss: 0.0060\n",
      "Epoch [5/10], Step [140/1063], Loss: 0.0085\n",
      "Epoch [5/10], Step [141/1063], Loss: 0.0358\n",
      "Epoch [5/10], Step [142/1063], Loss: 0.0842\n",
      "Epoch [5/10], Step [143/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [144/1063], Loss: 0.0214\n",
      "Epoch [5/10], Step [145/1063], Loss: 0.0038\n",
      "Epoch [5/10], Step [146/1063], Loss: 0.0028\n",
      "Epoch [5/10], Step [147/1063], Loss: 0.0080\n",
      "Epoch [5/10], Step [148/1063], Loss: 0.0078\n",
      "Epoch [5/10], Step [149/1063], Loss: 0.0057\n",
      "Epoch [5/10], Step [150/1063], Loss: 0.0041\n",
      "Epoch [5/10], Step [151/1063], Loss: 0.0136\n",
      "Epoch [5/10], Step [152/1063], Loss: 0.0025\n",
      "Epoch [5/10], Step [153/1063], Loss: 0.0120\n",
      "Epoch [5/10], Step [154/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [155/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [156/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [157/1063], Loss: 0.0170\n",
      "Epoch [5/10], Step [158/1063], Loss: 0.0087\n",
      "Epoch [5/10], Step [159/1063], Loss: 0.0936\n",
      "Epoch [5/10], Step [160/1063], Loss: 0.0028\n",
      "Epoch [5/10], Step [161/1063], Loss: 0.0020\n",
      "Epoch [5/10], Step [162/1063], Loss: 0.0062\n",
      "Epoch [5/10], Step [163/1063], Loss: 0.0958\n",
      "Epoch [5/10], Step [164/1063], Loss: 0.0230\n",
      "Epoch [5/10], Step [165/1063], Loss: 0.0037\n",
      "Epoch [5/10], Step [166/1063], Loss: 0.0617\n",
      "Epoch [5/10], Step [167/1063], Loss: 0.0027\n",
      "Epoch [5/10], Step [168/1063], Loss: 0.0035\n",
      "Epoch [5/10], Step [169/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [170/1063], Loss: 0.0072\n",
      "Epoch [5/10], Step [171/1063], Loss: 0.0027\n",
      "Epoch [5/10], Step [172/1063], Loss: 0.0038\n",
      "Epoch [5/10], Step [173/1063], Loss: 0.0042\n",
      "Epoch [5/10], Step [174/1063], Loss: 0.0208\n",
      "Epoch [5/10], Step [175/1063], Loss: 0.0259\n",
      "Epoch [5/10], Step [176/1063], Loss: 0.0352\n",
      "Epoch [5/10], Step [177/1063], Loss: 0.0373\n",
      "Epoch [5/10], Step [178/1063], Loss: 0.0184\n",
      "Epoch [5/10], Step [179/1063], Loss: 0.0400\n",
      "Epoch [5/10], Step [180/1063], Loss: 0.0495\n",
      "Epoch [5/10], Step [181/1063], Loss: 0.0108\n",
      "Epoch [5/10], Step [182/1063], Loss: 0.0308\n",
      "Epoch [5/10], Step [183/1063], Loss: 0.0193\n",
      "Epoch [5/10], Step [184/1063], Loss: 0.0028\n",
      "Epoch [5/10], Step [185/1063], Loss: 0.0022\n",
      "Epoch [5/10], Step [186/1063], Loss: 0.0053\n",
      "Epoch [5/10], Step [187/1063], Loss: 0.0038\n",
      "Epoch [5/10], Step [188/1063], Loss: 0.0037\n",
      "Epoch [5/10], Step [189/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [190/1063], Loss: 0.0017\n",
      "Epoch [5/10], Step [191/1063], Loss: 0.0137\n",
      "Epoch [5/10], Step [192/1063], Loss: 0.0241\n",
      "Epoch [5/10], Step [193/1063], Loss: 0.0093\n",
      "Epoch [5/10], Step [194/1063], Loss: 0.0375\n",
      "Epoch [5/10], Step [195/1063], Loss: 0.0020\n",
      "Epoch [5/10], Step [196/1063], Loss: 0.0053\n",
      "Epoch [5/10], Step [197/1063], Loss: 0.0070\n",
      "Epoch [5/10], Step [198/1063], Loss: 0.0188\n",
      "Epoch [5/10], Step [199/1063], Loss: 0.0042\n",
      "Epoch [5/10], Step [200/1063], Loss: 0.0027\n",
      "Epoch [5/10], Step [201/1063], Loss: 0.0097\n",
      "Epoch [5/10], Step [202/1063], Loss: 0.0091\n",
      "Epoch [5/10], Step [203/1063], Loss: 0.0114\n",
      "Epoch [5/10], Step [204/1063], Loss: 0.0111\n",
      "Epoch [5/10], Step [205/1063], Loss: 0.0070\n",
      "Epoch [5/10], Step [206/1063], Loss: 0.0852\n",
      "Epoch [5/10], Step [207/1063], Loss: 0.0114\n",
      "Epoch [5/10], Step [208/1063], Loss: 0.0050\n",
      "Epoch [5/10], Step [209/1063], Loss: 0.0305\n",
      "Epoch [5/10], Step [210/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [211/1063], Loss: 0.0041\n",
      "Epoch [5/10], Step [212/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [213/1063], Loss: 0.0145\n",
      "Epoch [5/10], Step [214/1063], Loss: 0.2138\n",
      "Epoch [5/10], Step [215/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [216/1063], Loss: 0.0721\n",
      "Epoch [5/10], Step [217/1063], Loss: 0.0243\n",
      "Epoch [5/10], Step [218/1063], Loss: 0.0283\n",
      "Epoch [5/10], Step [219/1063], Loss: 0.0822\n",
      "Epoch [5/10], Step [220/1063], Loss: 0.0052\n",
      "Epoch [5/10], Step [221/1063], Loss: 0.0068\n",
      "Epoch [5/10], Step [222/1063], Loss: 0.0014\n",
      "Epoch [5/10], Step [223/1063], Loss: 0.0040\n",
      "Epoch [5/10], Step [224/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [225/1063], Loss: 0.0029\n",
      "Epoch [5/10], Step [226/1063], Loss: 0.0051\n",
      "Epoch [5/10], Step [227/1063], Loss: 0.0074\n",
      "Epoch [5/10], Step [228/1063], Loss: 0.0352\n",
      "Epoch [5/10], Step [229/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [230/1063], Loss: 0.0464\n",
      "Epoch [5/10], Step [231/1063], Loss: 0.0570\n",
      "Epoch [5/10], Step [232/1063], Loss: 0.0039\n",
      "Epoch [5/10], Step [233/1063], Loss: 0.0419\n",
      "Epoch [5/10], Step [234/1063], Loss: 0.0711\n",
      "Epoch [5/10], Step [235/1063], Loss: 0.0014\n",
      "Epoch [5/10], Step [236/1063], Loss: 0.0074\n",
      "Epoch [5/10], Step [237/1063], Loss: 0.0064\n",
      "Epoch [5/10], Step [238/1063], Loss: 0.0034\n",
      "Epoch [5/10], Step [239/1063], Loss: 0.0134\n",
      "Epoch [5/10], Step [240/1063], Loss: 0.0031\n",
      "Epoch [5/10], Step [241/1063], Loss: 0.0591\n",
      "Epoch [5/10], Step [242/1063], Loss: 0.0022\n",
      "Epoch [5/10], Step [243/1063], Loss: 0.0254\n",
      "Epoch [5/10], Step [244/1063], Loss: 0.0044\n",
      "Epoch [5/10], Step [245/1063], Loss: 0.0101\n",
      "Epoch [5/10], Step [246/1063], Loss: 0.0408\n",
      "Epoch [5/10], Step [247/1063], Loss: 0.0037\n",
      "Epoch [5/10], Step [248/1063], Loss: 0.0192\n",
      "Epoch [5/10], Step [249/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [250/1063], Loss: 0.0376\n",
      "Epoch [5/10], Step [251/1063], Loss: 0.0049\n",
      "Epoch [5/10], Step [252/1063], Loss: 0.0080\n",
      "Epoch [5/10], Step [253/1063], Loss: 0.0059\n",
      "Epoch [5/10], Step [254/1063], Loss: 0.0060\n",
      "Epoch [5/10], Step [255/1063], Loss: 0.0140\n",
      "Epoch [5/10], Step [256/1063], Loss: 0.0044\n",
      "Epoch [5/10], Step [257/1063], Loss: 0.0115\n",
      "Epoch [5/10], Step [258/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [259/1063], Loss: 0.0067\n",
      "Epoch [5/10], Step [260/1063], Loss: 0.0133\n",
      "Epoch [5/10], Step [261/1063], Loss: 0.0265\n",
      "Epoch [5/10], Step [262/1063], Loss: 0.0083\n",
      "Epoch [5/10], Step [263/1063], Loss: 0.0207\n",
      "Epoch [5/10], Step [264/1063], Loss: 0.0314\n",
      "Epoch [5/10], Step [265/1063], Loss: 0.0068\n",
      "Epoch [5/10], Step [266/1063], Loss: 0.0036\n",
      "Epoch [5/10], Step [267/1063], Loss: 0.0175\n",
      "Epoch [5/10], Step [268/1063], Loss: 0.0037\n",
      "Epoch [5/10], Step [269/1063], Loss: 0.0046\n",
      "Epoch [5/10], Step [270/1063], Loss: 0.0069\n",
      "Epoch [5/10], Step [271/1063], Loss: 0.0033\n",
      "Epoch [5/10], Step [272/1063], Loss: 0.0111\n",
      "Epoch [5/10], Step [273/1063], Loss: 0.0400\n",
      "Epoch [5/10], Step [274/1063], Loss: 0.0086\n",
      "Epoch [5/10], Step [275/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [276/1063], Loss: 0.0017\n",
      "Epoch [5/10], Step [277/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [278/1063], Loss: 0.0239\n",
      "Epoch [5/10], Step [279/1063], Loss: 0.0044\n",
      "Epoch [5/10], Step [280/1063], Loss: 0.0275\n",
      "Epoch [5/10], Step [281/1063], Loss: 0.0044\n",
      "Epoch [5/10], Step [282/1063], Loss: 0.0033\n",
      "Epoch [5/10], Step [283/1063], Loss: 0.0012\n",
      "Epoch [5/10], Step [284/1063], Loss: 0.0125\n",
      "Epoch [5/10], Step [285/1063], Loss: 0.0043\n",
      "Epoch [5/10], Step [286/1063], Loss: 0.0361\n",
      "Epoch [5/10], Step [287/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [288/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [289/1063], Loss: 0.0110\n",
      "Epoch [5/10], Step [290/1063], Loss: 0.0019\n",
      "Epoch [5/10], Step [291/1063], Loss: 0.0067\n",
      "Epoch [5/10], Step [292/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [293/1063], Loss: 0.0005\n",
      "Epoch [5/10], Step [294/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [295/1063], Loss: 0.0026\n",
      "Epoch [5/10], Step [296/1063], Loss: 0.0024\n",
      "Epoch [5/10], Step [297/1063], Loss: 0.0193\n",
      "Epoch [5/10], Step [298/1063], Loss: 0.0037\n",
      "Epoch [5/10], Step [299/1063], Loss: 0.0331\n",
      "Epoch [5/10], Step [300/1063], Loss: 0.0056\n",
      "Epoch [5/10], Step [301/1063], Loss: 0.0026\n",
      "Epoch [5/10], Step [302/1063], Loss: 0.0113\n",
      "Epoch [5/10], Step [303/1063], Loss: 0.0005\n",
      "Epoch [5/10], Step [304/1063], Loss: 0.0084\n",
      "Epoch [5/10], Step [305/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [306/1063], Loss: 0.0104\n",
      "Epoch [5/10], Step [307/1063], Loss: 0.0331\n",
      "Epoch [5/10], Step [308/1063], Loss: 0.0008\n",
      "Epoch [5/10], Step [309/1063], Loss: 0.0008\n",
      "Epoch [5/10], Step [310/1063], Loss: 0.0120\n",
      "Epoch [5/10], Step [311/1063], Loss: 0.0032\n",
      "Epoch [5/10], Step [312/1063], Loss: 0.0750\n",
      "Epoch [5/10], Step [313/1063], Loss: 0.0033\n",
      "Epoch [5/10], Step [314/1063], Loss: 0.0897\n",
      "Epoch [5/10], Step [315/1063], Loss: 0.0256\n",
      "Epoch [5/10], Step [316/1063], Loss: 0.0008\n",
      "Epoch [5/10], Step [317/1063], Loss: 0.0041\n",
      "Epoch [5/10], Step [318/1063], Loss: 0.0060\n",
      "Epoch [5/10], Step [319/1063], Loss: 0.0017\n",
      "Epoch [5/10], Step [320/1063], Loss: 0.0012\n",
      "Epoch [5/10], Step [321/1063], Loss: 0.0000\n",
      "Epoch [5/10], Step [322/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [323/1063], Loss: 0.0028\n",
      "Epoch [5/10], Step [324/1063], Loss: 0.0014\n",
      "Epoch [5/10], Step [325/1063], Loss: 0.0147\n",
      "Epoch [5/10], Step [326/1063], Loss: 0.0013\n",
      "Epoch [5/10], Step [327/1063], Loss: 0.0103\n",
      "Epoch [5/10], Step [328/1063], Loss: 0.0002\n",
      "Epoch [5/10], Step [329/1063], Loss: 0.0030\n",
      "Epoch [5/10], Step [330/1063], Loss: 0.0019\n",
      "Epoch [5/10], Step [331/1063], Loss: 0.0177\n",
      "Epoch [5/10], Step [332/1063], Loss: 0.0416\n",
      "Epoch [5/10], Step [333/1063], Loss: 0.0030\n",
      "Epoch [5/10], Step [334/1063], Loss: 0.0162\n",
      "Epoch [5/10], Step [335/1063], Loss: 0.0322\n",
      "Epoch [5/10], Step [336/1063], Loss: 0.0039\n",
      "Epoch [5/10], Step [337/1063], Loss: 0.0136\n",
      "Epoch [5/10], Step [338/1063], Loss: 0.0033\n",
      "Epoch [5/10], Step [339/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [340/1063], Loss: 0.0133\n",
      "Epoch [5/10], Step [341/1063], Loss: 0.0383\n",
      "Epoch [5/10], Step [342/1063], Loss: 0.0040\n",
      "Epoch [5/10], Step [343/1063], Loss: 0.0035\n",
      "Epoch [5/10], Step [344/1063], Loss: 0.0017\n",
      "Epoch [5/10], Step [345/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [346/1063], Loss: 0.0019\n",
      "Epoch [5/10], Step [347/1063], Loss: 0.1215\n",
      "Epoch [5/10], Step [348/1063], Loss: 0.0001\n",
      "Epoch [5/10], Step [349/1063], Loss: 0.0812\n",
      "Epoch [5/10], Step [350/1063], Loss: 0.0061\n",
      "Epoch [5/10], Step [351/1063], Loss: 0.0001\n",
      "Epoch [5/10], Step [352/1063], Loss: 0.0151\n",
      "Epoch [5/10], Step [353/1063], Loss: 0.0188\n",
      "Epoch [5/10], Step [354/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [355/1063], Loss: 0.0052\n",
      "Epoch [5/10], Step [356/1063], Loss: 0.0052\n",
      "Epoch [5/10], Step [357/1063], Loss: 0.0752\n",
      "Epoch [5/10], Step [358/1063], Loss: 0.0128\n",
      "Epoch [5/10], Step [359/1063], Loss: 0.0246\n",
      "Epoch [5/10], Step [360/1063], Loss: 0.0026\n",
      "Epoch [5/10], Step [361/1063], Loss: 0.0221\n",
      "Epoch [5/10], Step [362/1063], Loss: 0.0024\n",
      "Epoch [5/10], Step [363/1063], Loss: 0.0052\n",
      "Epoch [5/10], Step [364/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [365/1063], Loss: 0.0129\n",
      "Epoch [5/10], Step [366/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [367/1063], Loss: 0.0036\n",
      "Epoch [5/10], Step [368/1063], Loss: 0.0019\n",
      "Epoch [5/10], Step [369/1063], Loss: 0.0113\n",
      "Epoch [5/10], Step [370/1063], Loss: 0.0085\n",
      "Epoch [5/10], Step [371/1063], Loss: 0.0040\n",
      "Epoch [5/10], Step [372/1063], Loss: 0.0259\n",
      "Epoch [5/10], Step [373/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [374/1063], Loss: 0.0039\n",
      "Epoch [5/10], Step [375/1063], Loss: 0.0146\n",
      "Epoch [5/10], Step [376/1063], Loss: 0.0311\n",
      "Epoch [5/10], Step [377/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [378/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [379/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [380/1063], Loss: 0.0119\n",
      "Epoch [5/10], Step [381/1063], Loss: 0.0726\n",
      "Epoch [5/10], Step [382/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [383/1063], Loss: 0.0214\n",
      "Epoch [5/10], Step [384/1063], Loss: 0.0119\n",
      "Epoch [5/10], Step [385/1063], Loss: 0.1117\n",
      "Epoch [5/10], Step [386/1063], Loss: 0.0083\n",
      "Epoch [5/10], Step [387/1063], Loss: 0.0112\n",
      "Epoch [5/10], Step [388/1063], Loss: 0.0033\n",
      "Epoch [5/10], Step [389/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [390/1063], Loss: 0.0022\n",
      "Epoch [5/10], Step [391/1063], Loss: 0.0029\n",
      "Epoch [5/10], Step [392/1063], Loss: 0.0008\n",
      "Epoch [5/10], Step [393/1063], Loss: 0.0174\n",
      "Epoch [5/10], Step [394/1063], Loss: 0.0096\n",
      "Epoch [5/10], Step [395/1063], Loss: 0.0228\n",
      "Epoch [5/10], Step [396/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [397/1063], Loss: 0.0066\n",
      "Epoch [5/10], Step [398/1063], Loss: 0.0185\n",
      "Epoch [5/10], Step [399/1063], Loss: 0.0048\n",
      "Epoch [5/10], Step [400/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [401/1063], Loss: 0.0617\n",
      "Epoch [5/10], Step [402/1063], Loss: 0.0583\n",
      "Epoch [5/10], Step [403/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [404/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [405/1063], Loss: 0.0105\n",
      "Epoch [5/10], Step [406/1063], Loss: 0.1514\n",
      "Epoch [5/10], Step [407/1063], Loss: 0.0331\n",
      "Epoch [5/10], Step [408/1063], Loss: 0.0029\n",
      "Epoch [5/10], Step [409/1063], Loss: 0.0796\n",
      "Epoch [5/10], Step [410/1063], Loss: 0.0106\n",
      "Epoch [5/10], Step [411/1063], Loss: 0.0013\n",
      "Epoch [5/10], Step [412/1063], Loss: 0.0073\n",
      "Epoch [5/10], Step [413/1063], Loss: 0.0019\n",
      "Epoch [5/10], Step [414/1063], Loss: 0.0040\n",
      "Epoch [5/10], Step [415/1063], Loss: 0.0073\n",
      "Epoch [5/10], Step [416/1063], Loss: 0.0582\n",
      "Epoch [5/10], Step [417/1063], Loss: 0.0404\n",
      "Epoch [5/10], Step [418/1063], Loss: 0.0001\n",
      "Epoch [5/10], Step [419/1063], Loss: 0.0028\n",
      "Epoch [5/10], Step [420/1063], Loss: 0.0005\n",
      "Epoch [5/10], Step [421/1063], Loss: 0.0111\n",
      "Epoch [5/10], Step [422/1063], Loss: 0.0052\n",
      "Epoch [5/10], Step [423/1063], Loss: 0.0078\n",
      "Epoch [5/10], Step [424/1063], Loss: 0.0025\n",
      "Epoch [5/10], Step [425/1063], Loss: 0.0035\n",
      "Epoch [5/10], Step [426/1063], Loss: 0.0612\n",
      "Epoch [5/10], Step [427/1063], Loss: 0.0034\n",
      "Epoch [5/10], Step [428/1063], Loss: 0.1038\n",
      "Epoch [5/10], Step [429/1063], Loss: 0.0523\n",
      "Epoch [5/10], Step [430/1063], Loss: 0.0026\n",
      "Epoch [5/10], Step [431/1063], Loss: 0.0432\n",
      "Epoch [5/10], Step [432/1063], Loss: 0.0110\n",
      "Epoch [5/10], Step [433/1063], Loss: 0.0118\n",
      "Epoch [5/10], Step [434/1063], Loss: 0.0005\n",
      "Epoch [5/10], Step [435/1063], Loss: 0.0112\n",
      "Epoch [5/10], Step [436/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [437/1063], Loss: 0.0307\n",
      "Epoch [5/10], Step [438/1063], Loss: 0.0012\n",
      "Epoch [5/10], Step [439/1063], Loss: 0.0075\n",
      "Epoch [5/10], Step [440/1063], Loss: 0.0517\n",
      "Epoch [5/10], Step [441/1063], Loss: 0.0444\n",
      "Epoch [5/10], Step [442/1063], Loss: 0.1077\n",
      "Epoch [5/10], Step [443/1063], Loss: 0.0013\n",
      "Epoch [5/10], Step [444/1063], Loss: 0.1154\n",
      "Epoch [5/10], Step [445/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [446/1063], Loss: 0.0117\n",
      "Epoch [5/10], Step [447/1063], Loss: 0.0326\n",
      "Epoch [5/10], Step [448/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [449/1063], Loss: 0.0208\n",
      "Epoch [5/10], Step [450/1063], Loss: 0.0560\n",
      "Epoch [5/10], Step [451/1063], Loss: 0.0030\n",
      "Epoch [5/10], Step [452/1063], Loss: 0.1243\n",
      "Epoch [5/10], Step [453/1063], Loss: 0.0439\n",
      "Epoch [5/10], Step [454/1063], Loss: 0.0023\n",
      "Epoch [5/10], Step [455/1063], Loss: 0.0091\n",
      "Epoch [5/10], Step [456/1063], Loss: 0.0464\n",
      "Epoch [5/10], Step [457/1063], Loss: 0.0533\n",
      "Epoch [5/10], Step [458/1063], Loss: 0.0151\n",
      "Epoch [5/10], Step [459/1063], Loss: 0.0227\n",
      "Epoch [5/10], Step [460/1063], Loss: 0.0332\n",
      "Epoch [5/10], Step [461/1063], Loss: 0.0020\n",
      "Epoch [5/10], Step [462/1063], Loss: 0.0839\n",
      "Epoch [5/10], Step [463/1063], Loss: 0.0161\n",
      "Epoch [5/10], Step [464/1063], Loss: 0.0751\n",
      "Epoch [5/10], Step [465/1063], Loss: 0.0293\n",
      "Epoch [5/10], Step [466/1063], Loss: 0.0134\n",
      "Epoch [5/10], Step [467/1063], Loss: 0.0022\n",
      "Epoch [5/10], Step [468/1063], Loss: 0.0481\n",
      "Epoch [5/10], Step [469/1063], Loss: 0.0331\n",
      "Epoch [5/10], Step [470/1063], Loss: 0.0268\n",
      "Epoch [5/10], Step [471/1063], Loss: 0.0122\n",
      "Epoch [5/10], Step [472/1063], Loss: 0.0752\n",
      "Epoch [5/10], Step [473/1063], Loss: 0.0101\n",
      "Epoch [5/10], Step [474/1063], Loss: 0.0187\n",
      "Epoch [5/10], Step [475/1063], Loss: 0.0032\n",
      "Epoch [5/10], Step [476/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [477/1063], Loss: 0.0051\n",
      "Epoch [5/10], Step [478/1063], Loss: 0.0017\n",
      "Epoch [5/10], Step [479/1063], Loss: 0.0068\n",
      "Epoch [5/10], Step [480/1063], Loss: 0.0217\n",
      "Epoch [5/10], Step [481/1063], Loss: 0.0064\n",
      "Epoch [5/10], Step [482/1063], Loss: 0.0017\n",
      "Epoch [5/10], Step [483/1063], Loss: 0.0087\n",
      "Epoch [5/10], Step [484/1063], Loss: 0.0114\n",
      "Epoch [5/10], Step [485/1063], Loss: 0.0023\n",
      "Epoch [5/10], Step [486/1063], Loss: 0.0081\n",
      "Epoch [5/10], Step [487/1063], Loss: 0.0051\n",
      "Epoch [5/10], Step [488/1063], Loss: 0.0114\n",
      "Epoch [5/10], Step [489/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [490/1063], Loss: 0.0451\n",
      "Epoch [5/10], Step [491/1063], Loss: 0.0063\n",
      "Epoch [5/10], Step [492/1063], Loss: 0.0369\n",
      "Epoch [5/10], Step [493/1063], Loss: 0.0033\n",
      "Epoch [5/10], Step [494/1063], Loss: 0.0065\n",
      "Epoch [5/10], Step [495/1063], Loss: 0.0029\n",
      "Epoch [5/10], Step [496/1063], Loss: 0.0074\n",
      "Epoch [5/10], Step [497/1063], Loss: 0.0040\n",
      "Epoch [5/10], Step [498/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [499/1063], Loss: 0.0038\n",
      "Epoch [5/10], Step [500/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [501/1063], Loss: 0.1567\n",
      "Epoch [5/10], Step [502/1063], Loss: 0.0111\n",
      "Epoch [5/10], Step [503/1063], Loss: 0.0343\n",
      "Epoch [5/10], Step [504/1063], Loss: 0.0040\n",
      "Epoch [5/10], Step [505/1063], Loss: 0.0044\n",
      "Epoch [5/10], Step [506/1063], Loss: 0.0005\n",
      "Epoch [5/10], Step [507/1063], Loss: 0.0046\n",
      "Epoch [5/10], Step [508/1063], Loss: 0.0081\n",
      "Epoch [5/10], Step [509/1063], Loss: 0.0054\n",
      "Epoch [5/10], Step [510/1063], Loss: 0.0044\n",
      "Epoch [5/10], Step [511/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [512/1063], Loss: 0.0043\n",
      "Epoch [5/10], Step [513/1063], Loss: 0.0468\n",
      "Epoch [5/10], Step [514/1063], Loss: 0.0027\n",
      "Epoch [5/10], Step [515/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [516/1063], Loss: 0.0559\n",
      "Epoch [5/10], Step [517/1063], Loss: 0.0189\n",
      "Epoch [5/10], Step [518/1063], Loss: 0.0086\n",
      "Epoch [5/10], Step [519/1063], Loss: 0.0060\n",
      "Epoch [5/10], Step [520/1063], Loss: 0.0109\n",
      "Epoch [5/10], Step [521/1063], Loss: 0.0127\n",
      "Epoch [5/10], Step [522/1063], Loss: 0.0206\n",
      "Epoch [5/10], Step [523/1063], Loss: 0.0141\n",
      "Epoch [5/10], Step [524/1063], Loss: 0.0392\n",
      "Epoch [5/10], Step [525/1063], Loss: 0.0120\n",
      "Epoch [5/10], Step [526/1063], Loss: 0.0099\n",
      "Epoch [5/10], Step [527/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [528/1063], Loss: 0.0101\n",
      "Epoch [5/10], Step [529/1063], Loss: 0.0024\n",
      "Epoch [5/10], Step [530/1063], Loss: 0.0007\n",
      "Epoch [5/10], Step [531/1063], Loss: 0.0111\n",
      "Epoch [5/10], Step [532/1063], Loss: 0.0172\n",
      "Epoch [5/10], Step [533/1063], Loss: 0.0096\n",
      "Epoch [5/10], Step [534/1063], Loss: 0.0030\n",
      "Epoch [5/10], Step [535/1063], Loss: 0.0154\n",
      "Epoch [5/10], Step [536/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [537/1063], Loss: 0.0014\n",
      "Epoch [5/10], Step [538/1063], Loss: 0.0060\n",
      "Epoch [5/10], Step [539/1063], Loss: 0.0609\n",
      "Epoch [5/10], Step [540/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [541/1063], Loss: 0.0034\n",
      "Epoch [5/10], Step [542/1063], Loss: 0.0234\n",
      "Epoch [5/10], Step [543/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [544/1063], Loss: 0.0154\n",
      "Epoch [5/10], Step [545/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [546/1063], Loss: 0.0047\n",
      "Epoch [5/10], Step [547/1063], Loss: 0.0040\n",
      "Epoch [5/10], Step [548/1063], Loss: 0.0014\n",
      "Epoch [5/10], Step [549/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [550/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [551/1063], Loss: 0.0997\n",
      "Epoch [5/10], Step [552/1063], Loss: 0.0105\n",
      "Epoch [5/10], Step [553/1063], Loss: 0.0008\n",
      "Epoch [5/10], Step [554/1063], Loss: 0.0092\n",
      "Epoch [5/10], Step [555/1063], Loss: 0.0082\n",
      "Epoch [5/10], Step [556/1063], Loss: 0.0069\n",
      "Epoch [5/10], Step [557/1063], Loss: 0.0699\n",
      "Epoch [5/10], Step [558/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [559/1063], Loss: 0.0044\n",
      "Epoch [5/10], Step [560/1063], Loss: 0.0039\n",
      "Epoch [5/10], Step [561/1063], Loss: 0.0093\n",
      "Epoch [5/10], Step [562/1063], Loss: 0.0196\n",
      "Epoch [5/10], Step [563/1063], Loss: 0.0043\n",
      "Epoch [5/10], Step [564/1063], Loss: 0.0026\n",
      "Epoch [5/10], Step [565/1063], Loss: 0.0062\n",
      "Epoch [5/10], Step [566/1063], Loss: 0.0067\n",
      "Epoch [5/10], Step [567/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [568/1063], Loss: 0.0088\n",
      "Epoch [5/10], Step [569/1063], Loss: 0.0287\n",
      "Epoch [5/10], Step [570/1063], Loss: 0.0675\n",
      "Epoch [5/10], Step [571/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [572/1063], Loss: 0.0024\n",
      "Epoch [5/10], Step [573/1063], Loss: 0.0453\n",
      "Epoch [5/10], Step [574/1063], Loss: 0.0007\n",
      "Epoch [5/10], Step [575/1063], Loss: 0.0029\n",
      "Epoch [5/10], Step [576/1063], Loss: 0.0402\n",
      "Epoch [5/10], Step [577/1063], Loss: 0.0017\n",
      "Epoch [5/10], Step [578/1063], Loss: 0.0024\n",
      "Epoch [5/10], Step [579/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [580/1063], Loss: 0.0133\n",
      "Epoch [5/10], Step [581/1063], Loss: 0.0300\n",
      "Epoch [5/10], Step [582/1063], Loss: 0.3438\n",
      "Epoch [5/10], Step [583/1063], Loss: 0.0086\n",
      "Epoch [5/10], Step [584/1063], Loss: 0.0375\n",
      "Epoch [5/10], Step [585/1063], Loss: 0.0050\n",
      "Epoch [5/10], Step [586/1063], Loss: 0.0093\n",
      "Epoch [5/10], Step [587/1063], Loss: 0.0583\n",
      "Epoch [5/10], Step [588/1063], Loss: 0.0666\n",
      "Epoch [5/10], Step [589/1063], Loss: 0.0127\n",
      "Epoch [5/10], Step [590/1063], Loss: 0.0293\n",
      "Epoch [5/10], Step [591/1063], Loss: 0.0210\n",
      "Epoch [5/10], Step [592/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [593/1063], Loss: 0.0053\n",
      "Epoch [5/10], Step [594/1063], Loss: 0.0097\n",
      "Epoch [5/10], Step [595/1063], Loss: 0.0022\n",
      "Epoch [5/10], Step [596/1063], Loss: 0.0040\n",
      "Epoch [5/10], Step [597/1063], Loss: 0.0123\n",
      "Epoch [5/10], Step [598/1063], Loss: 0.0337\n",
      "Epoch [5/10], Step [599/1063], Loss: 0.0190\n",
      "Epoch [5/10], Step [600/1063], Loss: 0.0439\n",
      "Epoch [5/10], Step [601/1063], Loss: 0.0019\n",
      "Epoch [5/10], Step [602/1063], Loss: 0.0087\n",
      "Epoch [5/10], Step [603/1063], Loss: 0.0076\n",
      "Epoch [5/10], Step [604/1063], Loss: 0.0059\n",
      "Epoch [5/10], Step [605/1063], Loss: 0.0511\n",
      "Epoch [5/10], Step [606/1063], Loss: 0.0122\n",
      "Epoch [5/10], Step [607/1063], Loss: 0.0124\n",
      "Epoch [5/10], Step [608/1063], Loss: 0.0057\n",
      "Epoch [5/10], Step [609/1063], Loss: 0.0280\n",
      "Epoch [5/10], Step [610/1063], Loss: 0.0116\n",
      "Epoch [5/10], Step [611/1063], Loss: 0.0076\n",
      "Epoch [5/10], Step [612/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [613/1063], Loss: 0.0023\n",
      "Epoch [5/10], Step [614/1063], Loss: 0.0013\n",
      "Epoch [5/10], Step [615/1063], Loss: 0.0414\n",
      "Epoch [5/10], Step [616/1063], Loss: 0.0049\n",
      "Epoch [5/10], Step [617/1063], Loss: 0.0271\n",
      "Epoch [5/10], Step [618/1063], Loss: 0.0066\n",
      "Epoch [5/10], Step [619/1063], Loss: 0.0023\n",
      "Epoch [5/10], Step [620/1063], Loss: 0.0652\n",
      "Epoch [5/10], Step [621/1063], Loss: 0.0002\n",
      "Epoch [5/10], Step [622/1063], Loss: 0.0346\n",
      "Epoch [5/10], Step [623/1063], Loss: 0.0061\n",
      "Epoch [5/10], Step [624/1063], Loss: 0.0037\n",
      "Epoch [5/10], Step [625/1063], Loss: 0.0116\n",
      "Epoch [5/10], Step [626/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [627/1063], Loss: 0.0191\n",
      "Epoch [5/10], Step [628/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [629/1063], Loss: 0.0417\n",
      "Epoch [5/10], Step [630/1063], Loss: 0.0142\n",
      "Epoch [5/10], Step [631/1063], Loss: 0.0008\n",
      "Epoch [5/10], Step [632/1063], Loss: 0.0021\n",
      "Epoch [5/10], Step [633/1063], Loss: 0.0154\n",
      "Epoch [5/10], Step [634/1063], Loss: 0.0354\n",
      "Epoch [5/10], Step [635/1063], Loss: 0.0092\n",
      "Epoch [5/10], Step [636/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [637/1063], Loss: 0.0167\n",
      "Epoch [5/10], Step [638/1063], Loss: 0.0169\n",
      "Epoch [5/10], Step [639/1063], Loss: 0.0076\n",
      "Epoch [5/10], Step [640/1063], Loss: 0.0192\n",
      "Epoch [5/10], Step [641/1063], Loss: 0.0078\n",
      "Epoch [5/10], Step [642/1063], Loss: 0.0063\n",
      "Epoch [5/10], Step [643/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [644/1063], Loss: 0.0137\n",
      "Epoch [5/10], Step [645/1063], Loss: 0.0055\n",
      "Epoch [5/10], Step [646/1063], Loss: 0.0002\n",
      "Epoch [5/10], Step [647/1063], Loss: 0.0025\n",
      "Epoch [5/10], Step [648/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [649/1063], Loss: 0.0563\n",
      "Epoch [5/10], Step [650/1063], Loss: 0.0058\n",
      "Epoch [5/10], Step [651/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [652/1063], Loss: 0.0294\n",
      "Epoch [5/10], Step [653/1063], Loss: 0.0064\n",
      "Epoch [5/10], Step [654/1063], Loss: 0.0080\n",
      "Epoch [5/10], Step [655/1063], Loss: 0.1087\n",
      "Epoch [5/10], Step [656/1063], Loss: 0.0389\n",
      "Epoch [5/10], Step [657/1063], Loss: 0.0023\n",
      "Epoch [5/10], Step [658/1063], Loss: 0.0038\n",
      "Epoch [5/10], Step [659/1063], Loss: 0.0021\n",
      "Epoch [5/10], Step [660/1063], Loss: 0.0403\n",
      "Epoch [5/10], Step [661/1063], Loss: 0.0154\n",
      "Epoch [5/10], Step [662/1063], Loss: 0.0497\n",
      "Epoch [5/10], Step [663/1063], Loss: 0.0090\n",
      "Epoch [5/10], Step [664/1063], Loss: 0.0028\n",
      "Epoch [5/10], Step [665/1063], Loss: 0.0249\n",
      "Epoch [5/10], Step [666/1063], Loss: 0.0052\n",
      "Epoch [5/10], Step [667/1063], Loss: 0.0157\n",
      "Epoch [5/10], Step [668/1063], Loss: 0.0020\n",
      "Epoch [5/10], Step [669/1063], Loss: 0.0602\n",
      "Epoch [5/10], Step [670/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [671/1063], Loss: 0.0030\n",
      "Epoch [5/10], Step [672/1063], Loss: 0.0049\n",
      "Epoch [5/10], Step [673/1063], Loss: 0.0184\n",
      "Epoch [5/10], Step [674/1063], Loss: 0.0365\n",
      "Epoch [5/10], Step [675/1063], Loss: 0.0063\n",
      "Epoch [5/10], Step [676/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [677/1063], Loss: 0.0227\n",
      "Epoch [5/10], Step [678/1063], Loss: 0.0008\n",
      "Epoch [5/10], Step [679/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [680/1063], Loss: 0.0141\n",
      "Epoch [5/10], Step [681/1063], Loss: 0.0215\n",
      "Epoch [5/10], Step [682/1063], Loss: 0.0021\n",
      "Epoch [5/10], Step [683/1063], Loss: 0.0120\n",
      "Epoch [5/10], Step [684/1063], Loss: 0.0046\n",
      "Epoch [5/10], Step [685/1063], Loss: 0.0075\n",
      "Epoch [5/10], Step [686/1063], Loss: 0.0669\n",
      "Epoch [5/10], Step [687/1063], Loss: 0.0195\n",
      "Epoch [5/10], Step [688/1063], Loss: 0.0672\n",
      "Epoch [5/10], Step [689/1063], Loss: 0.0916\n",
      "Epoch [5/10], Step [690/1063], Loss: 0.0272\n",
      "Epoch [5/10], Step [691/1063], Loss: 0.0014\n",
      "Epoch [5/10], Step [692/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [693/1063], Loss: 0.0008\n",
      "Epoch [5/10], Step [694/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [695/1063], Loss: 0.0012\n",
      "Epoch [5/10], Step [696/1063], Loss: 0.0088\n",
      "Epoch [5/10], Step [697/1063], Loss: 0.1557\n",
      "Epoch [5/10], Step [698/1063], Loss: 0.0054\n",
      "Epoch [5/10], Step [699/1063], Loss: 0.0393\n",
      "Epoch [5/10], Step [700/1063], Loss: 0.0214\n",
      "Epoch [5/10], Step [701/1063], Loss: 0.0060\n",
      "Epoch [5/10], Step [702/1063], Loss: 0.0039\n",
      "Epoch [5/10], Step [703/1063], Loss: 0.0024\n",
      "Epoch [5/10], Step [704/1063], Loss: 0.0067\n",
      "Epoch [5/10], Step [705/1063], Loss: 0.0132\n",
      "Epoch [5/10], Step [706/1063], Loss: 0.0023\n",
      "Epoch [5/10], Step [707/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [708/1063], Loss: 0.0330\n",
      "Epoch [5/10], Step [709/1063], Loss: 0.0034\n",
      "Epoch [5/10], Step [710/1063], Loss: 0.0116\n",
      "Epoch [5/10], Step [711/1063], Loss: 0.0101\n",
      "Epoch [5/10], Step [712/1063], Loss: 0.0483\n",
      "Epoch [5/10], Step [713/1063], Loss: 0.0125\n",
      "Epoch [5/10], Step [714/1063], Loss: 0.0169\n",
      "Epoch [5/10], Step [715/1063], Loss: 0.0158\n",
      "Epoch [5/10], Step [716/1063], Loss: 0.0479\n",
      "Epoch [5/10], Step [717/1063], Loss: 0.0209\n",
      "Epoch [5/10], Step [718/1063], Loss: 0.0050\n",
      "Epoch [5/10], Step [719/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [720/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [721/1063], Loss: 0.0271\n",
      "Epoch [5/10], Step [722/1063], Loss: 0.0030\n",
      "Epoch [5/10], Step [723/1063], Loss: 0.0044\n",
      "Epoch [5/10], Step [724/1063], Loss: 0.0072\n",
      "Epoch [5/10], Step [725/1063], Loss: 0.0127\n",
      "Epoch [5/10], Step [726/1063], Loss: 0.0007\n",
      "Epoch [5/10], Step [727/1063], Loss: 0.0040\n",
      "Epoch [5/10], Step [728/1063], Loss: 0.0149\n",
      "Epoch [5/10], Step [729/1063], Loss: 0.0017\n",
      "Epoch [5/10], Step [730/1063], Loss: 0.0048\n",
      "Epoch [5/10], Step [731/1063], Loss: 0.0022\n",
      "Epoch [5/10], Step [732/1063], Loss: 0.0041\n",
      "Epoch [5/10], Step [733/1063], Loss: 0.0450\n",
      "Epoch [5/10], Step [734/1063], Loss: 0.0021\n",
      "Epoch [5/10], Step [735/1063], Loss: 0.0380\n",
      "Epoch [5/10], Step [736/1063], Loss: 0.0028\n",
      "Epoch [5/10], Step [737/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [738/1063], Loss: 0.0786\n",
      "Epoch [5/10], Step [739/1063], Loss: 0.0268\n",
      "Epoch [5/10], Step [740/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [741/1063], Loss: 0.1857\n",
      "Epoch [5/10], Step [742/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [743/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [744/1063], Loss: 0.0215\n",
      "Epoch [5/10], Step [745/1063], Loss: 0.0317\n",
      "Epoch [5/10], Step [746/1063], Loss: 0.0012\n",
      "Epoch [5/10], Step [747/1063], Loss: 0.0111\n",
      "Epoch [5/10], Step [748/1063], Loss: 0.0414\n",
      "Epoch [5/10], Step [749/1063], Loss: 0.0169\n",
      "Epoch [5/10], Step [750/1063], Loss: 0.0041\n",
      "Epoch [5/10], Step [751/1063], Loss: 0.0318\n",
      "Epoch [5/10], Step [752/1063], Loss: 0.0173\n",
      "Epoch [5/10], Step [753/1063], Loss: 0.0046\n",
      "Epoch [5/10], Step [754/1063], Loss: 0.0041\n",
      "Epoch [5/10], Step [755/1063], Loss: 0.0277\n",
      "Epoch [5/10], Step [756/1063], Loss: 0.0014\n",
      "Epoch [5/10], Step [757/1063], Loss: 0.0029\n",
      "Epoch [5/10], Step [758/1063], Loss: 0.1346\n",
      "Epoch [5/10], Step [759/1063], Loss: 0.0008\n",
      "Epoch [5/10], Step [760/1063], Loss: 0.0003\n",
      "Epoch [5/10], Step [761/1063], Loss: 0.0091\n",
      "Epoch [5/10], Step [762/1063], Loss: 0.0297\n",
      "Epoch [5/10], Step [763/1063], Loss: 0.0173\n",
      "Epoch [5/10], Step [764/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [765/1063], Loss: 0.0414\n",
      "Epoch [5/10], Step [766/1063], Loss: 0.0146\n",
      "Epoch [5/10], Step [767/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [768/1063], Loss: 0.0213\n",
      "Epoch [5/10], Step [769/1063], Loss: 0.0003\n",
      "Epoch [5/10], Step [770/1063], Loss: 0.0035\n",
      "Epoch [5/10], Step [771/1063], Loss: 0.0172\n",
      "Epoch [5/10], Step [772/1063], Loss: 0.0056\n",
      "Epoch [5/10], Step [773/1063], Loss: 0.0189\n",
      "Epoch [5/10], Step [774/1063], Loss: 0.0180\n",
      "Epoch [5/10], Step [775/1063], Loss: 0.0995\n",
      "Epoch [5/10], Step [776/1063], Loss: 0.0021\n",
      "Epoch [5/10], Step [777/1063], Loss: 0.0031\n",
      "Epoch [5/10], Step [778/1063], Loss: 0.0013\n",
      "Epoch [5/10], Step [779/1063], Loss: 0.0183\n",
      "Epoch [5/10], Step [780/1063], Loss: 0.0721\n",
      "Epoch [5/10], Step [781/1063], Loss: 0.0532\n",
      "Epoch [5/10], Step [782/1063], Loss: 0.0003\n",
      "Epoch [5/10], Step [783/1063], Loss: 0.0495\n",
      "Epoch [5/10], Step [784/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [785/1063], Loss: 0.0671\n",
      "Epoch [5/10], Step [786/1063], Loss: 0.0525\n",
      "Epoch [5/10], Step [787/1063], Loss: 0.0102\n",
      "Epoch [5/10], Step [788/1063], Loss: 0.0036\n",
      "Epoch [5/10], Step [789/1063], Loss: 0.0003\n",
      "Epoch [5/10], Step [790/1063], Loss: 0.0105\n",
      "Epoch [5/10], Step [791/1063], Loss: 0.0215\n",
      "Epoch [5/10], Step [792/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [793/1063], Loss: 0.0124\n",
      "Epoch [5/10], Step [794/1063], Loss: 0.0092\n",
      "Epoch [5/10], Step [795/1063], Loss: 0.0126\n",
      "Epoch [5/10], Step [796/1063], Loss: 0.0101\n",
      "Epoch [5/10], Step [797/1063], Loss: 0.0086\n",
      "Epoch [5/10], Step [798/1063], Loss: 0.0262\n",
      "Epoch [5/10], Step [799/1063], Loss: 0.0027\n",
      "Epoch [5/10], Step [800/1063], Loss: 0.0171\n",
      "Epoch [5/10], Step [801/1063], Loss: 0.0046\n",
      "Epoch [5/10], Step [802/1063], Loss: 0.0049\n",
      "Epoch [5/10], Step [803/1063], Loss: 0.0139\n",
      "Epoch [5/10], Step [804/1063], Loss: 0.0305\n",
      "Epoch [5/10], Step [805/1063], Loss: 0.1373\n",
      "Epoch [5/10], Step [806/1063], Loss: 0.0072\n",
      "Epoch [5/10], Step [807/1063], Loss: 0.0021\n",
      "Epoch [5/10], Step [808/1063], Loss: 0.0099\n",
      "Epoch [5/10], Step [809/1063], Loss: 0.0019\n",
      "Epoch [5/10], Step [810/1063], Loss: 0.0035\n",
      "Epoch [5/10], Step [811/1063], Loss: 0.0379\n",
      "Epoch [5/10], Step [812/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [813/1063], Loss: 0.0095\n",
      "Epoch [5/10], Step [814/1063], Loss: 0.0026\n",
      "Epoch [5/10], Step [815/1063], Loss: 0.0008\n",
      "Epoch [5/10], Step [816/1063], Loss: 0.0048\n",
      "Epoch [5/10], Step [817/1063], Loss: 0.0538\n",
      "Epoch [5/10], Step [818/1063], Loss: 0.0672\n",
      "Epoch [5/10], Step [819/1063], Loss: 0.0022\n",
      "Epoch [5/10], Step [820/1063], Loss: 0.0039\n",
      "Epoch [5/10], Step [821/1063], Loss: 0.0159\n",
      "Epoch [5/10], Step [822/1063], Loss: 0.0564\n",
      "Epoch [5/10], Step [823/1063], Loss: 0.0292\n",
      "Epoch [5/10], Step [824/1063], Loss: 0.0561\n",
      "Epoch [5/10], Step [825/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [826/1063], Loss: 0.0409\n",
      "Epoch [5/10], Step [827/1063], Loss: 0.0197\n",
      "Epoch [5/10], Step [828/1063], Loss: 0.0067\n",
      "Epoch [5/10], Step [829/1063], Loss: 0.0946\n",
      "Epoch [5/10], Step [830/1063], Loss: 0.0070\n",
      "Epoch [5/10], Step [831/1063], Loss: 0.0224\n",
      "Epoch [5/10], Step [832/1063], Loss: 0.0127\n",
      "Epoch [5/10], Step [833/1063], Loss: 0.0744\n",
      "Epoch [5/10], Step [834/1063], Loss: 0.0422\n",
      "Epoch [5/10], Step [835/1063], Loss: 0.0064\n",
      "Epoch [5/10], Step [836/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [837/1063], Loss: 0.0293\n",
      "Epoch [5/10], Step [838/1063], Loss: 0.0247\n",
      "Epoch [5/10], Step [839/1063], Loss: 0.0035\n",
      "Epoch [5/10], Step [840/1063], Loss: 0.0069\n",
      "Epoch [5/10], Step [841/1063], Loss: 0.0249\n",
      "Epoch [5/10], Step [842/1063], Loss: 0.0344\n",
      "Epoch [5/10], Step [843/1063], Loss: 0.0336\n",
      "Epoch [5/10], Step [844/1063], Loss: 0.0966\n",
      "Epoch [5/10], Step [845/1063], Loss: 0.0055\n",
      "Epoch [5/10], Step [846/1063], Loss: 0.0026\n",
      "Epoch [5/10], Step [847/1063], Loss: 0.1302\n",
      "Epoch [5/10], Step [848/1063], Loss: 0.0485\n",
      "Epoch [5/10], Step [849/1063], Loss: 0.0112\n",
      "Epoch [5/10], Step [850/1063], Loss: 0.0061\n",
      "Epoch [5/10], Step [851/1063], Loss: 0.0153\n",
      "Epoch [5/10], Step [852/1063], Loss: 0.0025\n",
      "Epoch [5/10], Step [853/1063], Loss: 0.0755\n",
      "Epoch [5/10], Step [854/1063], Loss: 0.0051\n",
      "Epoch [5/10], Step [855/1063], Loss: 0.0136\n",
      "Epoch [5/10], Step [856/1063], Loss: 0.0084\n",
      "Epoch [5/10], Step [857/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [858/1063], Loss: 0.0372\n",
      "Epoch [5/10], Step [859/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [860/1063], Loss: 0.0046\n",
      "Epoch [5/10], Step [861/1063], Loss: 0.0085\n",
      "Epoch [5/10], Step [862/1063], Loss: 0.0094\n",
      "Epoch [5/10], Step [863/1063], Loss: 0.0612\n",
      "Epoch [5/10], Step [864/1063], Loss: 0.0035\n",
      "Epoch [5/10], Step [865/1063], Loss: 0.0404\n",
      "Epoch [5/10], Step [866/1063], Loss: 0.0079\n",
      "Epoch [5/10], Step [867/1063], Loss: 0.0035\n",
      "Epoch [5/10], Step [868/1063], Loss: 0.0014\n",
      "Epoch [5/10], Step [869/1063], Loss: 0.0284\n",
      "Epoch [5/10], Step [870/1063], Loss: 0.0105\n",
      "Epoch [5/10], Step [871/1063], Loss: 0.0036\n",
      "Epoch [5/10], Step [872/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [873/1063], Loss: 0.0472\n",
      "Epoch [5/10], Step [874/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [875/1063], Loss: 0.0143\n",
      "Epoch [5/10], Step [876/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [877/1063], Loss: 0.0025\n",
      "Epoch [5/10], Step [878/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [879/1063], Loss: 0.0208\n",
      "Epoch [5/10], Step [880/1063], Loss: 0.0028\n",
      "Epoch [5/10], Step [881/1063], Loss: 0.0090\n",
      "Epoch [5/10], Step [882/1063], Loss: 0.0199\n",
      "Epoch [5/10], Step [883/1063], Loss: 0.0139\n",
      "Epoch [5/10], Step [884/1063], Loss: 0.0048\n",
      "Epoch [5/10], Step [885/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [886/1063], Loss: 0.0041\n",
      "Epoch [5/10], Step [887/1063], Loss: 0.0027\n",
      "Epoch [5/10], Step [888/1063], Loss: 0.0021\n",
      "Epoch [5/10], Step [889/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [890/1063], Loss: 0.0030\n",
      "Epoch [5/10], Step [891/1063], Loss: 0.0243\n",
      "Epoch [5/10], Step [892/1063], Loss: 0.0546\n",
      "Epoch [5/10], Step [893/1063], Loss: 0.0138\n",
      "Epoch [5/10], Step [894/1063], Loss: 0.0256\n",
      "Epoch [5/10], Step [895/1063], Loss: 0.0268\n",
      "Epoch [5/10], Step [896/1063], Loss: 0.0259\n",
      "Epoch [5/10], Step [897/1063], Loss: 0.0047\n",
      "Epoch [5/10], Step [898/1063], Loss: 0.0692\n",
      "Epoch [5/10], Step [899/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [900/1063], Loss: 0.0778\n",
      "Epoch [5/10], Step [901/1063], Loss: 0.1251\n",
      "Epoch [5/10], Step [902/1063], Loss: 0.0946\n",
      "Epoch [5/10], Step [903/1063], Loss: 0.0219\n",
      "Epoch [5/10], Step [904/1063], Loss: 0.0284\n",
      "Epoch [5/10], Step [905/1063], Loss: 0.0361\n",
      "Epoch [5/10], Step [906/1063], Loss: 0.0013\n",
      "Epoch [5/10], Step [907/1063], Loss: 0.0108\n",
      "Epoch [5/10], Step [908/1063], Loss: 0.0454\n",
      "Epoch [5/10], Step [909/1063], Loss: 0.0090\n",
      "Epoch [5/10], Step [910/1063], Loss: 0.0026\n",
      "Epoch [5/10], Step [911/1063], Loss: 0.0105\n",
      "Epoch [5/10], Step [912/1063], Loss: 0.0103\n",
      "Epoch [5/10], Step [913/1063], Loss: 0.0219\n",
      "Epoch [5/10], Step [914/1063], Loss: 0.0007\n",
      "Epoch [5/10], Step [915/1063], Loss: 0.0033\n",
      "Epoch [5/10], Step [916/1063], Loss: 0.0767\n",
      "Epoch [5/10], Step [917/1063], Loss: 0.0100\n",
      "Epoch [5/10], Step [918/1063], Loss: 0.0451\n",
      "Epoch [5/10], Step [919/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [920/1063], Loss: 0.1023\n",
      "Epoch [5/10], Step [921/1063], Loss: 0.0647\n",
      "Epoch [5/10], Step [922/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [923/1063], Loss: 0.0498\n",
      "Epoch [5/10], Step [924/1063], Loss: 0.0580\n",
      "Epoch [5/10], Step [925/1063], Loss: 0.0129\n",
      "Epoch [5/10], Step [926/1063], Loss: 0.0039\n",
      "Epoch [5/10], Step [927/1063], Loss: 0.0021\n",
      "Epoch [5/10], Step [928/1063], Loss: 0.0095\n",
      "Epoch [5/10], Step [929/1063], Loss: 0.0503\n",
      "Epoch [5/10], Step [930/1063], Loss: 0.0594\n",
      "Epoch [5/10], Step [931/1063], Loss: 0.0463\n",
      "Epoch [5/10], Step [932/1063], Loss: 0.0198\n",
      "Epoch [5/10], Step [933/1063], Loss: 0.0060\n",
      "Epoch [5/10], Step [934/1063], Loss: 0.0511\n",
      "Epoch [5/10], Step [935/1063], Loss: 0.0031\n",
      "Epoch [5/10], Step [936/1063], Loss: 0.0131\n",
      "Epoch [5/10], Step [937/1063], Loss: 0.0056\n",
      "Epoch [5/10], Step [938/1063], Loss: 0.0614\n",
      "Epoch [5/10], Step [939/1063], Loss: 0.0183\n",
      "Epoch [5/10], Step [940/1063], Loss: 0.0592\n",
      "Epoch [5/10], Step [941/1063], Loss: 0.0037\n",
      "Epoch [5/10], Step [942/1063], Loss: 0.0158\n",
      "Epoch [5/10], Step [943/1063], Loss: 0.0086\n",
      "Epoch [5/10], Step [944/1063], Loss: 0.0041\n",
      "Epoch [5/10], Step [945/1063], Loss: 0.0007\n",
      "Epoch [5/10], Step [946/1063], Loss: 0.0007\n",
      "Epoch [5/10], Step [947/1063], Loss: 0.0311\n",
      "Epoch [5/10], Step [948/1063], Loss: 0.0209\n",
      "Epoch [5/10], Step [949/1063], Loss: 0.0287\n",
      "Epoch [5/10], Step [950/1063], Loss: 0.0159\n",
      "Epoch [5/10], Step [951/1063], Loss: 0.0988\n",
      "Epoch [5/10], Step [952/1063], Loss: 0.0039\n",
      "Epoch [5/10], Step [953/1063], Loss: 0.0237\n",
      "Epoch [5/10], Step [954/1063], Loss: 0.0023\n",
      "Epoch [5/10], Step [955/1063], Loss: 0.0007\n",
      "Epoch [5/10], Step [956/1063], Loss: 0.0124\n",
      "Epoch [5/10], Step [957/1063], Loss: 0.0524\n",
      "Epoch [5/10], Step [958/1063], Loss: 0.0060\n",
      "Epoch [5/10], Step [959/1063], Loss: 0.0061\n",
      "Epoch [5/10], Step [960/1063], Loss: 0.0044\n",
      "Epoch [5/10], Step [961/1063], Loss: 0.0055\n",
      "Epoch [5/10], Step [962/1063], Loss: 0.0381\n",
      "Epoch [5/10], Step [963/1063], Loss: 0.0014\n",
      "Epoch [5/10], Step [964/1063], Loss: 0.0188\n",
      "Epoch [5/10], Step [965/1063], Loss: 0.0485\n",
      "Epoch [5/10], Step [966/1063], Loss: 0.0509\n",
      "Epoch [5/10], Step [967/1063], Loss: 0.0016\n",
      "Epoch [5/10], Step [968/1063], Loss: 0.0054\n",
      "Epoch [5/10], Step [969/1063], Loss: 0.0059\n",
      "Epoch [5/10], Step [970/1063], Loss: 0.0048\n",
      "Epoch [5/10], Step [971/1063], Loss: 0.0041\n",
      "Epoch [5/10], Step [972/1063], Loss: 0.0017\n",
      "Epoch [5/10], Step [973/1063], Loss: 0.0081\n",
      "Epoch [5/10], Step [974/1063], Loss: 0.0069\n",
      "Epoch [5/10], Step [975/1063], Loss: 0.0843\n",
      "Epoch [5/10], Step [976/1063], Loss: 0.0139\n",
      "Epoch [5/10], Step [977/1063], Loss: 0.0364\n",
      "Epoch [5/10], Step [978/1063], Loss: 0.0462\n",
      "Epoch [5/10], Step [979/1063], Loss: 0.0029\n",
      "Epoch [5/10], Step [980/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [981/1063], Loss: 0.0115\n",
      "Epoch [5/10], Step [982/1063], Loss: 0.0236\n",
      "Epoch [5/10], Step [983/1063], Loss: 0.0053\n",
      "Epoch [5/10], Step [984/1063], Loss: 0.0020\n",
      "Epoch [5/10], Step [985/1063], Loss: 0.0043\n",
      "Epoch [5/10], Step [986/1063], Loss: 0.1095\n",
      "Epoch [5/10], Step [987/1063], Loss: 0.0141\n",
      "Epoch [5/10], Step [988/1063], Loss: 0.0577\n",
      "Epoch [5/10], Step [989/1063], Loss: 0.0023\n",
      "Epoch [5/10], Step [990/1063], Loss: 0.0084\n",
      "Epoch [5/10], Step [991/1063], Loss: 0.0684\n",
      "Epoch [5/10], Step [992/1063], Loss: 0.0020\n",
      "Epoch [5/10], Step [993/1063], Loss: 0.0448\n",
      "Epoch [5/10], Step [994/1063], Loss: 0.0013\n",
      "Epoch [5/10], Step [995/1063], Loss: 0.0360\n",
      "Epoch [5/10], Step [996/1063], Loss: 0.0119\n",
      "Epoch [5/10], Step [997/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [998/1063], Loss: 0.0028\n",
      "Epoch [5/10], Step [999/1063], Loss: 0.0226\n",
      "Epoch [5/10], Step [1000/1063], Loss: 0.0415\n",
      "Epoch [5/10], Step [1001/1063], Loss: 0.0164\n",
      "Epoch [5/10], Step [1002/1063], Loss: 0.0073\n",
      "Epoch [5/10], Step [1003/1063], Loss: 0.0057\n",
      "Epoch [5/10], Step [1004/1063], Loss: 0.0043\n",
      "Epoch [5/10], Step [1005/1063], Loss: 0.0044\n",
      "Epoch [5/10], Step [1006/1063], Loss: 0.0068\n",
      "Epoch [5/10], Step [1007/1063], Loss: 0.0098\n",
      "Epoch [5/10], Step [1008/1063], Loss: 0.0275\n",
      "Epoch [5/10], Step [1009/1063], Loss: 0.0115\n",
      "Epoch [5/10], Step [1010/1063], Loss: 0.0160\n",
      "Epoch [5/10], Step [1011/1063], Loss: 0.0142\n",
      "Epoch [5/10], Step [1012/1063], Loss: 0.0857\n",
      "Epoch [5/10], Step [1013/1063], Loss: 0.0181\n",
      "Epoch [5/10], Step [1014/1063], Loss: 0.0017\n",
      "Epoch [5/10], Step [1015/1063], Loss: 0.0010\n",
      "Epoch [5/10], Step [1016/1063], Loss: 0.0072\n",
      "Epoch [5/10], Step [1017/1063], Loss: 0.0054\n",
      "Epoch [5/10], Step [1018/1063], Loss: 0.0040\n",
      "Epoch [5/10], Step [1019/1063], Loss: 0.0029\n",
      "Epoch [5/10], Step [1020/1063], Loss: 0.0085\n",
      "Epoch [5/10], Step [1021/1063], Loss: 0.0169\n",
      "Epoch [5/10], Step [1022/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [1023/1063], Loss: 0.0259\n",
      "Epoch [5/10], Step [1024/1063], Loss: 0.0272\n",
      "Epoch [5/10], Step [1025/1063], Loss: 0.0685\n",
      "Epoch [5/10], Step [1026/1063], Loss: 0.0032\n",
      "Epoch [5/10], Step [1027/1063], Loss: 0.0227\n",
      "Epoch [5/10], Step [1028/1063], Loss: 0.0063\n",
      "Epoch [5/10], Step [1029/1063], Loss: 0.0255\n",
      "Epoch [5/10], Step [1030/1063], Loss: 0.0020\n",
      "Epoch [5/10], Step [1031/1063], Loss: 0.0215\n",
      "Epoch [5/10], Step [1032/1063], Loss: 0.0084\n",
      "Epoch [5/10], Step [1033/1063], Loss: 0.0195\n",
      "Epoch [5/10], Step [1034/1063], Loss: 0.0053\n",
      "Epoch [5/10], Step [1035/1063], Loss: 0.0030\n",
      "Epoch [5/10], Step [1036/1063], Loss: 0.0004\n",
      "Epoch [5/10], Step [1037/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [1038/1063], Loss: 0.0018\n",
      "Epoch [5/10], Step [1039/1063], Loss: 0.0104\n",
      "Epoch [5/10], Step [1040/1063], Loss: 0.0003\n",
      "Epoch [5/10], Step [1041/1063], Loss: 0.0011\n",
      "Epoch [5/10], Step [1042/1063], Loss: 0.0069\n",
      "Epoch [5/10], Step [1043/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [1044/1063], Loss: 0.0012\n",
      "Epoch [5/10], Step [1045/1063], Loss: 0.0065\n",
      "Epoch [5/10], Step [1046/1063], Loss: 0.0112\n",
      "Epoch [5/10], Step [1047/1063], Loss: 0.0025\n",
      "Epoch [5/10], Step [1048/1063], Loss: 0.0002\n",
      "Epoch [5/10], Step [1049/1063], Loss: 0.1286\n",
      "Epoch [5/10], Step [1050/1063], Loss: 0.0015\n",
      "Epoch [5/10], Step [1051/1063], Loss: 0.0021\n",
      "Epoch [5/10], Step [1052/1063], Loss: 0.0094\n",
      "Epoch [5/10], Step [1053/1063], Loss: 0.0009\n",
      "Epoch [5/10], Step [1054/1063], Loss: 0.0082\n",
      "Epoch [5/10], Step [1055/1063], Loss: 0.0436\n",
      "Epoch [5/10], Step [1056/1063], Loss: 0.0030\n",
      "Epoch [5/10], Step [1057/1063], Loss: 0.0203\n",
      "Epoch [5/10], Step [1058/1063], Loss: 0.0179\n",
      "Epoch [5/10], Step [1059/1063], Loss: 0.0006\n",
      "Epoch [5/10], Step [1060/1063], Loss: 0.0212\n",
      "Epoch [5/10], Step [1061/1063], Loss: 0.0174\n",
      "Epoch [5/10], Step [1062/1063], Loss: 0.0196\n",
      "Epoch [5/10], Step [1063/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [1/1063], Loss: 0.0021\n",
      "Epoch [6/10], Step [2/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [3/1063], Loss: 0.0435\n",
      "Epoch [6/10], Step [4/1063], Loss: 0.0509\n",
      "Epoch [6/10], Step [5/1063], Loss: 0.0052\n",
      "Epoch [6/10], Step [6/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [7/1063], Loss: 0.0036\n",
      "Epoch [6/10], Step [8/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [9/1063], Loss: 0.0191\n",
      "Epoch [6/10], Step [10/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [11/1063], Loss: 0.0036\n",
      "Epoch [6/10], Step [12/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [13/1063], Loss: 0.0042\n",
      "Epoch [6/10], Step [14/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [15/1063], Loss: 0.0040\n",
      "Epoch [6/10], Step [16/1063], Loss: 0.0043\n",
      "Epoch [6/10], Step [17/1063], Loss: 0.0012\n",
      "Epoch [6/10], Step [18/1063], Loss: 0.0025\n",
      "Epoch [6/10], Step [19/1063], Loss: 0.0155\n",
      "Epoch [6/10], Step [20/1063], Loss: 0.0020\n",
      "Epoch [6/10], Step [21/1063], Loss: 0.0057\n",
      "Epoch [6/10], Step [22/1063], Loss: 0.0117\n",
      "Epoch [6/10], Step [23/1063], Loss: 0.0060\n",
      "Epoch [6/10], Step [24/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [25/1063], Loss: 0.0065\n",
      "Epoch [6/10], Step [26/1063], Loss: 0.0235\n",
      "Epoch [6/10], Step [27/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [28/1063], Loss: 0.0979\n",
      "Epoch [6/10], Step [29/1063], Loss: 0.0030\n",
      "Epoch [6/10], Step [30/1063], Loss: 0.0101\n",
      "Epoch [6/10], Step [31/1063], Loss: 0.0460\n",
      "Epoch [6/10], Step [32/1063], Loss: 0.0076\n",
      "Epoch [6/10], Step [33/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [34/1063], Loss: 0.0045\n",
      "Epoch [6/10], Step [35/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [36/1063], Loss: 0.0234\n",
      "Epoch [6/10], Step [37/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [38/1063], Loss: 0.0070\n",
      "Epoch [6/10], Step [39/1063], Loss: 0.0193\n",
      "Epoch [6/10], Step [40/1063], Loss: 0.0114\n",
      "Epoch [6/10], Step [41/1063], Loss: 0.0273\n",
      "Epoch [6/10], Step [42/1063], Loss: 0.0272\n",
      "Epoch [6/10], Step [43/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [44/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [45/1063], Loss: 0.0035\n",
      "Epoch [6/10], Step [46/1063], Loss: 0.0056\n",
      "Epoch [6/10], Step [47/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [48/1063], Loss: 0.0132\n",
      "Epoch [6/10], Step [49/1063], Loss: 0.0051\n",
      "Epoch [6/10], Step [50/1063], Loss: 0.0170\n",
      "Epoch [6/10], Step [51/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [52/1063], Loss: 0.0062\n",
      "Epoch [6/10], Step [53/1063], Loss: 0.0084\n",
      "Epoch [6/10], Step [54/1063], Loss: 0.0018\n",
      "Epoch [6/10], Step [55/1063], Loss: 0.0059\n",
      "Epoch [6/10], Step [56/1063], Loss: 0.0118\n",
      "Epoch [6/10], Step [57/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [58/1063], Loss: 0.0182\n",
      "Epoch [6/10], Step [59/1063], Loss: 0.0026\n",
      "Epoch [6/10], Step [60/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [61/1063], Loss: 0.0175\n",
      "Epoch [6/10], Step [62/1063], Loss: 0.0723\n",
      "Epoch [6/10], Step [63/1063], Loss: 0.0020\n",
      "Epoch [6/10], Step [64/1063], Loss: 0.0157\n",
      "Epoch [6/10], Step [65/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [66/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [67/1063], Loss: 0.0030\n",
      "Epoch [6/10], Step [68/1063], Loss: 0.0036\n",
      "Epoch [6/10], Step [69/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [70/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [71/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [72/1063], Loss: 0.0130\n",
      "Epoch [6/10], Step [73/1063], Loss: 0.0020\n",
      "Epoch [6/10], Step [74/1063], Loss: 0.0126\n",
      "Epoch [6/10], Step [75/1063], Loss: 0.0016\n",
      "Epoch [6/10], Step [76/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [77/1063], Loss: 0.0480\n",
      "Epoch [6/10], Step [78/1063], Loss: 0.0203\n",
      "Epoch [6/10], Step [79/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [80/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [81/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [82/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [83/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [84/1063], Loss: 0.0024\n",
      "Epoch [6/10], Step [85/1063], Loss: 0.0069\n",
      "Epoch [6/10], Step [86/1063], Loss: 0.0065\n",
      "Epoch [6/10], Step [87/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [88/1063], Loss: 0.0153\n",
      "Epoch [6/10], Step [89/1063], Loss: 0.0064\n",
      "Epoch [6/10], Step [90/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [91/1063], Loss: 0.0028\n",
      "Epoch [6/10], Step [92/1063], Loss: 0.0768\n",
      "Epoch [6/10], Step [93/1063], Loss: 0.0156\n",
      "Epoch [6/10], Step [94/1063], Loss: 0.0044\n",
      "Epoch [6/10], Step [95/1063], Loss: 0.0020\n",
      "Epoch [6/10], Step [96/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [97/1063], Loss: 0.0024\n",
      "Epoch [6/10], Step [98/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [99/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [100/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [101/1063], Loss: 0.0012\n",
      "Epoch [6/10], Step [102/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [103/1063], Loss: 0.0562\n",
      "Epoch [6/10], Step [104/1063], Loss: 0.0203\n",
      "Epoch [6/10], Step [105/1063], Loss: 0.0058\n",
      "Epoch [6/10], Step [106/1063], Loss: 0.0432\n",
      "Epoch [6/10], Step [107/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [108/1063], Loss: 0.0182\n",
      "Epoch [6/10], Step [109/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [110/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [111/1063], Loss: 0.0050\n",
      "Epoch [6/10], Step [112/1063], Loss: 0.0572\n",
      "Epoch [6/10], Step [113/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [114/1063], Loss: 0.0016\n",
      "Epoch [6/10], Step [115/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [116/1063], Loss: 0.0208\n",
      "Epoch [6/10], Step [117/1063], Loss: 0.0019\n",
      "Epoch [6/10], Step [118/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [119/1063], Loss: 0.0074\n",
      "Epoch [6/10], Step [120/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [121/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [122/1063], Loss: 0.0029\n",
      "Epoch [6/10], Step [123/1063], Loss: 0.0024\n",
      "Epoch [6/10], Step [124/1063], Loss: 0.0027\n",
      "Epoch [6/10], Step [125/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [126/1063], Loss: 0.0214\n",
      "Epoch [6/10], Step [127/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [128/1063], Loss: 0.0024\n",
      "Epoch [6/10], Step [129/1063], Loss: 0.0346\n",
      "Epoch [6/10], Step [130/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [131/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [132/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [133/1063], Loss: 0.0098\n",
      "Epoch [6/10], Step [134/1063], Loss: 0.0833\n",
      "Epoch [6/10], Step [135/1063], Loss: 0.0038\n",
      "Epoch [6/10], Step [136/1063], Loss: 0.0424\n",
      "Epoch [6/10], Step [137/1063], Loss: 0.0024\n",
      "Epoch [6/10], Step [138/1063], Loss: 0.0110\n",
      "Epoch [6/10], Step [139/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [140/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [141/1063], Loss: 0.0237\n",
      "Epoch [6/10], Step [142/1063], Loss: 0.0283\n",
      "Epoch [6/10], Step [143/1063], Loss: 0.0020\n",
      "Epoch [6/10], Step [144/1063], Loss: 0.0027\n",
      "Epoch [6/10], Step [145/1063], Loss: 0.0327\n",
      "Epoch [6/10], Step [146/1063], Loss: 0.0033\n",
      "Epoch [6/10], Step [147/1063], Loss: 0.0455\n",
      "Epoch [6/10], Step [148/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [149/1063], Loss: 0.0097\n",
      "Epoch [6/10], Step [150/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [151/1063], Loss: 0.0093\n",
      "Epoch [6/10], Step [152/1063], Loss: 0.0438\n",
      "Epoch [6/10], Step [153/1063], Loss: 0.0210\n",
      "Epoch [6/10], Step [154/1063], Loss: 0.0152\n",
      "Epoch [6/10], Step [155/1063], Loss: 0.0182\n",
      "Epoch [6/10], Step [156/1063], Loss: 0.0139\n",
      "Epoch [6/10], Step [157/1063], Loss: 0.0114\n",
      "Epoch [6/10], Step [158/1063], Loss: 0.0025\n",
      "Epoch [6/10], Step [159/1063], Loss: 0.0077\n",
      "Epoch [6/10], Step [160/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [161/1063], Loss: 0.0036\n",
      "Epoch [6/10], Step [162/1063], Loss: 0.0031\n",
      "Epoch [6/10], Step [163/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [164/1063], Loss: 0.1847\n",
      "Epoch [6/10], Step [165/1063], Loss: 0.0175\n",
      "Epoch [6/10], Step [166/1063], Loss: 0.0048\n",
      "Epoch [6/10], Step [167/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [168/1063], Loss: 0.0162\n",
      "Epoch [6/10], Step [169/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [170/1063], Loss: 0.0282\n",
      "Epoch [6/10], Step [171/1063], Loss: 0.0318\n",
      "Epoch [6/10], Step [172/1063], Loss: 0.0148\n",
      "Epoch [6/10], Step [173/1063], Loss: 0.0062\n",
      "Epoch [6/10], Step [174/1063], Loss: 0.0360\n",
      "Epoch [6/10], Step [175/1063], Loss: 0.0075\n",
      "Epoch [6/10], Step [176/1063], Loss: 0.0544\n",
      "Epoch [6/10], Step [177/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [178/1063], Loss: 0.0141\n",
      "Epoch [6/10], Step [179/1063], Loss: 0.0033\n",
      "Epoch [6/10], Step [180/1063], Loss: 0.0121\n",
      "Epoch [6/10], Step [181/1063], Loss: 0.0046\n",
      "Epoch [6/10], Step [182/1063], Loss: 0.0048\n",
      "Epoch [6/10], Step [183/1063], Loss: 0.0438\n",
      "Epoch [6/10], Step [184/1063], Loss: 0.0136\n",
      "Epoch [6/10], Step [185/1063], Loss: 0.0399\n",
      "Epoch [6/10], Step [186/1063], Loss: 0.0119\n",
      "Epoch [6/10], Step [187/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [188/1063], Loss: 0.0082\n",
      "Epoch [6/10], Step [189/1063], Loss: 0.0368\n",
      "Epoch [6/10], Step [190/1063], Loss: 0.0032\n",
      "Epoch [6/10], Step [191/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [192/1063], Loss: 0.0411\n",
      "Epoch [6/10], Step [193/1063], Loss: 0.0317\n",
      "Epoch [6/10], Step [194/1063], Loss: 0.0066\n",
      "Epoch [6/10], Step [195/1063], Loss: 0.0040\n",
      "Epoch [6/10], Step [196/1063], Loss: 0.0078\n",
      "Epoch [6/10], Step [197/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [198/1063], Loss: 0.0108\n",
      "Epoch [6/10], Step [199/1063], Loss: 0.0037\n",
      "Epoch [6/10], Step [200/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [201/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [202/1063], Loss: 0.0016\n",
      "Epoch [6/10], Step [203/1063], Loss: 0.0048\n",
      "Epoch [6/10], Step [204/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [205/1063], Loss: 0.0012\n",
      "Epoch [6/10], Step [206/1063], Loss: 0.0054\n",
      "Epoch [6/10], Step [207/1063], Loss: 0.0017\n",
      "Epoch [6/10], Step [208/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [209/1063], Loss: 0.0040\n",
      "Epoch [6/10], Step [210/1063], Loss: 0.0092\n",
      "Epoch [6/10], Step [211/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [212/1063], Loss: 0.0325\n",
      "Epoch [6/10], Step [213/1063], Loss: 0.0089\n",
      "Epoch [6/10], Step [214/1063], Loss: 0.0081\n",
      "Epoch [6/10], Step [215/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [216/1063], Loss: 0.0254\n",
      "Epoch [6/10], Step [217/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [218/1063], Loss: 0.0016\n",
      "Epoch [6/10], Step [219/1063], Loss: 0.0072\n",
      "Epoch [6/10], Step [220/1063], Loss: 0.0119\n",
      "Epoch [6/10], Step [221/1063], Loss: 0.0175\n",
      "Epoch [6/10], Step [222/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [223/1063], Loss: 0.0350\n",
      "Epoch [6/10], Step [224/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [225/1063], Loss: 0.0132\n",
      "Epoch [6/10], Step [226/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [227/1063], Loss: 0.0045\n",
      "Epoch [6/10], Step [228/1063], Loss: 0.0033\n",
      "Epoch [6/10], Step [229/1063], Loss: 0.0077\n",
      "Epoch [6/10], Step [230/1063], Loss: 0.0052\n",
      "Epoch [6/10], Step [231/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [232/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [233/1063], Loss: 0.0018\n",
      "Epoch [6/10], Step [234/1063], Loss: 0.0112\n",
      "Epoch [6/10], Step [235/1063], Loss: 0.0045\n",
      "Epoch [6/10], Step [236/1063], Loss: 0.0057\n",
      "Epoch [6/10], Step [237/1063], Loss: 0.0044\n",
      "Epoch [6/10], Step [238/1063], Loss: 0.0176\n",
      "Epoch [6/10], Step [239/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [240/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [241/1063], Loss: 0.0037\n",
      "Epoch [6/10], Step [242/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [243/1063], Loss: 0.0039\n",
      "Epoch [6/10], Step [244/1063], Loss: 0.0043\n",
      "Epoch [6/10], Step [245/1063], Loss: 0.0106\n",
      "Epoch [6/10], Step [246/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [247/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [248/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [249/1063], Loss: 0.0041\n",
      "Epoch [6/10], Step [250/1063], Loss: 0.0161\n",
      "Epoch [6/10], Step [251/1063], Loss: 0.0036\n",
      "Epoch [6/10], Step [252/1063], Loss: 0.0060\n",
      "Epoch [6/10], Step [253/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [254/1063], Loss: 0.0062\n",
      "Epoch [6/10], Step [255/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [256/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [257/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [258/1063], Loss: 0.0136\n",
      "Epoch [6/10], Step [259/1063], Loss: 0.0026\n",
      "Epoch [6/10], Step [260/1063], Loss: 0.0642\n",
      "Epoch [6/10], Step [261/1063], Loss: 0.0612\n",
      "Epoch [6/10], Step [262/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [263/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [264/1063], Loss: 0.0158\n",
      "Epoch [6/10], Step [265/1063], Loss: 0.0044\n",
      "Epoch [6/10], Step [266/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [267/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [268/1063], Loss: 0.0055\n",
      "Epoch [6/10], Step [269/1063], Loss: 0.0037\n",
      "Epoch [6/10], Step [270/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [271/1063], Loss: 0.0087\n",
      "Epoch [6/10], Step [272/1063], Loss: 0.0096\n",
      "Epoch [6/10], Step [273/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [274/1063], Loss: 0.0018\n",
      "Epoch [6/10], Step [275/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [276/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [277/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [278/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [279/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [280/1063], Loss: 0.0262\n",
      "Epoch [6/10], Step [281/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [282/1063], Loss: 0.0105\n",
      "Epoch [6/10], Step [283/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [284/1063], Loss: 0.0106\n",
      "Epoch [6/10], Step [285/1063], Loss: 0.0862\n",
      "Epoch [6/10], Step [286/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [287/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [288/1063], Loss: 0.0146\n",
      "Epoch [6/10], Step [289/1063], Loss: 0.1859\n",
      "Epoch [6/10], Step [290/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [291/1063], Loss: 0.0170\n",
      "Epoch [6/10], Step [292/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [293/1063], Loss: 0.0190\n",
      "Epoch [6/10], Step [294/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [295/1063], Loss: 0.1162\n",
      "Epoch [6/10], Step [296/1063], Loss: 0.0059\n",
      "Epoch [6/10], Step [297/1063], Loss: 0.0128\n",
      "Epoch [6/10], Step [298/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [299/1063], Loss: 0.0260\n",
      "Epoch [6/10], Step [300/1063], Loss: 0.0142\n",
      "Epoch [6/10], Step [301/1063], Loss: 0.0027\n",
      "Epoch [6/10], Step [302/1063], Loss: 0.0298\n",
      "Epoch [6/10], Step [303/1063], Loss: 0.0040\n",
      "Epoch [6/10], Step [304/1063], Loss: 0.0038\n",
      "Epoch [6/10], Step [305/1063], Loss: 0.0074\n",
      "Epoch [6/10], Step [306/1063], Loss: 0.0838\n",
      "Epoch [6/10], Step [307/1063], Loss: 0.0096\n",
      "Epoch [6/10], Step [308/1063], Loss: 0.0204\n",
      "Epoch [6/10], Step [309/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [310/1063], Loss: 0.0012\n",
      "Epoch [6/10], Step [311/1063], Loss: 0.0016\n",
      "Epoch [6/10], Step [312/1063], Loss: 0.0071\n",
      "Epoch [6/10], Step [313/1063], Loss: 0.0042\n",
      "Epoch [6/10], Step [314/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [315/1063], Loss: 0.0039\n",
      "Epoch [6/10], Step [316/1063], Loss: 0.0780\n",
      "Epoch [6/10], Step [317/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [318/1063], Loss: 0.0227\n",
      "Epoch [6/10], Step [319/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [320/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [321/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [322/1063], Loss: 0.0077\n",
      "Epoch [6/10], Step [323/1063], Loss: 0.0109\n",
      "Epoch [6/10], Step [324/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [325/1063], Loss: 0.0019\n",
      "Epoch [6/10], Step [326/1063], Loss: 0.0025\n",
      "Epoch [6/10], Step [327/1063], Loss: 0.0098\n",
      "Epoch [6/10], Step [328/1063], Loss: 0.0606\n",
      "Epoch [6/10], Step [329/1063], Loss: 0.0028\n",
      "Epoch [6/10], Step [330/1063], Loss: 0.0641\n",
      "Epoch [6/10], Step [331/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [332/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [333/1063], Loss: 0.0064\n",
      "Epoch [6/10], Step [334/1063], Loss: 0.0066\n",
      "Epoch [6/10], Step [335/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [336/1063], Loss: 0.0024\n",
      "Epoch [6/10], Step [337/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [338/1063], Loss: 0.0017\n",
      "Epoch [6/10], Step [339/1063], Loss: 0.0321\n",
      "Epoch [6/10], Step [340/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [341/1063], Loss: 0.0070\n",
      "Epoch [6/10], Step [342/1063], Loss: 0.0079\n",
      "Epoch [6/10], Step [343/1063], Loss: 0.0033\n",
      "Epoch [6/10], Step [344/1063], Loss: 0.0232\n",
      "Epoch [6/10], Step [345/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [346/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [347/1063], Loss: 0.0123\n",
      "Epoch [6/10], Step [348/1063], Loss: 0.0018\n",
      "Epoch [6/10], Step [349/1063], Loss: 0.0031\n",
      "Epoch [6/10], Step [350/1063], Loss: 0.0216\n",
      "Epoch [6/10], Step [351/1063], Loss: 0.0111\n",
      "Epoch [6/10], Step [352/1063], Loss: 0.0935\n",
      "Epoch [6/10], Step [353/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [354/1063], Loss: 0.0044\n",
      "Epoch [6/10], Step [355/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [356/1063], Loss: 0.0032\n",
      "Epoch [6/10], Step [357/1063], Loss: 0.0053\n",
      "Epoch [6/10], Step [358/1063], Loss: 0.0082\n",
      "Epoch [6/10], Step [359/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [360/1063], Loss: 0.0192\n",
      "Epoch [6/10], Step [361/1063], Loss: 0.0119\n",
      "Epoch [6/10], Step [362/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [363/1063], Loss: 0.0019\n",
      "Epoch [6/10], Step [364/1063], Loss: 0.0096\n",
      "Epoch [6/10], Step [365/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [366/1063], Loss: 0.0017\n",
      "Epoch [6/10], Step [367/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [368/1063], Loss: 0.0158\n",
      "Epoch [6/10], Step [369/1063], Loss: 0.0049\n",
      "Epoch [6/10], Step [370/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [371/1063], Loss: 0.0037\n",
      "Epoch [6/10], Step [372/1063], Loss: 0.0019\n",
      "Epoch [6/10], Step [373/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [374/1063], Loss: 0.0100\n",
      "Epoch [6/10], Step [375/1063], Loss: 0.0144\n",
      "Epoch [6/10], Step [376/1063], Loss: 0.0500\n",
      "Epoch [6/10], Step [377/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [378/1063], Loss: 0.0191\n",
      "Epoch [6/10], Step [379/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [380/1063], Loss: 0.0232\n",
      "Epoch [6/10], Step [381/1063], Loss: 0.1384\n",
      "Epoch [6/10], Step [382/1063], Loss: 0.0088\n",
      "Epoch [6/10], Step [383/1063], Loss: 0.0374\n",
      "Epoch [6/10], Step [384/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [385/1063], Loss: 0.0086\n",
      "Epoch [6/10], Step [386/1063], Loss: 0.0021\n",
      "Epoch [6/10], Step [387/1063], Loss: 0.0053\n",
      "Epoch [6/10], Step [388/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [389/1063], Loss: 0.0216\n",
      "Epoch [6/10], Step [390/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [391/1063], Loss: 0.0130\n",
      "Epoch [6/10], Step [392/1063], Loss: 0.0071\n",
      "Epoch [6/10], Step [393/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [394/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [395/1063], Loss: 0.0789\n",
      "Epoch [6/10], Step [396/1063], Loss: 0.0218\n",
      "Epoch [6/10], Step [397/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [398/1063], Loss: 0.0043\n",
      "Epoch [6/10], Step [399/1063], Loss: 0.0149\n",
      "Epoch [6/10], Step [400/1063], Loss: 0.0227\n",
      "Epoch [6/10], Step [401/1063], Loss: 0.0878\n",
      "Epoch [6/10], Step [402/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [403/1063], Loss: 0.0153\n",
      "Epoch [6/10], Step [404/1063], Loss: 0.0372\n",
      "Epoch [6/10], Step [405/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [406/1063], Loss: 0.0195\n",
      "Epoch [6/10], Step [407/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [408/1063], Loss: 0.0103\n",
      "Epoch [6/10], Step [409/1063], Loss: 0.0030\n",
      "Epoch [6/10], Step [410/1063], Loss: 0.0012\n",
      "Epoch [6/10], Step [411/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [412/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [413/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [414/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [415/1063], Loss: 0.0470\n",
      "Epoch [6/10], Step [416/1063], Loss: 0.0212\n",
      "Epoch [6/10], Step [417/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [418/1063], Loss: 0.0037\n",
      "Epoch [6/10], Step [419/1063], Loss: 0.0039\n",
      "Epoch [6/10], Step [420/1063], Loss: 0.0284\n",
      "Epoch [6/10], Step [421/1063], Loss: 0.0340\n",
      "Epoch [6/10], Step [422/1063], Loss: 0.0224\n",
      "Epoch [6/10], Step [423/1063], Loss: 0.0181\n",
      "Epoch [6/10], Step [424/1063], Loss: 0.0016\n",
      "Epoch [6/10], Step [425/1063], Loss: 0.0285\n",
      "Epoch [6/10], Step [426/1063], Loss: 0.0323\n",
      "Epoch [6/10], Step [427/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [428/1063], Loss: 0.0412\n",
      "Epoch [6/10], Step [429/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [430/1063], Loss: 0.0202\n",
      "Epoch [6/10], Step [431/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [432/1063], Loss: 0.0501\n",
      "Epoch [6/10], Step [433/1063], Loss: 0.0422\n",
      "Epoch [6/10], Step [434/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [435/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [436/1063], Loss: 0.0017\n",
      "Epoch [6/10], Step [437/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [438/1063], Loss: 0.0115\n",
      "Epoch [6/10], Step [439/1063], Loss: 0.0063\n",
      "Epoch [6/10], Step [440/1063], Loss: 0.0063\n",
      "Epoch [6/10], Step [441/1063], Loss: 0.0432\n",
      "Epoch [6/10], Step [442/1063], Loss: 0.0030\n",
      "Epoch [6/10], Step [443/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [444/1063], Loss: 0.0038\n",
      "Epoch [6/10], Step [445/1063], Loss: 0.0090\n",
      "Epoch [6/10], Step [446/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [447/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [448/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [449/1063], Loss: 0.0045\n",
      "Epoch [6/10], Step [450/1063], Loss: 0.0440\n",
      "Epoch [6/10], Step [451/1063], Loss: 0.0210\n",
      "Epoch [6/10], Step [452/1063], Loss: 0.0672\n",
      "Epoch [6/10], Step [453/1063], Loss: 0.0118\n",
      "Epoch [6/10], Step [454/1063], Loss: 0.0045\n",
      "Epoch [6/10], Step [455/1063], Loss: 0.0052\n",
      "Epoch [6/10], Step [456/1063], Loss: 0.0365\n",
      "Epoch [6/10], Step [457/1063], Loss: 0.0035\n",
      "Epoch [6/10], Step [458/1063], Loss: 0.0161\n",
      "Epoch [6/10], Step [459/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [460/1063], Loss: 0.0631\n",
      "Epoch [6/10], Step [461/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [462/1063], Loss: 0.0068\n",
      "Epoch [6/10], Step [463/1063], Loss: 0.0232\n",
      "Epoch [6/10], Step [464/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [465/1063], Loss: 0.0041\n",
      "Epoch [6/10], Step [466/1063], Loss: 0.0032\n",
      "Epoch [6/10], Step [467/1063], Loss: 0.0251\n",
      "Epoch [6/10], Step [468/1063], Loss: 0.0242\n",
      "Epoch [6/10], Step [469/1063], Loss: 0.0218\n",
      "Epoch [6/10], Step [470/1063], Loss: 0.0118\n",
      "Epoch [6/10], Step [471/1063], Loss: 0.0076\n",
      "Epoch [6/10], Step [472/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [473/1063], Loss: 0.0341\n",
      "Epoch [6/10], Step [474/1063], Loss: 0.0027\n",
      "Epoch [6/10], Step [475/1063], Loss: 0.0205\n",
      "Epoch [6/10], Step [476/1063], Loss: 0.0266\n",
      "Epoch [6/10], Step [477/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [478/1063], Loss: 0.0144\n",
      "Epoch [6/10], Step [479/1063], Loss: 0.1149\n",
      "Epoch [6/10], Step [480/1063], Loss: 0.0037\n",
      "Epoch [6/10], Step [481/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [482/1063], Loss: 0.0163\n",
      "Epoch [6/10], Step [483/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [484/1063], Loss: 0.0101\n",
      "Epoch [6/10], Step [485/1063], Loss: 0.0072\n",
      "Epoch [6/10], Step [486/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [487/1063], Loss: 0.0021\n",
      "Epoch [6/10], Step [488/1063], Loss: 0.0763\n",
      "Epoch [6/10], Step [489/1063], Loss: 0.0126\n",
      "Epoch [6/10], Step [490/1063], Loss: 0.0075\n",
      "Epoch [6/10], Step [491/1063], Loss: 0.1124\n",
      "Epoch [6/10], Step [492/1063], Loss: 0.0050\n",
      "Epoch [6/10], Step [493/1063], Loss: 0.0032\n",
      "Epoch [6/10], Step [494/1063], Loss: 0.0020\n",
      "Epoch [6/10], Step [495/1063], Loss: 0.0235\n",
      "Epoch [6/10], Step [496/1063], Loss: 0.0020\n",
      "Epoch [6/10], Step [497/1063], Loss: 0.0510\n",
      "Epoch [6/10], Step [498/1063], Loss: 0.0514\n",
      "Epoch [6/10], Step [499/1063], Loss: 0.0059\n",
      "Epoch [6/10], Step [500/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [501/1063], Loss: 0.0826\n",
      "Epoch [6/10], Step [502/1063], Loss: 0.0078\n",
      "Epoch [6/10], Step [503/1063], Loss: 0.0218\n",
      "Epoch [6/10], Step [504/1063], Loss: 0.0055\n",
      "Epoch [6/10], Step [505/1063], Loss: 0.0855\n",
      "Epoch [6/10], Step [506/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [507/1063], Loss: 0.0342\n",
      "Epoch [6/10], Step [508/1063], Loss: 0.0049\n",
      "Epoch [6/10], Step [509/1063], Loss: 0.0133\n",
      "Epoch [6/10], Step [510/1063], Loss: 0.0124\n",
      "Epoch [6/10], Step [511/1063], Loss: 0.0130\n",
      "Epoch [6/10], Step [512/1063], Loss: 0.0240\n",
      "Epoch [6/10], Step [513/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [514/1063], Loss: 0.0049\n",
      "Epoch [6/10], Step [515/1063], Loss: 0.0031\n",
      "Epoch [6/10], Step [516/1063], Loss: 0.0660\n",
      "Epoch [6/10], Step [517/1063], Loss: 0.0683\n",
      "Epoch [6/10], Step [518/1063], Loss: 0.0207\n",
      "Epoch [6/10], Step [519/1063], Loss: 0.0403\n",
      "Epoch [6/10], Step [520/1063], Loss: 0.0143\n",
      "Epoch [6/10], Step [521/1063], Loss: 0.0051\n",
      "Epoch [6/10], Step [522/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [523/1063], Loss: 0.0214\n",
      "Epoch [6/10], Step [524/1063], Loss: 0.0023\n",
      "Epoch [6/10], Step [525/1063], Loss: 0.0016\n",
      "Epoch [6/10], Step [526/1063], Loss: 0.0117\n",
      "Epoch [6/10], Step [527/1063], Loss: 0.0058\n",
      "Epoch [6/10], Step [528/1063], Loss: 0.0018\n",
      "Epoch [6/10], Step [529/1063], Loss: 0.0042\n",
      "Epoch [6/10], Step [530/1063], Loss: 0.0012\n",
      "Epoch [6/10], Step [531/1063], Loss: 0.0145\n",
      "Epoch [6/10], Step [532/1063], Loss: 0.0088\n",
      "Epoch [6/10], Step [533/1063], Loss: 0.0167\n",
      "Epoch [6/10], Step [534/1063], Loss: 0.0338\n",
      "Epoch [6/10], Step [535/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [536/1063], Loss: 0.0188\n",
      "Epoch [6/10], Step [537/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [538/1063], Loss: 0.0070\n",
      "Epoch [6/10], Step [539/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [540/1063], Loss: 0.0155\n",
      "Epoch [6/10], Step [541/1063], Loss: 0.0258\n",
      "Epoch [6/10], Step [542/1063], Loss: 0.0105\n",
      "Epoch [6/10], Step [543/1063], Loss: 0.0128\n",
      "Epoch [6/10], Step [544/1063], Loss: 0.0081\n",
      "Epoch [6/10], Step [545/1063], Loss: 0.0017\n",
      "Epoch [6/10], Step [546/1063], Loss: 0.0071\n",
      "Epoch [6/10], Step [547/1063], Loss: 0.0057\n",
      "Epoch [6/10], Step [548/1063], Loss: 0.0451\n",
      "Epoch [6/10], Step [549/1063], Loss: 0.1186\n",
      "Epoch [6/10], Step [550/1063], Loss: 0.0117\n",
      "Epoch [6/10], Step [551/1063], Loss: 0.0102\n",
      "Epoch [6/10], Step [552/1063], Loss: 0.0360\n",
      "Epoch [6/10], Step [553/1063], Loss: 0.0689\n",
      "Epoch [6/10], Step [554/1063], Loss: 0.0180\n",
      "Epoch [6/10], Step [555/1063], Loss: 0.0273\n",
      "Epoch [6/10], Step [556/1063], Loss: 0.0103\n",
      "Epoch [6/10], Step [557/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [558/1063], Loss: 0.0116\n",
      "Epoch [6/10], Step [559/1063], Loss: 0.0088\n",
      "Epoch [6/10], Step [560/1063], Loss: 0.1256\n",
      "Epoch [6/10], Step [561/1063], Loss: 0.0026\n",
      "Epoch [6/10], Step [562/1063], Loss: 0.0487\n",
      "Epoch [6/10], Step [563/1063], Loss: 0.0135\n",
      "Epoch [6/10], Step [564/1063], Loss: 0.0091\n",
      "Epoch [6/10], Step [565/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [566/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [567/1063], Loss: 0.0024\n",
      "Epoch [6/10], Step [568/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [569/1063], Loss: 0.0553\n",
      "Epoch [6/10], Step [570/1063], Loss: 0.0023\n",
      "Epoch [6/10], Step [571/1063], Loss: 0.0076\n",
      "Epoch [6/10], Step [572/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [573/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [574/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [575/1063], Loss: 0.0036\n",
      "Epoch [6/10], Step [576/1063], Loss: 0.0322\n",
      "Epoch [6/10], Step [577/1063], Loss: 0.0080\n",
      "Epoch [6/10], Step [578/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [579/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [580/1063], Loss: 0.0538\n",
      "Epoch [6/10], Step [581/1063], Loss: 0.0874\n",
      "Epoch [6/10], Step [582/1063], Loss: 0.0049\n",
      "Epoch [6/10], Step [583/1063], Loss: 0.0019\n",
      "Epoch [6/10], Step [584/1063], Loss: 0.0285\n",
      "Epoch [6/10], Step [585/1063], Loss: 0.0024\n",
      "Epoch [6/10], Step [586/1063], Loss: 0.0395\n",
      "Epoch [6/10], Step [587/1063], Loss: 0.0654\n",
      "Epoch [6/10], Step [588/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [589/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [590/1063], Loss: 0.0031\n",
      "Epoch [6/10], Step [591/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [592/1063], Loss: 0.0058\n",
      "Epoch [6/10], Step [593/1063], Loss: 0.0569\n",
      "Epoch [6/10], Step [594/1063], Loss: 0.0020\n",
      "Epoch [6/10], Step [595/1063], Loss: 0.0275\n",
      "Epoch [6/10], Step [596/1063], Loss: 0.0088\n",
      "Epoch [6/10], Step [597/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [598/1063], Loss: 0.0424\n",
      "Epoch [6/10], Step [599/1063], Loss: 0.0393\n",
      "Epoch [6/10], Step [600/1063], Loss: 0.0033\n",
      "Epoch [6/10], Step [601/1063], Loss: 0.0044\n",
      "Epoch [6/10], Step [602/1063], Loss: 0.0029\n",
      "Epoch [6/10], Step [603/1063], Loss: 0.0042\n",
      "Epoch [6/10], Step [604/1063], Loss: 0.0237\n",
      "Epoch [6/10], Step [605/1063], Loss: 0.0054\n",
      "Epoch [6/10], Step [606/1063], Loss: 0.0029\n",
      "Epoch [6/10], Step [607/1063], Loss: 0.0245\n",
      "Epoch [6/10], Step [608/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [609/1063], Loss: 0.0069\n",
      "Epoch [6/10], Step [610/1063], Loss: 0.0135\n",
      "Epoch [6/10], Step [611/1063], Loss: 0.0327\n",
      "Epoch [6/10], Step [612/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [613/1063], Loss: 0.0239\n",
      "Epoch [6/10], Step [614/1063], Loss: 0.0031\n",
      "Epoch [6/10], Step [615/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [616/1063], Loss: 0.0104\n",
      "Epoch [6/10], Step [617/1063], Loss: 0.1413\n",
      "Epoch [6/10], Step [618/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [619/1063], Loss: 0.0332\n",
      "Epoch [6/10], Step [620/1063], Loss: 0.0114\n",
      "Epoch [6/10], Step [621/1063], Loss: 0.0049\n",
      "Epoch [6/10], Step [622/1063], Loss: 0.0241\n",
      "Epoch [6/10], Step [623/1063], Loss: 0.0091\n",
      "Epoch [6/10], Step [624/1063], Loss: 0.0687\n",
      "Epoch [6/10], Step [625/1063], Loss: 0.0297\n",
      "Epoch [6/10], Step [626/1063], Loss: 0.0133\n",
      "Epoch [6/10], Step [627/1063], Loss: 0.0039\n",
      "Epoch [6/10], Step [628/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [629/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [630/1063], Loss: 0.0534\n",
      "Epoch [6/10], Step [631/1063], Loss: 0.0155\n",
      "Epoch [6/10], Step [632/1063], Loss: 0.0091\n",
      "Epoch [6/10], Step [633/1063], Loss: 0.0280\n",
      "Epoch [6/10], Step [634/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [635/1063], Loss: 0.0269\n",
      "Epoch [6/10], Step [636/1063], Loss: 0.0066\n",
      "Epoch [6/10], Step [637/1063], Loss: 0.0351\n",
      "Epoch [6/10], Step [638/1063], Loss: 0.0301\n",
      "Epoch [6/10], Step [639/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [640/1063], Loss: 0.0202\n",
      "Epoch [6/10], Step [641/1063], Loss: 0.0788\n",
      "Epoch [6/10], Step [642/1063], Loss: 0.0018\n",
      "Epoch [6/10], Step [643/1063], Loss: 0.0029\n",
      "Epoch [6/10], Step [644/1063], Loss: 0.0488\n",
      "Epoch [6/10], Step [645/1063], Loss: 0.0130\n",
      "Epoch [6/10], Step [646/1063], Loss: 0.0105\n",
      "Epoch [6/10], Step [647/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [648/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [649/1063], Loss: 0.0026\n",
      "Epoch [6/10], Step [650/1063], Loss: 0.0257\n",
      "Epoch [6/10], Step [651/1063], Loss: 0.0053\n",
      "Epoch [6/10], Step [652/1063], Loss: 0.0382\n",
      "Epoch [6/10], Step [653/1063], Loss: 0.0110\n",
      "Epoch [6/10], Step [654/1063], Loss: 0.0077\n",
      "Epoch [6/10], Step [655/1063], Loss: 0.0382\n",
      "Epoch [6/10], Step [656/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [657/1063], Loss: 0.0098\n",
      "Epoch [6/10], Step [658/1063], Loss: 0.0560\n",
      "Epoch [6/10], Step [659/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [660/1063], Loss: 0.0027\n",
      "Epoch [6/10], Step [661/1063], Loss: 0.0497\n",
      "Epoch [6/10], Step [662/1063], Loss: 0.0084\n",
      "Epoch [6/10], Step [663/1063], Loss: 0.0045\n",
      "Epoch [6/10], Step [664/1063], Loss: 0.0060\n",
      "Epoch [6/10], Step [665/1063], Loss: 0.0282\n",
      "Epoch [6/10], Step [666/1063], Loss: 0.0047\n",
      "Epoch [6/10], Step [667/1063], Loss: 0.0230\n",
      "Epoch [6/10], Step [668/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [669/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [670/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [671/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [672/1063], Loss: 0.0032\n",
      "Epoch [6/10], Step [673/1063], Loss: 0.0059\n",
      "Epoch [6/10], Step [674/1063], Loss: 0.0069\n",
      "Epoch [6/10], Step [675/1063], Loss: 0.0096\n",
      "Epoch [6/10], Step [676/1063], Loss: 0.0104\n",
      "Epoch [6/10], Step [677/1063], Loss: 0.0477\n",
      "Epoch [6/10], Step [678/1063], Loss: 0.1187\n",
      "Epoch [6/10], Step [679/1063], Loss: 0.0020\n",
      "Epoch [6/10], Step [680/1063], Loss: 0.0023\n",
      "Epoch [6/10], Step [681/1063], Loss: 0.0253\n",
      "Epoch [6/10], Step [682/1063], Loss: 0.0031\n",
      "Epoch [6/10], Step [683/1063], Loss: 0.0021\n",
      "Epoch [6/10], Step [684/1063], Loss: 0.0152\n",
      "Epoch [6/10], Step [685/1063], Loss: 0.0144\n",
      "Epoch [6/10], Step [686/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [687/1063], Loss: 0.0119\n",
      "Epoch [6/10], Step [688/1063], Loss: 0.0044\n",
      "Epoch [6/10], Step [689/1063], Loss: 0.0074\n",
      "Epoch [6/10], Step [690/1063], Loss: 0.0017\n",
      "Epoch [6/10], Step [691/1063], Loss: 0.0018\n",
      "Epoch [6/10], Step [692/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [693/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [694/1063], Loss: 0.0111\n",
      "Epoch [6/10], Step [695/1063], Loss: 0.0109\n",
      "Epoch [6/10], Step [696/1063], Loss: 0.0039\n",
      "Epoch [6/10], Step [697/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [698/1063], Loss: 0.0030\n",
      "Epoch [6/10], Step [699/1063], Loss: 0.0259\n",
      "Epoch [6/10], Step [700/1063], Loss: 0.0211\n",
      "Epoch [6/10], Step [701/1063], Loss: 0.0330\n",
      "Epoch [6/10], Step [702/1063], Loss: 0.0027\n",
      "Epoch [6/10], Step [703/1063], Loss: 0.0178\n",
      "Epoch [6/10], Step [704/1063], Loss: 0.0043\n",
      "Epoch [6/10], Step [705/1063], Loss: 0.0090\n",
      "Epoch [6/10], Step [706/1063], Loss: 0.0017\n",
      "Epoch [6/10], Step [707/1063], Loss: 0.0028\n",
      "Epoch [6/10], Step [708/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [709/1063], Loss: 0.1097\n",
      "Epoch [6/10], Step [710/1063], Loss: 0.0054\n",
      "Epoch [6/10], Step [711/1063], Loss: 0.0378\n",
      "Epoch [6/10], Step [712/1063], Loss: 0.0036\n",
      "Epoch [6/10], Step [713/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [714/1063], Loss: 0.0052\n",
      "Epoch [6/10], Step [715/1063], Loss: 0.0204\n",
      "Epoch [6/10], Step [716/1063], Loss: 0.0034\n",
      "Epoch [6/10], Step [717/1063], Loss: 0.0369\n",
      "Epoch [6/10], Step [718/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [719/1063], Loss: 0.0048\n",
      "Epoch [6/10], Step [720/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [721/1063], Loss: 0.0082\n",
      "Epoch [6/10], Step [722/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [723/1063], Loss: 0.0798\n",
      "Epoch [6/10], Step [724/1063], Loss: 0.0541\n",
      "Epoch [6/10], Step [725/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [726/1063], Loss: 0.0528\n",
      "Epoch [6/10], Step [727/1063], Loss: 0.0030\n",
      "Epoch [6/10], Step [728/1063], Loss: 0.0030\n",
      "Epoch [6/10], Step [729/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [730/1063], Loss: 0.0076\n",
      "Epoch [6/10], Step [731/1063], Loss: 0.0151\n",
      "Epoch [6/10], Step [732/1063], Loss: 0.0112\n",
      "Epoch [6/10], Step [733/1063], Loss: 0.0154\n",
      "Epoch [6/10], Step [734/1063], Loss: 0.0508\n",
      "Epoch [6/10], Step [735/1063], Loss: 0.0021\n",
      "Epoch [6/10], Step [736/1063], Loss: 0.0047\n",
      "Epoch [6/10], Step [737/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [738/1063], Loss: 0.0150\n",
      "Epoch [6/10], Step [739/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [740/1063], Loss: 0.0019\n",
      "Epoch [6/10], Step [741/1063], Loss: 0.0120\n",
      "Epoch [6/10], Step [742/1063], Loss: 0.0017\n",
      "Epoch [6/10], Step [743/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [744/1063], Loss: 0.0040\n",
      "Epoch [6/10], Step [745/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [746/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [747/1063], Loss: 0.0066\n",
      "Epoch [6/10], Step [748/1063], Loss: 0.0981\n",
      "Epoch [6/10], Step [749/1063], Loss: 0.0034\n",
      "Epoch [6/10], Step [750/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [751/1063], Loss: 0.0024\n",
      "Epoch [6/10], Step [752/1063], Loss: 0.0189\n",
      "Epoch [6/10], Step [753/1063], Loss: 0.0209\n",
      "Epoch [6/10], Step [754/1063], Loss: 0.0145\n",
      "Epoch [6/10], Step [755/1063], Loss: 0.0016\n",
      "Epoch [6/10], Step [756/1063], Loss: 0.0380\n",
      "Epoch [6/10], Step [757/1063], Loss: 0.0023\n",
      "Epoch [6/10], Step [758/1063], Loss: 0.0030\n",
      "Epoch [6/10], Step [759/1063], Loss: 0.0054\n",
      "Epoch [6/10], Step [760/1063], Loss: 0.0215\n",
      "Epoch [6/10], Step [761/1063], Loss: 0.0019\n",
      "Epoch [6/10], Step [762/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [763/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [764/1063], Loss: 0.0021\n",
      "Epoch [6/10], Step [765/1063], Loss: 0.0062\n",
      "Epoch [6/10], Step [766/1063], Loss: 0.0278\n",
      "Epoch [6/10], Step [767/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [768/1063], Loss: 0.0062\n",
      "Epoch [6/10], Step [769/1063], Loss: 0.0075\n",
      "Epoch [6/10], Step [770/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [771/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [772/1063], Loss: 0.0034\n",
      "Epoch [6/10], Step [773/1063], Loss: 0.0036\n",
      "Epoch [6/10], Step [774/1063], Loss: 0.0526\n",
      "Epoch [6/10], Step [775/1063], Loss: 0.0223\n",
      "Epoch [6/10], Step [776/1063], Loss: 0.0049\n",
      "Epoch [6/10], Step [777/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [778/1063], Loss: 0.0027\n",
      "Epoch [6/10], Step [779/1063], Loss: 0.0053\n",
      "Epoch [6/10], Step [780/1063], Loss: 0.0027\n",
      "Epoch [6/10], Step [781/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [782/1063], Loss: 0.0047\n",
      "Epoch [6/10], Step [783/1063], Loss: 0.0196\n",
      "Epoch [6/10], Step [784/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [785/1063], Loss: 0.0167\n",
      "Epoch [6/10], Step [786/1063], Loss: 0.0012\n",
      "Epoch [6/10], Step [787/1063], Loss: 0.0457\n",
      "Epoch [6/10], Step [788/1063], Loss: 0.0102\n",
      "Epoch [6/10], Step [789/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [790/1063], Loss: 0.0114\n",
      "Epoch [6/10], Step [791/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [792/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [793/1063], Loss: 0.0290\n",
      "Epoch [6/10], Step [794/1063], Loss: 0.0019\n",
      "Epoch [6/10], Step [795/1063], Loss: 0.0028\n",
      "Epoch [6/10], Step [796/1063], Loss: 0.0224\n",
      "Epoch [6/10], Step [797/1063], Loss: 0.0055\n",
      "Epoch [6/10], Step [798/1063], Loss: 0.0869\n",
      "Epoch [6/10], Step [799/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [800/1063], Loss: 0.1023\n",
      "Epoch [6/10], Step [801/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [802/1063], Loss: 0.0490\n",
      "Epoch [6/10], Step [803/1063], Loss: 0.0216\n",
      "Epoch [6/10], Step [804/1063], Loss: 0.0126\n",
      "Epoch [6/10], Step [805/1063], Loss: 0.0035\n",
      "Epoch [6/10], Step [806/1063], Loss: 0.0375\n",
      "Epoch [6/10], Step [807/1063], Loss: 0.0227\n",
      "Epoch [6/10], Step [808/1063], Loss: 0.0054\n",
      "Epoch [6/10], Step [809/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [810/1063], Loss: 0.0390\n",
      "Epoch [6/10], Step [811/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [812/1063], Loss: 0.0167\n",
      "Epoch [6/10], Step [813/1063], Loss: 0.0107\n",
      "Epoch [6/10], Step [814/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [815/1063], Loss: 0.0622\n",
      "Epoch [6/10], Step [816/1063], Loss: 0.0085\n",
      "Epoch [6/10], Step [817/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [818/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [819/1063], Loss: 0.0202\n",
      "Epoch [6/10], Step [820/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [821/1063], Loss: 0.0205\n",
      "Epoch [6/10], Step [822/1063], Loss: 0.0066\n",
      "Epoch [6/10], Step [823/1063], Loss: 0.0017\n",
      "Epoch [6/10], Step [824/1063], Loss: 0.0041\n",
      "Epoch [6/10], Step [825/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [826/1063], Loss: 0.0237\n",
      "Epoch [6/10], Step [827/1063], Loss: 0.0261\n",
      "Epoch [6/10], Step [828/1063], Loss: 0.0039\n",
      "Epoch [6/10], Step [829/1063], Loss: 0.0041\n",
      "Epoch [6/10], Step [830/1063], Loss: 0.0032\n",
      "Epoch [6/10], Step [831/1063], Loss: 0.0301\n",
      "Epoch [6/10], Step [832/1063], Loss: 0.0037\n",
      "Epoch [6/10], Step [833/1063], Loss: 0.1272\n",
      "Epoch [6/10], Step [834/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [835/1063], Loss: 0.0053\n",
      "Epoch [6/10], Step [836/1063], Loss: 0.0098\n",
      "Epoch [6/10], Step [837/1063], Loss: 0.0044\n",
      "Epoch [6/10], Step [838/1063], Loss: 0.0044\n",
      "Epoch [6/10], Step [839/1063], Loss: 0.0140\n",
      "Epoch [6/10], Step [840/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [841/1063], Loss: 0.0019\n",
      "Epoch [6/10], Step [842/1063], Loss: 0.0120\n",
      "Epoch [6/10], Step [843/1063], Loss: 0.0602\n",
      "Epoch [6/10], Step [844/1063], Loss: 0.0495\n",
      "Epoch [6/10], Step [845/1063], Loss: 0.0101\n",
      "Epoch [6/10], Step [846/1063], Loss: 0.0066\n",
      "Epoch [6/10], Step [847/1063], Loss: 0.0041\n",
      "Epoch [6/10], Step [848/1063], Loss: 0.0026\n",
      "Epoch [6/10], Step [849/1063], Loss: 0.0085\n",
      "Epoch [6/10], Step [850/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [851/1063], Loss: 0.0282\n",
      "Epoch [6/10], Step [852/1063], Loss: 0.0701\n",
      "Epoch [6/10], Step [853/1063], Loss: 0.0084\n",
      "Epoch [6/10], Step [854/1063], Loss: 0.0122\n",
      "Epoch [6/10], Step [855/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [856/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [857/1063], Loss: 0.0058\n",
      "Epoch [6/10], Step [858/1063], Loss: 0.0274\n",
      "Epoch [6/10], Step [859/1063], Loss: 0.0128\n",
      "Epoch [6/10], Step [860/1063], Loss: 0.0045\n",
      "Epoch [6/10], Step [861/1063], Loss: 0.0044\n",
      "Epoch [6/10], Step [862/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [863/1063], Loss: 0.0081\n",
      "Epoch [6/10], Step [864/1063], Loss: 0.0042\n",
      "Epoch [6/10], Step [865/1063], Loss: 0.0384\n",
      "Epoch [6/10], Step [866/1063], Loss: 0.0012\n",
      "Epoch [6/10], Step [867/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [868/1063], Loss: 0.0131\n",
      "Epoch [6/10], Step [869/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [870/1063], Loss: 0.0252\n",
      "Epoch [6/10], Step [871/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [872/1063], Loss: 0.0113\n",
      "Epoch [6/10], Step [873/1063], Loss: 0.0083\n",
      "Epoch [6/10], Step [874/1063], Loss: 0.0024\n",
      "Epoch [6/10], Step [875/1063], Loss: 0.0144\n",
      "Epoch [6/10], Step [876/1063], Loss: 0.0265\n",
      "Epoch [6/10], Step [877/1063], Loss: 0.0111\n",
      "Epoch [6/10], Step [878/1063], Loss: 0.0924\n",
      "Epoch [6/10], Step [879/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [880/1063], Loss: 0.0104\n",
      "Epoch [6/10], Step [881/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [882/1063], Loss: 0.0062\n",
      "Epoch [6/10], Step [883/1063], Loss: 0.0027\n",
      "Epoch [6/10], Step [884/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [885/1063], Loss: 0.0011\n",
      "Epoch [6/10], Step [886/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [887/1063], Loss: 0.0028\n",
      "Epoch [6/10], Step [888/1063], Loss: 0.0432\n",
      "Epoch [6/10], Step [889/1063], Loss: 0.0124\n",
      "Epoch [6/10], Step [890/1063], Loss: 0.0004\n",
      "Epoch [6/10], Step [891/1063], Loss: 0.0301\n",
      "Epoch [6/10], Step [892/1063], Loss: 0.0175\n",
      "Epoch [6/10], Step [893/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [894/1063], Loss: 0.0036\n",
      "Epoch [6/10], Step [895/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [896/1063], Loss: 0.0082\n",
      "Epoch [6/10], Step [897/1063], Loss: 0.0457\n",
      "Epoch [6/10], Step [898/1063], Loss: 0.0059\n",
      "Epoch [6/10], Step [899/1063], Loss: 0.0091\n",
      "Epoch [6/10], Step [900/1063], Loss: 0.0025\n",
      "Epoch [6/10], Step [901/1063], Loss: 0.0175\n",
      "Epoch [6/10], Step [902/1063], Loss: 0.0023\n",
      "Epoch [6/10], Step [903/1063], Loss: 0.0387\n",
      "Epoch [6/10], Step [904/1063], Loss: 0.0035\n",
      "Epoch [6/10], Step [905/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [906/1063], Loss: 0.0000\n",
      "Epoch [6/10], Step [907/1063], Loss: 0.0007\n",
      "Epoch [6/10], Step [908/1063], Loss: 0.0067\n",
      "Epoch [6/10], Step [909/1063], Loss: 0.0138\n",
      "Epoch [6/10], Step [910/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [911/1063], Loss: 0.0081\n",
      "Epoch [6/10], Step [912/1063], Loss: 0.0565\n",
      "Epoch [6/10], Step [913/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [914/1063], Loss: 0.0017\n",
      "Epoch [6/10], Step [915/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [916/1063], Loss: 0.0029\n",
      "Epoch [6/10], Step [917/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [918/1063], Loss: 0.0050\n",
      "Epoch [6/10], Step [919/1063], Loss: 0.0072\n",
      "Epoch [6/10], Step [920/1063], Loss: 0.0327\n",
      "Epoch [6/10], Step [921/1063], Loss: 0.0079\n",
      "Epoch [6/10], Step [922/1063], Loss: 0.0050\n",
      "Epoch [6/10], Step [923/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [924/1063], Loss: 0.0033\n",
      "Epoch [6/10], Step [925/1063], Loss: 0.0156\n",
      "Epoch [6/10], Step [926/1063], Loss: 0.0485\n",
      "Epoch [6/10], Step [927/1063], Loss: 0.0310\n",
      "Epoch [6/10], Step [928/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [929/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [930/1063], Loss: 0.0075\n",
      "Epoch [6/10], Step [931/1063], Loss: 0.0025\n",
      "Epoch [6/10], Step [932/1063], Loss: 0.0066\n",
      "Epoch [6/10], Step [933/1063], Loss: 0.0241\n",
      "Epoch [6/10], Step [934/1063], Loss: 0.0108\n",
      "Epoch [6/10], Step [935/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [936/1063], Loss: 0.0057\n",
      "Epoch [6/10], Step [937/1063], Loss: 0.0174\n",
      "Epoch [6/10], Step [938/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [939/1063], Loss: 0.0092\n",
      "Epoch [6/10], Step [940/1063], Loss: 0.0092\n",
      "Epoch [6/10], Step [941/1063], Loss: 0.0016\n",
      "Epoch [6/10], Step [942/1063], Loss: 0.0016\n",
      "Epoch [6/10], Step [943/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [944/1063], Loss: 0.0171\n",
      "Epoch [6/10], Step [945/1063], Loss: 0.0038\n",
      "Epoch [6/10], Step [946/1063], Loss: 0.0084\n",
      "Epoch [6/10], Step [947/1063], Loss: 0.0174\n",
      "Epoch [6/10], Step [948/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [949/1063], Loss: 0.0040\n",
      "Epoch [6/10], Step [950/1063], Loss: 0.0253\n",
      "Epoch [6/10], Step [951/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [952/1063], Loss: 0.0908\n",
      "Epoch [6/10], Step [953/1063], Loss: 0.0216\n",
      "Epoch [6/10], Step [954/1063], Loss: 0.0001\n",
      "Epoch [6/10], Step [955/1063], Loss: 0.0107\n",
      "Epoch [6/10], Step [956/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [957/1063], Loss: 0.0590\n",
      "Epoch [6/10], Step [958/1063], Loss: 0.0105\n",
      "Epoch [6/10], Step [959/1063], Loss: 0.0570\n",
      "Epoch [6/10], Step [960/1063], Loss: 0.0129\n",
      "Epoch [6/10], Step [961/1063], Loss: 0.0471\n",
      "Epoch [6/10], Step [962/1063], Loss: 0.0041\n",
      "Epoch [6/10], Step [963/1063], Loss: 0.0020\n",
      "Epoch [6/10], Step [964/1063], Loss: 0.0009\n",
      "Epoch [6/10], Step [965/1063], Loss: 0.0140\n",
      "Epoch [6/10], Step [966/1063], Loss: 0.0200\n",
      "Epoch [6/10], Step [967/1063], Loss: 0.0014\n",
      "Epoch [6/10], Step [968/1063], Loss: 0.0099\n",
      "Epoch [6/10], Step [969/1063], Loss: 0.0373\n",
      "Epoch [6/10], Step [970/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [971/1063], Loss: 0.0324\n",
      "Epoch [6/10], Step [972/1063], Loss: 0.0099\n",
      "Epoch [6/10], Step [973/1063], Loss: 0.0022\n",
      "Epoch [6/10], Step [974/1063], Loss: 0.0070\n",
      "Epoch [6/10], Step [975/1063], Loss: 0.3258\n",
      "Epoch [6/10], Step [976/1063], Loss: 0.0830\n",
      "Epoch [6/10], Step [977/1063], Loss: 0.0032\n",
      "Epoch [6/10], Step [978/1063], Loss: 0.0019\n",
      "Epoch [6/10], Step [979/1063], Loss: 0.0113\n",
      "Epoch [6/10], Step [980/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [981/1063], Loss: 0.0029\n",
      "Epoch [6/10], Step [982/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [983/1063], Loss: 0.0003\n",
      "Epoch [6/10], Step [984/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [985/1063], Loss: 0.1044\n",
      "Epoch [6/10], Step [986/1063], Loss: 0.0068\n",
      "Epoch [6/10], Step [987/1063], Loss: 0.0077\n",
      "Epoch [6/10], Step [988/1063], Loss: 0.0057\n",
      "Epoch [6/10], Step [989/1063], Loss: 0.0025\n",
      "Epoch [6/10], Step [990/1063], Loss: 0.0105\n",
      "Epoch [6/10], Step [991/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [992/1063], Loss: 0.0036\n",
      "Epoch [6/10], Step [993/1063], Loss: 0.0372\n",
      "Epoch [6/10], Step [994/1063], Loss: 0.0040\n",
      "Epoch [6/10], Step [995/1063], Loss: 0.0172\n",
      "Epoch [6/10], Step [996/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [997/1063], Loss: 0.0252\n",
      "Epoch [6/10], Step [998/1063], Loss: 0.0117\n",
      "Epoch [6/10], Step [999/1063], Loss: 0.0193\n",
      "Epoch [6/10], Step [1000/1063], Loss: 0.0422\n",
      "Epoch [6/10], Step [1001/1063], Loss: 0.0037\n",
      "Epoch [6/10], Step [1002/1063], Loss: 0.0111\n",
      "Epoch [6/10], Step [1003/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [1004/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [1005/1063], Loss: 0.0024\n",
      "Epoch [6/10], Step [1006/1063], Loss: 0.0065\n",
      "Epoch [6/10], Step [1007/1063], Loss: 0.0185\n",
      "Epoch [6/10], Step [1008/1063], Loss: 0.0138\n",
      "Epoch [6/10], Step [1009/1063], Loss: 0.0032\n",
      "Epoch [6/10], Step [1010/1063], Loss: 0.0006\n",
      "Epoch [6/10], Step [1011/1063], Loss: 0.0483\n",
      "Epoch [6/10], Step [1012/1063], Loss: 0.0063\n",
      "Epoch [6/10], Step [1013/1063], Loss: 0.0082\n",
      "Epoch [6/10], Step [1014/1063], Loss: 0.0008\n",
      "Epoch [6/10], Step [1015/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [1016/1063], Loss: 0.0018\n",
      "Epoch [6/10], Step [1017/1063], Loss: 0.0094\n",
      "Epoch [6/10], Step [1018/1063], Loss: 0.1460\n",
      "Epoch [6/10], Step [1019/1063], Loss: 0.0109\n",
      "Epoch [6/10], Step [1020/1063], Loss: 0.0020\n",
      "Epoch [6/10], Step [1021/1063], Loss: 0.0013\n",
      "Epoch [6/10], Step [1022/1063], Loss: 0.0376\n",
      "Epoch [6/10], Step [1023/1063], Loss: 0.0048\n",
      "Epoch [6/10], Step [1024/1063], Loss: 0.0036\n",
      "Epoch [6/10], Step [1025/1063], Loss: 0.0095\n",
      "Epoch [6/10], Step [1026/1063], Loss: 0.0090\n",
      "Epoch [6/10], Step [1027/1063], Loss: 0.0015\n",
      "Epoch [6/10], Step [1028/1063], Loss: 0.0260\n",
      "Epoch [6/10], Step [1029/1063], Loss: 0.0048\n",
      "Epoch [6/10], Step [1030/1063], Loss: 0.0105\n",
      "Epoch [6/10], Step [1031/1063], Loss: 0.0016\n",
      "Epoch [6/10], Step [1032/1063], Loss: 0.0618\n",
      "Epoch [6/10], Step [1033/1063], Loss: 0.0010\n",
      "Epoch [6/10], Step [1034/1063], Loss: 0.0303\n",
      "Epoch [6/10], Step [1035/1063], Loss: 0.0126\n",
      "Epoch [6/10], Step [1036/1063], Loss: 0.0033\n",
      "Epoch [6/10], Step [1037/1063], Loss: 0.0170\n",
      "Epoch [6/10], Step [1038/1063], Loss: 0.0041\n",
      "Epoch [6/10], Step [1039/1063], Loss: 0.0207\n",
      "Epoch [6/10], Step [1040/1063], Loss: 0.0019\n",
      "Epoch [6/10], Step [1041/1063], Loss: 0.0037\n",
      "Epoch [6/10], Step [1042/1063], Loss: 0.0155\n",
      "Epoch [6/10], Step [1043/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [1044/1063], Loss: 0.0017\n",
      "Epoch [6/10], Step [1045/1063], Loss: 0.0196\n",
      "Epoch [6/10], Step [1046/1063], Loss: 0.0020\n",
      "Epoch [6/10], Step [1047/1063], Loss: 0.0100\n",
      "Epoch [6/10], Step [1048/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [1049/1063], Loss: 0.0089\n",
      "Epoch [6/10], Step [1050/1063], Loss: 0.0133\n",
      "Epoch [6/10], Step [1051/1063], Loss: 0.0305\n",
      "Epoch [6/10], Step [1052/1063], Loss: 0.0040\n",
      "Epoch [6/10], Step [1053/1063], Loss: 0.0147\n",
      "Epoch [6/10], Step [1054/1063], Loss: 0.0120\n",
      "Epoch [6/10], Step [1055/1063], Loss: 0.0043\n",
      "Epoch [6/10], Step [1056/1063], Loss: 0.0084\n",
      "Epoch [6/10], Step [1057/1063], Loss: 0.0076\n",
      "Epoch [6/10], Step [1058/1063], Loss: 0.0002\n",
      "Epoch [6/10], Step [1059/1063], Loss: 0.0092\n",
      "Epoch [6/10], Step [1060/1063], Loss: 0.0005\n",
      "Epoch [6/10], Step [1061/1063], Loss: 0.0288\n",
      "Epoch [6/10], Step [1062/1063], Loss: 0.0051\n",
      "Epoch [6/10], Step [1063/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [1/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [2/1063], Loss: 0.0041\n",
      "Epoch [7/10], Step [3/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [4/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [5/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [6/1063], Loss: 0.0057\n",
      "Epoch [7/10], Step [7/1063], Loss: 0.0089\n",
      "Epoch [7/10], Step [8/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [9/1063], Loss: 0.0344\n",
      "Epoch [7/10], Step [10/1063], Loss: 0.0049\n",
      "Epoch [7/10], Step [11/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [12/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [13/1063], Loss: 0.0030\n",
      "Epoch [7/10], Step [14/1063], Loss: 0.0270\n",
      "Epoch [7/10], Step [15/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [16/1063], Loss: 0.0331\n",
      "Epoch [7/10], Step [17/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [18/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [19/1063], Loss: 0.0140\n",
      "Epoch [7/10], Step [20/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [21/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [22/1063], Loss: 0.0225\n",
      "Epoch [7/10], Step [23/1063], Loss: 0.0029\n",
      "Epoch [7/10], Step [24/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [25/1063], Loss: 0.0041\n",
      "Epoch [7/10], Step [26/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [27/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [28/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [29/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [30/1063], Loss: 0.0192\n",
      "Epoch [7/10], Step [31/1063], Loss: 0.0040\n",
      "Epoch [7/10], Step [32/1063], Loss: 0.0061\n",
      "Epoch [7/10], Step [33/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [34/1063], Loss: 0.0091\n",
      "Epoch [7/10], Step [35/1063], Loss: 0.0019\n",
      "Epoch [7/10], Step [36/1063], Loss: 0.0122\n",
      "Epoch [7/10], Step [37/1063], Loss: 0.0033\n",
      "Epoch [7/10], Step [38/1063], Loss: 0.0145\n",
      "Epoch [7/10], Step [39/1063], Loss: 0.0121\n",
      "Epoch [7/10], Step [40/1063], Loss: 0.0045\n",
      "Epoch [7/10], Step [41/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [42/1063], Loss: 0.0034\n",
      "Epoch [7/10], Step [43/1063], Loss: 0.0032\n",
      "Epoch [7/10], Step [44/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [45/1063], Loss: 0.0019\n",
      "Epoch [7/10], Step [46/1063], Loss: 0.0123\n",
      "Epoch [7/10], Step [47/1063], Loss: 0.0093\n",
      "Epoch [7/10], Step [48/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [49/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [50/1063], Loss: 0.1442\n",
      "Epoch [7/10], Step [51/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [52/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [53/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [54/1063], Loss: 0.0030\n",
      "Epoch [7/10], Step [55/1063], Loss: 0.0077\n",
      "Epoch [7/10], Step [56/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [57/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [58/1063], Loss: 0.0159\n",
      "Epoch [7/10], Step [59/1063], Loss: 0.0110\n",
      "Epoch [7/10], Step [60/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [61/1063], Loss: 0.0026\n",
      "Epoch [7/10], Step [62/1063], Loss: 0.0083\n",
      "Epoch [7/10], Step [63/1063], Loss: 0.0251\n",
      "Epoch [7/10], Step [64/1063], Loss: 0.0068\n",
      "Epoch [7/10], Step [65/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [66/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [67/1063], Loss: 0.0019\n",
      "Epoch [7/10], Step [68/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [69/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [70/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [71/1063], Loss: 0.0424\n",
      "Epoch [7/10], Step [72/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [73/1063], Loss: 0.0219\n",
      "Epoch [7/10], Step [74/1063], Loss: 0.0020\n",
      "Epoch [7/10], Step [75/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [76/1063], Loss: 0.0039\n",
      "Epoch [7/10], Step [77/1063], Loss: 0.0097\n",
      "Epoch [7/10], Step [78/1063], Loss: 0.0157\n",
      "Epoch [7/10], Step [79/1063], Loss: 0.0035\n",
      "Epoch [7/10], Step [80/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [81/1063], Loss: 0.0023\n",
      "Epoch [7/10], Step [82/1063], Loss: 0.0029\n",
      "Epoch [7/10], Step [83/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [84/1063], Loss: 0.0019\n",
      "Epoch [7/10], Step [85/1063], Loss: 0.0166\n",
      "Epoch [7/10], Step [86/1063], Loss: 0.0276\n",
      "Epoch [7/10], Step [87/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [88/1063], Loss: 0.0120\n",
      "Epoch [7/10], Step [89/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [90/1063], Loss: 0.0043\n",
      "Epoch [7/10], Step [91/1063], Loss: 0.0269\n",
      "Epoch [7/10], Step [92/1063], Loss: 0.0017\n",
      "Epoch [7/10], Step [93/1063], Loss: 0.0059\n",
      "Epoch [7/10], Step [94/1063], Loss: 0.0035\n",
      "Epoch [7/10], Step [95/1063], Loss: 0.0126\n",
      "Epoch [7/10], Step [96/1063], Loss: 0.0067\n",
      "Epoch [7/10], Step [97/1063], Loss: 0.0439\n",
      "Epoch [7/10], Step [98/1063], Loss: 0.0033\n",
      "Epoch [7/10], Step [99/1063], Loss: 0.0047\n",
      "Epoch [7/10], Step [100/1063], Loss: 0.0159\n",
      "Epoch [7/10], Step [101/1063], Loss: 0.0048\n",
      "Epoch [7/10], Step [102/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [103/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [104/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [105/1063], Loss: 0.0266\n",
      "Epoch [7/10], Step [106/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [107/1063], Loss: 0.0172\n",
      "Epoch [7/10], Step [108/1063], Loss: 0.0064\n",
      "Epoch [7/10], Step [109/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [110/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [111/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [112/1063], Loss: 0.0193\n",
      "Epoch [7/10], Step [113/1063], Loss: 0.0846\n",
      "Epoch [7/10], Step [114/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [115/1063], Loss: 0.0033\n",
      "Epoch [7/10], Step [116/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [117/1063], Loss: 0.0121\n",
      "Epoch [7/10], Step [118/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [119/1063], Loss: 0.0053\n",
      "Epoch [7/10], Step [120/1063], Loss: 0.0114\n",
      "Epoch [7/10], Step [121/1063], Loss: 0.0022\n",
      "Epoch [7/10], Step [122/1063], Loss: 0.0382\n",
      "Epoch [7/10], Step [123/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [124/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [125/1063], Loss: 0.0639\n",
      "Epoch [7/10], Step [126/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [127/1063], Loss: 0.0059\n",
      "Epoch [7/10], Step [128/1063], Loss: 0.0156\n",
      "Epoch [7/10], Step [129/1063], Loss: 0.0045\n",
      "Epoch [7/10], Step [130/1063], Loss: 0.0157\n",
      "Epoch [7/10], Step [131/1063], Loss: 0.0149\n",
      "Epoch [7/10], Step [132/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [133/1063], Loss: 0.0039\n",
      "Epoch [7/10], Step [134/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [135/1063], Loss: 0.0025\n",
      "Epoch [7/10], Step [136/1063], Loss: 0.0552\n",
      "Epoch [7/10], Step [137/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [138/1063], Loss: 0.0076\n",
      "Epoch [7/10], Step [139/1063], Loss: 0.0073\n",
      "Epoch [7/10], Step [140/1063], Loss: 0.0058\n",
      "Epoch [7/10], Step [141/1063], Loss: 0.0175\n",
      "Epoch [7/10], Step [142/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [143/1063], Loss: 0.0393\n",
      "Epoch [7/10], Step [144/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [145/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [146/1063], Loss: 0.0214\n",
      "Epoch [7/10], Step [147/1063], Loss: 0.0029\n",
      "Epoch [7/10], Step [148/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [149/1063], Loss: 0.0141\n",
      "Epoch [7/10], Step [150/1063], Loss: 0.0020\n",
      "Epoch [7/10], Step [151/1063], Loss: 0.0478\n",
      "Epoch [7/10], Step [152/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [153/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [154/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [155/1063], Loss: 0.0032\n",
      "Epoch [7/10], Step [156/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [157/1063], Loss: 0.0049\n",
      "Epoch [7/10], Step [158/1063], Loss: 0.0244\n",
      "Epoch [7/10], Step [159/1063], Loss: 0.0077\n",
      "Epoch [7/10], Step [160/1063], Loss: 0.0037\n",
      "Epoch [7/10], Step [161/1063], Loss: 0.0029\n",
      "Epoch [7/10], Step [162/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [163/1063], Loss: 0.0079\n",
      "Epoch [7/10], Step [164/1063], Loss: 0.0024\n",
      "Epoch [7/10], Step [165/1063], Loss: 0.0067\n",
      "Epoch [7/10], Step [166/1063], Loss: 0.0036\n",
      "Epoch [7/10], Step [167/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [168/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [169/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [170/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [171/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [172/1063], Loss: 0.0350\n",
      "Epoch [7/10], Step [173/1063], Loss: 0.0362\n",
      "Epoch [7/10], Step [174/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [175/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [176/1063], Loss: 0.0033\n",
      "Epoch [7/10], Step [177/1063], Loss: 0.0237\n",
      "Epoch [7/10], Step [178/1063], Loss: 0.0103\n",
      "Epoch [7/10], Step [179/1063], Loss: 0.0036\n",
      "Epoch [7/10], Step [180/1063], Loss: 0.0376\n",
      "Epoch [7/10], Step [181/1063], Loss: 0.0077\n",
      "Epoch [7/10], Step [182/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [183/1063], Loss: 0.0293\n",
      "Epoch [7/10], Step [184/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [185/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [186/1063], Loss: 0.0432\n",
      "Epoch [7/10], Step [187/1063], Loss: 0.0020\n",
      "Epoch [7/10], Step [188/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [189/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [190/1063], Loss: 0.0020\n",
      "Epoch [7/10], Step [191/1063], Loss: 0.0311\n",
      "Epoch [7/10], Step [192/1063], Loss: 0.1005\n",
      "Epoch [7/10], Step [193/1063], Loss: 0.0071\n",
      "Epoch [7/10], Step [194/1063], Loss: 0.0103\n",
      "Epoch [7/10], Step [195/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [196/1063], Loss: 0.1295\n",
      "Epoch [7/10], Step [197/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [198/1063], Loss: 0.0396\n",
      "Epoch [7/10], Step [199/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [200/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [201/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [202/1063], Loss: 0.0028\n",
      "Epoch [7/10], Step [203/1063], Loss: 0.0692\n",
      "Epoch [7/10], Step [204/1063], Loss: 0.0084\n",
      "Epoch [7/10], Step [205/1063], Loss: 0.0092\n",
      "Epoch [7/10], Step [206/1063], Loss: 0.0149\n",
      "Epoch [7/10], Step [207/1063], Loss: 0.0029\n",
      "Epoch [7/10], Step [208/1063], Loss: 0.0377\n",
      "Epoch [7/10], Step [209/1063], Loss: 0.0116\n",
      "Epoch [7/10], Step [210/1063], Loss: 0.0051\n",
      "Epoch [7/10], Step [211/1063], Loss: 0.0090\n",
      "Epoch [7/10], Step [212/1063], Loss: 0.0022\n",
      "Epoch [7/10], Step [213/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [214/1063], Loss: 0.0703\n",
      "Epoch [7/10], Step [215/1063], Loss: 0.0409\n",
      "Epoch [7/10], Step [216/1063], Loss: 0.0069\n",
      "Epoch [7/10], Step [217/1063], Loss: 0.0034\n",
      "Epoch [7/10], Step [218/1063], Loss: 0.0042\n",
      "Epoch [7/10], Step [219/1063], Loss: 0.0049\n",
      "Epoch [7/10], Step [220/1063], Loss: 0.0421\n",
      "Epoch [7/10], Step [221/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [222/1063], Loss: 0.0229\n",
      "Epoch [7/10], Step [223/1063], Loss: 0.0053\n",
      "Epoch [7/10], Step [224/1063], Loss: 0.0037\n",
      "Epoch [7/10], Step [225/1063], Loss: 0.0068\n",
      "Epoch [7/10], Step [226/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [227/1063], Loss: 0.0058\n",
      "Epoch [7/10], Step [228/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [229/1063], Loss: 0.0024\n",
      "Epoch [7/10], Step [230/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [231/1063], Loss: 0.0134\n",
      "Epoch [7/10], Step [232/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [233/1063], Loss: 0.0249\n",
      "Epoch [7/10], Step [234/1063], Loss: 0.0189\n",
      "Epoch [7/10], Step [235/1063], Loss: 0.0088\n",
      "Epoch [7/10], Step [236/1063], Loss: 0.0040\n",
      "Epoch [7/10], Step [237/1063], Loss: 0.1247\n",
      "Epoch [7/10], Step [238/1063], Loss: 0.0020\n",
      "Epoch [7/10], Step [239/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [240/1063], Loss: 0.0024\n",
      "Epoch [7/10], Step [241/1063], Loss: 0.0040\n",
      "Epoch [7/10], Step [242/1063], Loss: 0.0107\n",
      "Epoch [7/10], Step [243/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [244/1063], Loss: 0.0350\n",
      "Epoch [7/10], Step [245/1063], Loss: 0.0114\n",
      "Epoch [7/10], Step [246/1063], Loss: 0.0049\n",
      "Epoch [7/10], Step [247/1063], Loss: 0.0055\n",
      "Epoch [7/10], Step [248/1063], Loss: 0.0064\n",
      "Epoch [7/10], Step [249/1063], Loss: 0.0534\n",
      "Epoch [7/10], Step [250/1063], Loss: 0.0105\n",
      "Epoch [7/10], Step [251/1063], Loss: 0.0311\n",
      "Epoch [7/10], Step [252/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [253/1063], Loss: 0.0060\n",
      "Epoch [7/10], Step [254/1063], Loss: 0.0234\n",
      "Epoch [7/10], Step [255/1063], Loss: 0.0113\n",
      "Epoch [7/10], Step [256/1063], Loss: 0.0041\n",
      "Epoch [7/10], Step [257/1063], Loss: 0.0375\n",
      "Epoch [7/10], Step [258/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [259/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [260/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [261/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [262/1063], Loss: 0.0040\n",
      "Epoch [7/10], Step [263/1063], Loss: 0.0408\n",
      "Epoch [7/10], Step [264/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [265/1063], Loss: 0.0049\n",
      "Epoch [7/10], Step [266/1063], Loss: 0.0135\n",
      "Epoch [7/10], Step [267/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [268/1063], Loss: 0.0049\n",
      "Epoch [7/10], Step [269/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [270/1063], Loss: 0.0166\n",
      "Epoch [7/10], Step [271/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [272/1063], Loss: 0.0034\n",
      "Epoch [7/10], Step [273/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [274/1063], Loss: 0.0023\n",
      "Epoch [7/10], Step [275/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [276/1063], Loss: 0.0060\n",
      "Epoch [7/10], Step [277/1063], Loss: 0.0059\n",
      "Epoch [7/10], Step [278/1063], Loss: 0.0041\n",
      "Epoch [7/10], Step [279/1063], Loss: 0.0042\n",
      "Epoch [7/10], Step [280/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [281/1063], Loss: 0.0026\n",
      "Epoch [7/10], Step [282/1063], Loss: 0.0025\n",
      "Epoch [7/10], Step [283/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [284/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [285/1063], Loss: 0.0032\n",
      "Epoch [7/10], Step [286/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [287/1063], Loss: 0.0022\n",
      "Epoch [7/10], Step [288/1063], Loss: 0.0242\n",
      "Epoch [7/10], Step [289/1063], Loss: 0.1516\n",
      "Epoch [7/10], Step [290/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [291/1063], Loss: 0.0076\n",
      "Epoch [7/10], Step [292/1063], Loss: 0.0064\n",
      "Epoch [7/10], Step [293/1063], Loss: 0.0025\n",
      "Epoch [7/10], Step [294/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [295/1063], Loss: 0.0019\n",
      "Epoch [7/10], Step [296/1063], Loss: 0.0036\n",
      "Epoch [7/10], Step [297/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [298/1063], Loss: 0.0299\n",
      "Epoch [7/10], Step [299/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [300/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [301/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [302/1063], Loss: 0.0358\n",
      "Epoch [7/10], Step [303/1063], Loss: 0.0059\n",
      "Epoch [7/10], Step [304/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [305/1063], Loss: 0.0019\n",
      "Epoch [7/10], Step [306/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [307/1063], Loss: 0.0074\n",
      "Epoch [7/10], Step [308/1063], Loss: 0.0255\n",
      "Epoch [7/10], Step [309/1063], Loss: 0.0022\n",
      "Epoch [7/10], Step [310/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [311/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [312/1063], Loss: 0.0117\n",
      "Epoch [7/10], Step [313/1063], Loss: 0.0021\n",
      "Epoch [7/10], Step [314/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [315/1063], Loss: 0.0041\n",
      "Epoch [7/10], Step [316/1063], Loss: 0.0032\n",
      "Epoch [7/10], Step [317/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [318/1063], Loss: 0.0079\n",
      "Epoch [7/10], Step [319/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [320/1063], Loss: 0.0021\n",
      "Epoch [7/10], Step [321/1063], Loss: 0.0274\n",
      "Epoch [7/10], Step [322/1063], Loss: 0.0040\n",
      "Epoch [7/10], Step [323/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [324/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [325/1063], Loss: 0.0071\n",
      "Epoch [7/10], Step [326/1063], Loss: 0.0027\n",
      "Epoch [7/10], Step [327/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [328/1063], Loss: 0.0031\n",
      "Epoch [7/10], Step [329/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [330/1063], Loss: 0.0017\n",
      "Epoch [7/10], Step [331/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [332/1063], Loss: 0.0055\n",
      "Epoch [7/10], Step [333/1063], Loss: 0.0032\n",
      "Epoch [7/10], Step [334/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [335/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [336/1063], Loss: 0.0178\n",
      "Epoch [7/10], Step [337/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [338/1063], Loss: 0.0329\n",
      "Epoch [7/10], Step [339/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [340/1063], Loss: 0.0023\n",
      "Epoch [7/10], Step [341/1063], Loss: 0.0098\n",
      "Epoch [7/10], Step [342/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [343/1063], Loss: 0.0039\n",
      "Epoch [7/10], Step [344/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [345/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [346/1063], Loss: 0.0136\n",
      "Epoch [7/10], Step [347/1063], Loss: 0.0037\n",
      "Epoch [7/10], Step [348/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [349/1063], Loss: 0.0112\n",
      "Epoch [7/10], Step [350/1063], Loss: 0.0035\n",
      "Epoch [7/10], Step [351/1063], Loss: 0.0026\n",
      "Epoch [7/10], Step [352/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [353/1063], Loss: 0.0059\n",
      "Epoch [7/10], Step [354/1063], Loss: 0.0202\n",
      "Epoch [7/10], Step [355/1063], Loss: 0.0048\n",
      "Epoch [7/10], Step [356/1063], Loss: 0.0043\n",
      "Epoch [7/10], Step [357/1063], Loss: 0.0020\n",
      "Epoch [7/10], Step [358/1063], Loss: 0.0258\n",
      "Epoch [7/10], Step [359/1063], Loss: 0.0040\n",
      "Epoch [7/10], Step [360/1063], Loss: 0.0062\n",
      "Epoch [7/10], Step [361/1063], Loss: 0.0061\n",
      "Epoch [7/10], Step [362/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [363/1063], Loss: 0.0050\n",
      "Epoch [7/10], Step [364/1063], Loss: 0.0414\n",
      "Epoch [7/10], Step [365/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [366/1063], Loss: 0.0042\n",
      "Epoch [7/10], Step [367/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [368/1063], Loss: 0.0074\n",
      "Epoch [7/10], Step [369/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [370/1063], Loss: 0.0064\n",
      "Epoch [7/10], Step [371/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [372/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [373/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [374/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [375/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [376/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [377/1063], Loss: 0.0066\n",
      "Epoch [7/10], Step [378/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [379/1063], Loss: 0.0033\n",
      "Epoch [7/10], Step [380/1063], Loss: 0.0028\n",
      "Epoch [7/10], Step [381/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [382/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [383/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [384/1063], Loss: 0.0050\n",
      "Epoch [7/10], Step [385/1063], Loss: 0.0034\n",
      "Epoch [7/10], Step [386/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [387/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [388/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [389/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [390/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [391/1063], Loss: 0.0481\n",
      "Epoch [7/10], Step [392/1063], Loss: 0.1109\n",
      "Epoch [7/10], Step [393/1063], Loss: 0.2366\n",
      "Epoch [7/10], Step [394/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [395/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [396/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [397/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [398/1063], Loss: 0.0062\n",
      "Epoch [7/10], Step [399/1063], Loss: 0.0054\n",
      "Epoch [7/10], Step [400/1063], Loss: 0.0045\n",
      "Epoch [7/10], Step [401/1063], Loss: 0.0108\n",
      "Epoch [7/10], Step [402/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [403/1063], Loss: 0.0027\n",
      "Epoch [7/10], Step [404/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [405/1063], Loss: 0.0049\n",
      "Epoch [7/10], Step [406/1063], Loss: 0.0056\n",
      "Epoch [7/10], Step [407/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [408/1063], Loss: 0.0068\n",
      "Epoch [7/10], Step [409/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [410/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [411/1063], Loss: 0.0030\n",
      "Epoch [7/10], Step [412/1063], Loss: 0.0033\n",
      "Epoch [7/10], Step [413/1063], Loss: 0.0034\n",
      "Epoch [7/10], Step [414/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [415/1063], Loss: 0.0232\n",
      "Epoch [7/10], Step [416/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [417/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [418/1063], Loss: 0.0147\n",
      "Epoch [7/10], Step [419/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [420/1063], Loss: 0.0026\n",
      "Epoch [7/10], Step [421/1063], Loss: 0.0030\n",
      "Epoch [7/10], Step [422/1063], Loss: 0.0178\n",
      "Epoch [7/10], Step [423/1063], Loss: 0.0030\n",
      "Epoch [7/10], Step [424/1063], Loss: 0.0099\n",
      "Epoch [7/10], Step [425/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [426/1063], Loss: 0.0236\n",
      "Epoch [7/10], Step [427/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [428/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [429/1063], Loss: 0.0039\n",
      "Epoch [7/10], Step [430/1063], Loss: 0.0055\n",
      "Epoch [7/10], Step [431/1063], Loss: 0.0167\n",
      "Epoch [7/10], Step [432/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [433/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [434/1063], Loss: 0.0030\n",
      "Epoch [7/10], Step [435/1063], Loss: 0.0032\n",
      "Epoch [7/10], Step [436/1063], Loss: 0.0026\n",
      "Epoch [7/10], Step [437/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [438/1063], Loss: 0.0040\n",
      "Epoch [7/10], Step [439/1063], Loss: 0.0078\n",
      "Epoch [7/10], Step [440/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [441/1063], Loss: 0.0043\n",
      "Epoch [7/10], Step [442/1063], Loss: 0.0069\n",
      "Epoch [7/10], Step [443/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [444/1063], Loss: 0.0142\n",
      "Epoch [7/10], Step [445/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [446/1063], Loss: 0.0094\n",
      "Epoch [7/10], Step [447/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [448/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [449/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [450/1063], Loss: 0.0024\n",
      "Epoch [7/10], Step [451/1063], Loss: 0.0253\n",
      "Epoch [7/10], Step [452/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [453/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [454/1063], Loss: 0.0347\n",
      "Epoch [7/10], Step [455/1063], Loss: 0.0116\n",
      "Epoch [7/10], Step [456/1063], Loss: 0.0489\n",
      "Epoch [7/10], Step [457/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [458/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [459/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [460/1063], Loss: 0.0071\n",
      "Epoch [7/10], Step [461/1063], Loss: 0.0022\n",
      "Epoch [7/10], Step [462/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [463/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [464/1063], Loss: 0.0675\n",
      "Epoch [7/10], Step [465/1063], Loss: 0.0067\n",
      "Epoch [7/10], Step [466/1063], Loss: 0.0107\n",
      "Epoch [7/10], Step [467/1063], Loss: 0.0542\n",
      "Epoch [7/10], Step [468/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [469/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [470/1063], Loss: 0.0027\n",
      "Epoch [7/10], Step [471/1063], Loss: 0.0161\n",
      "Epoch [7/10], Step [472/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [473/1063], Loss: 0.0031\n",
      "Epoch [7/10], Step [474/1063], Loss: 0.1120\n",
      "Epoch [7/10], Step [475/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [476/1063], Loss: 0.0208\n",
      "Epoch [7/10], Step [477/1063], Loss: 0.0082\n",
      "Epoch [7/10], Step [478/1063], Loss: 0.0102\n",
      "Epoch [7/10], Step [479/1063], Loss: 0.0441\n",
      "Epoch [7/10], Step [480/1063], Loss: 0.0022\n",
      "Epoch [7/10], Step [481/1063], Loss: 0.0024\n",
      "Epoch [7/10], Step [482/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [483/1063], Loss: 0.0023\n",
      "Epoch [7/10], Step [484/1063], Loss: 0.0071\n",
      "Epoch [7/10], Step [485/1063], Loss: 0.0298\n",
      "Epoch [7/10], Step [486/1063], Loss: 0.0025\n",
      "Epoch [7/10], Step [487/1063], Loss: 0.0052\n",
      "Epoch [7/10], Step [488/1063], Loss: 0.0119\n",
      "Epoch [7/10], Step [489/1063], Loss: 0.0031\n",
      "Epoch [7/10], Step [490/1063], Loss: 0.0022\n",
      "Epoch [7/10], Step [491/1063], Loss: 0.0034\n",
      "Epoch [7/10], Step [492/1063], Loss: 0.0050\n",
      "Epoch [7/10], Step [493/1063], Loss: 0.0597\n",
      "Epoch [7/10], Step [494/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [495/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [496/1063], Loss: 0.0279\n",
      "Epoch [7/10], Step [497/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [498/1063], Loss: 0.0033\n",
      "Epoch [7/10], Step [499/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [500/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [501/1063], Loss: 0.0107\n",
      "Epoch [7/10], Step [502/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [503/1063], Loss: 0.0017\n",
      "Epoch [7/10], Step [504/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [505/1063], Loss: 0.0099\n",
      "Epoch [7/10], Step [506/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [507/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [508/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [509/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [510/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [511/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [512/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [513/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [514/1063], Loss: 0.0039\n",
      "Epoch [7/10], Step [515/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [516/1063], Loss: 0.0130\n",
      "Epoch [7/10], Step [517/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [518/1063], Loss: 0.0017\n",
      "Epoch [7/10], Step [519/1063], Loss: 0.0043\n",
      "Epoch [7/10], Step [520/1063], Loss: 0.0027\n",
      "Epoch [7/10], Step [521/1063], Loss: 0.0054\n",
      "Epoch [7/10], Step [522/1063], Loss: 0.0048\n",
      "Epoch [7/10], Step [523/1063], Loss: 0.0120\n",
      "Epoch [7/10], Step [524/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [525/1063], Loss: 0.0027\n",
      "Epoch [7/10], Step [526/1063], Loss: 0.0037\n",
      "Epoch [7/10], Step [527/1063], Loss: 0.0204\n",
      "Epoch [7/10], Step [528/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [529/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [530/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [531/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [532/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [533/1063], Loss: 0.0574\n",
      "Epoch [7/10], Step [534/1063], Loss: 0.0097\n",
      "Epoch [7/10], Step [535/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [536/1063], Loss: 0.0052\n",
      "Epoch [7/10], Step [537/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [538/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [539/1063], Loss: 0.0072\n",
      "Epoch [7/10], Step [540/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [541/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [542/1063], Loss: 0.0019\n",
      "Epoch [7/10], Step [543/1063], Loss: 0.0036\n",
      "Epoch [7/10], Step [544/1063], Loss: 0.0390\n",
      "Epoch [7/10], Step [545/1063], Loss: 0.0027\n",
      "Epoch [7/10], Step [546/1063], Loss: 0.0524\n",
      "Epoch [7/10], Step [547/1063], Loss: 0.0124\n",
      "Epoch [7/10], Step [548/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [549/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [550/1063], Loss: 0.0110\n",
      "Epoch [7/10], Step [551/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [552/1063], Loss: 0.0276\n",
      "Epoch [7/10], Step [553/1063], Loss: 0.0066\n",
      "Epoch [7/10], Step [554/1063], Loss: 0.0117\n",
      "Epoch [7/10], Step [555/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [556/1063], Loss: 0.0137\n",
      "Epoch [7/10], Step [557/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [558/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [559/1063], Loss: 0.0038\n",
      "Epoch [7/10], Step [560/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [561/1063], Loss: 0.0298\n",
      "Epoch [7/10], Step [562/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [563/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [564/1063], Loss: 0.0019\n",
      "Epoch [7/10], Step [565/1063], Loss: 0.0071\n",
      "Epoch [7/10], Step [566/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [567/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [568/1063], Loss: 0.0099\n",
      "Epoch [7/10], Step [569/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [570/1063], Loss: 0.0079\n",
      "Epoch [7/10], Step [571/1063], Loss: 0.0022\n",
      "Epoch [7/10], Step [572/1063], Loss: 0.0559\n",
      "Epoch [7/10], Step [573/1063], Loss: 0.0381\n",
      "Epoch [7/10], Step [574/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [575/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [576/1063], Loss: 0.0040\n",
      "Epoch [7/10], Step [577/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [578/1063], Loss: 0.0277\n",
      "Epoch [7/10], Step [579/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [580/1063], Loss: 0.0031\n",
      "Epoch [7/10], Step [581/1063], Loss: 0.0116\n",
      "Epoch [7/10], Step [582/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [583/1063], Loss: 0.0214\n",
      "Epoch [7/10], Step [584/1063], Loss: 0.0166\n",
      "Epoch [7/10], Step [585/1063], Loss: 0.0100\n",
      "Epoch [7/10], Step [586/1063], Loss: 0.0061\n",
      "Epoch [7/10], Step [587/1063], Loss: 0.0047\n",
      "Epoch [7/10], Step [588/1063], Loss: 0.0037\n",
      "Epoch [7/10], Step [589/1063], Loss: 0.0112\n",
      "Epoch [7/10], Step [590/1063], Loss: 0.0020\n",
      "Epoch [7/10], Step [591/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [592/1063], Loss: 0.0053\n",
      "Epoch [7/10], Step [593/1063], Loss: 0.0091\n",
      "Epoch [7/10], Step [594/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [595/1063], Loss: 0.0249\n",
      "Epoch [7/10], Step [596/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [597/1063], Loss: 0.0198\n",
      "Epoch [7/10], Step [598/1063], Loss: 0.0283\n",
      "Epoch [7/10], Step [599/1063], Loss: 0.0070\n",
      "Epoch [7/10], Step [600/1063], Loss: 0.0047\n",
      "Epoch [7/10], Step [601/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [602/1063], Loss: 0.0037\n",
      "Epoch [7/10], Step [603/1063], Loss: 0.0020\n",
      "Epoch [7/10], Step [604/1063], Loss: 0.0223\n",
      "Epoch [7/10], Step [605/1063], Loss: 0.0094\n",
      "Epoch [7/10], Step [606/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [607/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [608/1063], Loss: 0.0021\n",
      "Epoch [7/10], Step [609/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [610/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [611/1063], Loss: 0.0426\n",
      "Epoch [7/10], Step [612/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [613/1063], Loss: 0.1035\n",
      "Epoch [7/10], Step [614/1063], Loss: 0.0047\n",
      "Epoch [7/10], Step [615/1063], Loss: 0.0036\n",
      "Epoch [7/10], Step [616/1063], Loss: 0.0073\n",
      "Epoch [7/10], Step [617/1063], Loss: 0.0095\n",
      "Epoch [7/10], Step [618/1063], Loss: 0.0023\n",
      "Epoch [7/10], Step [619/1063], Loss: 0.0031\n",
      "Epoch [7/10], Step [620/1063], Loss: 0.0049\n",
      "Epoch [7/10], Step [621/1063], Loss: 0.0034\n",
      "Epoch [7/10], Step [622/1063], Loss: 0.0061\n",
      "Epoch [7/10], Step [623/1063], Loss: 0.0156\n",
      "Epoch [7/10], Step [624/1063], Loss: 0.0127\n",
      "Epoch [7/10], Step [625/1063], Loss: 0.0122\n",
      "Epoch [7/10], Step [626/1063], Loss: 0.0264\n",
      "Epoch [7/10], Step [627/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [628/1063], Loss: 0.0056\n",
      "Epoch [7/10], Step [629/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [630/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [631/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [632/1063], Loss: 0.0099\n",
      "Epoch [7/10], Step [633/1063], Loss: 0.0124\n",
      "Epoch [7/10], Step [634/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [635/1063], Loss: 0.0028\n",
      "Epoch [7/10], Step [636/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [637/1063], Loss: 0.0023\n",
      "Epoch [7/10], Step [638/1063], Loss: 0.0083\n",
      "Epoch [7/10], Step [639/1063], Loss: 0.1012\n",
      "Epoch [7/10], Step [640/1063], Loss: 0.0221\n",
      "Epoch [7/10], Step [641/1063], Loss: 0.0311\n",
      "Epoch [7/10], Step [642/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [643/1063], Loss: 0.0292\n",
      "Epoch [7/10], Step [644/1063], Loss: 0.0128\n",
      "Epoch [7/10], Step [645/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [646/1063], Loss: 0.0103\n",
      "Epoch [7/10], Step [647/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [648/1063], Loss: 0.0037\n",
      "Epoch [7/10], Step [649/1063], Loss: 0.0122\n",
      "Epoch [7/10], Step [650/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [651/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [652/1063], Loss: 0.0097\n",
      "Epoch [7/10], Step [653/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [654/1063], Loss: 0.0023\n",
      "Epoch [7/10], Step [655/1063], Loss: 0.0293\n",
      "Epoch [7/10], Step [656/1063], Loss: 0.0160\n",
      "Epoch [7/10], Step [657/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [658/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [659/1063], Loss: 0.0198\n",
      "Epoch [7/10], Step [660/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [661/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [662/1063], Loss: 0.0121\n",
      "Epoch [7/10], Step [663/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [664/1063], Loss: 0.0051\n",
      "Epoch [7/10], Step [665/1063], Loss: 0.0038\n",
      "Epoch [7/10], Step [666/1063], Loss: 0.0038\n",
      "Epoch [7/10], Step [667/1063], Loss: 0.0120\n",
      "Epoch [7/10], Step [668/1063], Loss: 0.0137\n",
      "Epoch [7/10], Step [669/1063], Loss: 0.0068\n",
      "Epoch [7/10], Step [670/1063], Loss: 0.0026\n",
      "Epoch [7/10], Step [671/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [672/1063], Loss: 0.0036\n",
      "Epoch [7/10], Step [673/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [674/1063], Loss: 0.0185\n",
      "Epoch [7/10], Step [675/1063], Loss: 0.0271\n",
      "Epoch [7/10], Step [676/1063], Loss: 0.0153\n",
      "Epoch [7/10], Step [677/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [678/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [679/1063], Loss: 0.0027\n",
      "Epoch [7/10], Step [680/1063], Loss: 0.0255\n",
      "Epoch [7/10], Step [681/1063], Loss: 0.0066\n",
      "Epoch [7/10], Step [682/1063], Loss: 0.0022\n",
      "Epoch [7/10], Step [683/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [684/1063], Loss: 0.0131\n",
      "Epoch [7/10], Step [685/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [686/1063], Loss: 0.0032\n",
      "Epoch [7/10], Step [687/1063], Loss: 0.0123\n",
      "Epoch [7/10], Step [688/1063], Loss: 0.0158\n",
      "Epoch [7/10], Step [689/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [690/1063], Loss: 0.0087\n",
      "Epoch [7/10], Step [691/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [692/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [693/1063], Loss: 0.0031\n",
      "Epoch [7/10], Step [694/1063], Loss: 0.0118\n",
      "Epoch [7/10], Step [695/1063], Loss: 0.0208\n",
      "Epoch [7/10], Step [696/1063], Loss: 0.1350\n",
      "Epoch [7/10], Step [697/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [698/1063], Loss: 0.0050\n",
      "Epoch [7/10], Step [699/1063], Loss: 0.0372\n",
      "Epoch [7/10], Step [700/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [701/1063], Loss: 0.0802\n",
      "Epoch [7/10], Step [702/1063], Loss: 0.0205\n",
      "Epoch [7/10], Step [703/1063], Loss: 0.0232\n",
      "Epoch [7/10], Step [704/1063], Loss: 0.0888\n",
      "Epoch [7/10], Step [705/1063], Loss: 0.0693\n",
      "Epoch [7/10], Step [706/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [707/1063], Loss: 0.0041\n",
      "Epoch [7/10], Step [708/1063], Loss: 0.0059\n",
      "Epoch [7/10], Step [709/1063], Loss: 0.0074\n",
      "Epoch [7/10], Step [710/1063], Loss: 0.1828\n",
      "Epoch [7/10], Step [711/1063], Loss: 0.0057\n",
      "Epoch [7/10], Step [712/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [713/1063], Loss: 0.0153\n",
      "Epoch [7/10], Step [714/1063], Loss: 0.0089\n",
      "Epoch [7/10], Step [715/1063], Loss: 0.0052\n",
      "Epoch [7/10], Step [716/1063], Loss: 0.0171\n",
      "Epoch [7/10], Step [717/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [718/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [719/1063], Loss: 0.0084\n",
      "Epoch [7/10], Step [720/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [721/1063], Loss: 0.0037\n",
      "Epoch [7/10], Step [722/1063], Loss: 0.0195\n",
      "Epoch [7/10], Step [723/1063], Loss: 0.0426\n",
      "Epoch [7/10], Step [724/1063], Loss: 0.0035\n",
      "Epoch [7/10], Step [725/1063], Loss: 0.0470\n",
      "Epoch [7/10], Step [726/1063], Loss: 0.0185\n",
      "Epoch [7/10], Step [727/1063], Loss: 0.0041\n",
      "Epoch [7/10], Step [728/1063], Loss: 0.0146\n",
      "Epoch [7/10], Step [729/1063], Loss: 0.0146\n",
      "Epoch [7/10], Step [730/1063], Loss: 0.0396\n",
      "Epoch [7/10], Step [731/1063], Loss: 0.1542\n",
      "Epoch [7/10], Step [732/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [733/1063], Loss: 0.0019\n",
      "Epoch [7/10], Step [734/1063], Loss: 0.0917\n",
      "Epoch [7/10], Step [735/1063], Loss: 0.0144\n",
      "Epoch [7/10], Step [736/1063], Loss: 0.0076\n",
      "Epoch [7/10], Step [737/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [738/1063], Loss: 0.0080\n",
      "Epoch [7/10], Step [739/1063], Loss: 0.0417\n",
      "Epoch [7/10], Step [740/1063], Loss: 0.0158\n",
      "Epoch [7/10], Step [741/1063], Loss: 0.0041\n",
      "Epoch [7/10], Step [742/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [743/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [744/1063], Loss: 0.0098\n",
      "Epoch [7/10], Step [745/1063], Loss: 0.0831\n",
      "Epoch [7/10], Step [746/1063], Loss: 0.0055\n",
      "Epoch [7/10], Step [747/1063], Loss: 0.0239\n",
      "Epoch [7/10], Step [748/1063], Loss: 0.0114\n",
      "Epoch [7/10], Step [749/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [750/1063], Loss: 0.0220\n",
      "Epoch [7/10], Step [751/1063], Loss: 0.0036\n",
      "Epoch [7/10], Step [752/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [753/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [754/1063], Loss: 0.0035\n",
      "Epoch [7/10], Step [755/1063], Loss: 0.0084\n",
      "Epoch [7/10], Step [756/1063], Loss: 0.0074\n",
      "Epoch [7/10], Step [757/1063], Loss: 0.0086\n",
      "Epoch [7/10], Step [758/1063], Loss: 0.0267\n",
      "Epoch [7/10], Step [759/1063], Loss: 0.0111\n",
      "Epoch [7/10], Step [760/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [761/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [762/1063], Loss: 0.0067\n",
      "Epoch [7/10], Step [763/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [764/1063], Loss: 0.0074\n",
      "Epoch [7/10], Step [765/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [766/1063], Loss: 0.0109\n",
      "Epoch [7/10], Step [767/1063], Loss: 0.0033\n",
      "Epoch [7/10], Step [768/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [769/1063], Loss: 0.0085\n",
      "Epoch [7/10], Step [770/1063], Loss: 0.0150\n",
      "Epoch [7/10], Step [771/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [772/1063], Loss: 0.0749\n",
      "Epoch [7/10], Step [773/1063], Loss: 0.0088\n",
      "Epoch [7/10], Step [774/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [775/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [776/1063], Loss: 0.0047\n",
      "Epoch [7/10], Step [777/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [778/1063], Loss: 0.0066\n",
      "Epoch [7/10], Step [779/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [780/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [781/1063], Loss: 0.0028\n",
      "Epoch [7/10], Step [782/1063], Loss: 0.0120\n",
      "Epoch [7/10], Step [783/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [784/1063], Loss: 0.0067\n",
      "Epoch [7/10], Step [785/1063], Loss: 0.0167\n",
      "Epoch [7/10], Step [786/1063], Loss: 0.0059\n",
      "Epoch [7/10], Step [787/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [788/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [789/1063], Loss: 0.0036\n",
      "Epoch [7/10], Step [790/1063], Loss: 0.0654\n",
      "Epoch [7/10], Step [791/1063], Loss: 0.0129\n",
      "Epoch [7/10], Step [792/1063], Loss: 0.0967\n",
      "Epoch [7/10], Step [793/1063], Loss: 0.0022\n",
      "Epoch [7/10], Step [794/1063], Loss: 0.0105\n",
      "Epoch [7/10], Step [795/1063], Loss: 0.0142\n",
      "Epoch [7/10], Step [796/1063], Loss: 0.0151\n",
      "Epoch [7/10], Step [797/1063], Loss: 0.0100\n",
      "Epoch [7/10], Step [798/1063], Loss: 0.0912\n",
      "Epoch [7/10], Step [799/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [800/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [801/1063], Loss: 0.0042\n",
      "Epoch [7/10], Step [802/1063], Loss: 0.0115\n",
      "Epoch [7/10], Step [803/1063], Loss: 0.0230\n",
      "Epoch [7/10], Step [804/1063], Loss: 0.0329\n",
      "Epoch [7/10], Step [805/1063], Loss: 0.0037\n",
      "Epoch [7/10], Step [806/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [807/1063], Loss: 0.0221\n",
      "Epoch [7/10], Step [808/1063], Loss: 0.0278\n",
      "Epoch [7/10], Step [809/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [810/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [811/1063], Loss: 0.0062\n",
      "Epoch [7/10], Step [812/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [813/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [814/1063], Loss: 0.0061\n",
      "Epoch [7/10], Step [815/1063], Loss: 0.0037\n",
      "Epoch [7/10], Step [816/1063], Loss: 0.0163\n",
      "Epoch [7/10], Step [817/1063], Loss: 0.0140\n",
      "Epoch [7/10], Step [818/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [819/1063], Loss: 0.0672\n",
      "Epoch [7/10], Step [820/1063], Loss: 0.0053\n",
      "Epoch [7/10], Step [821/1063], Loss: 0.0118\n",
      "Epoch [7/10], Step [822/1063], Loss: 0.0044\n",
      "Epoch [7/10], Step [823/1063], Loss: 0.0052\n",
      "Epoch [7/10], Step [824/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [825/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [826/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [827/1063], Loss: 0.0067\n",
      "Epoch [7/10], Step [828/1063], Loss: 0.0085\n",
      "Epoch [7/10], Step [829/1063], Loss: 0.0019\n",
      "Epoch [7/10], Step [830/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [831/1063], Loss: 0.0017\n",
      "Epoch [7/10], Step [832/1063], Loss: 0.0254\n",
      "Epoch [7/10], Step [833/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [834/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [835/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [836/1063], Loss: 0.0517\n",
      "Epoch [7/10], Step [837/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [838/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [839/1063], Loss: 0.0149\n",
      "Epoch [7/10], Step [840/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [841/1063], Loss: 0.0695\n",
      "Epoch [7/10], Step [842/1063], Loss: 0.0121\n",
      "Epoch [7/10], Step [843/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [844/1063], Loss: 0.0025\n",
      "Epoch [7/10], Step [845/1063], Loss: 0.1054\n",
      "Epoch [7/10], Step [846/1063], Loss: 0.0239\n",
      "Epoch [7/10], Step [847/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [848/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [849/1063], Loss: 0.0488\n",
      "Epoch [7/10], Step [850/1063], Loss: 0.0203\n",
      "Epoch [7/10], Step [851/1063], Loss: 0.0025\n",
      "Epoch [7/10], Step [852/1063], Loss: 0.0135\n",
      "Epoch [7/10], Step [853/1063], Loss: 0.0166\n",
      "Epoch [7/10], Step [854/1063], Loss: 0.0081\n",
      "Epoch [7/10], Step [855/1063], Loss: 0.0038\n",
      "Epoch [7/10], Step [856/1063], Loss: 0.0322\n",
      "Epoch [7/10], Step [857/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [858/1063], Loss: 0.0063\n",
      "Epoch [7/10], Step [859/1063], Loss: 0.0022\n",
      "Epoch [7/10], Step [860/1063], Loss: 0.0090\n",
      "Epoch [7/10], Step [861/1063], Loss: 0.0277\n",
      "Epoch [7/10], Step [862/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [863/1063], Loss: 0.0057\n",
      "Epoch [7/10], Step [864/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [865/1063], Loss: 0.0075\n",
      "Epoch [7/10], Step [866/1063], Loss: 0.0267\n",
      "Epoch [7/10], Step [867/1063], Loss: 0.0078\n",
      "Epoch [7/10], Step [868/1063], Loss: 0.0909\n",
      "Epoch [7/10], Step [869/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [870/1063], Loss: 0.0034\n",
      "Epoch [7/10], Step [871/1063], Loss: 0.0036\n",
      "Epoch [7/10], Step [872/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [873/1063], Loss: 0.0037\n",
      "Epoch [7/10], Step [874/1063], Loss: 0.0069\n",
      "Epoch [7/10], Step [875/1063], Loss: 0.0129\n",
      "Epoch [7/10], Step [876/1063], Loss: 0.0638\n",
      "Epoch [7/10], Step [877/1063], Loss: 0.1274\n",
      "Epoch [7/10], Step [878/1063], Loss: 0.0928\n",
      "Epoch [7/10], Step [879/1063], Loss: 0.0617\n",
      "Epoch [7/10], Step [880/1063], Loss: 0.0462\n",
      "Epoch [7/10], Step [881/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [882/1063], Loss: 0.0193\n",
      "Epoch [7/10], Step [883/1063], Loss: 0.0079\n",
      "Epoch [7/10], Step [884/1063], Loss: 0.0111\n",
      "Epoch [7/10], Step [885/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [886/1063], Loss: 0.0085\n",
      "Epoch [7/10], Step [887/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [888/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [889/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [890/1063], Loss: 0.0494\n",
      "Epoch [7/10], Step [891/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [892/1063], Loss: 0.0268\n",
      "Epoch [7/10], Step [893/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [894/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [895/1063], Loss: 0.0159\n",
      "Epoch [7/10], Step [896/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [897/1063], Loss: 0.0865\n",
      "Epoch [7/10], Step [898/1063], Loss: 0.0206\n",
      "Epoch [7/10], Step [899/1063], Loss: 0.0122\n",
      "Epoch [7/10], Step [900/1063], Loss: 0.0269\n",
      "Epoch [7/10], Step [901/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [902/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [903/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [904/1063], Loss: 0.0020\n",
      "Epoch [7/10], Step [905/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [906/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [907/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [908/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [909/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [910/1063], Loss: 0.0021\n",
      "Epoch [7/10], Step [911/1063], Loss: 0.0179\n",
      "Epoch [7/10], Step [912/1063], Loss: 0.0177\n",
      "Epoch [7/10], Step [913/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [914/1063], Loss: 0.0036\n",
      "Epoch [7/10], Step [915/1063], Loss: 0.0031\n",
      "Epoch [7/10], Step [916/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [917/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [918/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [919/1063], Loss: 0.0035\n",
      "Epoch [7/10], Step [920/1063], Loss: 0.0028\n",
      "Epoch [7/10], Step [921/1063], Loss: 0.0021\n",
      "Epoch [7/10], Step [922/1063], Loss: 0.0050\n",
      "Epoch [7/10], Step [923/1063], Loss: 0.0533\n",
      "Epoch [7/10], Step [924/1063], Loss: 0.0055\n",
      "Epoch [7/10], Step [925/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [926/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [927/1063], Loss: 0.0065\n",
      "Epoch [7/10], Step [928/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [929/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [930/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [931/1063], Loss: 0.0278\n",
      "Epoch [7/10], Step [932/1063], Loss: 0.0019\n",
      "Epoch [7/10], Step [933/1063], Loss: 0.0014\n",
      "Epoch [7/10], Step [934/1063], Loss: 0.0084\n",
      "Epoch [7/10], Step [935/1063], Loss: 0.0264\n",
      "Epoch [7/10], Step [936/1063], Loss: 0.0033\n",
      "Epoch [7/10], Step [937/1063], Loss: 0.0037\n",
      "Epoch [7/10], Step [938/1063], Loss: 0.0017\n",
      "Epoch [7/10], Step [939/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [940/1063], Loss: 0.0005\n",
      "Epoch [7/10], Step [941/1063], Loss: 0.0051\n",
      "Epoch [7/10], Step [942/1063], Loss: 0.0065\n",
      "Epoch [7/10], Step [943/1063], Loss: 0.0302\n",
      "Epoch [7/10], Step [944/1063], Loss: 0.0030\n",
      "Epoch [7/10], Step [945/1063], Loss: 0.0532\n",
      "Epoch [7/10], Step [946/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [947/1063], Loss: 0.0820\n",
      "Epoch [7/10], Step [948/1063], Loss: 0.0024\n",
      "Epoch [7/10], Step [949/1063], Loss: 0.0059\n",
      "Epoch [7/10], Step [950/1063], Loss: 0.0142\n",
      "Epoch [7/10], Step [951/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [952/1063], Loss: 0.0016\n",
      "Epoch [7/10], Step [953/1063], Loss: 0.0065\n",
      "Epoch [7/10], Step [954/1063], Loss: 0.0714\n",
      "Epoch [7/10], Step [955/1063], Loss: 0.0175\n",
      "Epoch [7/10], Step [956/1063], Loss: 0.0064\n",
      "Epoch [7/10], Step [957/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [958/1063], Loss: 0.0389\n",
      "Epoch [7/10], Step [959/1063], Loss: 0.0032\n",
      "Epoch [7/10], Step [960/1063], Loss: 0.0717\n",
      "Epoch [7/10], Step [961/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [962/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [963/1063], Loss: 0.0025\n",
      "Epoch [7/10], Step [964/1063], Loss: 0.0051\n",
      "Epoch [7/10], Step [965/1063], Loss: 0.0531\n",
      "Epoch [7/10], Step [966/1063], Loss: 0.0032\n",
      "Epoch [7/10], Step [967/1063], Loss: 0.0135\n",
      "Epoch [7/10], Step [968/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [969/1063], Loss: 0.0289\n",
      "Epoch [7/10], Step [970/1063], Loss: 0.0010\n",
      "Epoch [7/10], Step [971/1063], Loss: 0.0404\n",
      "Epoch [7/10], Step [972/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [973/1063], Loss: 0.0011\n",
      "Epoch [7/10], Step [974/1063], Loss: 0.0636\n",
      "Epoch [7/10], Step [975/1063], Loss: 0.0055\n",
      "Epoch [7/10], Step [976/1063], Loss: 0.0266\n",
      "Epoch [7/10], Step [977/1063], Loss: 0.0054\n",
      "Epoch [7/10], Step [978/1063], Loss: 0.0658\n",
      "Epoch [7/10], Step [979/1063], Loss: 0.0115\n",
      "Epoch [7/10], Step [980/1063], Loss: 0.0058\n",
      "Epoch [7/10], Step [981/1063], Loss: 0.0144\n",
      "Epoch [7/10], Step [982/1063], Loss: 0.0021\n",
      "Epoch [7/10], Step [983/1063], Loss: 0.0032\n",
      "Epoch [7/10], Step [984/1063], Loss: 0.0050\n",
      "Epoch [7/10], Step [985/1063], Loss: 0.0085\n",
      "Epoch [7/10], Step [986/1063], Loss: 0.0026\n",
      "Epoch [7/10], Step [987/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [988/1063], Loss: 0.0137\n",
      "Epoch [7/10], Step [989/1063], Loss: 0.0046\n",
      "Epoch [7/10], Step [990/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [991/1063], Loss: 0.0080\n",
      "Epoch [7/10], Step [992/1063], Loss: 0.0174\n",
      "Epoch [7/10], Step [993/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [994/1063], Loss: 0.0139\n",
      "Epoch [7/10], Step [995/1063], Loss: 0.0139\n",
      "Epoch [7/10], Step [996/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [997/1063], Loss: 0.0081\n",
      "Epoch [7/10], Step [998/1063], Loss: 0.0404\n",
      "Epoch [7/10], Step [999/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [1000/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [1001/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [1002/1063], Loss: 0.0157\n",
      "Epoch [7/10], Step [1003/1063], Loss: 0.0105\n",
      "Epoch [7/10], Step [1004/1063], Loss: 0.0021\n",
      "Epoch [7/10], Step [1005/1063], Loss: 0.0032\n",
      "Epoch [7/10], Step [1006/1063], Loss: 0.0008\n",
      "Epoch [7/10], Step [1007/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [1008/1063], Loss: 0.0012\n",
      "Epoch [7/10], Step [1009/1063], Loss: 0.0400\n",
      "Epoch [7/10], Step [1010/1063], Loss: 0.0006\n",
      "Epoch [7/10], Step [1011/1063], Loss: 0.0094\n",
      "Epoch [7/10], Step [1012/1063], Loss: 0.0028\n",
      "Epoch [7/10], Step [1013/1063], Loss: 0.0038\n",
      "Epoch [7/10], Step [1014/1063], Loss: 0.0120\n",
      "Epoch [7/10], Step [1015/1063], Loss: 0.0030\n",
      "Epoch [7/10], Step [1016/1063], Loss: 0.0074\n",
      "Epoch [7/10], Step [1017/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [1018/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [1019/1063], Loss: 0.0156\n",
      "Epoch [7/10], Step [1020/1063], Loss: 0.0596\n",
      "Epoch [7/10], Step [1021/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [1022/1063], Loss: 0.0169\n",
      "Epoch [7/10], Step [1023/1063], Loss: 0.0240\n",
      "Epoch [7/10], Step [1024/1063], Loss: 0.0291\n",
      "Epoch [7/10], Step [1025/1063], Loss: 0.0049\n",
      "Epoch [7/10], Step [1026/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [1027/1063], Loss: 0.0419\n",
      "Epoch [7/10], Step [1028/1063], Loss: 0.0007\n",
      "Epoch [7/10], Step [1029/1063], Loss: 0.0053\n",
      "Epoch [7/10], Step [1030/1063], Loss: 0.0165\n",
      "Epoch [7/10], Step [1031/1063], Loss: 0.0080\n",
      "Epoch [7/10], Step [1032/1063], Loss: 0.0002\n",
      "Epoch [7/10], Step [1033/1063], Loss: 0.0062\n",
      "Epoch [7/10], Step [1034/1063], Loss: 0.0071\n",
      "Epoch [7/10], Step [1035/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [1036/1063], Loss: 0.0009\n",
      "Epoch [7/10], Step [1037/1063], Loss: 0.0078\n",
      "Epoch [7/10], Step [1038/1063], Loss: 0.0034\n",
      "Epoch [7/10], Step [1039/1063], Loss: 0.0018\n",
      "Epoch [7/10], Step [1040/1063], Loss: 0.0000\n",
      "Epoch [7/10], Step [1041/1063], Loss: 0.0030\n",
      "Epoch [7/10], Step [1042/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [1043/1063], Loss: 0.0217\n",
      "Epoch [7/10], Step [1044/1063], Loss: 0.0013\n",
      "Epoch [7/10], Step [1045/1063], Loss: 0.0182\n",
      "Epoch [7/10], Step [1046/1063], Loss: 0.0043\n",
      "Epoch [7/10], Step [1047/1063], Loss: 0.0003\n",
      "Epoch [7/10], Step [1048/1063], Loss: 0.0004\n",
      "Epoch [7/10], Step [1049/1063], Loss: 0.0024\n",
      "Epoch [7/10], Step [1050/1063], Loss: 0.0151\n",
      "Epoch [7/10], Step [1051/1063], Loss: 0.0076\n",
      "Epoch [7/10], Step [1052/1063], Loss: 0.0029\n",
      "Epoch [7/10], Step [1053/1063], Loss: 0.0217\n",
      "Epoch [7/10], Step [1054/1063], Loss: 0.0001\n",
      "Epoch [7/10], Step [1055/1063], Loss: 0.0115\n",
      "Epoch [7/10], Step [1056/1063], Loss: 0.0078\n",
      "Epoch [7/10], Step [1057/1063], Loss: 0.0065\n",
      "Epoch [7/10], Step [1058/1063], Loss: 0.0093\n",
      "Epoch [7/10], Step [1059/1063], Loss: 0.0015\n",
      "Epoch [7/10], Step [1060/1063], Loss: 0.0058\n",
      "Epoch [7/10], Step [1061/1063], Loss: 0.0512\n",
      "Epoch [7/10], Step [1062/1063], Loss: 0.0122\n",
      "Epoch [7/10], Step [1063/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [1/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [2/1063], Loss: 0.0023\n",
      "Epoch [8/10], Step [3/1063], Loss: 0.0018\n",
      "Epoch [8/10], Step [4/1063], Loss: 0.0289\n",
      "Epoch [8/10], Step [5/1063], Loss: 0.0022\n",
      "Epoch [8/10], Step [6/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [7/1063], Loss: 0.0024\n",
      "Epoch [8/10], Step [8/1063], Loss: 0.0026\n",
      "Epoch [8/10], Step [9/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [10/1063], Loss: 0.0023\n",
      "Epoch [8/10], Step [11/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [12/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [13/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [14/1063], Loss: 0.0106\n",
      "Epoch [8/10], Step [15/1063], Loss: 0.0198\n",
      "Epoch [8/10], Step [16/1063], Loss: 0.0028\n",
      "Epoch [8/10], Step [17/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [18/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [19/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [20/1063], Loss: 0.1004\n",
      "Epoch [8/10], Step [21/1063], Loss: 0.0769\n",
      "Epoch [8/10], Step [22/1063], Loss: 0.0330\n",
      "Epoch [8/10], Step [23/1063], Loss: 0.0025\n",
      "Epoch [8/10], Step [24/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [25/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [26/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [27/1063], Loss: 0.0278\n",
      "Epoch [8/10], Step [28/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [29/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [30/1063], Loss: 0.0172\n",
      "Epoch [8/10], Step [31/1063], Loss: 0.0037\n",
      "Epoch [8/10], Step [32/1063], Loss: 0.0022\n",
      "Epoch [8/10], Step [33/1063], Loss: 0.0067\n",
      "Epoch [8/10], Step [34/1063], Loss: 0.0046\n",
      "Epoch [8/10], Step [35/1063], Loss: 0.0099\n",
      "Epoch [8/10], Step [36/1063], Loss: 0.0045\n",
      "Epoch [8/10], Step [37/1063], Loss: 0.0375\n",
      "Epoch [8/10], Step [38/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [39/1063], Loss: 0.0125\n",
      "Epoch [8/10], Step [40/1063], Loss: 0.0321\n",
      "Epoch [8/10], Step [41/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [42/1063], Loss: 0.0095\n",
      "Epoch [8/10], Step [43/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [44/1063], Loss: 0.0050\n",
      "Epoch [8/10], Step [45/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [46/1063], Loss: 0.0033\n",
      "Epoch [8/10], Step [47/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [48/1063], Loss: 0.0117\n",
      "Epoch [8/10], Step [49/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [50/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [51/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [52/1063], Loss: 0.0083\n",
      "Epoch [8/10], Step [53/1063], Loss: 0.0114\n",
      "Epoch [8/10], Step [54/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [55/1063], Loss: 0.0123\n",
      "Epoch [8/10], Step [56/1063], Loss: 0.0253\n",
      "Epoch [8/10], Step [57/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [58/1063], Loss: 0.0072\n",
      "Epoch [8/10], Step [59/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [60/1063], Loss: 0.0023\n",
      "Epoch [8/10], Step [61/1063], Loss: 0.0222\n",
      "Epoch [8/10], Step [62/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [63/1063], Loss: 0.0043\n",
      "Epoch [8/10], Step [64/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [65/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [66/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [67/1063], Loss: 0.0042\n",
      "Epoch [8/10], Step [68/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [69/1063], Loss: 0.0050\n",
      "Epoch [8/10], Step [70/1063], Loss: 0.0177\n",
      "Epoch [8/10], Step [71/1063], Loss: 0.0036\n",
      "Epoch [8/10], Step [72/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [73/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [74/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [75/1063], Loss: 0.0535\n",
      "Epoch [8/10], Step [76/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [77/1063], Loss: 0.0022\n",
      "Epoch [8/10], Step [78/1063], Loss: 0.0075\n",
      "Epoch [8/10], Step [79/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [80/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [81/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [82/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [83/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [84/1063], Loss: 0.0372\n",
      "Epoch [8/10], Step [85/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [86/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [87/1063], Loss: 0.0038\n",
      "Epoch [8/10], Step [88/1063], Loss: 0.0340\n",
      "Epoch [8/10], Step [89/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [90/1063], Loss: 0.0032\n",
      "Epoch [8/10], Step [91/1063], Loss: 0.0018\n",
      "Epoch [8/10], Step [92/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [93/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [94/1063], Loss: 0.0108\n",
      "Epoch [8/10], Step [95/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [96/1063], Loss: 0.0017\n",
      "Epoch [8/10], Step [97/1063], Loss: 0.0076\n",
      "Epoch [8/10], Step [98/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [99/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [100/1063], Loss: 0.0068\n",
      "Epoch [8/10], Step [101/1063], Loss: 0.0048\n",
      "Epoch [8/10], Step [102/1063], Loss: 0.0087\n",
      "Epoch [8/10], Step [103/1063], Loss: 0.0030\n",
      "Epoch [8/10], Step [104/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [105/1063], Loss: 0.0201\n",
      "Epoch [8/10], Step [106/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [107/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [108/1063], Loss: 0.0026\n",
      "Epoch [8/10], Step [109/1063], Loss: 0.0043\n",
      "Epoch [8/10], Step [110/1063], Loss: 0.0212\n",
      "Epoch [8/10], Step [111/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [112/1063], Loss: 0.0274\n",
      "Epoch [8/10], Step [113/1063], Loss: 0.0181\n",
      "Epoch [8/10], Step [114/1063], Loss: 0.0088\n",
      "Epoch [8/10], Step [115/1063], Loss: 0.0039\n",
      "Epoch [8/10], Step [116/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [117/1063], Loss: 0.0066\n",
      "Epoch [8/10], Step [118/1063], Loss: 0.0192\n",
      "Epoch [8/10], Step [119/1063], Loss: 0.0289\n",
      "Epoch [8/10], Step [120/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [121/1063], Loss: 0.0017\n",
      "Epoch [8/10], Step [122/1063], Loss: 0.0600\n",
      "Epoch [8/10], Step [123/1063], Loss: 0.0023\n",
      "Epoch [8/10], Step [124/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [125/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [126/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [127/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [128/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [129/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [130/1063], Loss: 0.0092\n",
      "Epoch [8/10], Step [131/1063], Loss: 0.0077\n",
      "Epoch [8/10], Step [132/1063], Loss: 0.0045\n",
      "Epoch [8/10], Step [133/1063], Loss: 0.0105\n",
      "Epoch [8/10], Step [134/1063], Loss: 0.0024\n",
      "Epoch [8/10], Step [135/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [136/1063], Loss: 0.0359\n",
      "Epoch [8/10], Step [137/1063], Loss: 0.0073\n",
      "Epoch [8/10], Step [138/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [139/1063], Loss: 0.0081\n",
      "Epoch [8/10], Step [140/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [141/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [142/1063], Loss: 0.0172\n",
      "Epoch [8/10], Step [143/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [144/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [145/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [146/1063], Loss: 0.0034\n",
      "Epoch [8/10], Step [147/1063], Loss: 0.0053\n",
      "Epoch [8/10], Step [148/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [149/1063], Loss: 0.0443\n",
      "Epoch [8/10], Step [150/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [151/1063], Loss: 0.0276\n",
      "Epoch [8/10], Step [152/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [153/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [154/1063], Loss: 0.0086\n",
      "Epoch [8/10], Step [155/1063], Loss: 0.0211\n",
      "Epoch [8/10], Step [156/1063], Loss: 0.0350\n",
      "Epoch [8/10], Step [157/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [158/1063], Loss: 0.0097\n",
      "Epoch [8/10], Step [159/1063], Loss: 0.0149\n",
      "Epoch [8/10], Step [160/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [161/1063], Loss: 0.0079\n",
      "Epoch [8/10], Step [162/1063], Loss: 0.0060\n",
      "Epoch [8/10], Step [163/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [164/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [165/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [166/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [167/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [168/1063], Loss: 0.0039\n",
      "Epoch [8/10], Step [169/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [170/1063], Loss: 0.0032\n",
      "Epoch [8/10], Step [171/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [172/1063], Loss: 0.0061\n",
      "Epoch [8/10], Step [173/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [174/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [175/1063], Loss: 0.0038\n",
      "Epoch [8/10], Step [176/1063], Loss: 0.0217\n",
      "Epoch [8/10], Step [177/1063], Loss: 0.0049\n",
      "Epoch [8/10], Step [178/1063], Loss: 0.0081\n",
      "Epoch [8/10], Step [179/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [180/1063], Loss: 0.0013\n",
      "Epoch [8/10], Step [181/1063], Loss: 0.0071\n",
      "Epoch [8/10], Step [182/1063], Loss: 0.0036\n",
      "Epoch [8/10], Step [183/1063], Loss: 0.0024\n",
      "Epoch [8/10], Step [184/1063], Loss: 0.0055\n",
      "Epoch [8/10], Step [185/1063], Loss: 0.0156\n",
      "Epoch [8/10], Step [186/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [187/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [188/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [189/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [190/1063], Loss: 0.0032\n",
      "Epoch [8/10], Step [191/1063], Loss: 0.0131\n",
      "Epoch [8/10], Step [192/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [193/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [194/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [195/1063], Loss: 0.0049\n",
      "Epoch [8/10], Step [196/1063], Loss: 0.0032\n",
      "Epoch [8/10], Step [197/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [198/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [199/1063], Loss: 0.0054\n",
      "Epoch [8/10], Step [200/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [201/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [202/1063], Loss: 0.0202\n",
      "Epoch [8/10], Step [203/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [204/1063], Loss: 0.0190\n",
      "Epoch [8/10], Step [205/1063], Loss: 0.0018\n",
      "Epoch [8/10], Step [206/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [207/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [208/1063], Loss: 0.0013\n",
      "Epoch [8/10], Step [209/1063], Loss: 0.0037\n",
      "Epoch [8/10], Step [210/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [211/1063], Loss: 0.0065\n",
      "Epoch [8/10], Step [212/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [213/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [214/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [215/1063], Loss: 0.0034\n",
      "Epoch [8/10], Step [216/1063], Loss: 0.0040\n",
      "Epoch [8/10], Step [217/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [218/1063], Loss: 0.0238\n",
      "Epoch [8/10], Step [219/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [220/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [221/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [222/1063], Loss: 0.0165\n",
      "Epoch [8/10], Step [223/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [224/1063], Loss: 0.0045\n",
      "Epoch [8/10], Step [225/1063], Loss: 0.0013\n",
      "Epoch [8/10], Step [226/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [227/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [228/1063], Loss: 0.0041\n",
      "Epoch [8/10], Step [229/1063], Loss: 0.0923\n",
      "Epoch [8/10], Step [230/1063], Loss: 0.0060\n",
      "Epoch [8/10], Step [231/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [232/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [233/1063], Loss: 0.0033\n",
      "Epoch [8/10], Step [234/1063], Loss: 0.0038\n",
      "Epoch [8/10], Step [235/1063], Loss: 0.0980\n",
      "Epoch [8/10], Step [236/1063], Loss: 0.0059\n",
      "Epoch [8/10], Step [237/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [238/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [239/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [240/1063], Loss: 0.0035\n",
      "Epoch [8/10], Step [241/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [242/1063], Loss: 0.0217\n",
      "Epoch [8/10], Step [243/1063], Loss: 0.0109\n",
      "Epoch [8/10], Step [244/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [245/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [246/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [247/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [248/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [249/1063], Loss: 0.0017\n",
      "Epoch [8/10], Step [250/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [251/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [252/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [253/1063], Loss: 0.0605\n",
      "Epoch [8/10], Step [254/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [255/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [256/1063], Loss: 0.0036\n",
      "Epoch [8/10], Step [257/1063], Loss: 0.0117\n",
      "Epoch [8/10], Step [258/1063], Loss: 0.0082\n",
      "Epoch [8/10], Step [259/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [260/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [261/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [262/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [263/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [264/1063], Loss: 0.0472\n",
      "Epoch [8/10], Step [265/1063], Loss: 0.0427\n",
      "Epoch [8/10], Step [266/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [267/1063], Loss: 0.0033\n",
      "Epoch [8/10], Step [268/1063], Loss: 0.0022\n",
      "Epoch [8/10], Step [269/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [270/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [271/1063], Loss: 0.0105\n",
      "Epoch [8/10], Step [272/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [273/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [274/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [275/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [276/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [277/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [278/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [279/1063], Loss: 0.0923\n",
      "Epoch [8/10], Step [280/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [281/1063], Loss: 0.0691\n",
      "Epoch [8/10], Step [282/1063], Loss: 0.0039\n",
      "Epoch [8/10], Step [283/1063], Loss: 0.0030\n",
      "Epoch [8/10], Step [284/1063], Loss: 0.0034\n",
      "Epoch [8/10], Step [285/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [286/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [287/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [288/1063], Loss: 0.0022\n",
      "Epoch [8/10], Step [289/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [290/1063], Loss: 0.0117\n",
      "Epoch [8/10], Step [291/1063], Loss: 0.0024\n",
      "Epoch [8/10], Step [292/1063], Loss: 0.0338\n",
      "Epoch [8/10], Step [293/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [294/1063], Loss: 0.1188\n",
      "Epoch [8/10], Step [295/1063], Loss: 0.0099\n",
      "Epoch [8/10], Step [296/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [297/1063], Loss: 0.0025\n",
      "Epoch [8/10], Step [298/1063], Loss: 0.0039\n",
      "Epoch [8/10], Step [299/1063], Loss: 0.1126\n",
      "Epoch [8/10], Step [300/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [301/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [302/1063], Loss: 0.0154\n",
      "Epoch [8/10], Step [303/1063], Loss: 0.0105\n",
      "Epoch [8/10], Step [304/1063], Loss: 0.0023\n",
      "Epoch [8/10], Step [305/1063], Loss: 0.0040\n",
      "Epoch [8/10], Step [306/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [307/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [308/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [309/1063], Loss: 0.0182\n",
      "Epoch [8/10], Step [310/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [311/1063], Loss: 0.0104\n",
      "Epoch [8/10], Step [312/1063], Loss: 0.0198\n",
      "Epoch [8/10], Step [313/1063], Loss: 0.0018\n",
      "Epoch [8/10], Step [314/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [315/1063], Loss: 0.0143\n",
      "Epoch [8/10], Step [316/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [317/1063], Loss: 0.0024\n",
      "Epoch [8/10], Step [318/1063], Loss: 0.0121\n",
      "Epoch [8/10], Step [319/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [320/1063], Loss: 0.0328\n",
      "Epoch [8/10], Step [321/1063], Loss: 0.0157\n",
      "Epoch [8/10], Step [322/1063], Loss: 0.0085\n",
      "Epoch [8/10], Step [323/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [324/1063], Loss: 0.0108\n",
      "Epoch [8/10], Step [325/1063], Loss: 0.0020\n",
      "Epoch [8/10], Step [326/1063], Loss: 0.0307\n",
      "Epoch [8/10], Step [327/1063], Loss: 0.0035\n",
      "Epoch [8/10], Step [328/1063], Loss: 0.0307\n",
      "Epoch [8/10], Step [329/1063], Loss: 0.0050\n",
      "Epoch [8/10], Step [330/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [331/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [332/1063], Loss: 0.0067\n",
      "Epoch [8/10], Step [333/1063], Loss: 0.0077\n",
      "Epoch [8/10], Step [334/1063], Loss: 0.0097\n",
      "Epoch [8/10], Step [335/1063], Loss: 0.0077\n",
      "Epoch [8/10], Step [336/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [337/1063], Loss: 0.0025\n",
      "Epoch [8/10], Step [338/1063], Loss: 0.0023\n",
      "Epoch [8/10], Step [339/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [340/1063], Loss: 0.0099\n",
      "Epoch [8/10], Step [341/1063], Loss: 0.0075\n",
      "Epoch [8/10], Step [342/1063], Loss: 0.0344\n",
      "Epoch [8/10], Step [343/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [344/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [345/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [346/1063], Loss: 0.0045\n",
      "Epoch [8/10], Step [347/1063], Loss: 0.0031\n",
      "Epoch [8/10], Step [348/1063], Loss: 0.0031\n",
      "Epoch [8/10], Step [349/1063], Loss: 0.1006\n",
      "Epoch [8/10], Step [350/1063], Loss: 0.0078\n",
      "Epoch [8/10], Step [351/1063], Loss: 0.0175\n",
      "Epoch [8/10], Step [352/1063], Loss: 0.0498\n",
      "Epoch [8/10], Step [353/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [354/1063], Loss: 0.0130\n",
      "Epoch [8/10], Step [355/1063], Loss: 0.0249\n",
      "Epoch [8/10], Step [356/1063], Loss: 0.0590\n",
      "Epoch [8/10], Step [357/1063], Loss: 0.0369\n",
      "Epoch [8/10], Step [358/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [359/1063], Loss: 0.0044\n",
      "Epoch [8/10], Step [360/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [361/1063], Loss: 0.0026\n",
      "Epoch [8/10], Step [362/1063], Loss: 0.0161\n",
      "Epoch [8/10], Step [363/1063], Loss: 0.0412\n",
      "Epoch [8/10], Step [364/1063], Loss: 0.0057\n",
      "Epoch [8/10], Step [365/1063], Loss: 0.0030\n",
      "Epoch [8/10], Step [366/1063], Loss: 0.0348\n",
      "Epoch [8/10], Step [367/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [368/1063], Loss: 0.0023\n",
      "Epoch [8/10], Step [369/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [370/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [371/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [372/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [373/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [374/1063], Loss: 0.0220\n",
      "Epoch [8/10], Step [375/1063], Loss: 0.0040\n",
      "Epoch [8/10], Step [376/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [377/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [378/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [379/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [380/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [381/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [382/1063], Loss: 0.0035\n",
      "Epoch [8/10], Step [383/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [384/1063], Loss: 0.0745\n",
      "Epoch [8/10], Step [385/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [386/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [387/1063], Loss: 0.0076\n",
      "Epoch [8/10], Step [388/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [389/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [390/1063], Loss: 0.0241\n",
      "Epoch [8/10], Step [391/1063], Loss: 0.0631\n",
      "Epoch [8/10], Step [392/1063], Loss: 0.0185\n",
      "Epoch [8/10], Step [393/1063], Loss: 0.0026\n",
      "Epoch [8/10], Step [394/1063], Loss: 0.0013\n",
      "Epoch [8/10], Step [395/1063], Loss: 0.0079\n",
      "Epoch [8/10], Step [396/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [397/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [398/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [399/1063], Loss: 0.0040\n",
      "Epoch [8/10], Step [400/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [401/1063], Loss: 0.0080\n",
      "Epoch [8/10], Step [402/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [403/1063], Loss: 0.0027\n",
      "Epoch [8/10], Step [404/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [405/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [406/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [407/1063], Loss: 0.0030\n",
      "Epoch [8/10], Step [408/1063], Loss: 0.0129\n",
      "Epoch [8/10], Step [409/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [410/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [411/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [412/1063], Loss: 0.0020\n",
      "Epoch [8/10], Step [413/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [414/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [415/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [416/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [417/1063], Loss: 0.0844\n",
      "Epoch [8/10], Step [418/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [419/1063], Loss: 0.0188\n",
      "Epoch [8/10], Step [420/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [421/1063], Loss: 0.0048\n",
      "Epoch [8/10], Step [422/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [423/1063], Loss: 0.0254\n",
      "Epoch [8/10], Step [424/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [425/1063], Loss: 0.0037\n",
      "Epoch [8/10], Step [426/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [427/1063], Loss: 0.0078\n",
      "Epoch [8/10], Step [428/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [429/1063], Loss: 0.0158\n",
      "Epoch [8/10], Step [430/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [431/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [432/1063], Loss: 0.0030\n",
      "Epoch [8/10], Step [433/1063], Loss: 0.0041\n",
      "Epoch [8/10], Step [434/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [435/1063], Loss: 0.0120\n",
      "Epoch [8/10], Step [436/1063], Loss: 0.0017\n",
      "Epoch [8/10], Step [437/1063], Loss: 0.0017\n",
      "Epoch [8/10], Step [438/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [439/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [440/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [441/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [442/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [443/1063], Loss: 0.0150\n",
      "Epoch [8/10], Step [444/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [445/1063], Loss: 0.0318\n",
      "Epoch [8/10], Step [446/1063], Loss: 0.0396\n",
      "Epoch [8/10], Step [447/1063], Loss: 0.0075\n",
      "Epoch [8/10], Step [448/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [449/1063], Loss: 0.0040\n",
      "Epoch [8/10], Step [450/1063], Loss: 0.0304\n",
      "Epoch [8/10], Step [451/1063], Loss: 0.0017\n",
      "Epoch [8/10], Step [452/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [453/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [454/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [455/1063], Loss: 0.0069\n",
      "Epoch [8/10], Step [456/1063], Loss: 0.0569\n",
      "Epoch [8/10], Step [457/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [458/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [459/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [460/1063], Loss: 0.0025\n",
      "Epoch [8/10], Step [461/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [462/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [463/1063], Loss: 0.0203\n",
      "Epoch [8/10], Step [464/1063], Loss: 0.0080\n",
      "Epoch [8/10], Step [465/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [466/1063], Loss: 0.0407\n",
      "Epoch [8/10], Step [467/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [468/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [469/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [470/1063], Loss: 0.0038\n",
      "Epoch [8/10], Step [471/1063], Loss: 0.0189\n",
      "Epoch [8/10], Step [472/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [473/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [474/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [475/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [476/1063], Loss: 0.0030\n",
      "Epoch [8/10], Step [477/1063], Loss: 0.0122\n",
      "Epoch [8/10], Step [478/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [479/1063], Loss: 0.0453\n",
      "Epoch [8/10], Step [480/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [481/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [482/1063], Loss: 0.0024\n",
      "Epoch [8/10], Step [483/1063], Loss: 0.0044\n",
      "Epoch [8/10], Step [484/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [485/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [486/1063], Loss: 0.0023\n",
      "Epoch [8/10], Step [487/1063], Loss: 0.0826\n",
      "Epoch [8/10], Step [488/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [489/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [490/1063], Loss: 0.0061\n",
      "Epoch [8/10], Step [491/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [492/1063], Loss: 0.0130\n",
      "Epoch [8/10], Step [493/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [494/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [495/1063], Loss: 0.0022\n",
      "Epoch [8/10], Step [496/1063], Loss: 0.0245\n",
      "Epoch [8/10], Step [497/1063], Loss: 0.0024\n",
      "Epoch [8/10], Step [498/1063], Loss: 0.0074\n",
      "Epoch [8/10], Step [499/1063], Loss: 0.0243\n",
      "Epoch [8/10], Step [500/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [501/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [502/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [503/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [504/1063], Loss: 0.0020\n",
      "Epoch [8/10], Step [505/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [506/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [507/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [508/1063], Loss: 0.0238\n",
      "Epoch [8/10], Step [509/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [510/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [511/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [512/1063], Loss: 0.0022\n",
      "Epoch [8/10], Step [513/1063], Loss: 0.0248\n",
      "Epoch [8/10], Step [514/1063], Loss: 0.0110\n",
      "Epoch [8/10], Step [515/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [516/1063], Loss: 0.0013\n",
      "Epoch [8/10], Step [517/1063], Loss: 0.0108\n",
      "Epoch [8/10], Step [518/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [519/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [520/1063], Loss: 0.0031\n",
      "Epoch [8/10], Step [521/1063], Loss: 0.0622\n",
      "Epoch [8/10], Step [522/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [523/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [524/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [525/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [526/1063], Loss: 0.0128\n",
      "Epoch [8/10], Step [527/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [528/1063], Loss: 0.0161\n",
      "Epoch [8/10], Step [529/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [530/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [531/1063], Loss: 0.0396\n",
      "Epoch [8/10], Step [532/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [533/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [534/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [535/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [536/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [537/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [538/1063], Loss: 0.0028\n",
      "Epoch [8/10], Step [539/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [540/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [541/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [542/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [543/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [544/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [545/1063], Loss: 0.0030\n",
      "Epoch [8/10], Step [546/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [547/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [548/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [549/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [550/1063], Loss: 0.0061\n",
      "Epoch [8/10], Step [551/1063], Loss: 0.0788\n",
      "Epoch [8/10], Step [552/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [553/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [554/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [555/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [556/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [557/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [558/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [559/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [560/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [561/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [562/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [563/1063], Loss: 0.0364\n",
      "Epoch [8/10], Step [564/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [565/1063], Loss: 0.0146\n",
      "Epoch [8/10], Step [566/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [567/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [568/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [569/1063], Loss: 0.0089\n",
      "Epoch [8/10], Step [570/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [571/1063], Loss: 0.0018\n",
      "Epoch [8/10], Step [572/1063], Loss: 0.0180\n",
      "Epoch [8/10], Step [573/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [574/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [575/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [576/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [577/1063], Loss: 0.0017\n",
      "Epoch [8/10], Step [578/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [579/1063], Loss: 0.0212\n",
      "Epoch [8/10], Step [580/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [581/1063], Loss: 0.0407\n",
      "Epoch [8/10], Step [582/1063], Loss: 0.0028\n",
      "Epoch [8/10], Step [583/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [584/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [585/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [586/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [587/1063], Loss: 0.0017\n",
      "Epoch [8/10], Step [588/1063], Loss: 0.0040\n",
      "Epoch [8/10], Step [589/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [590/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [591/1063], Loss: 0.0085\n",
      "Epoch [8/10], Step [592/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [593/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [594/1063], Loss: 0.1021\n",
      "Epoch [8/10], Step [595/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [596/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [597/1063], Loss: 0.0039\n",
      "Epoch [8/10], Step [598/1063], Loss: 0.0024\n",
      "Epoch [8/10], Step [599/1063], Loss: 0.0317\n",
      "Epoch [8/10], Step [600/1063], Loss: 0.0025\n",
      "Epoch [8/10], Step [601/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [602/1063], Loss: 0.0231\n",
      "Epoch [8/10], Step [603/1063], Loss: 0.0038\n",
      "Epoch [8/10], Step [604/1063], Loss: 0.0037\n",
      "Epoch [8/10], Step [605/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [606/1063], Loss: 0.0013\n",
      "Epoch [8/10], Step [607/1063], Loss: 0.0045\n",
      "Epoch [8/10], Step [608/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [609/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [610/1063], Loss: 0.0072\n",
      "Epoch [8/10], Step [611/1063], Loss: 0.0035\n",
      "Epoch [8/10], Step [612/1063], Loss: 0.0192\n",
      "Epoch [8/10], Step [613/1063], Loss: 0.0034\n",
      "Epoch [8/10], Step [614/1063], Loss: 0.0032\n",
      "Epoch [8/10], Step [615/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [616/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [617/1063], Loss: 0.0065\n",
      "Epoch [8/10], Step [618/1063], Loss: 0.0430\n",
      "Epoch [8/10], Step [619/1063], Loss: 0.0331\n",
      "Epoch [8/10], Step [620/1063], Loss: 0.0030\n",
      "Epoch [8/10], Step [621/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [622/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [623/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [624/1063], Loss: 0.0338\n",
      "Epoch [8/10], Step [625/1063], Loss: 0.0018\n",
      "Epoch [8/10], Step [626/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [627/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [628/1063], Loss: 0.1048\n",
      "Epoch [8/10], Step [629/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [630/1063], Loss: 0.0020\n",
      "Epoch [8/10], Step [631/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [632/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [633/1063], Loss: 0.2147\n",
      "Epoch [8/10], Step [634/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [635/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [636/1063], Loss: 0.0273\n",
      "Epoch [8/10], Step [637/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [638/1063], Loss: 0.0061\n",
      "Epoch [8/10], Step [639/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [640/1063], Loss: 0.0161\n",
      "Epoch [8/10], Step [641/1063], Loss: 0.0030\n",
      "Epoch [8/10], Step [642/1063], Loss: 0.0089\n",
      "Epoch [8/10], Step [643/1063], Loss: 0.0077\n",
      "Epoch [8/10], Step [644/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [645/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [646/1063], Loss: 0.0037\n",
      "Epoch [8/10], Step [647/1063], Loss: 0.0027\n",
      "Epoch [8/10], Step [648/1063], Loss: 0.0124\n",
      "Epoch [8/10], Step [649/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [650/1063], Loss: 0.0433\n",
      "Epoch [8/10], Step [651/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [652/1063], Loss: 0.0056\n",
      "Epoch [8/10], Step [653/1063], Loss: 0.0040\n",
      "Epoch [8/10], Step [654/1063], Loss: 0.1208\n",
      "Epoch [8/10], Step [655/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [656/1063], Loss: 0.0076\n",
      "Epoch [8/10], Step [657/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [658/1063], Loss: 0.0762\n",
      "Epoch [8/10], Step [659/1063], Loss: 0.0574\n",
      "Epoch [8/10], Step [660/1063], Loss: 0.0041\n",
      "Epoch [8/10], Step [661/1063], Loss: 0.0075\n",
      "Epoch [8/10], Step [662/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [663/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [664/1063], Loss: 0.0216\n",
      "Epoch [8/10], Step [665/1063], Loss: 0.0040\n",
      "Epoch [8/10], Step [666/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [667/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [668/1063], Loss: 0.0155\n",
      "Epoch [8/10], Step [669/1063], Loss: 0.0031\n",
      "Epoch [8/10], Step [670/1063], Loss: 0.0258\n",
      "Epoch [8/10], Step [671/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [672/1063], Loss: 0.0594\n",
      "Epoch [8/10], Step [673/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [674/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [675/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [676/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [677/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [678/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [679/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [680/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [681/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [682/1063], Loss: 0.0031\n",
      "Epoch [8/10], Step [683/1063], Loss: 0.0101\n",
      "Epoch [8/10], Step [684/1063], Loss: 0.0179\n",
      "Epoch [8/10], Step [685/1063], Loss: 0.0022\n",
      "Epoch [8/10], Step [686/1063], Loss: 0.0041\n",
      "Epoch [8/10], Step [687/1063], Loss: 0.0033\n",
      "Epoch [8/10], Step [688/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [689/1063], Loss: 0.0148\n",
      "Epoch [8/10], Step [690/1063], Loss: 0.0154\n",
      "Epoch [8/10], Step [691/1063], Loss: 0.0168\n",
      "Epoch [8/10], Step [692/1063], Loss: 0.0044\n",
      "Epoch [8/10], Step [693/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [694/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [695/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [696/1063], Loss: 0.0026\n",
      "Epoch [8/10], Step [697/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [698/1063], Loss: 0.0083\n",
      "Epoch [8/10], Step [699/1063], Loss: 0.0395\n",
      "Epoch [8/10], Step [700/1063], Loss: 0.0042\n",
      "Epoch [8/10], Step [701/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [702/1063], Loss: 0.0077\n",
      "Epoch [8/10], Step [703/1063], Loss: 0.0049\n",
      "Epoch [8/10], Step [704/1063], Loss: 0.0040\n",
      "Epoch [8/10], Step [705/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [706/1063], Loss: 0.0038\n",
      "Epoch [8/10], Step [707/1063], Loss: 0.0025\n",
      "Epoch [8/10], Step [708/1063], Loss: 0.0092\n",
      "Epoch [8/10], Step [709/1063], Loss: 0.0162\n",
      "Epoch [8/10], Step [710/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [711/1063], Loss: 0.0101\n",
      "Epoch [8/10], Step [712/1063], Loss: 0.0205\n",
      "Epoch [8/10], Step [713/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [714/1063], Loss: 0.0256\n",
      "Epoch [8/10], Step [715/1063], Loss: 0.0100\n",
      "Epoch [8/10], Step [716/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [717/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [718/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [719/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [720/1063], Loss: 0.0623\n",
      "Epoch [8/10], Step [721/1063], Loss: 0.0020\n",
      "Epoch [8/10], Step [722/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [723/1063], Loss: 0.2057\n",
      "Epoch [8/10], Step [724/1063], Loss: 0.0049\n",
      "Epoch [8/10], Step [725/1063], Loss: 0.0055\n",
      "Epoch [8/10], Step [726/1063], Loss: 0.0161\n",
      "Epoch [8/10], Step [727/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [728/1063], Loss: 0.0176\n",
      "Epoch [8/10], Step [729/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [730/1063], Loss: 0.0026\n",
      "Epoch [8/10], Step [731/1063], Loss: 0.0024\n",
      "Epoch [8/10], Step [732/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [733/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [734/1063], Loss: 0.0025\n",
      "Epoch [8/10], Step [735/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [736/1063], Loss: 0.0071\n",
      "Epoch [8/10], Step [737/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [738/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [739/1063], Loss: 0.0108\n",
      "Epoch [8/10], Step [740/1063], Loss: 0.0024\n",
      "Epoch [8/10], Step [741/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [742/1063], Loss: 0.0182\n",
      "Epoch [8/10], Step [743/1063], Loss: 0.0018\n",
      "Epoch [8/10], Step [744/1063], Loss: 0.0036\n",
      "Epoch [8/10], Step [745/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [746/1063], Loss: 0.0146\n",
      "Epoch [8/10], Step [747/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [748/1063], Loss: 0.0534\n",
      "Epoch [8/10], Step [749/1063], Loss: 0.0023\n",
      "Epoch [8/10], Step [750/1063], Loss: 0.0205\n",
      "Epoch [8/10], Step [751/1063], Loss: 0.0356\n",
      "Epoch [8/10], Step [752/1063], Loss: 0.0023\n",
      "Epoch [8/10], Step [753/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [754/1063], Loss: 0.0108\n",
      "Epoch [8/10], Step [755/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [756/1063], Loss: 0.0090\n",
      "Epoch [8/10], Step [757/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [758/1063], Loss: 0.0411\n",
      "Epoch [8/10], Step [759/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [760/1063], Loss: 0.0013\n",
      "Epoch [8/10], Step [761/1063], Loss: 0.0112\n",
      "Epoch [8/10], Step [762/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [763/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [764/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [765/1063], Loss: 0.0058\n",
      "Epoch [8/10], Step [766/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [767/1063], Loss: 0.0055\n",
      "Epoch [8/10], Step [768/1063], Loss: 0.0136\n",
      "Epoch [8/10], Step [769/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [770/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [771/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [772/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [773/1063], Loss: 0.0064\n",
      "Epoch [8/10], Step [774/1063], Loss: 0.0287\n",
      "Epoch [8/10], Step [775/1063], Loss: 0.0193\n",
      "Epoch [8/10], Step [776/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [777/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [778/1063], Loss: 0.0049\n",
      "Epoch [8/10], Step [779/1063], Loss: 0.0058\n",
      "Epoch [8/10], Step [780/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [781/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [782/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [783/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [784/1063], Loss: 0.0157\n",
      "Epoch [8/10], Step [785/1063], Loss: 0.0112\n",
      "Epoch [8/10], Step [786/1063], Loss: 0.0028\n",
      "Epoch [8/10], Step [787/1063], Loss: 0.0046\n",
      "Epoch [8/10], Step [788/1063], Loss: 0.0092\n",
      "Epoch [8/10], Step [789/1063], Loss: 0.0132\n",
      "Epoch [8/10], Step [790/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [791/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [792/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [793/1063], Loss: 0.0546\n",
      "Epoch [8/10], Step [794/1063], Loss: 0.0050\n",
      "Epoch [8/10], Step [795/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [796/1063], Loss: 0.0036\n",
      "Epoch [8/10], Step [797/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [798/1063], Loss: 0.0062\n",
      "Epoch [8/10], Step [799/1063], Loss: 0.0109\n",
      "Epoch [8/10], Step [800/1063], Loss: 0.0037\n",
      "Epoch [8/10], Step [801/1063], Loss: 0.0216\n",
      "Epoch [8/10], Step [802/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [803/1063], Loss: 0.1257\n",
      "Epoch [8/10], Step [804/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [805/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [806/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [807/1063], Loss: 0.0309\n",
      "Epoch [8/10], Step [808/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [809/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [810/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [811/1063], Loss: 0.0023\n",
      "Epoch [8/10], Step [812/1063], Loss: 0.0133\n",
      "Epoch [8/10], Step [813/1063], Loss: 0.0095\n",
      "Epoch [8/10], Step [814/1063], Loss: 0.0020\n",
      "Epoch [8/10], Step [815/1063], Loss: 0.0394\n",
      "Epoch [8/10], Step [816/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [817/1063], Loss: 0.0025\n",
      "Epoch [8/10], Step [818/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [819/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [820/1063], Loss: 0.0040\n",
      "Epoch [8/10], Step [821/1063], Loss: 0.0062\n",
      "Epoch [8/10], Step [822/1063], Loss: 0.0145\n",
      "Epoch [8/10], Step [823/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [824/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [825/1063], Loss: 0.0157\n",
      "Epoch [8/10], Step [826/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [827/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [828/1063], Loss: 0.0154\n",
      "Epoch [8/10], Step [829/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [830/1063], Loss: 0.0054\n",
      "Epoch [8/10], Step [831/1063], Loss: 0.0033\n",
      "Epoch [8/10], Step [832/1063], Loss: 0.0197\n",
      "Epoch [8/10], Step [833/1063], Loss: 0.0025\n",
      "Epoch [8/10], Step [834/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [835/1063], Loss: 0.0013\n",
      "Epoch [8/10], Step [836/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [837/1063], Loss: 0.0093\n",
      "Epoch [8/10], Step [838/1063], Loss: 0.1097\n",
      "Epoch [8/10], Step [839/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [840/1063], Loss: 0.0349\n",
      "Epoch [8/10], Step [841/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [842/1063], Loss: 0.0041\n",
      "Epoch [8/10], Step [843/1063], Loss: 0.0173\n",
      "Epoch [8/10], Step [844/1063], Loss: 0.0057\n",
      "Epoch [8/10], Step [845/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [846/1063], Loss: 0.1205\n",
      "Epoch [8/10], Step [847/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [848/1063], Loss: 0.0030\n",
      "Epoch [8/10], Step [849/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [850/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [851/1063], Loss: 0.0374\n",
      "Epoch [8/10], Step [852/1063], Loss: 0.0038\n",
      "Epoch [8/10], Step [853/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [854/1063], Loss: 0.0040\n",
      "Epoch [8/10], Step [855/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [856/1063], Loss: 0.0120\n",
      "Epoch [8/10], Step [857/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [858/1063], Loss: 0.0480\n",
      "Epoch [8/10], Step [859/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [860/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [861/1063], Loss: 0.0303\n",
      "Epoch [8/10], Step [862/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [863/1063], Loss: 0.0033\n",
      "Epoch [8/10], Step [864/1063], Loss: 0.0222\n",
      "Epoch [8/10], Step [865/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [866/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [867/1063], Loss: 0.0040\n",
      "Epoch [8/10], Step [868/1063], Loss: 0.0245\n",
      "Epoch [8/10], Step [869/1063], Loss: 0.0050\n",
      "Epoch [8/10], Step [870/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [871/1063], Loss: 0.0037\n",
      "Epoch [8/10], Step [872/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [873/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [874/1063], Loss: 0.0395\n",
      "Epoch [8/10], Step [875/1063], Loss: 0.0043\n",
      "Epoch [8/10], Step [876/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [877/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [878/1063], Loss: 0.0045\n",
      "Epoch [8/10], Step [879/1063], Loss: 0.0097\n",
      "Epoch [8/10], Step [880/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [881/1063], Loss: 0.0293\n",
      "Epoch [8/10], Step [882/1063], Loss: 0.0111\n",
      "Epoch [8/10], Step [883/1063], Loss: 0.0409\n",
      "Epoch [8/10], Step [884/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [885/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [886/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [887/1063], Loss: 0.0026\n",
      "Epoch [8/10], Step [888/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [889/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [890/1063], Loss: 0.0071\n",
      "Epoch [8/10], Step [891/1063], Loss: 0.0179\n",
      "Epoch [8/10], Step [892/1063], Loss: 0.0068\n",
      "Epoch [8/10], Step [893/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [894/1063], Loss: 0.0434\n",
      "Epoch [8/10], Step [895/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [896/1063], Loss: 0.0165\n",
      "Epoch [8/10], Step [897/1063], Loss: 0.0042\n",
      "Epoch [8/10], Step [898/1063], Loss: 0.0029\n",
      "Epoch [8/10], Step [899/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [900/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [901/1063], Loss: 0.0048\n",
      "Epoch [8/10], Step [902/1063], Loss: 0.0322\n",
      "Epoch [8/10], Step [903/1063], Loss: 0.0085\n",
      "Epoch [8/10], Step [904/1063], Loss: 0.0017\n",
      "Epoch [8/10], Step [905/1063], Loss: 0.0513\n",
      "Epoch [8/10], Step [906/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [907/1063], Loss: 0.0225\n",
      "Epoch [8/10], Step [908/1063], Loss: 0.0047\n",
      "Epoch [8/10], Step [909/1063], Loss: 0.0044\n",
      "Epoch [8/10], Step [910/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [911/1063], Loss: 0.0207\n",
      "Epoch [8/10], Step [912/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [913/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [914/1063], Loss: 0.0662\n",
      "Epoch [8/10], Step [915/1063], Loss: 0.0286\n",
      "Epoch [8/10], Step [916/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [917/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [918/1063], Loss: 0.0332\n",
      "Epoch [8/10], Step [919/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [920/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [921/1063], Loss: 0.0059\n",
      "Epoch [8/10], Step [922/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [923/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [924/1063], Loss: 0.0195\n",
      "Epoch [8/10], Step [925/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [926/1063], Loss: 0.0017\n",
      "Epoch [8/10], Step [927/1063], Loss: 0.0238\n",
      "Epoch [8/10], Step [928/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [929/1063], Loss: 0.0050\n",
      "Epoch [8/10], Step [930/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [931/1063], Loss: 0.0924\n",
      "Epoch [8/10], Step [932/1063], Loss: 0.0502\n",
      "Epoch [8/10], Step [933/1063], Loss: 0.0027\n",
      "Epoch [8/10], Step [934/1063], Loss: 0.0037\n",
      "Epoch [8/10], Step [935/1063], Loss: 0.0038\n",
      "Epoch [8/10], Step [936/1063], Loss: 0.0250\n",
      "Epoch [8/10], Step [937/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [938/1063], Loss: 0.0127\n",
      "Epoch [8/10], Step [939/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [940/1063], Loss: 0.0114\n",
      "Epoch [8/10], Step [941/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [942/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [943/1063], Loss: 0.0352\n",
      "Epoch [8/10], Step [944/1063], Loss: 0.0129\n",
      "Epoch [8/10], Step [945/1063], Loss: 0.0065\n",
      "Epoch [8/10], Step [946/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [947/1063], Loss: 0.0010\n",
      "Epoch [8/10], Step [948/1063], Loss: 0.0426\n",
      "Epoch [8/10], Step [949/1063], Loss: 0.0025\n",
      "Epoch [8/10], Step [950/1063], Loss: 0.0105\n",
      "Epoch [8/10], Step [951/1063], Loss: 0.0042\n",
      "Epoch [8/10], Step [952/1063], Loss: 0.0268\n",
      "Epoch [8/10], Step [953/1063], Loss: 0.0020\n",
      "Epoch [8/10], Step [954/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [955/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [956/1063], Loss: 0.0241\n",
      "Epoch [8/10], Step [957/1063], Loss: 0.0133\n",
      "Epoch [8/10], Step [958/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [959/1063], Loss: 0.0218\n",
      "Epoch [8/10], Step [960/1063], Loss: 0.0023\n",
      "Epoch [8/10], Step [961/1063], Loss: 0.0101\n",
      "Epoch [8/10], Step [962/1063], Loss: 0.0187\n",
      "Epoch [8/10], Step [963/1063], Loss: 0.0027\n",
      "Epoch [8/10], Step [964/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [965/1063], Loss: 0.0073\n",
      "Epoch [8/10], Step [966/1063], Loss: 0.0068\n",
      "Epoch [8/10], Step [967/1063], Loss: 0.0123\n",
      "Epoch [8/10], Step [968/1063], Loss: 0.0262\n",
      "Epoch [8/10], Step [969/1063], Loss: 0.0029\n",
      "Epoch [8/10], Step [970/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [971/1063], Loss: 0.0013\n",
      "Epoch [8/10], Step [972/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [973/1063], Loss: 0.0056\n",
      "Epoch [8/10], Step [974/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [975/1063], Loss: 0.0259\n",
      "Epoch [8/10], Step [976/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [977/1063], Loss: 0.0052\n",
      "Epoch [8/10], Step [978/1063], Loss: 0.0011\n",
      "Epoch [8/10], Step [979/1063], Loss: 0.0114\n",
      "Epoch [8/10], Step [980/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [981/1063], Loss: 0.0026\n",
      "Epoch [8/10], Step [982/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [983/1063], Loss: 0.0031\n",
      "Epoch [8/10], Step [984/1063], Loss: 0.0027\n",
      "Epoch [8/10], Step [985/1063], Loss: 0.0223\n",
      "Epoch [8/10], Step [986/1063], Loss: 0.0118\n",
      "Epoch [8/10], Step [987/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [988/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [989/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [990/1063], Loss: 0.0529\n",
      "Epoch [8/10], Step [991/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [992/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [993/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [994/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [995/1063], Loss: 0.0033\n",
      "Epoch [8/10], Step [996/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [997/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [998/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [999/1063], Loss: 0.0030\n",
      "Epoch [8/10], Step [1000/1063], Loss: 0.0052\n",
      "Epoch [8/10], Step [1001/1063], Loss: 0.0038\n",
      "Epoch [8/10], Step [1002/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [1003/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [1004/1063], Loss: 0.0199\n",
      "Epoch [8/10], Step [1005/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [1006/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [1007/1063], Loss: 0.0009\n",
      "Epoch [8/10], Step [1008/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [1009/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [1010/1063], Loss: 0.0062\n",
      "Epoch [8/10], Step [1011/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [1012/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [1013/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [1014/1063], Loss: 0.0017\n",
      "Epoch [8/10], Step [1015/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [1016/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [1017/1063], Loss: 0.0053\n",
      "Epoch [8/10], Step [1018/1063], Loss: 0.0026\n",
      "Epoch [8/10], Step [1019/1063], Loss: 0.0001\n",
      "Epoch [8/10], Step [1020/1063], Loss: 0.0072\n",
      "Epoch [8/10], Step [1021/1063], Loss: 0.0021\n",
      "Epoch [8/10], Step [1022/1063], Loss: 0.0027\n",
      "Epoch [8/10], Step [1023/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [1024/1063], Loss: 0.0015\n",
      "Epoch [8/10], Step [1025/1063], Loss: 0.0017\n",
      "Epoch [8/10], Step [1026/1063], Loss: 0.0000\n",
      "Epoch [8/10], Step [1027/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [1028/1063], Loss: 0.0082\n",
      "Epoch [8/10], Step [1029/1063], Loss: 0.0158\n",
      "Epoch [8/10], Step [1030/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [1031/1063], Loss: 0.0008\n",
      "Epoch [8/10], Step [1032/1063], Loss: 0.0012\n",
      "Epoch [8/10], Step [1033/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [1034/1063], Loss: 0.0279\n",
      "Epoch [8/10], Step [1035/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [1036/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [1037/1063], Loss: 0.0095\n",
      "Epoch [8/10], Step [1038/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [1039/1063], Loss: 0.0018\n",
      "Epoch [8/10], Step [1040/1063], Loss: 0.0163\n",
      "Epoch [8/10], Step [1041/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [1042/1063], Loss: 0.0240\n",
      "Epoch [8/10], Step [1043/1063], Loss: 0.0004\n",
      "Epoch [8/10], Step [1044/1063], Loss: 0.0262\n",
      "Epoch [8/10], Step [1045/1063], Loss: 0.0005\n",
      "Epoch [8/10], Step [1046/1063], Loss: 0.0019\n",
      "Epoch [8/10], Step [1047/1063], Loss: 0.0018\n",
      "Epoch [8/10], Step [1048/1063], Loss: 0.0500\n",
      "Epoch [8/10], Step [1049/1063], Loss: 0.0016\n",
      "Epoch [8/10], Step [1050/1063], Loss: 0.0047\n",
      "Epoch [8/10], Step [1051/1063], Loss: 0.0034\n",
      "Epoch [8/10], Step [1052/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [1053/1063], Loss: 0.0007\n",
      "Epoch [8/10], Step [1054/1063], Loss: 0.0002\n",
      "Epoch [8/10], Step [1055/1063], Loss: 0.0003\n",
      "Epoch [8/10], Step [1056/1063], Loss: 0.0075\n",
      "Epoch [8/10], Step [1057/1063], Loss: 0.0043\n",
      "Epoch [8/10], Step [1058/1063], Loss: 0.0014\n",
      "Epoch [8/10], Step [1059/1063], Loss: 0.0314\n",
      "Epoch [8/10], Step [1060/1063], Loss: 0.0304\n",
      "Epoch [8/10], Step [1061/1063], Loss: 0.0123\n",
      "Epoch [8/10], Step [1062/1063], Loss: 0.0006\n",
      "Epoch [8/10], Step [1063/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [1/1063], Loss: 0.0147\n",
      "Epoch [9/10], Step [2/1063], Loss: 0.0039\n",
      "Epoch [9/10], Step [3/1063], Loss: 0.0068\n",
      "Epoch [9/10], Step [4/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [5/1063], Loss: 0.0028\n",
      "Epoch [9/10], Step [6/1063], Loss: 0.0072\n",
      "Epoch [9/10], Step [7/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [8/1063], Loss: 0.0125\n",
      "Epoch [9/10], Step [9/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [10/1063], Loss: 0.0020\n",
      "Epoch [9/10], Step [11/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [12/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [13/1063], Loss: 0.0770\n",
      "Epoch [9/10], Step [14/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [15/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [16/1063], Loss: 0.0025\n",
      "Epoch [9/10], Step [17/1063], Loss: 0.0033\n",
      "Epoch [9/10], Step [18/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [19/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [20/1063], Loss: 0.0040\n",
      "Epoch [9/10], Step [21/1063], Loss: 0.0017\n",
      "Epoch [9/10], Step [22/1063], Loss: 0.0082\n",
      "Epoch [9/10], Step [23/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [24/1063], Loss: 0.0019\n",
      "Epoch [9/10], Step [25/1063], Loss: 0.0203\n",
      "Epoch [9/10], Step [26/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [27/1063], Loss: 0.1327\n",
      "Epoch [9/10], Step [28/1063], Loss: 0.0558\n",
      "Epoch [9/10], Step [29/1063], Loss: 0.0016\n",
      "Epoch [9/10], Step [30/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [31/1063], Loss: 0.0015\n",
      "Epoch [9/10], Step [32/1063], Loss: 0.0357\n",
      "Epoch [9/10], Step [33/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [34/1063], Loss: 0.0029\n",
      "Epoch [9/10], Step [35/1063], Loss: 0.0028\n",
      "Epoch [9/10], Step [36/1063], Loss: 0.0016\n",
      "Epoch [9/10], Step [37/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [38/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [39/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [40/1063], Loss: 0.0054\n",
      "Epoch [9/10], Step [41/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [42/1063], Loss: 0.0570\n",
      "Epoch [9/10], Step [43/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [44/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [45/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [46/1063], Loss: 0.0149\n",
      "Epoch [9/10], Step [47/1063], Loss: 0.0023\n",
      "Epoch [9/10], Step [48/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [49/1063], Loss: 0.0020\n",
      "Epoch [9/10], Step [50/1063], Loss: 0.0038\n",
      "Epoch [9/10], Step [51/1063], Loss: 0.0079\n",
      "Epoch [9/10], Step [52/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [53/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [54/1063], Loss: 0.0153\n",
      "Epoch [9/10], Step [55/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [56/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [57/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [58/1063], Loss: 0.0108\n",
      "Epoch [9/10], Step [59/1063], Loss: 0.0020\n",
      "Epoch [9/10], Step [60/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [61/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [62/1063], Loss: 0.0120\n",
      "Epoch [9/10], Step [63/1063], Loss: 0.0027\n",
      "Epoch [9/10], Step [64/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [65/1063], Loss: 0.0022\n",
      "Epoch [9/10], Step [66/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [67/1063], Loss: 0.0101\n",
      "Epoch [9/10], Step [68/1063], Loss: 0.0016\n",
      "Epoch [9/10], Step [69/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [70/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [71/1063], Loss: 0.0071\n",
      "Epoch [9/10], Step [72/1063], Loss: 0.0093\n",
      "Epoch [9/10], Step [73/1063], Loss: 0.0075\n",
      "Epoch [9/10], Step [74/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [75/1063], Loss: 0.0031\n",
      "Epoch [9/10], Step [76/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [77/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [78/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [79/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [80/1063], Loss: 0.0035\n",
      "Epoch [9/10], Step [81/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [82/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [83/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [84/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [85/1063], Loss: 0.0089\n",
      "Epoch [9/10], Step [86/1063], Loss: 0.0590\n",
      "Epoch [9/10], Step [87/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [88/1063], Loss: 0.0048\n",
      "Epoch [9/10], Step [89/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [90/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [91/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [92/1063], Loss: 0.0016\n",
      "Epoch [9/10], Step [93/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [94/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [95/1063], Loss: 0.0024\n",
      "Epoch [9/10], Step [96/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [97/1063], Loss: 0.0196\n",
      "Epoch [9/10], Step [98/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [99/1063], Loss: 0.0025\n",
      "Epoch [9/10], Step [100/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [101/1063], Loss: 0.0062\n",
      "Epoch [9/10], Step [102/1063], Loss: 0.0027\n",
      "Epoch [9/10], Step [103/1063], Loss: 0.0242\n",
      "Epoch [9/10], Step [104/1063], Loss: 0.0081\n",
      "Epoch [9/10], Step [105/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [106/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [107/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [108/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [109/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [110/1063], Loss: 0.0026\n",
      "Epoch [9/10], Step [111/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [112/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [113/1063], Loss: 0.0066\n",
      "Epoch [9/10], Step [114/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [115/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [116/1063], Loss: 0.0666\n",
      "Epoch [9/10], Step [117/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [118/1063], Loss: 0.0079\n",
      "Epoch [9/10], Step [119/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [120/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [121/1063], Loss: 0.0032\n",
      "Epoch [9/10], Step [122/1063], Loss: 0.0216\n",
      "Epoch [9/10], Step [123/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [124/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [125/1063], Loss: 0.0015\n",
      "Epoch [9/10], Step [126/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [127/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [128/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [129/1063], Loss: 0.0035\n",
      "Epoch [9/10], Step [130/1063], Loss: 0.0166\n",
      "Epoch [9/10], Step [131/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [132/1063], Loss: 0.0373\n",
      "Epoch [9/10], Step [133/1063], Loss: 0.0020\n",
      "Epoch [9/10], Step [134/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [135/1063], Loss: 0.0141\n",
      "Epoch [9/10], Step [136/1063], Loss: 0.0026\n",
      "Epoch [9/10], Step [137/1063], Loss: 0.0423\n",
      "Epoch [9/10], Step [138/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [139/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [140/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [141/1063], Loss: 0.0103\n",
      "Epoch [9/10], Step [142/1063], Loss: 0.0079\n",
      "Epoch [9/10], Step [143/1063], Loss: 0.0231\n",
      "Epoch [9/10], Step [144/1063], Loss: 0.0163\n",
      "Epoch [9/10], Step [145/1063], Loss: 0.0094\n",
      "Epoch [9/10], Step [146/1063], Loss: 0.0269\n",
      "Epoch [9/10], Step [147/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [148/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [149/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [150/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [151/1063], Loss: 0.0114\n",
      "Epoch [9/10], Step [152/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [153/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [154/1063], Loss: 0.0029\n",
      "Epoch [9/10], Step [155/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [156/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [157/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [158/1063], Loss: 0.0054\n",
      "Epoch [9/10], Step [159/1063], Loss: 0.0056\n",
      "Epoch [9/10], Step [160/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [161/1063], Loss: 0.0086\n",
      "Epoch [9/10], Step [162/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [163/1063], Loss: 0.0054\n",
      "Epoch [9/10], Step [164/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [165/1063], Loss: 0.0134\n",
      "Epoch [9/10], Step [166/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [167/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [168/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [169/1063], Loss: 0.0171\n",
      "Epoch [9/10], Step [170/1063], Loss: 0.0017\n",
      "Epoch [9/10], Step [171/1063], Loss: 0.0053\n",
      "Epoch [9/10], Step [172/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [173/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [174/1063], Loss: 0.0022\n",
      "Epoch [9/10], Step [175/1063], Loss: 0.0017\n",
      "Epoch [9/10], Step [176/1063], Loss: 0.0017\n",
      "Epoch [9/10], Step [177/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [178/1063], Loss: 0.0016\n",
      "Epoch [9/10], Step [179/1063], Loss: 0.0072\n",
      "Epoch [9/10], Step [180/1063], Loss: 0.0033\n",
      "Epoch [9/10], Step [181/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [182/1063], Loss: 0.0253\n",
      "Epoch [9/10], Step [183/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [184/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [185/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [186/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [187/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [188/1063], Loss: 0.0189\n",
      "Epoch [9/10], Step [189/1063], Loss: 0.0016\n",
      "Epoch [9/10], Step [190/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [191/1063], Loss: 0.0031\n",
      "Epoch [9/10], Step [192/1063], Loss: 0.0432\n",
      "Epoch [9/10], Step [193/1063], Loss: 0.0033\n",
      "Epoch [9/10], Step [194/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [195/1063], Loss: 0.0056\n",
      "Epoch [9/10], Step [196/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [197/1063], Loss: 0.0017\n",
      "Epoch [9/10], Step [198/1063], Loss: 0.0017\n",
      "Epoch [9/10], Step [199/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [200/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [201/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [202/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [203/1063], Loss: 0.0027\n",
      "Epoch [9/10], Step [204/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [205/1063], Loss: 0.0083\n",
      "Epoch [9/10], Step [206/1063], Loss: 0.0022\n",
      "Epoch [9/10], Step [207/1063], Loss: 0.0695\n",
      "Epoch [9/10], Step [208/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [209/1063], Loss: 0.0022\n",
      "Epoch [9/10], Step [210/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [211/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [212/1063], Loss: 0.0062\n",
      "Epoch [9/10], Step [213/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [214/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [215/1063], Loss: 0.0156\n",
      "Epoch [9/10], Step [216/1063], Loss: 0.0043\n",
      "Epoch [9/10], Step [217/1063], Loss: 0.0104\n",
      "Epoch [9/10], Step [218/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [219/1063], Loss: 0.0061\n",
      "Epoch [9/10], Step [220/1063], Loss: 0.0080\n",
      "Epoch [9/10], Step [221/1063], Loss: 0.0021\n",
      "Epoch [9/10], Step [222/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [223/1063], Loss: 0.0042\n",
      "Epoch [9/10], Step [224/1063], Loss: 0.0452\n",
      "Epoch [9/10], Step [225/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [226/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [227/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [228/1063], Loss: 0.0071\n",
      "Epoch [9/10], Step [229/1063], Loss: 0.0077\n",
      "Epoch [9/10], Step [230/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [231/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [232/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [233/1063], Loss: 0.0061\n",
      "Epoch [9/10], Step [234/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [235/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [236/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [237/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [238/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [239/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [240/1063], Loss: 0.0045\n",
      "Epoch [9/10], Step [241/1063], Loss: 0.0141\n",
      "Epoch [9/10], Step [242/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [243/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [244/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [245/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [246/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [247/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [248/1063], Loss: 0.0127\n",
      "Epoch [9/10], Step [249/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [250/1063], Loss: 0.0099\n",
      "Epoch [9/10], Step [251/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [252/1063], Loss: 0.0074\n",
      "Epoch [9/10], Step [253/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [254/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [255/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [256/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [257/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [258/1063], Loss: 0.0027\n",
      "Epoch [9/10], Step [259/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [260/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [261/1063], Loss: 0.0034\n",
      "Epoch [9/10], Step [262/1063], Loss: 0.0180\n",
      "Epoch [9/10], Step [263/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [264/1063], Loss: 0.0281\n",
      "Epoch [9/10], Step [265/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [266/1063], Loss: 0.0037\n",
      "Epoch [9/10], Step [267/1063], Loss: 0.0018\n",
      "Epoch [9/10], Step [268/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [269/1063], Loss: 0.0032\n",
      "Epoch [9/10], Step [270/1063], Loss: 0.0139\n",
      "Epoch [9/10], Step [271/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [272/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [273/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [274/1063], Loss: 0.0171\n",
      "Epoch [9/10], Step [275/1063], Loss: 0.0033\n",
      "Epoch [9/10], Step [276/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [277/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [278/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [279/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [280/1063], Loss: 0.0291\n",
      "Epoch [9/10], Step [281/1063], Loss: 0.0144\n",
      "Epoch [9/10], Step [282/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [283/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [284/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [285/1063], Loss: 0.0121\n",
      "Epoch [9/10], Step [286/1063], Loss: 0.0263\n",
      "Epoch [9/10], Step [287/1063], Loss: 0.0090\n",
      "Epoch [9/10], Step [288/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [289/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [290/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [291/1063], Loss: 0.0077\n",
      "Epoch [9/10], Step [292/1063], Loss: 0.0015\n",
      "Epoch [9/10], Step [293/1063], Loss: 0.0138\n",
      "Epoch [9/10], Step [294/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [295/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [296/1063], Loss: 0.0893\n",
      "Epoch [9/10], Step [297/1063], Loss: 0.0025\n",
      "Epoch [9/10], Step [298/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [299/1063], Loss: 0.0051\n",
      "Epoch [9/10], Step [300/1063], Loss: 0.0025\n",
      "Epoch [9/10], Step [301/1063], Loss: 0.0016\n",
      "Epoch [9/10], Step [302/1063], Loss: 0.0067\n",
      "Epoch [9/10], Step [303/1063], Loss: 0.0079\n",
      "Epoch [9/10], Step [304/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [305/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [306/1063], Loss: 0.0038\n",
      "Epoch [9/10], Step [307/1063], Loss: 0.0015\n",
      "Epoch [9/10], Step [308/1063], Loss: 0.0038\n",
      "Epoch [9/10], Step [309/1063], Loss: 0.1284\n",
      "Epoch [9/10], Step [310/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [311/1063], Loss: 0.1373\n",
      "Epoch [9/10], Step [312/1063], Loss: 0.0198\n",
      "Epoch [9/10], Step [313/1063], Loss: 0.0032\n",
      "Epoch [9/10], Step [314/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [315/1063], Loss: 0.0053\n",
      "Epoch [9/10], Step [316/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [317/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [318/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [319/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [320/1063], Loss: 0.0027\n",
      "Epoch [9/10], Step [321/1063], Loss: 0.0606\n",
      "Epoch [9/10], Step [322/1063], Loss: 0.0105\n",
      "Epoch [9/10], Step [323/1063], Loss: 0.0074\n",
      "Epoch [9/10], Step [324/1063], Loss: 0.0022\n",
      "Epoch [9/10], Step [325/1063], Loss: 0.0026\n",
      "Epoch [9/10], Step [326/1063], Loss: 0.0016\n",
      "Epoch [9/10], Step [327/1063], Loss: 0.0341\n",
      "Epoch [9/10], Step [328/1063], Loss: 0.0423\n",
      "Epoch [9/10], Step [329/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [330/1063], Loss: 0.0028\n",
      "Epoch [9/10], Step [331/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [332/1063], Loss: 0.0046\n",
      "Epoch [9/10], Step [333/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [334/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [335/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [336/1063], Loss: 0.0147\n",
      "Epoch [9/10], Step [337/1063], Loss: 0.0065\n",
      "Epoch [9/10], Step [338/1063], Loss: 0.0022\n",
      "Epoch [9/10], Step [339/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [340/1063], Loss: 0.0155\n",
      "Epoch [9/10], Step [341/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [342/1063], Loss: 0.0229\n",
      "Epoch [9/10], Step [343/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [344/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [345/1063], Loss: 0.0017\n",
      "Epoch [9/10], Step [346/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [347/1063], Loss: 0.0054\n",
      "Epoch [9/10], Step [348/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [349/1063], Loss: 0.0065\n",
      "Epoch [9/10], Step [350/1063], Loss: 0.0113\n",
      "Epoch [9/10], Step [351/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [352/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [353/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [354/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [355/1063], Loss: 0.0075\n",
      "Epoch [9/10], Step [356/1063], Loss: 0.0292\n",
      "Epoch [9/10], Step [357/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [358/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [359/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [360/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [361/1063], Loss: 0.0029\n",
      "Epoch [9/10], Step [362/1063], Loss: 0.0162\n",
      "Epoch [9/10], Step [363/1063], Loss: 0.0052\n",
      "Epoch [9/10], Step [364/1063], Loss: 0.0133\n",
      "Epoch [9/10], Step [365/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [366/1063], Loss: 0.0269\n",
      "Epoch [9/10], Step [367/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [368/1063], Loss: 0.0110\n",
      "Epoch [9/10], Step [369/1063], Loss: 0.0080\n",
      "Epoch [9/10], Step [370/1063], Loss: 0.0086\n",
      "Epoch [9/10], Step [371/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [372/1063], Loss: 0.0026\n",
      "Epoch [9/10], Step [373/1063], Loss: 0.0071\n",
      "Epoch [9/10], Step [374/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [375/1063], Loss: 0.0037\n",
      "Epoch [9/10], Step [376/1063], Loss: 0.0064\n",
      "Epoch [9/10], Step [377/1063], Loss: 0.0131\n",
      "Epoch [9/10], Step [378/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [379/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [380/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [381/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [382/1063], Loss: 0.0040\n",
      "Epoch [9/10], Step [383/1063], Loss: 0.0017\n",
      "Epoch [9/10], Step [384/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [385/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [386/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [387/1063], Loss: 0.0035\n",
      "Epoch [9/10], Step [388/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [389/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [390/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [391/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [392/1063], Loss: 0.0038\n",
      "Epoch [9/10], Step [393/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [394/1063], Loss: 0.0039\n",
      "Epoch [9/10], Step [395/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [396/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [397/1063], Loss: 0.0016\n",
      "Epoch [9/10], Step [398/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [399/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [400/1063], Loss: 0.0029\n",
      "Epoch [9/10], Step [401/1063], Loss: 0.0021\n",
      "Epoch [9/10], Step [402/1063], Loss: 0.0029\n",
      "Epoch [9/10], Step [403/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [404/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [405/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [406/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [407/1063], Loss: 0.0043\n",
      "Epoch [9/10], Step [408/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [409/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [410/1063], Loss: 0.0045\n",
      "Epoch [9/10], Step [411/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [412/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [413/1063], Loss: 0.0338\n",
      "Epoch [9/10], Step [414/1063], Loss: 0.0077\n",
      "Epoch [9/10], Step [415/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [416/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [417/1063], Loss: 0.0015\n",
      "Epoch [9/10], Step [418/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [419/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [420/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [421/1063], Loss: 0.0701\n",
      "Epoch [9/10], Step [422/1063], Loss: 0.0035\n",
      "Epoch [9/10], Step [423/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [424/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [425/1063], Loss: 0.0016\n",
      "Epoch [9/10], Step [426/1063], Loss: 0.0052\n",
      "Epoch [9/10], Step [427/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [428/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [429/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [430/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [431/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [432/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [433/1063], Loss: 0.0078\n",
      "Epoch [9/10], Step [434/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [435/1063], Loss: 0.0044\n",
      "Epoch [9/10], Step [436/1063], Loss: 0.0048\n",
      "Epoch [9/10], Step [437/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [438/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [439/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [440/1063], Loss: 0.0048\n",
      "Epoch [9/10], Step [441/1063], Loss: 0.0705\n",
      "Epoch [9/10], Step [442/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [443/1063], Loss: 0.0020\n",
      "Epoch [9/10], Step [444/1063], Loss: 0.0188\n",
      "Epoch [9/10], Step [445/1063], Loss: 0.0084\n",
      "Epoch [9/10], Step [446/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [447/1063], Loss: 0.0121\n",
      "Epoch [9/10], Step [448/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [449/1063], Loss: 0.0036\n",
      "Epoch [9/10], Step [450/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [451/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [452/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [453/1063], Loss: 0.0054\n",
      "Epoch [9/10], Step [454/1063], Loss: 0.0082\n",
      "Epoch [9/10], Step [455/1063], Loss: 0.0050\n",
      "Epoch [9/10], Step [456/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [457/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [458/1063], Loss: 0.0030\n",
      "Epoch [9/10], Step [459/1063], Loss: 0.0055\n",
      "Epoch [9/10], Step [460/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [461/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [462/1063], Loss: 0.0059\n",
      "Epoch [9/10], Step [463/1063], Loss: 0.0023\n",
      "Epoch [9/10], Step [464/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [465/1063], Loss: 0.0188\n",
      "Epoch [9/10], Step [466/1063], Loss: 0.0051\n",
      "Epoch [9/10], Step [467/1063], Loss: 0.0081\n",
      "Epoch [9/10], Step [468/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [469/1063], Loss: 0.0017\n",
      "Epoch [9/10], Step [470/1063], Loss: 0.0065\n",
      "Epoch [9/10], Step [471/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [472/1063], Loss: 0.0252\n",
      "Epoch [9/10], Step [473/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [474/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [475/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [476/1063], Loss: 0.0198\n",
      "Epoch [9/10], Step [477/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [478/1063], Loss: 0.0275\n",
      "Epoch [9/10], Step [479/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [480/1063], Loss: 0.0105\n",
      "Epoch [9/10], Step [481/1063], Loss: 0.0121\n",
      "Epoch [9/10], Step [482/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [483/1063], Loss: 0.0056\n",
      "Epoch [9/10], Step [484/1063], Loss: 0.0019\n",
      "Epoch [9/10], Step [485/1063], Loss: 0.0105\n",
      "Epoch [9/10], Step [486/1063], Loss: 0.0102\n",
      "Epoch [9/10], Step [487/1063], Loss: 0.0682\n",
      "Epoch [9/10], Step [488/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [489/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [490/1063], Loss: 0.0159\n",
      "Epoch [9/10], Step [491/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [492/1063], Loss: 0.0036\n",
      "Epoch [9/10], Step [493/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [494/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [495/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [496/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [497/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [498/1063], Loss: 0.0038\n",
      "Epoch [9/10], Step [499/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [500/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [501/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [502/1063], Loss: 0.0024\n",
      "Epoch [9/10], Step [503/1063], Loss: 0.0183\n",
      "Epoch [9/10], Step [504/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [505/1063], Loss: 0.0073\n",
      "Epoch [9/10], Step [506/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [507/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [508/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [509/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [510/1063], Loss: 0.0119\n",
      "Epoch [9/10], Step [511/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [512/1063], Loss: 0.0327\n",
      "Epoch [9/10], Step [513/1063], Loss: 0.0034\n",
      "Epoch [9/10], Step [514/1063], Loss: 0.0023\n",
      "Epoch [9/10], Step [515/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [516/1063], Loss: 0.0080\n",
      "Epoch [9/10], Step [517/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [518/1063], Loss: 0.0051\n",
      "Epoch [9/10], Step [519/1063], Loss: 0.0023\n",
      "Epoch [9/10], Step [520/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [521/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [522/1063], Loss: 0.0668\n",
      "Epoch [9/10], Step [523/1063], Loss: 0.0024\n",
      "Epoch [9/10], Step [524/1063], Loss: 0.0072\n",
      "Epoch [9/10], Step [525/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [526/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [527/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [528/1063], Loss: 0.0029\n",
      "Epoch [9/10], Step [529/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [530/1063], Loss: 0.0095\n",
      "Epoch [9/10], Step [531/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [532/1063], Loss: 0.0030\n",
      "Epoch [9/10], Step [533/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [534/1063], Loss: 0.0033\n",
      "Epoch [9/10], Step [535/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [536/1063], Loss: 0.0035\n",
      "Epoch [9/10], Step [537/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [538/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [539/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [540/1063], Loss: 0.0033\n",
      "Epoch [9/10], Step [541/1063], Loss: 0.0705\n",
      "Epoch [9/10], Step [542/1063], Loss: 0.0044\n",
      "Epoch [9/10], Step [543/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [544/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [545/1063], Loss: 0.0058\n",
      "Epoch [9/10], Step [546/1063], Loss: 0.0222\n",
      "Epoch [9/10], Step [547/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [548/1063], Loss: 0.0030\n",
      "Epoch [9/10], Step [549/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [550/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [551/1063], Loss: 0.0016\n",
      "Epoch [9/10], Step [552/1063], Loss: 0.0110\n",
      "Epoch [9/10], Step [553/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [554/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [555/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [556/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [557/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [558/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [559/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [560/1063], Loss: 0.0731\n",
      "Epoch [9/10], Step [561/1063], Loss: 0.0262\n",
      "Epoch [9/10], Step [562/1063], Loss: 0.0040\n",
      "Epoch [9/10], Step [563/1063], Loss: 0.0295\n",
      "Epoch [9/10], Step [564/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [565/1063], Loss: 0.0589\n",
      "Epoch [9/10], Step [566/1063], Loss: 0.0021\n",
      "Epoch [9/10], Step [567/1063], Loss: 0.0063\n",
      "Epoch [9/10], Step [568/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [569/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [570/1063], Loss: 0.0367\n",
      "Epoch [9/10], Step [571/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [572/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [573/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [574/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [575/1063], Loss: 0.0015\n",
      "Epoch [9/10], Step [576/1063], Loss: 0.0068\n",
      "Epoch [9/10], Step [577/1063], Loss: 0.0020\n",
      "Epoch [9/10], Step [578/1063], Loss: 0.0034\n",
      "Epoch [9/10], Step [579/1063], Loss: 0.0099\n",
      "Epoch [9/10], Step [580/1063], Loss: 0.0050\n",
      "Epoch [9/10], Step [581/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [582/1063], Loss: 0.0199\n",
      "Epoch [9/10], Step [583/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [584/1063], Loss: 0.0239\n",
      "Epoch [9/10], Step [585/1063], Loss: 0.0351\n",
      "Epoch [9/10], Step [586/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [587/1063], Loss: 0.0022\n",
      "Epoch [9/10], Step [588/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [589/1063], Loss: 0.0063\n",
      "Epoch [9/10], Step [590/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [591/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [592/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [593/1063], Loss: 0.0025\n",
      "Epoch [9/10], Step [594/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [595/1063], Loss: 0.0105\n",
      "Epoch [9/10], Step [596/1063], Loss: 0.0039\n",
      "Epoch [9/10], Step [597/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [598/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [599/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [600/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [601/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [602/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [603/1063], Loss: 0.0600\n",
      "Epoch [9/10], Step [604/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [605/1063], Loss: 0.0335\n",
      "Epoch [9/10], Step [606/1063], Loss: 0.0282\n",
      "Epoch [9/10], Step [607/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [608/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [609/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [610/1063], Loss: 0.0096\n",
      "Epoch [9/10], Step [611/1063], Loss: 0.0030\n",
      "Epoch [9/10], Step [612/1063], Loss: 0.0028\n",
      "Epoch [9/10], Step [613/1063], Loss: 0.0033\n",
      "Epoch [9/10], Step [614/1063], Loss: 0.0059\n",
      "Epoch [9/10], Step [615/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [616/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [617/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [618/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [619/1063], Loss: 0.0398\n",
      "Epoch [9/10], Step [620/1063], Loss: 0.0028\n",
      "Epoch [9/10], Step [621/1063], Loss: 0.0185\n",
      "Epoch [9/10], Step [622/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [623/1063], Loss: 0.0050\n",
      "Epoch [9/10], Step [624/1063], Loss: 0.0054\n",
      "Epoch [9/10], Step [625/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [626/1063], Loss: 0.0054\n",
      "Epoch [9/10], Step [627/1063], Loss: 0.0161\n",
      "Epoch [9/10], Step [628/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [629/1063], Loss: 0.0049\n",
      "Epoch [9/10], Step [630/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [631/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [632/1063], Loss: 0.0073\n",
      "Epoch [9/10], Step [633/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [634/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [635/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [636/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [637/1063], Loss: 0.0024\n",
      "Epoch [9/10], Step [638/1063], Loss: 0.0054\n",
      "Epoch [9/10], Step [639/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [640/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [641/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [642/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [643/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [644/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [645/1063], Loss: 0.0162\n",
      "Epoch [9/10], Step [646/1063], Loss: 0.0059\n",
      "Epoch [9/10], Step [647/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [648/1063], Loss: 0.0096\n",
      "Epoch [9/10], Step [649/1063], Loss: 0.0280\n",
      "Epoch [9/10], Step [650/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [651/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [652/1063], Loss: 0.0038\n",
      "Epoch [9/10], Step [653/1063], Loss: 0.0017\n",
      "Epoch [9/10], Step [654/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [655/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [656/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [657/1063], Loss: 0.0050\n",
      "Epoch [9/10], Step [658/1063], Loss: 0.0330\n",
      "Epoch [9/10], Step [659/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [660/1063], Loss: 0.0206\n",
      "Epoch [9/10], Step [661/1063], Loss: 0.0471\n",
      "Epoch [9/10], Step [662/1063], Loss: 0.1044\n",
      "Epoch [9/10], Step [663/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [664/1063], Loss: 0.0029\n",
      "Epoch [9/10], Step [665/1063], Loss: 0.0020\n",
      "Epoch [9/10], Step [666/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [667/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [668/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [669/1063], Loss: 0.0258\n",
      "Epoch [9/10], Step [670/1063], Loss: 0.0021\n",
      "Epoch [9/10], Step [671/1063], Loss: 0.0019\n",
      "Epoch [9/10], Step [672/1063], Loss: 0.0265\n",
      "Epoch [9/10], Step [673/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [674/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [675/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [676/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [677/1063], Loss: 0.1911\n",
      "Epoch [9/10], Step [678/1063], Loss: 0.0138\n",
      "Epoch [9/10], Step [679/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [680/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [681/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [682/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [683/1063], Loss: 0.0161\n",
      "Epoch [9/10], Step [684/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [685/1063], Loss: 0.0083\n",
      "Epoch [9/10], Step [686/1063], Loss: 0.0108\n",
      "Epoch [9/10], Step [687/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [688/1063], Loss: 0.0574\n",
      "Epoch [9/10], Step [689/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [690/1063], Loss: 0.0025\n",
      "Epoch [9/10], Step [691/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [692/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [693/1063], Loss: 0.0018\n",
      "Epoch [9/10], Step [694/1063], Loss: 0.0188\n",
      "Epoch [9/10], Step [695/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [696/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [697/1063], Loss: 0.0019\n",
      "Epoch [9/10], Step [698/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [699/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [700/1063], Loss: 0.0110\n",
      "Epoch [9/10], Step [701/1063], Loss: 0.0057\n",
      "Epoch [9/10], Step [702/1063], Loss: 0.0109\n",
      "Epoch [9/10], Step [703/1063], Loss: 0.0140\n",
      "Epoch [9/10], Step [704/1063], Loss: 0.0061\n",
      "Epoch [9/10], Step [705/1063], Loss: 0.0029\n",
      "Epoch [9/10], Step [706/1063], Loss: 0.0028\n",
      "Epoch [9/10], Step [707/1063], Loss: 0.0049\n",
      "Epoch [9/10], Step [708/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [709/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [710/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [711/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [712/1063], Loss: 0.0197\n",
      "Epoch [9/10], Step [713/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [714/1063], Loss: 0.0065\n",
      "Epoch [9/10], Step [715/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [716/1063], Loss: 0.0041\n",
      "Epoch [9/10], Step [717/1063], Loss: 0.0105\n",
      "Epoch [9/10], Step [718/1063], Loss: 0.0020\n",
      "Epoch [9/10], Step [719/1063], Loss: 0.0058\n",
      "Epoch [9/10], Step [720/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [721/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [722/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [723/1063], Loss: 0.0207\n",
      "Epoch [9/10], Step [724/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [725/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [726/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [727/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [728/1063], Loss: 0.0022\n",
      "Epoch [9/10], Step [729/1063], Loss: 0.0093\n",
      "Epoch [9/10], Step [730/1063], Loss: 0.0315\n",
      "Epoch [9/10], Step [731/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [732/1063], Loss: 0.0267\n",
      "Epoch [9/10], Step [733/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [734/1063], Loss: 0.0023\n",
      "Epoch [9/10], Step [735/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [736/1063], Loss: 0.0183\n",
      "Epoch [9/10], Step [737/1063], Loss: 0.0206\n",
      "Epoch [9/10], Step [738/1063], Loss: 0.0174\n",
      "Epoch [9/10], Step [739/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [740/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [741/1063], Loss: 0.0027\n",
      "Epoch [9/10], Step [742/1063], Loss: 0.0027\n",
      "Epoch [9/10], Step [743/1063], Loss: 0.0442\n",
      "Epoch [9/10], Step [744/1063], Loss: 0.0162\n",
      "Epoch [9/10], Step [745/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [746/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [747/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [748/1063], Loss: 0.0110\n",
      "Epoch [9/10], Step [749/1063], Loss: 0.0162\n",
      "Epoch [9/10], Step [750/1063], Loss: 0.0482\n",
      "Epoch [9/10], Step [751/1063], Loss: 0.0731\n",
      "Epoch [9/10], Step [752/1063], Loss: 0.0028\n",
      "Epoch [9/10], Step [753/1063], Loss: 0.0101\n",
      "Epoch [9/10], Step [754/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [755/1063], Loss: 0.0039\n",
      "Epoch [9/10], Step [756/1063], Loss: 0.0038\n",
      "Epoch [9/10], Step [757/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [758/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [759/1063], Loss: 0.0095\n",
      "Epoch [9/10], Step [760/1063], Loss: 0.0236\n",
      "Epoch [9/10], Step [761/1063], Loss: 0.0440\n",
      "Epoch [9/10], Step [762/1063], Loss: 0.0950\n",
      "Epoch [9/10], Step [763/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [764/1063], Loss: 0.0054\n",
      "Epoch [9/10], Step [765/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [766/1063], Loss: 0.0018\n",
      "Epoch [9/10], Step [767/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [768/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [769/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [770/1063], Loss: 0.0043\n",
      "Epoch [9/10], Step [771/1063], Loss: 0.0497\n",
      "Epoch [9/10], Step [772/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [773/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [774/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [775/1063], Loss: 0.0027\n",
      "Epoch [9/10], Step [776/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [777/1063], Loss: 0.0041\n",
      "Epoch [9/10], Step [778/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [779/1063], Loss: 0.0075\n",
      "Epoch [9/10], Step [780/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [781/1063], Loss: 0.0126\n",
      "Epoch [9/10], Step [782/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [783/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [784/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [785/1063], Loss: 0.0042\n",
      "Epoch [9/10], Step [786/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [787/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [788/1063], Loss: 0.0069\n",
      "Epoch [9/10], Step [789/1063], Loss: 0.0018\n",
      "Epoch [9/10], Step [790/1063], Loss: 0.0070\n",
      "Epoch [9/10], Step [791/1063], Loss: 0.0084\n",
      "Epoch [9/10], Step [792/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [793/1063], Loss: 0.0040\n",
      "Epoch [9/10], Step [794/1063], Loss: 0.0020\n",
      "Epoch [9/10], Step [795/1063], Loss: 0.0025\n",
      "Epoch [9/10], Step [796/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [797/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [798/1063], Loss: 0.0340\n",
      "Epoch [9/10], Step [799/1063], Loss: 0.0074\n",
      "Epoch [9/10], Step [800/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [801/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [802/1063], Loss: 0.0026\n",
      "Epoch [9/10], Step [803/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [804/1063], Loss: 0.0303\n",
      "Epoch [9/10], Step [805/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [806/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [807/1063], Loss: 0.0019\n",
      "Epoch [9/10], Step [808/1063], Loss: 0.0067\n",
      "Epoch [9/10], Step [809/1063], Loss: 0.0023\n",
      "Epoch [9/10], Step [810/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [811/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [812/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [813/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [814/1063], Loss: 0.0049\n",
      "Epoch [9/10], Step [815/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [816/1063], Loss: 0.0598\n",
      "Epoch [9/10], Step [817/1063], Loss: 0.0249\n",
      "Epoch [9/10], Step [818/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [819/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [820/1063], Loss: 0.0094\n",
      "Epoch [9/10], Step [821/1063], Loss: 0.0018\n",
      "Epoch [9/10], Step [822/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [823/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [824/1063], Loss: 0.0025\n",
      "Epoch [9/10], Step [825/1063], Loss: 0.0047\n",
      "Epoch [9/10], Step [826/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [827/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [828/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [829/1063], Loss: 0.0486\n",
      "Epoch [9/10], Step [830/1063], Loss: 0.0220\n",
      "Epoch [9/10], Step [831/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [832/1063], Loss: 0.0109\n",
      "Epoch [9/10], Step [833/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [834/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [835/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [836/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [837/1063], Loss: 0.0140\n",
      "Epoch [9/10], Step [838/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [839/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [840/1063], Loss: 0.0062\n",
      "Epoch [9/10], Step [841/1063], Loss: 0.0048\n",
      "Epoch [9/10], Step [842/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [843/1063], Loss: 0.0415\n",
      "Epoch [9/10], Step [844/1063], Loss: 0.0031\n",
      "Epoch [9/10], Step [845/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [846/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [847/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [848/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [849/1063], Loss: 0.0032\n",
      "Epoch [9/10], Step [850/1063], Loss: 0.0161\n",
      "Epoch [9/10], Step [851/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [852/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [853/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [854/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [855/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [856/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [857/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [858/1063], Loss: 0.0042\n",
      "Epoch [9/10], Step [859/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [860/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [861/1063], Loss: 0.0063\n",
      "Epoch [9/10], Step [862/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [863/1063], Loss: 0.0038\n",
      "Epoch [9/10], Step [864/1063], Loss: 0.0022\n",
      "Epoch [9/10], Step [865/1063], Loss: 0.0614\n",
      "Epoch [9/10], Step [866/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [867/1063], Loss: 0.0026\n",
      "Epoch [9/10], Step [868/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [869/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [870/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [871/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [872/1063], Loss: 0.0620\n",
      "Epoch [9/10], Step [873/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [874/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [875/1063], Loss: 0.0091\n",
      "Epoch [9/10], Step [876/1063], Loss: 0.1055\n",
      "Epoch [9/10], Step [877/1063], Loss: 0.0039\n",
      "Epoch [9/10], Step [878/1063], Loss: 0.0148\n",
      "Epoch [9/10], Step [879/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [880/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [881/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [882/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [883/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [884/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [885/1063], Loss: 0.0038\n",
      "Epoch [9/10], Step [886/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [887/1063], Loss: 0.0338\n",
      "Epoch [9/10], Step [888/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [889/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [890/1063], Loss: 0.0034\n",
      "Epoch [9/10], Step [891/1063], Loss: 0.0052\n",
      "Epoch [9/10], Step [892/1063], Loss: 0.0198\n",
      "Epoch [9/10], Step [893/1063], Loss: 0.0025\n",
      "Epoch [9/10], Step [894/1063], Loss: 0.0334\n",
      "Epoch [9/10], Step [895/1063], Loss: 0.0275\n",
      "Epoch [9/10], Step [896/1063], Loss: 0.0025\n",
      "Epoch [9/10], Step [897/1063], Loss: 0.0091\n",
      "Epoch [9/10], Step [898/1063], Loss: 0.0054\n",
      "Epoch [9/10], Step [899/1063], Loss: 0.0102\n",
      "Epoch [9/10], Step [900/1063], Loss: 0.0112\n",
      "Epoch [9/10], Step [901/1063], Loss: 0.0034\n",
      "Epoch [9/10], Step [902/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [903/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [904/1063], Loss: 0.0033\n",
      "Epoch [9/10], Step [905/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [906/1063], Loss: 0.0037\n",
      "Epoch [9/10], Step [907/1063], Loss: 0.0036\n",
      "Epoch [9/10], Step [908/1063], Loss: 0.0022\n",
      "Epoch [9/10], Step [909/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [910/1063], Loss: 0.0041\n",
      "Epoch [9/10], Step [911/1063], Loss: 0.0016\n",
      "Epoch [9/10], Step [912/1063], Loss: 0.0138\n",
      "Epoch [9/10], Step [913/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [914/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [915/1063], Loss: 0.0236\n",
      "Epoch [9/10], Step [916/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [917/1063], Loss: 0.0475\n",
      "Epoch [9/10], Step [918/1063], Loss: 0.0075\n",
      "Epoch [9/10], Step [919/1063], Loss: 0.0183\n",
      "Epoch [9/10], Step [920/1063], Loss: 0.0042\n",
      "Epoch [9/10], Step [921/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [922/1063], Loss: 0.0252\n",
      "Epoch [9/10], Step [923/1063], Loss: 0.0099\n",
      "Epoch [9/10], Step [924/1063], Loss: 0.0077\n",
      "Epoch [9/10], Step [925/1063], Loss: 0.0284\n",
      "Epoch [9/10], Step [926/1063], Loss: 0.0009\n",
      "Epoch [9/10], Step [927/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [928/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [929/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [930/1063], Loss: 0.0164\n",
      "Epoch [9/10], Step [931/1063], Loss: 0.0035\n",
      "Epoch [9/10], Step [932/1063], Loss: 0.0382\n",
      "Epoch [9/10], Step [933/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [934/1063], Loss: 0.0019\n",
      "Epoch [9/10], Step [935/1063], Loss: 0.0015\n",
      "Epoch [9/10], Step [936/1063], Loss: 0.0173\n",
      "Epoch [9/10], Step [937/1063], Loss: 0.0098\n",
      "Epoch [9/10], Step [938/1063], Loss: 0.0188\n",
      "Epoch [9/10], Step [939/1063], Loss: 0.0182\n",
      "Epoch [9/10], Step [940/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [941/1063], Loss: 0.0045\n",
      "Epoch [9/10], Step [942/1063], Loss: 0.0035\n",
      "Epoch [9/10], Step [943/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [944/1063], Loss: 0.0031\n",
      "Epoch [9/10], Step [945/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [946/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [947/1063], Loss: 0.0055\n",
      "Epoch [9/10], Step [948/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [949/1063], Loss: 0.0020\n",
      "Epoch [9/10], Step [950/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [951/1063], Loss: 0.0412\n",
      "Epoch [9/10], Step [952/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [953/1063], Loss: 0.0027\n",
      "Epoch [9/10], Step [954/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [955/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [956/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [957/1063], Loss: 0.0111\n",
      "Epoch [9/10], Step [958/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [959/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [960/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [961/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [962/1063], Loss: 0.0062\n",
      "Epoch [9/10], Step [963/1063], Loss: 0.0114\n",
      "Epoch [9/10], Step [964/1063], Loss: 0.0030\n",
      "Epoch [9/10], Step [965/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [966/1063], Loss: 0.0083\n",
      "Epoch [9/10], Step [967/1063], Loss: 0.0021\n",
      "Epoch [9/10], Step [968/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [969/1063], Loss: 0.0034\n",
      "Epoch [9/10], Step [970/1063], Loss: 0.0078\n",
      "Epoch [9/10], Step [971/1063], Loss: 0.0022\n",
      "Epoch [9/10], Step [972/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [973/1063], Loss: 0.0022\n",
      "Epoch [9/10], Step [974/1063], Loss: 0.0026\n",
      "Epoch [9/10], Step [975/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [976/1063], Loss: 0.0020\n",
      "Epoch [9/10], Step [977/1063], Loss: 0.0063\n",
      "Epoch [9/10], Step [978/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [979/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [980/1063], Loss: 0.0008\n",
      "Epoch [9/10], Step [981/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [982/1063], Loss: 0.0169\n",
      "Epoch [9/10], Step [983/1063], Loss: 0.0023\n",
      "Epoch [9/10], Step [984/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [985/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [986/1063], Loss: 0.0043\n",
      "Epoch [9/10], Step [987/1063], Loss: 0.0036\n",
      "Epoch [9/10], Step [988/1063], Loss: 0.0006\n",
      "Epoch [9/10], Step [989/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [990/1063], Loss: 0.0053\n",
      "Epoch [9/10], Step [991/1063], Loss: 0.0010\n",
      "Epoch [9/10], Step [992/1063], Loss: 0.0024\n",
      "Epoch [9/10], Step [993/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [994/1063], Loss: 0.0417\n",
      "Epoch [9/10], Step [995/1063], Loss: 0.0046\n",
      "Epoch [9/10], Step [996/1063], Loss: 0.0023\n",
      "Epoch [9/10], Step [997/1063], Loss: 0.0880\n",
      "Epoch [9/10], Step [998/1063], Loss: 0.0407\n",
      "Epoch [9/10], Step [999/1063], Loss: 0.0011\n",
      "Epoch [9/10], Step [1000/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [1001/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [1002/1063], Loss: 0.0176\n",
      "Epoch [9/10], Step [1003/1063], Loss: 0.0023\n",
      "Epoch [9/10], Step [1004/1063], Loss: 0.0056\n",
      "Epoch [9/10], Step [1005/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [1006/1063], Loss: 0.0043\n",
      "Epoch [9/10], Step [1007/1063], Loss: 0.0025\n",
      "Epoch [9/10], Step [1008/1063], Loss: 0.0070\n",
      "Epoch [9/10], Step [1009/1063], Loss: 0.0079\n",
      "Epoch [9/10], Step [1010/1063], Loss: 0.0048\n",
      "Epoch [9/10], Step [1011/1063], Loss: 0.0476\n",
      "Epoch [9/10], Step [1012/1063], Loss: 0.0184\n",
      "Epoch [9/10], Step [1013/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [1014/1063], Loss: 0.0137\n",
      "Epoch [9/10], Step [1015/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [1016/1063], Loss: 0.0013\n",
      "Epoch [9/10], Step [1017/1063], Loss: 0.0037\n",
      "Epoch [9/10], Step [1018/1063], Loss: 0.0002\n",
      "Epoch [9/10], Step [1019/1063], Loss: 0.0111\n",
      "Epoch [9/10], Step [1020/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [1021/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [1022/1063], Loss: 0.0012\n",
      "Epoch [9/10], Step [1023/1063], Loss: 0.0045\n",
      "Epoch [9/10], Step [1024/1063], Loss: 0.0096\n",
      "Epoch [9/10], Step [1025/1063], Loss: 0.0087\n",
      "Epoch [9/10], Step [1026/1063], Loss: 0.0039\n",
      "Epoch [9/10], Step [1027/1063], Loss: 0.0354\n",
      "Epoch [9/10], Step [1028/1063], Loss: 0.0007\n",
      "Epoch [9/10], Step [1029/1063], Loss: 0.0019\n",
      "Epoch [9/10], Step [1030/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [1031/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [1032/1063], Loss: 0.0320\n",
      "Epoch [9/10], Step [1033/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [1034/1063], Loss: 0.0215\n",
      "Epoch [9/10], Step [1035/1063], Loss: 0.0029\n",
      "Epoch [9/10], Step [1036/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [1037/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [1038/1063], Loss: 0.0014\n",
      "Epoch [9/10], Step [1039/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [1040/1063], Loss: 0.0282\n",
      "Epoch [9/10], Step [1041/1063], Loss: 0.0748\n",
      "Epoch [9/10], Step [1042/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [1043/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [1044/1063], Loss: 0.0000\n",
      "Epoch [9/10], Step [1045/1063], Loss: 0.0322\n",
      "Epoch [9/10], Step [1046/1063], Loss: 0.0198\n",
      "Epoch [9/10], Step [1047/1063], Loss: 0.0003\n",
      "Epoch [9/10], Step [1048/1063], Loss: 0.0020\n",
      "Epoch [9/10], Step [1049/1063], Loss: 0.0051\n",
      "Epoch [9/10], Step [1050/1063], Loss: 0.1324\n",
      "Epoch [9/10], Step [1051/1063], Loss: 0.0005\n",
      "Epoch [9/10], Step [1052/1063], Loss: 0.0061\n",
      "Epoch [9/10], Step [1053/1063], Loss: 0.0128\n",
      "Epoch [9/10], Step [1054/1063], Loss: 0.0139\n",
      "Epoch [9/10], Step [1055/1063], Loss: 0.0095\n",
      "Epoch [9/10], Step [1056/1063], Loss: 0.0004\n",
      "Epoch [9/10], Step [1057/1063], Loss: 0.0083\n",
      "Epoch [9/10], Step [1058/1063], Loss: 0.0122\n",
      "Epoch [9/10], Step [1059/1063], Loss: 0.0049\n",
      "Epoch [9/10], Step [1060/1063], Loss: 0.0001\n",
      "Epoch [9/10], Step [1061/1063], Loss: 0.0040\n",
      "Epoch [9/10], Step [1062/1063], Loss: 0.0522\n",
      "Epoch [9/10], Step [1063/1063], Loss: 0.0543\n",
      "Epoch [10/10], Step [1/1063], Loss: 0.0045\n",
      "Epoch [10/10], Step [2/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [3/1063], Loss: 0.0117\n",
      "Epoch [10/10], Step [4/1063], Loss: 0.0096\n",
      "Epoch [10/10], Step [5/1063], Loss: 0.0060\n",
      "Epoch [10/10], Step [6/1063], Loss: 0.0144\n",
      "Epoch [10/10], Step [7/1063], Loss: 0.0027\n",
      "Epoch [10/10], Step [8/1063], Loss: 0.0025\n",
      "Epoch [10/10], Step [9/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [10/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [11/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [12/1063], Loss: 0.0036\n",
      "Epoch [10/10], Step [13/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [14/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [15/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [16/1063], Loss: 0.0015\n",
      "Epoch [10/10], Step [17/1063], Loss: 0.0047\n",
      "Epoch [10/10], Step [18/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [19/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [20/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [21/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [22/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [23/1063], Loss: 0.0147\n",
      "Epoch [10/10], Step [24/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [25/1063], Loss: 0.0265\n",
      "Epoch [10/10], Step [26/1063], Loss: 0.0026\n",
      "Epoch [10/10], Step [27/1063], Loss: 0.0061\n",
      "Epoch [10/10], Step [28/1063], Loss: 0.0034\n",
      "Epoch [10/10], Step [29/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [30/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [31/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [32/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [33/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [34/1063], Loss: 0.0075\n",
      "Epoch [10/10], Step [35/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [36/1063], Loss: 0.0157\n",
      "Epoch [10/10], Step [37/1063], Loss: 0.0079\n",
      "Epoch [10/10], Step [38/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [39/1063], Loss: 0.0022\n",
      "Epoch [10/10], Step [40/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [41/1063], Loss: 0.0050\n",
      "Epoch [10/10], Step [42/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [43/1063], Loss: 0.0251\n",
      "Epoch [10/10], Step [44/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [45/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [46/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [47/1063], Loss: 0.0028\n",
      "Epoch [10/10], Step [48/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [49/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [50/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [51/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [52/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [53/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [54/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [55/1063], Loss: 0.0384\n",
      "Epoch [10/10], Step [56/1063], Loss: 0.0029\n",
      "Epoch [10/10], Step [57/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [58/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [59/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [60/1063], Loss: 0.0268\n",
      "Epoch [10/10], Step [61/1063], Loss: 0.0150\n",
      "Epoch [10/10], Step [62/1063], Loss: 0.0058\n",
      "Epoch [10/10], Step [63/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [64/1063], Loss: 0.0346\n",
      "Epoch [10/10], Step [65/1063], Loss: 0.0033\n",
      "Epoch [10/10], Step [66/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [67/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [68/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [69/1063], Loss: 0.0034\n",
      "Epoch [10/10], Step [70/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [71/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [72/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [73/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [74/1063], Loss: 0.0089\n",
      "Epoch [10/10], Step [75/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [76/1063], Loss: 0.0055\n",
      "Epoch [10/10], Step [77/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [78/1063], Loss: 0.0183\n",
      "Epoch [10/10], Step [79/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [80/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [81/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [82/1063], Loss: 0.0052\n",
      "Epoch [10/10], Step [83/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [84/1063], Loss: 0.0256\n",
      "Epoch [10/10], Step [85/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [86/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [87/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [88/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [89/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [90/1063], Loss: 0.0041\n",
      "Epoch [10/10], Step [91/1063], Loss: 0.0083\n",
      "Epoch [10/10], Step [92/1063], Loss: 0.0043\n",
      "Epoch [10/10], Step [93/1063], Loss: 0.0033\n",
      "Epoch [10/10], Step [94/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [95/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [96/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [97/1063], Loss: 0.0319\n",
      "Epoch [10/10], Step [98/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [99/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [100/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [101/1063], Loss: 0.0034\n",
      "Epoch [10/10], Step [102/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [103/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [104/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [105/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [106/1063], Loss: 0.0118\n",
      "Epoch [10/10], Step [107/1063], Loss: 0.0123\n",
      "Epoch [10/10], Step [108/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [109/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [110/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [111/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [112/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [113/1063], Loss: 0.0054\n",
      "Epoch [10/10], Step [114/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [115/1063], Loss: 0.0086\n",
      "Epoch [10/10], Step [116/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [117/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [118/1063], Loss: 0.0162\n",
      "Epoch [10/10], Step [119/1063], Loss: 0.0124\n",
      "Epoch [10/10], Step [120/1063], Loss: 0.0080\n",
      "Epoch [10/10], Step [121/1063], Loss: 0.0109\n",
      "Epoch [10/10], Step [122/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [123/1063], Loss: 0.0052\n",
      "Epoch [10/10], Step [124/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [125/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [126/1063], Loss: 0.0047\n",
      "Epoch [10/10], Step [127/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [128/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [129/1063], Loss: 0.0096\n",
      "Epoch [10/10], Step [130/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [131/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [132/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [133/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [134/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [135/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [136/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [137/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [138/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [139/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [140/1063], Loss: 0.0139\n",
      "Epoch [10/10], Step [141/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [142/1063], Loss: 0.0120\n",
      "Epoch [10/10], Step [143/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [144/1063], Loss: 0.0015\n",
      "Epoch [10/10], Step [145/1063], Loss: 0.0033\n",
      "Epoch [10/10], Step [146/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [147/1063], Loss: 0.0238\n",
      "Epoch [10/10], Step [148/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [149/1063], Loss: 0.0063\n",
      "Epoch [10/10], Step [150/1063], Loss: 0.0175\n",
      "Epoch [10/10], Step [151/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [152/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [153/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [154/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [155/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [156/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [157/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [158/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [159/1063], Loss: 0.0022\n",
      "Epoch [10/10], Step [160/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [161/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [162/1063], Loss: 0.0039\n",
      "Epoch [10/10], Step [163/1063], Loss: 0.0053\n",
      "Epoch [10/10], Step [164/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [165/1063], Loss: 0.0074\n",
      "Epoch [10/10], Step [166/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [167/1063], Loss: 0.0225\n",
      "Epoch [10/10], Step [168/1063], Loss: 0.0039\n",
      "Epoch [10/10], Step [169/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [170/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [171/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [172/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [173/1063], Loss: 0.0368\n",
      "Epoch [10/10], Step [174/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [175/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [176/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [177/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [178/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [179/1063], Loss: 0.0089\n",
      "Epoch [10/10], Step [180/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [181/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [182/1063], Loss: 0.0368\n",
      "Epoch [10/10], Step [183/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [184/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [185/1063], Loss: 0.0029\n",
      "Epoch [10/10], Step [186/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [187/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [188/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [189/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [190/1063], Loss: 0.0386\n",
      "Epoch [10/10], Step [191/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [192/1063], Loss: 0.0071\n",
      "Epoch [10/10], Step [193/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [194/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [195/1063], Loss: 0.0072\n",
      "Epoch [10/10], Step [196/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [197/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [198/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [199/1063], Loss: 0.0037\n",
      "Epoch [10/10], Step [200/1063], Loss: 0.0032\n",
      "Epoch [10/10], Step [201/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [202/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [203/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [204/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [205/1063], Loss: 0.0065\n",
      "Epoch [10/10], Step [206/1063], Loss: 0.0027\n",
      "Epoch [10/10], Step [207/1063], Loss: 0.0019\n",
      "Epoch [10/10], Step [208/1063], Loss: 0.0120\n",
      "Epoch [10/10], Step [209/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [210/1063], Loss: 0.0016\n",
      "Epoch [10/10], Step [211/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [212/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [213/1063], Loss: 0.0043\n",
      "Epoch [10/10], Step [214/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [215/1063], Loss: 0.0031\n",
      "Epoch [10/10], Step [216/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [217/1063], Loss: 0.0015\n",
      "Epoch [10/10], Step [218/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [219/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [220/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [221/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [222/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [223/1063], Loss: 0.0105\n",
      "Epoch [10/10], Step [224/1063], Loss: 0.0016\n",
      "Epoch [10/10], Step [225/1063], Loss: 0.0057\n",
      "Epoch [10/10], Step [226/1063], Loss: 0.0369\n",
      "Epoch [10/10], Step [227/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [228/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [229/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [230/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [231/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [232/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [233/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [234/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [235/1063], Loss: 0.0225\n",
      "Epoch [10/10], Step [236/1063], Loss: 0.0053\n",
      "Epoch [10/10], Step [237/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [238/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [239/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [240/1063], Loss: 0.0077\n",
      "Epoch [10/10], Step [241/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [242/1063], Loss: 0.0634\n",
      "Epoch [10/10], Step [243/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [244/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [245/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [246/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [247/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [248/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [249/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [250/1063], Loss: 0.0071\n",
      "Epoch [10/10], Step [251/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [252/1063], Loss: 0.0381\n",
      "Epoch [10/10], Step [253/1063], Loss: 0.0315\n",
      "Epoch [10/10], Step [254/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [255/1063], Loss: 0.0088\n",
      "Epoch [10/10], Step [256/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [257/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [258/1063], Loss: 0.0033\n",
      "Epoch [10/10], Step [259/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [260/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [261/1063], Loss: 0.0033\n",
      "Epoch [10/10], Step [262/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [263/1063], Loss: 0.0234\n",
      "Epoch [10/10], Step [264/1063], Loss: 0.0085\n",
      "Epoch [10/10], Step [265/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [266/1063], Loss: 0.0019\n",
      "Epoch [10/10], Step [267/1063], Loss: 0.0185\n",
      "Epoch [10/10], Step [268/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [269/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [270/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [271/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [272/1063], Loss: 0.0059\n",
      "Epoch [10/10], Step [273/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [274/1063], Loss: 0.0026\n",
      "Epoch [10/10], Step [275/1063], Loss: 0.0032\n",
      "Epoch [10/10], Step [276/1063], Loss: 0.0062\n",
      "Epoch [10/10], Step [277/1063], Loss: 0.0038\n",
      "Epoch [10/10], Step [278/1063], Loss: 0.0032\n",
      "Epoch [10/10], Step [279/1063], Loss: 0.0026\n",
      "Epoch [10/10], Step [280/1063], Loss: 0.0019\n",
      "Epoch [10/10], Step [281/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [282/1063], Loss: 0.0055\n",
      "Epoch [10/10], Step [283/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [284/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [285/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [286/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [287/1063], Loss: 0.0345\n",
      "Epoch [10/10], Step [288/1063], Loss: 0.0484\n",
      "Epoch [10/10], Step [289/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [290/1063], Loss: 0.0026\n",
      "Epoch [10/10], Step [291/1063], Loss: 0.0196\n",
      "Epoch [10/10], Step [292/1063], Loss: 0.0807\n",
      "Epoch [10/10], Step [293/1063], Loss: 0.0124\n",
      "Epoch [10/10], Step [294/1063], Loss: 0.0036\n",
      "Epoch [10/10], Step [295/1063], Loss: 0.0051\n",
      "Epoch [10/10], Step [296/1063], Loss: 0.0026\n",
      "Epoch [10/10], Step [297/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [298/1063], Loss: 0.0062\n",
      "Epoch [10/10], Step [299/1063], Loss: 0.0052\n",
      "Epoch [10/10], Step [300/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [301/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [302/1063], Loss: 0.0173\n",
      "Epoch [10/10], Step [303/1063], Loss: 0.0103\n",
      "Epoch [10/10], Step [304/1063], Loss: 0.0033\n",
      "Epoch [10/10], Step [305/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [306/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [307/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [308/1063], Loss: 0.0093\n",
      "Epoch [10/10], Step [309/1063], Loss: 0.0037\n",
      "Epoch [10/10], Step [310/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [311/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [312/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [313/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [314/1063], Loss: 0.0039\n",
      "Epoch [10/10], Step [315/1063], Loss: 0.0031\n",
      "Epoch [10/10], Step [316/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [317/1063], Loss: 0.0053\n",
      "Epoch [10/10], Step [318/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [319/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [320/1063], Loss: 0.0070\n",
      "Epoch [10/10], Step [321/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [322/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [323/1063], Loss: 0.0015\n",
      "Epoch [10/10], Step [324/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [325/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [326/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [327/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [328/1063], Loss: 0.0323\n",
      "Epoch [10/10], Step [329/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [330/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [331/1063], Loss: 0.0033\n",
      "Epoch [10/10], Step [332/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [333/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [334/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [335/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [336/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [337/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [338/1063], Loss: 0.0043\n",
      "Epoch [10/10], Step [339/1063], Loss: 0.0047\n",
      "Epoch [10/10], Step [340/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [341/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [342/1063], Loss: 0.0262\n",
      "Epoch [10/10], Step [343/1063], Loss: 0.0096\n",
      "Epoch [10/10], Step [344/1063], Loss: 0.0038\n",
      "Epoch [10/10], Step [345/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [346/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [347/1063], Loss: 0.0059\n",
      "Epoch [10/10], Step [348/1063], Loss: 0.0081\n",
      "Epoch [10/10], Step [349/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [350/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [351/1063], Loss: 0.0058\n",
      "Epoch [10/10], Step [352/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [353/1063], Loss: 0.0160\n",
      "Epoch [10/10], Step [354/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [355/1063], Loss: 0.0066\n",
      "Epoch [10/10], Step [356/1063], Loss: 0.0694\n",
      "Epoch [10/10], Step [357/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [358/1063], Loss: 0.0320\n",
      "Epoch [10/10], Step [359/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [360/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [361/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [362/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [363/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [364/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [365/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [366/1063], Loss: 0.0143\n",
      "Epoch [10/10], Step [367/1063], Loss: 0.0049\n",
      "Epoch [10/10], Step [368/1063], Loss: 0.0027\n",
      "Epoch [10/10], Step [369/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [370/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [371/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [372/1063], Loss: 0.0123\n",
      "Epoch [10/10], Step [373/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [374/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [375/1063], Loss: 0.0481\n",
      "Epoch [10/10], Step [376/1063], Loss: 0.0209\n",
      "Epoch [10/10], Step [377/1063], Loss: 0.0047\n",
      "Epoch [10/10], Step [378/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [379/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [380/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [381/1063], Loss: 0.0215\n",
      "Epoch [10/10], Step [382/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [383/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [384/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [385/1063], Loss: 0.0084\n",
      "Epoch [10/10], Step [386/1063], Loss: 0.0097\n",
      "Epoch [10/10], Step [387/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [388/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [389/1063], Loss: 0.0584\n",
      "Epoch [10/10], Step [390/1063], Loss: 0.0986\n",
      "Epoch [10/10], Step [391/1063], Loss: 0.0050\n",
      "Epoch [10/10], Step [392/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [393/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [394/1063], Loss: 0.0035\n",
      "Epoch [10/10], Step [395/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [396/1063], Loss: 0.0034\n",
      "Epoch [10/10], Step [397/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [398/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [399/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [400/1063], Loss: 0.0056\n",
      "Epoch [10/10], Step [401/1063], Loss: 0.0113\n",
      "Epoch [10/10], Step [402/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [403/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [404/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [405/1063], Loss: 0.0189\n",
      "Epoch [10/10], Step [406/1063], Loss: 0.0034\n",
      "Epoch [10/10], Step [407/1063], Loss: 0.0125\n",
      "Epoch [10/10], Step [408/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [409/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [410/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [411/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [412/1063], Loss: 0.0015\n",
      "Epoch [10/10], Step [413/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [414/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [415/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [416/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [417/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [418/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [419/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [420/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [421/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [422/1063], Loss: 0.0072\n",
      "Epoch [10/10], Step [423/1063], Loss: 0.0161\n",
      "Epoch [10/10], Step [424/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [425/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [426/1063], Loss: 0.0035\n",
      "Epoch [10/10], Step [427/1063], Loss: 0.0071\n",
      "Epoch [10/10], Step [428/1063], Loss: 0.1074\n",
      "Epoch [10/10], Step [429/1063], Loss: 0.0570\n",
      "Epoch [10/10], Step [430/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [431/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [432/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [433/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [434/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [435/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [436/1063], Loss: 0.0022\n",
      "Epoch [10/10], Step [437/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [438/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [439/1063], Loss: 0.0109\n",
      "Epoch [10/10], Step [440/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [441/1063], Loss: 0.0050\n",
      "Epoch [10/10], Step [442/1063], Loss: 0.0446\n",
      "Epoch [10/10], Step [443/1063], Loss: 0.0067\n",
      "Epoch [10/10], Step [444/1063], Loss: 0.0043\n",
      "Epoch [10/10], Step [445/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [446/1063], Loss: 0.0427\n",
      "Epoch [10/10], Step [447/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [448/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [449/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [450/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [451/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [452/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [453/1063], Loss: 0.0043\n",
      "Epoch [10/10], Step [454/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [455/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [456/1063], Loss: 0.0603\n",
      "Epoch [10/10], Step [457/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [458/1063], Loss: 0.0568\n",
      "Epoch [10/10], Step [459/1063], Loss: 0.0025\n",
      "Epoch [10/10], Step [460/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [461/1063], Loss: 0.0056\n",
      "Epoch [10/10], Step [462/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [463/1063], Loss: 0.0024\n",
      "Epoch [10/10], Step [464/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [465/1063], Loss: 0.0019\n",
      "Epoch [10/10], Step [466/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [467/1063], Loss: 0.0165\n",
      "Epoch [10/10], Step [468/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [469/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [470/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [471/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [472/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [473/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [474/1063], Loss: 0.0039\n",
      "Epoch [10/10], Step [475/1063], Loss: 0.0096\n",
      "Epoch [10/10], Step [476/1063], Loss: 0.0024\n",
      "Epoch [10/10], Step [477/1063], Loss: 0.0373\n",
      "Epoch [10/10], Step [478/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [479/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [480/1063], Loss: 0.0023\n",
      "Epoch [10/10], Step [481/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [482/1063], Loss: 0.0025\n",
      "Epoch [10/10], Step [483/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [484/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [485/1063], Loss: 0.0727\n",
      "Epoch [10/10], Step [486/1063], Loss: 0.0190\n",
      "Epoch [10/10], Step [487/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [488/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [489/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [490/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [491/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [492/1063], Loss: 0.0046\n",
      "Epoch [10/10], Step [493/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [494/1063], Loss: 0.0070\n",
      "Epoch [10/10], Step [495/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [496/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [497/1063], Loss: 0.0267\n",
      "Epoch [10/10], Step [498/1063], Loss: 0.0123\n",
      "Epoch [10/10], Step [499/1063], Loss: 0.0156\n",
      "Epoch [10/10], Step [500/1063], Loss: 0.0027\n",
      "Epoch [10/10], Step [501/1063], Loss: 0.0094\n",
      "Epoch [10/10], Step [502/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [503/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [504/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [505/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [506/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [507/1063], Loss: 0.0154\n",
      "Epoch [10/10], Step [508/1063], Loss: 0.0052\n",
      "Epoch [10/10], Step [509/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [510/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [511/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [512/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [513/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [514/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [515/1063], Loss: 0.0025\n",
      "Epoch [10/10], Step [516/1063], Loss: 0.0043\n",
      "Epoch [10/10], Step [517/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [518/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [519/1063], Loss: 0.0294\n",
      "Epoch [10/10], Step [520/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [521/1063], Loss: 0.0245\n",
      "Epoch [10/10], Step [522/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [523/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [524/1063], Loss: 0.0386\n",
      "Epoch [10/10], Step [525/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [526/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [527/1063], Loss: 0.0049\n",
      "Epoch [10/10], Step [528/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [529/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [530/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [531/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [532/1063], Loss: 0.0107\n",
      "Epoch [10/10], Step [533/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [534/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [535/1063], Loss: 0.0016\n",
      "Epoch [10/10], Step [536/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [537/1063], Loss: 0.0031\n",
      "Epoch [10/10], Step [538/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [539/1063], Loss: 0.1127\n",
      "Epoch [10/10], Step [540/1063], Loss: 0.0271\n",
      "Epoch [10/10], Step [541/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [542/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [543/1063], Loss: 0.0220\n",
      "Epoch [10/10], Step [544/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [545/1063], Loss: 0.0136\n",
      "Epoch [10/10], Step [546/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [547/1063], Loss: 0.0518\n",
      "Epoch [10/10], Step [548/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [549/1063], Loss: 0.0065\n",
      "Epoch [10/10], Step [550/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [551/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [552/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [553/1063], Loss: 0.0030\n",
      "Epoch [10/10], Step [554/1063], Loss: 0.0162\n",
      "Epoch [10/10], Step [555/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [556/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [557/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [558/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [559/1063], Loss: 0.0029\n",
      "Epoch [10/10], Step [560/1063], Loss: 0.0097\n",
      "Epoch [10/10], Step [561/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [562/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [563/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [564/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [565/1063], Loss: 0.0035\n",
      "Epoch [10/10], Step [566/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [567/1063], Loss: 0.0144\n",
      "Epoch [10/10], Step [568/1063], Loss: 0.0022\n",
      "Epoch [10/10], Step [569/1063], Loss: 0.0044\n",
      "Epoch [10/10], Step [570/1063], Loss: 0.0070\n",
      "Epoch [10/10], Step [571/1063], Loss: 0.0174\n",
      "Epoch [10/10], Step [572/1063], Loss: 0.0033\n",
      "Epoch [10/10], Step [573/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [574/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [575/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [576/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [577/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [578/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [579/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [580/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [581/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [582/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [583/1063], Loss: 0.0138\n",
      "Epoch [10/10], Step [584/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [585/1063], Loss: 0.0047\n",
      "Epoch [10/10], Step [586/1063], Loss: 0.0038\n",
      "Epoch [10/10], Step [587/1063], Loss: 0.0244\n",
      "Epoch [10/10], Step [588/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [589/1063], Loss: 0.0083\n",
      "Epoch [10/10], Step [590/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [591/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [592/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [593/1063], Loss: 0.0045\n",
      "Epoch [10/10], Step [594/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [595/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [596/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [597/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [598/1063], Loss: 0.0024\n",
      "Epoch [10/10], Step [599/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [600/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [601/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [602/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [603/1063], Loss: 0.0432\n",
      "Epoch [10/10], Step [604/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [605/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [606/1063], Loss: 0.0217\n",
      "Epoch [10/10], Step [607/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [608/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [609/1063], Loss: 0.0036\n",
      "Epoch [10/10], Step [610/1063], Loss: 0.0108\n",
      "Epoch [10/10], Step [611/1063], Loss: 0.0064\n",
      "Epoch [10/10], Step [612/1063], Loss: 0.0509\n",
      "Epoch [10/10], Step [613/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [614/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [615/1063], Loss: 0.0116\n",
      "Epoch [10/10], Step [616/1063], Loss: 0.0079\n",
      "Epoch [10/10], Step [617/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [618/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [619/1063], Loss: 0.0088\n",
      "Epoch [10/10], Step [620/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [621/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [622/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [623/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [624/1063], Loss: 0.0506\n",
      "Epoch [10/10], Step [625/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [626/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [627/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [628/1063], Loss: 0.0019\n",
      "Epoch [10/10], Step [629/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [630/1063], Loss: 0.0048\n",
      "Epoch [10/10], Step [631/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [632/1063], Loss: 0.0035\n",
      "Epoch [10/10], Step [633/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [634/1063], Loss: 0.0039\n",
      "Epoch [10/10], Step [635/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [636/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [637/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [638/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [639/1063], Loss: 0.0559\n",
      "Epoch [10/10], Step [640/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [641/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [642/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [643/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [644/1063], Loss: 0.0344\n",
      "Epoch [10/10], Step [645/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [646/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [647/1063], Loss: 0.0289\n",
      "Epoch [10/10], Step [648/1063], Loss: 0.0810\n",
      "Epoch [10/10], Step [649/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [650/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [651/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [652/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [653/1063], Loss: 0.0038\n",
      "Epoch [10/10], Step [654/1063], Loss: 0.0401\n",
      "Epoch [10/10], Step [655/1063], Loss: 0.0042\n",
      "Epoch [10/10], Step [656/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [657/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [658/1063], Loss: 0.0098\n",
      "Epoch [10/10], Step [659/1063], Loss: 0.0105\n",
      "Epoch [10/10], Step [660/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [661/1063], Loss: 0.0045\n",
      "Epoch [10/10], Step [662/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [663/1063], Loss: 0.0139\n",
      "Epoch [10/10], Step [664/1063], Loss: 0.0017\n",
      "Epoch [10/10], Step [665/1063], Loss: 0.0169\n",
      "Epoch [10/10], Step [666/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [667/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [668/1063], Loss: 0.0026\n",
      "Epoch [10/10], Step [669/1063], Loss: 0.0165\n",
      "Epoch [10/10], Step [670/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [671/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [672/1063], Loss: 0.0027\n",
      "Epoch [10/10], Step [673/1063], Loss: 0.0022\n",
      "Epoch [10/10], Step [674/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [675/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [676/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [677/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [678/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [679/1063], Loss: 0.0171\n",
      "Epoch [10/10], Step [680/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [681/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [682/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [683/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [684/1063], Loss: 0.0048\n",
      "Epoch [10/10], Step [685/1063], Loss: 0.0050\n",
      "Epoch [10/10], Step [686/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [687/1063], Loss: 0.0358\n",
      "Epoch [10/10], Step [688/1063], Loss: 0.0029\n",
      "Epoch [10/10], Step [689/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [690/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [691/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [692/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [693/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [694/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [695/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [696/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [697/1063], Loss: 0.0049\n",
      "Epoch [10/10], Step [698/1063], Loss: 0.0023\n",
      "Epoch [10/10], Step [699/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [700/1063], Loss: 0.0030\n",
      "Epoch [10/10], Step [701/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [702/1063], Loss: 0.0178\n",
      "Epoch [10/10], Step [703/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [704/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [705/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [706/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [707/1063], Loss: 0.0031\n",
      "Epoch [10/10], Step [708/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [709/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [710/1063], Loss: 0.0201\n",
      "Epoch [10/10], Step [711/1063], Loss: 0.0025\n",
      "Epoch [10/10], Step [712/1063], Loss: 0.0187\n",
      "Epoch [10/10], Step [713/1063], Loss: 0.0023\n",
      "Epoch [10/10], Step [714/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [715/1063], Loss: 0.0023\n",
      "Epoch [10/10], Step [716/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [717/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [718/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [719/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [720/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [721/1063], Loss: 0.0177\n",
      "Epoch [10/10], Step [722/1063], Loss: 0.0086\n",
      "Epoch [10/10], Step [723/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [724/1063], Loss: 0.0091\n",
      "Epoch [10/10], Step [725/1063], Loss: 0.0780\n",
      "Epoch [10/10], Step [726/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [727/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [728/1063], Loss: 0.0348\n",
      "Epoch [10/10], Step [729/1063], Loss: 0.0026\n",
      "Epoch [10/10], Step [730/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [731/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [732/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [733/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [734/1063], Loss: 0.0036\n",
      "Epoch [10/10], Step [735/1063], Loss: 0.0028\n",
      "Epoch [10/10], Step [736/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [737/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [738/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [739/1063], Loss: 0.0026\n",
      "Epoch [10/10], Step [740/1063], Loss: 0.0176\n",
      "Epoch [10/10], Step [741/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [742/1063], Loss: 0.0486\n",
      "Epoch [10/10], Step [743/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [744/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [745/1063], Loss: 0.0083\n",
      "Epoch [10/10], Step [746/1063], Loss: 0.0194\n",
      "Epoch [10/10], Step [747/1063], Loss: 0.0047\n",
      "Epoch [10/10], Step [748/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [749/1063], Loss: 0.0149\n",
      "Epoch [10/10], Step [750/1063], Loss: 0.0017\n",
      "Epoch [10/10], Step [751/1063], Loss: 0.0071\n",
      "Epoch [10/10], Step [752/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [753/1063], Loss: 0.0051\n",
      "Epoch [10/10], Step [754/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [755/1063], Loss: 0.0117\n",
      "Epoch [10/10], Step [756/1063], Loss: 0.0641\n",
      "Epoch [10/10], Step [757/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [758/1063], Loss: 0.0113\n",
      "Epoch [10/10], Step [759/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [760/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [761/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [762/1063], Loss: 0.0108\n",
      "Epoch [10/10], Step [763/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [764/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [765/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [766/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [767/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [768/1063], Loss: 0.0040\n",
      "Epoch [10/10], Step [769/1063], Loss: 0.0017\n",
      "Epoch [10/10], Step [770/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [771/1063], Loss: 0.0058\n",
      "Epoch [10/10], Step [772/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [773/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [774/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [775/1063], Loss: 0.0030\n",
      "Epoch [10/10], Step [776/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [777/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [778/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [779/1063], Loss: 0.0277\n",
      "Epoch [10/10], Step [780/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [781/1063], Loss: 0.0030\n",
      "Epoch [10/10], Step [782/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [783/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [784/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [785/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [786/1063], Loss: 0.0068\n",
      "Epoch [10/10], Step [787/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [788/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [789/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [790/1063], Loss: 0.0309\n",
      "Epoch [10/10], Step [791/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [792/1063], Loss: 0.0040\n",
      "Epoch [10/10], Step [793/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [794/1063], Loss: 0.0587\n",
      "Epoch [10/10], Step [795/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [796/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [797/1063], Loss: 0.0059\n",
      "Epoch [10/10], Step [798/1063], Loss: 0.0119\n",
      "Epoch [10/10], Step [799/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [800/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [801/1063], Loss: 0.0419\n",
      "Epoch [10/10], Step [802/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [803/1063], Loss: 0.0061\n",
      "Epoch [10/10], Step [804/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [805/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [806/1063], Loss: 0.0030\n",
      "Epoch [10/10], Step [807/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [808/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [809/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [810/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [811/1063], Loss: 0.1135\n",
      "Epoch [10/10], Step [812/1063], Loss: 0.0024\n",
      "Epoch [10/10], Step [813/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [814/1063], Loss: 0.0016\n",
      "Epoch [10/10], Step [815/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [816/1063], Loss: 0.0250\n",
      "Epoch [10/10], Step [817/1063], Loss: 0.0232\n",
      "Epoch [10/10], Step [818/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [819/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [820/1063], Loss: 0.0043\n",
      "Epoch [10/10], Step [821/1063], Loss: 0.0552\n",
      "Epoch [10/10], Step [822/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [823/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [824/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [825/1063], Loss: 0.0139\n",
      "Epoch [10/10], Step [826/1063], Loss: 0.0066\n",
      "Epoch [10/10], Step [827/1063], Loss: 0.0151\n",
      "Epoch [10/10], Step [828/1063], Loss: 0.0161\n",
      "Epoch [10/10], Step [829/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [830/1063], Loss: 0.0098\n",
      "Epoch [10/10], Step [831/1063], Loss: 0.0066\n",
      "Epoch [10/10], Step [832/1063], Loss: 0.0048\n",
      "Epoch [10/10], Step [833/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [834/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [835/1063], Loss: 0.0063\n",
      "Epoch [10/10], Step [836/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [837/1063], Loss: 0.0044\n",
      "Epoch [10/10], Step [838/1063], Loss: 0.0178\n",
      "Epoch [10/10], Step [839/1063], Loss: 0.0647\n",
      "Epoch [10/10], Step [840/1063], Loss: 0.0202\n",
      "Epoch [10/10], Step [841/1063], Loss: 0.0126\n",
      "Epoch [10/10], Step [842/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [843/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [844/1063], Loss: 0.0065\n",
      "Epoch [10/10], Step [845/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [846/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [847/1063], Loss: 0.0710\n",
      "Epoch [10/10], Step [848/1063], Loss: 0.0059\n",
      "Epoch [10/10], Step [849/1063], Loss: 0.0026\n",
      "Epoch [10/10], Step [850/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [851/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [852/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [853/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [854/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [855/1063], Loss: 0.0050\n",
      "Epoch [10/10], Step [856/1063], Loss: 0.0425\n",
      "Epoch [10/10], Step [857/1063], Loss: 0.0019\n",
      "Epoch [10/10], Step [858/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [859/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [860/1063], Loss: 0.0155\n",
      "Epoch [10/10], Step [861/1063], Loss: 0.0063\n",
      "Epoch [10/10], Step [862/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [863/1063], Loss: 0.0174\n",
      "Epoch [10/10], Step [864/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [865/1063], Loss: 0.0068\n",
      "Epoch [10/10], Step [866/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [867/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [868/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [869/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [870/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [871/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [872/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [873/1063], Loss: 0.0042\n",
      "Epoch [10/10], Step [874/1063], Loss: 0.0041\n",
      "Epoch [10/10], Step [875/1063], Loss: 0.0850\n",
      "Epoch [10/10], Step [876/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [877/1063], Loss: 0.0017\n",
      "Epoch [10/10], Step [878/1063], Loss: 0.0266\n",
      "Epoch [10/10], Step [879/1063], Loss: 0.0019\n",
      "Epoch [10/10], Step [880/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [881/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [882/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [883/1063], Loss: 0.0439\n",
      "Epoch [10/10], Step [884/1063], Loss: 0.0030\n",
      "Epoch [10/10], Step [885/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [886/1063], Loss: 0.0058\n",
      "Epoch [10/10], Step [887/1063], Loss: 0.0019\n",
      "Epoch [10/10], Step [888/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [889/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [890/1063], Loss: 0.0142\n",
      "Epoch [10/10], Step [891/1063], Loss: 0.0024\n",
      "Epoch [10/10], Step [892/1063], Loss: 0.0780\n",
      "Epoch [10/10], Step [893/1063], Loss: 0.0031\n",
      "Epoch [10/10], Step [894/1063], Loss: 0.0008\n",
      "Epoch [10/10], Step [895/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [896/1063], Loss: 0.0066\n",
      "Epoch [10/10], Step [897/1063], Loss: 0.0060\n",
      "Epoch [10/10], Step [898/1063], Loss: 0.0237\n",
      "Epoch [10/10], Step [899/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [900/1063], Loss: 0.1723\n",
      "Epoch [10/10], Step [901/1063], Loss: 0.0054\n",
      "Epoch [10/10], Step [902/1063], Loss: 0.0181\n",
      "Epoch [10/10], Step [903/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [904/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [905/1063], Loss: 0.0034\n",
      "Epoch [10/10], Step [906/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [907/1063], Loss: 0.0162\n",
      "Epoch [10/10], Step [908/1063], Loss: 0.0016\n",
      "Epoch [10/10], Step [909/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [910/1063], Loss: 0.0098\n",
      "Epoch [10/10], Step [911/1063], Loss: 0.0059\n",
      "Epoch [10/10], Step [912/1063], Loss: 0.0049\n",
      "Epoch [10/10], Step [913/1063], Loss: 0.0019\n",
      "Epoch [10/10], Step [914/1063], Loss: 0.0073\n",
      "Epoch [10/10], Step [915/1063], Loss: 0.0092\n",
      "Epoch [10/10], Step [916/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [917/1063], Loss: 0.0031\n",
      "Epoch [10/10], Step [918/1063], Loss: 0.0132\n",
      "Epoch [10/10], Step [919/1063], Loss: 0.0133\n",
      "Epoch [10/10], Step [920/1063], Loss: 0.0060\n",
      "Epoch [10/10], Step [921/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [922/1063], Loss: 0.0063\n",
      "Epoch [10/10], Step [923/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [924/1063], Loss: 0.0045\n",
      "Epoch [10/10], Step [925/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [926/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [927/1063], Loss: 0.0029\n",
      "Epoch [10/10], Step [928/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [929/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [930/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [931/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [932/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [933/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [934/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [935/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [936/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [937/1063], Loss: 0.0067\n",
      "Epoch [10/10], Step [938/1063], Loss: 0.0016\n",
      "Epoch [10/10], Step [939/1063], Loss: 0.0067\n",
      "Epoch [10/10], Step [940/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [941/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [942/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [943/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [944/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [945/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [946/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [947/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [948/1063], Loss: 0.0222\n",
      "Epoch [10/10], Step [949/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [950/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [951/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [952/1063], Loss: 0.1048\n",
      "Epoch [10/10], Step [953/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [954/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [955/1063], Loss: 0.0124\n",
      "Epoch [10/10], Step [956/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [957/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [958/1063], Loss: 0.0046\n",
      "Epoch [10/10], Step [959/1063], Loss: 0.0549\n",
      "Epoch [10/10], Step [960/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [961/1063], Loss: 0.0041\n",
      "Epoch [10/10], Step [962/1063], Loss: 0.0098\n",
      "Epoch [10/10], Step [963/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [964/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [965/1063], Loss: 0.0070\n",
      "Epoch [10/10], Step [966/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [967/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [968/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [969/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [970/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [971/1063], Loss: 0.0036\n",
      "Epoch [10/10], Step [972/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [973/1063], Loss: 0.0121\n",
      "Epoch [10/10], Step [974/1063], Loss: 0.0006\n",
      "Epoch [10/10], Step [975/1063], Loss: 0.0333\n",
      "Epoch [10/10], Step [976/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [977/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [978/1063], Loss: 0.0522\n",
      "Epoch [10/10], Step [979/1063], Loss: 0.0021\n",
      "Epoch [10/10], Step [980/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [981/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [982/1063], Loss: 0.0016\n",
      "Epoch [10/10], Step [983/1063], Loss: 0.1038\n",
      "Epoch [10/10], Step [984/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [985/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [986/1063], Loss: 0.0069\n",
      "Epoch [10/10], Step [987/1063], Loss: 0.0011\n",
      "Epoch [10/10], Step [988/1063], Loss: 0.0258\n",
      "Epoch [10/10], Step [989/1063], Loss: 0.0156\n",
      "Epoch [10/10], Step [990/1063], Loss: 0.1251\n",
      "Epoch [10/10], Step [991/1063], Loss: 0.0130\n",
      "Epoch [10/10], Step [992/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [993/1063], Loss: 0.0020\n",
      "Epoch [10/10], Step [994/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [995/1063], Loss: 0.0173\n",
      "Epoch [10/10], Step [996/1063], Loss: 0.0094\n",
      "Epoch [10/10], Step [997/1063], Loss: 0.0038\n",
      "Epoch [10/10], Step [998/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [999/1063], Loss: 0.0275\n",
      "Epoch [10/10], Step [1000/1063], Loss: 0.0033\n",
      "Epoch [10/10], Step [1001/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [1002/1063], Loss: 0.0115\n",
      "Epoch [10/10], Step [1003/1063], Loss: 0.0152\n",
      "Epoch [10/10], Step [1004/1063], Loss: 0.0244\n",
      "Epoch [10/10], Step [1005/1063], Loss: 0.0900\n",
      "Epoch [10/10], Step [1006/1063], Loss: 0.0099\n",
      "Epoch [10/10], Step [1007/1063], Loss: 0.0115\n",
      "Epoch [10/10], Step [1008/1063], Loss: 0.0028\n",
      "Epoch [10/10], Step [1009/1063], Loss: 0.0038\n",
      "Epoch [10/10], Step [1010/1063], Loss: 0.0065\n",
      "Epoch [10/10], Step [1011/1063], Loss: 0.0528\n",
      "Epoch [10/10], Step [1012/1063], Loss: 0.0459\n",
      "Epoch [10/10], Step [1013/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [1014/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [1015/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [1016/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [1017/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [1018/1063], Loss: 0.0059\n",
      "Epoch [10/10], Step [1019/1063], Loss: 0.0025\n",
      "Epoch [10/10], Step [1020/1063], Loss: 0.0015\n",
      "Epoch [10/10], Step [1021/1063], Loss: 0.0060\n",
      "Epoch [10/10], Step [1022/1063], Loss: 0.0112\n",
      "Epoch [10/10], Step [1023/1063], Loss: 0.0012\n",
      "Epoch [10/10], Step [1024/1063], Loss: 0.0068\n",
      "Epoch [10/10], Step [1025/1063], Loss: 0.0019\n",
      "Epoch [10/10], Step [1026/1063], Loss: 0.0273\n",
      "Epoch [10/10], Step [1027/1063], Loss: 0.0103\n",
      "Epoch [10/10], Step [1028/1063], Loss: 0.0240\n",
      "Epoch [10/10], Step [1029/1063], Loss: 0.0013\n",
      "Epoch [10/10], Step [1030/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [1031/1063], Loss: 0.1677\n",
      "Epoch [10/10], Step [1032/1063], Loss: 0.0202\n",
      "Epoch [10/10], Step [1033/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [1034/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [1035/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [1036/1063], Loss: 0.0005\n",
      "Epoch [10/10], Step [1037/1063], Loss: 0.0038\n",
      "Epoch [10/10], Step [1038/1063], Loss: 0.0082\n",
      "Epoch [10/10], Step [1039/1063], Loss: 0.0100\n",
      "Epoch [10/10], Step [1040/1063], Loss: 0.0018\n",
      "Epoch [10/10], Step [1041/1063], Loss: 0.0141\n",
      "Epoch [10/10], Step [1042/1063], Loss: 0.0078\n",
      "Epoch [10/10], Step [1043/1063], Loss: 0.0000\n",
      "Epoch [10/10], Step [1044/1063], Loss: 0.0001\n",
      "Epoch [10/10], Step [1045/1063], Loss: 0.0014\n",
      "Epoch [10/10], Step [1046/1063], Loss: 0.1043\n",
      "Epoch [10/10], Step [1047/1063], Loss: 0.0010\n",
      "Epoch [10/10], Step [1048/1063], Loss: 0.0027\n",
      "Epoch [10/10], Step [1049/1063], Loss: 0.0009\n",
      "Epoch [10/10], Step [1050/1063], Loss: 0.0057\n",
      "Epoch [10/10], Step [1051/1063], Loss: 0.0003\n",
      "Epoch [10/10], Step [1052/1063], Loss: 0.0043\n",
      "Epoch [10/10], Step [1053/1063], Loss: 0.0007\n",
      "Epoch [10/10], Step [1054/1063], Loss: 0.0002\n",
      "Epoch [10/10], Step [1055/1063], Loss: 0.0150\n",
      "Epoch [10/10], Step [1056/1063], Loss: 0.0077\n",
      "Epoch [10/10], Step [1057/1063], Loss: 0.0019\n",
      "Epoch [10/10], Step [1058/1063], Loss: 0.1447\n",
      "Epoch [10/10], Step [1059/1063], Loss: 0.0017\n",
      "Epoch [10/10], Step [1060/1063], Loss: 0.0197\n",
      "Epoch [10/10], Step [1061/1063], Loss: 0.0099\n",
      "Epoch [10/10], Step [1062/1063], Loss: 0.0004\n",
      "Epoch [10/10], Step [1063/1063], Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "\n",
    "# Prefer CUDA > metal > CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "loss_train_history = []\n",
    "loss_validation_history = []\n",
    "start_time = time.time()\n",
    "\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(loader_train):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Step [{i+1}/{len(loader_train)}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    loss_train_history.append(running_loss / len(loader_train))\n",
    "\n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader_validation:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    loss_validation_history.append(val_loss / len(loader_validation))\n",
    "    \n",
    "    ax.clear()\n",
    "    ax.plot(range(1, epoch+2), loss_train_history, label='Train Loss')\n",
    "    ax.plot(range(1, epoch+2), loss_validation_history, label='Validation Loss')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    ax.set_title('Training and Validation Loss')\n",
    "    plt.pause(0.1)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_train_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot training and validation loss\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[43mloss_train_history\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), loss_validation_history, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_train_history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training and validation loss\n",
    "plt.plot(range(1, EPOCHS+1), loss_train_history, label='Train Loss')\n",
    "plt.plot(range(1, EPOCHS+1), loss_validation_history, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "train_acc = evaluate(loader_train)\n",
    "val_acc = evaluate(loader_validation)\n",
    "test_acc = evaluate(loader_test)\n",
    "\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(f\"Train Accuracy: {train_acc:.3f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.3f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments_JF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
