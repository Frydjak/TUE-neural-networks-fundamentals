{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True # Used to display additional information during program execution\n",
    "TEST_SIZE = 1000\n",
    "VALIDATION_SIZE = 1000\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 785\n",
      "m = 70000\n",
      "labels_train.shape = (69000,)\n",
      "values_train.shape = (784, 69000)\n",
      "labels_test.shape = (1000,)\n",
      "values_test.shape = (784, 1000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from a file\n",
    "data = pd.read_csv('Datasets/MNIST_CSV/mnist.csv', header=None)\n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data)\n",
    "\n",
    "data_test = data[0:TEST_SIZE].T\n",
    "labels_test = data_test[0]\n",
    "values_test = data_test[1:n] / 255\n",
    "\n",
    "data_validation = data[TEST_SIZE:(TEST_SIZE+VALIDATION_SIZE)].T\n",
    "labels_validation = data_validation[0]\n",
    "values_validation = data_validation[1:n] / 255\n",
    "\n",
    "data_train = data[TEST_SIZE:m].T\n",
    "labels_train = data_train[0]\n",
    "values_train = data_train[1:n] / 255\n",
    "\n",
    "values_test = data_test[1:n].astype(np.float32) / 255.0\n",
    "values_validation = data_validation[1:n].astype(np.float32) / 255.0\n",
    "values_train = data_train[1:n].astype(np.float32) / 255.0\n",
    "\n",
    "def show_image(values, index):\n",
    "    \"\"\"\n",
    "    Display image selected by index from given values matrix\n",
    "    \"\"\"\n",
    "    image = values[:, index, None]\n",
    "    image = image.reshape((28,28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "if DEBUG:\n",
    "    print(\"n =\",n)\n",
    "    print(\"m =\",m)\n",
    "    print(\"labels_train.shape =\",labels_train.shape)\n",
    "    print(\"values_train.shape =\",values_train.shape)\n",
    "    print(\"labels_test.shape =\",labels_test.shape)\n",
    "    print(\"values_test.shape =\",values_test.shape)\n",
    "    show_image(values_train, 0)\n",
    "    print(\"Label:\",labels_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch tensors\n",
    "values_train = torch.tensor(values_train.T, dtype=torch.float32).view(-1, 1, 28, 28)\n",
    "values_validation = torch.tensor(values_validation.T, dtype=torch.float32).view(-1, 1, 28, 28)\n",
    "values_test = torch.tensor(values_test.T, dtype=torch.float32).view(-1, 1, 28, 28)\n",
    "\n",
    "labels_train = torch.tensor(labels_train, dtype=torch.long)\n",
    "labels_validation = torch.tensor(labels_validation, dtype=torch.long)\n",
    "labels_test = torch.tensor(labels_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(values_train, labels_train)\n",
    "validation_dataset = TensorDataset(values_validation, labels_validation)\n",
    "test_dataset = TensorDataset(values_test, labels_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Option to print a sample to verify data correctness\n",
    "if DEBUG:\n",
    "    sample_idx = 0\n",
    "    plt.imshow(values_train[sample_idx].squeeze(), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(\"Sample Label:\", labels_train[sample_idx].item())\n",
    "\n",
    "train_dataset = TensorDataset(values_train, labels_train)\n",
    "validation_dataset = TensorDataset(values_validation, labels_validation)\n",
    "test_dataset = TensorDataset(values_test, labels_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/1079], Loss: 2.3013\n",
      "Epoch [1/10], Step [2/1079], Loss: 2.2705\n",
      "Epoch [1/10], Step [3/1079], Loss: 2.3106\n",
      "Epoch [1/10], Step [4/1079], Loss: 2.2637\n",
      "Epoch [1/10], Step [5/1079], Loss: 2.2307\n",
      "Epoch [1/10], Step [6/1079], Loss: 2.1748\n",
      "Epoch [1/10], Step [7/1079], Loss: 2.1545\n",
      "Epoch [1/10], Step [8/1079], Loss: 2.1090\n",
      "Epoch [1/10], Step [9/1079], Loss: 2.0893\n",
      "Epoch [1/10], Step [10/1079], Loss: 2.0363\n",
      "Epoch [1/10], Step [11/1079], Loss: 1.9114\n",
      "Epoch [1/10], Step [12/1079], Loss: 1.8646\n",
      "Epoch [1/10], Step [13/1079], Loss: 1.7775\n",
      "Epoch [1/10], Step [14/1079], Loss: 1.7222\n",
      "Epoch [1/10], Step [15/1079], Loss: 1.6040\n",
      "Epoch [1/10], Step [16/1079], Loss: 1.4444\n",
      "Epoch [1/10], Step [17/1079], Loss: 1.4464\n",
      "Epoch [1/10], Step [18/1079], Loss: 1.5033\n",
      "Epoch [1/10], Step [19/1079], Loss: 1.3172\n",
      "Epoch [1/10], Step [20/1079], Loss: 1.1069\n",
      "Epoch [1/10], Step [21/1079], Loss: 1.0607\n",
      "Epoch [1/10], Step [22/1079], Loss: 1.1668\n",
      "Epoch [1/10], Step [23/1079], Loss: 0.9220\n",
      "Epoch [1/10], Step [24/1079], Loss: 0.8945\n",
      "Epoch [1/10], Step [25/1079], Loss: 0.8590\n",
      "Epoch [1/10], Step [26/1079], Loss: 0.8081\n",
      "Epoch [1/10], Step [27/1079], Loss: 0.8049\n",
      "Epoch [1/10], Step [28/1079], Loss: 0.6201\n",
      "Epoch [1/10], Step [29/1079], Loss: 0.7828\n",
      "Epoch [1/10], Step [30/1079], Loss: 0.8320\n",
      "Epoch [1/10], Step [31/1079], Loss: 0.7009\n",
      "Epoch [1/10], Step [32/1079], Loss: 1.0466\n",
      "Epoch [1/10], Step [33/1079], Loss: 0.7331\n",
      "Epoch [1/10], Step [34/1079], Loss: 0.6018\n",
      "Epoch [1/10], Step [35/1079], Loss: 0.7739\n",
      "Epoch [1/10], Step [36/1079], Loss: 0.7222\n",
      "Epoch [1/10], Step [37/1079], Loss: 0.5273\n",
      "Epoch [1/10], Step [38/1079], Loss: 0.6238\n",
      "Epoch [1/10], Step [39/1079], Loss: 0.9734\n",
      "Epoch [1/10], Step [40/1079], Loss: 0.7384\n",
      "Epoch [1/10], Step [41/1079], Loss: 0.5580\n",
      "Epoch [1/10], Step [42/1079], Loss: 0.6372\n",
      "Epoch [1/10], Step [43/1079], Loss: 0.4681\n",
      "Epoch [1/10], Step [44/1079], Loss: 0.3646\n",
      "Epoch [1/10], Step [45/1079], Loss: 0.6792\n",
      "Epoch [1/10], Step [46/1079], Loss: 0.4155\n",
      "Epoch [1/10], Step [47/1079], Loss: 0.4280\n",
      "Epoch [1/10], Step [48/1079], Loss: 0.8175\n",
      "Epoch [1/10], Step [49/1079], Loss: 0.6122\n",
      "Epoch [1/10], Step [50/1079], Loss: 0.3873\n",
      "Epoch [1/10], Step [51/1079], Loss: 0.4522\n",
      "Epoch [1/10], Step [52/1079], Loss: 0.4376\n",
      "Epoch [1/10], Step [53/1079], Loss: 0.4218\n",
      "Epoch [1/10], Step [54/1079], Loss: 0.5139\n",
      "Epoch [1/10], Step [55/1079], Loss: 0.5243\n",
      "Epoch [1/10], Step [56/1079], Loss: 0.3729\n",
      "Epoch [1/10], Step [57/1079], Loss: 0.6588\n",
      "Epoch [1/10], Step [58/1079], Loss: 0.4210\n",
      "Epoch [1/10], Step [59/1079], Loss: 0.2966\n",
      "Epoch [1/10], Step [60/1079], Loss: 0.3895\n",
      "Epoch [1/10], Step [61/1079], Loss: 0.3213\n",
      "Epoch [1/10], Step [62/1079], Loss: 0.4778\n",
      "Epoch [1/10], Step [63/1079], Loss: 0.5318\n",
      "Epoch [1/10], Step [64/1079], Loss: 0.4222\n",
      "Epoch [1/10], Step [65/1079], Loss: 0.3439\n",
      "Epoch [1/10], Step [66/1079], Loss: 0.5377\n",
      "Epoch [1/10], Step [67/1079], Loss: 0.2918\n",
      "Epoch [1/10], Step [68/1079], Loss: 0.3828\n",
      "Epoch [1/10], Step [69/1079], Loss: 0.2949\n",
      "Epoch [1/10], Step [70/1079], Loss: 0.3681\n",
      "Epoch [1/10], Step [71/1079], Loss: 0.4178\n",
      "Epoch [1/10], Step [72/1079], Loss: 0.4235\n",
      "Epoch [1/10], Step [73/1079], Loss: 0.5320\n",
      "Epoch [1/10], Step [74/1079], Loss: 0.2576\n",
      "Epoch [1/10], Step [75/1079], Loss: 0.3159\n",
      "Epoch [1/10], Step [76/1079], Loss: 0.3395\n",
      "Epoch [1/10], Step [77/1079], Loss: 0.2460\n",
      "Epoch [1/10], Step [78/1079], Loss: 0.3159\n",
      "Epoch [1/10], Step [79/1079], Loss: 0.2707\n",
      "Epoch [1/10], Step [80/1079], Loss: 0.2386\n",
      "Epoch [1/10], Step [81/1079], Loss: 0.1680\n",
      "Epoch [1/10], Step [82/1079], Loss: 0.3818\n",
      "Epoch [1/10], Step [83/1079], Loss: 0.2687\n",
      "Epoch [1/10], Step [84/1079], Loss: 0.3699\n",
      "Epoch [1/10], Step [85/1079], Loss: 0.3221\n",
      "Epoch [1/10], Step [86/1079], Loss: 0.2578\n",
      "Epoch [1/10], Step [87/1079], Loss: 0.3808\n",
      "Epoch [1/10], Step [88/1079], Loss: 0.4631\n",
      "Epoch [1/10], Step [89/1079], Loss: 0.4119\n",
      "Epoch [1/10], Step [90/1079], Loss: 0.3391\n",
      "Epoch [1/10], Step [91/1079], Loss: 0.3457\n",
      "Epoch [1/10], Step [92/1079], Loss: 0.3124\n",
      "Epoch [1/10], Step [93/1079], Loss: 0.3529\n",
      "Epoch [1/10], Step [94/1079], Loss: 0.2497\n",
      "Epoch [1/10], Step [95/1079], Loss: 0.2484\n",
      "Epoch [1/10], Step [96/1079], Loss: 0.3551\n",
      "Epoch [1/10], Step [97/1079], Loss: 0.4787\n",
      "Epoch [1/10], Step [98/1079], Loss: 0.3094\n",
      "Epoch [1/10], Step [99/1079], Loss: 0.3469\n",
      "Epoch [1/10], Step [100/1079], Loss: 0.5848\n",
      "Epoch [1/10], Step [101/1079], Loss: 0.3673\n",
      "Epoch [1/10], Step [102/1079], Loss: 0.2629\n",
      "Epoch [1/10], Step [103/1079], Loss: 0.4717\n",
      "Epoch [1/10], Step [104/1079], Loss: 0.3537\n",
      "Epoch [1/10], Step [105/1079], Loss: 0.3273\n",
      "Epoch [1/10], Step [106/1079], Loss: 0.2780\n",
      "Epoch [1/10], Step [107/1079], Loss: 0.2036\n",
      "Epoch [1/10], Step [108/1079], Loss: 0.3656\n",
      "Epoch [1/10], Step [109/1079], Loss: 0.2749\n",
      "Epoch [1/10], Step [110/1079], Loss: 0.1840\n",
      "Epoch [1/10], Step [111/1079], Loss: 0.3554\n",
      "Epoch [1/10], Step [112/1079], Loss: 0.3221\n",
      "Epoch [1/10], Step [113/1079], Loss: 0.2205\n",
      "Epoch [1/10], Step [114/1079], Loss: 0.3437\n",
      "Epoch [1/10], Step [115/1079], Loss: 0.3488\n",
      "Epoch [1/10], Step [116/1079], Loss: 0.2371\n",
      "Epoch [1/10], Step [117/1079], Loss: 0.1122\n",
      "Epoch [1/10], Step [118/1079], Loss: 0.5345\n",
      "Epoch [1/10], Step [119/1079], Loss: 0.2607\n",
      "Epoch [1/10], Step [120/1079], Loss: 0.2756\n",
      "Epoch [1/10], Step [121/1079], Loss: 0.3511\n",
      "Epoch [1/10], Step [122/1079], Loss: 0.1971\n",
      "Epoch [1/10], Step [123/1079], Loss: 0.1095\n",
      "Epoch [1/10], Step [124/1079], Loss: 0.2556\n",
      "Epoch [1/10], Step [125/1079], Loss: 0.4883\n",
      "Epoch [1/10], Step [126/1079], Loss: 0.2519\n",
      "Epoch [1/10], Step [127/1079], Loss: 0.1756\n",
      "Epoch [1/10], Step [128/1079], Loss: 0.2883\n",
      "Epoch [1/10], Step [129/1079], Loss: 0.3556\n",
      "Epoch [1/10], Step [130/1079], Loss: 0.1612\n",
      "Epoch [1/10], Step [131/1079], Loss: 0.3610\n",
      "Epoch [1/10], Step [132/1079], Loss: 0.3232\n",
      "Epoch [1/10], Step [133/1079], Loss: 0.2609\n",
      "Epoch [1/10], Step [134/1079], Loss: 0.2986\n",
      "Epoch [1/10], Step [135/1079], Loss: 0.3510\n",
      "Epoch [1/10], Step [136/1079], Loss: 0.2654\n",
      "Epoch [1/10], Step [137/1079], Loss: 0.1929\n",
      "Epoch [1/10], Step [138/1079], Loss: 0.1496\n",
      "Epoch [1/10], Step [139/1079], Loss: 0.1301\n",
      "Epoch [1/10], Step [140/1079], Loss: 0.2260\n",
      "Epoch [1/10], Step [141/1079], Loss: 0.2588\n",
      "Epoch [1/10], Step [142/1079], Loss: 0.1559\n",
      "Epoch [1/10], Step [143/1079], Loss: 0.2425\n",
      "Epoch [1/10], Step [144/1079], Loss: 0.2414\n",
      "Epoch [1/10], Step [145/1079], Loss: 0.1928\n",
      "Epoch [1/10], Step [146/1079], Loss: 0.1495\n",
      "Epoch [1/10], Step [147/1079], Loss: 0.1794\n",
      "Epoch [1/10], Step [148/1079], Loss: 0.2597\n",
      "Epoch [1/10], Step [149/1079], Loss: 0.1026\n",
      "Epoch [1/10], Step [150/1079], Loss: 0.1039\n",
      "Epoch [1/10], Step [151/1079], Loss: 0.1891\n",
      "Epoch [1/10], Step [152/1079], Loss: 0.2075\n",
      "Epoch [1/10], Step [153/1079], Loss: 0.1189\n",
      "Epoch [1/10], Step [154/1079], Loss: 0.1294\n",
      "Epoch [1/10], Step [155/1079], Loss: 0.2520\n",
      "Epoch [1/10], Step [156/1079], Loss: 0.1301\n",
      "Epoch [1/10], Step [157/1079], Loss: 0.1529\n",
      "Epoch [1/10], Step [158/1079], Loss: 0.2094\n",
      "Epoch [1/10], Step [159/1079], Loss: 0.1949\n",
      "Epoch [1/10], Step [160/1079], Loss: 0.4216\n",
      "Epoch [1/10], Step [161/1079], Loss: 0.1687\n",
      "Epoch [1/10], Step [162/1079], Loss: 0.1585\n",
      "Epoch [1/10], Step [163/1079], Loss: 0.1064\n",
      "Epoch [1/10], Step [164/1079], Loss: 0.2368\n",
      "Epoch [1/10], Step [165/1079], Loss: 0.3750\n",
      "Epoch [1/10], Step [166/1079], Loss: 0.1033\n",
      "Epoch [1/10], Step [167/1079], Loss: 0.3005\n",
      "Epoch [1/10], Step [168/1079], Loss: 0.1624\n",
      "Epoch [1/10], Step [169/1079], Loss: 0.0493\n",
      "Epoch [1/10], Step [170/1079], Loss: 0.1833\n",
      "Epoch [1/10], Step [171/1079], Loss: 0.0805\n",
      "Epoch [1/10], Step [172/1079], Loss: 0.2029\n",
      "Epoch [1/10], Step [173/1079], Loss: 0.1836\n",
      "Epoch [1/10], Step [174/1079], Loss: 0.3967\n",
      "Epoch [1/10], Step [175/1079], Loss: 0.1903\n",
      "Epoch [1/10], Step [176/1079], Loss: 0.0437\n",
      "Epoch [1/10], Step [177/1079], Loss: 0.1445\n",
      "Epoch [1/10], Step [178/1079], Loss: 0.3528\n",
      "Epoch [1/10], Step [179/1079], Loss: 0.1219\n",
      "Epoch [1/10], Step [180/1079], Loss: 0.2977\n",
      "Epoch [1/10], Step [181/1079], Loss: 0.2528\n",
      "Epoch [1/10], Step [182/1079], Loss: 0.0602\n",
      "Epoch [1/10], Step [183/1079], Loss: 0.1370\n",
      "Epoch [1/10], Step [184/1079], Loss: 0.2646\n",
      "Epoch [1/10], Step [185/1079], Loss: 0.1026\n",
      "Epoch [1/10], Step [186/1079], Loss: 0.2024\n",
      "Epoch [1/10], Step [187/1079], Loss: 0.1774\n",
      "Epoch [1/10], Step [188/1079], Loss: 0.1761\n",
      "Epoch [1/10], Step [189/1079], Loss: 0.2486\n",
      "Epoch [1/10], Step [190/1079], Loss: 0.1174\n",
      "Epoch [1/10], Step [191/1079], Loss: 0.2114\n",
      "Epoch [1/10], Step [192/1079], Loss: 0.1666\n",
      "Epoch [1/10], Step [193/1079], Loss: 0.2080\n",
      "Epoch [1/10], Step [194/1079], Loss: 0.1553\n",
      "Epoch [1/10], Step [195/1079], Loss: 0.4485\n",
      "Epoch [1/10], Step [196/1079], Loss: 0.1282\n",
      "Epoch [1/10], Step [197/1079], Loss: 0.1969\n",
      "Epoch [1/10], Step [198/1079], Loss: 0.1240\n",
      "Epoch [1/10], Step [199/1079], Loss: 0.3140\n",
      "Epoch [1/10], Step [200/1079], Loss: 0.3176\n",
      "Epoch [1/10], Step [201/1079], Loss: 0.2570\n",
      "Epoch [1/10], Step [202/1079], Loss: 0.1177\n",
      "Epoch [1/10], Step [203/1079], Loss: 0.0679\n",
      "Epoch [1/10], Step [204/1079], Loss: 0.1332\n",
      "Epoch [1/10], Step [205/1079], Loss: 0.1346\n",
      "Epoch [1/10], Step [206/1079], Loss: 0.1123\n",
      "Epoch [1/10], Step [207/1079], Loss: 0.0779\n",
      "Epoch [1/10], Step [208/1079], Loss: 0.1437\n",
      "Epoch [1/10], Step [209/1079], Loss: 0.0819\n",
      "Epoch [1/10], Step [210/1079], Loss: 0.1750\n",
      "Epoch [1/10], Step [211/1079], Loss: 0.1241\n",
      "Epoch [1/10], Step [212/1079], Loss: 0.2582\n",
      "Epoch [1/10], Step [213/1079], Loss: 0.1536\n",
      "Epoch [1/10], Step [214/1079], Loss: 0.0455\n",
      "Epoch [1/10], Step [215/1079], Loss: 0.2790\n",
      "Epoch [1/10], Step [216/1079], Loss: 0.3274\n",
      "Epoch [1/10], Step [217/1079], Loss: 0.1268\n",
      "Epoch [1/10], Step [218/1079], Loss: 0.0939\n",
      "Epoch [1/10], Step [219/1079], Loss: 0.0577\n",
      "Epoch [1/10], Step [220/1079], Loss: 0.1236\n",
      "Epoch [1/10], Step [221/1079], Loss: 0.1420\n",
      "Epoch [1/10], Step [222/1079], Loss: 0.1608\n",
      "Epoch [1/10], Step [223/1079], Loss: 0.1893\n",
      "Epoch [1/10], Step [224/1079], Loss: 0.2062\n",
      "Epoch [1/10], Step [225/1079], Loss: 0.2140\n",
      "Epoch [1/10], Step [226/1079], Loss: 0.2114\n",
      "Epoch [1/10], Step [227/1079], Loss: 0.1344\n",
      "Epoch [1/10], Step [228/1079], Loss: 0.1622\n",
      "Epoch [1/10], Step [229/1079], Loss: 0.2356\n",
      "Epoch [1/10], Step [230/1079], Loss: 0.2284\n",
      "Epoch [1/10], Step [231/1079], Loss: 0.1516\n",
      "Epoch [1/10], Step [232/1079], Loss: 0.1281\n",
      "Epoch [1/10], Step [233/1079], Loss: 0.1065\n",
      "Epoch [1/10], Step [234/1079], Loss: 0.4493\n",
      "Epoch [1/10], Step [235/1079], Loss: 0.0952\n",
      "Epoch [1/10], Step [236/1079], Loss: 0.2296\n",
      "Epoch [1/10], Step [237/1079], Loss: 0.1408\n",
      "Epoch [1/10], Step [238/1079], Loss: 0.1157\n",
      "Epoch [1/10], Step [239/1079], Loss: 0.1025\n",
      "Epoch [1/10], Step [240/1079], Loss: 0.1996\n",
      "Epoch [1/10], Step [241/1079], Loss: 0.0643\n",
      "Epoch [1/10], Step [242/1079], Loss: 0.0882\n",
      "Epoch [1/10], Step [243/1079], Loss: 0.2289\n",
      "Epoch [1/10], Step [244/1079], Loss: 0.2135\n",
      "Epoch [1/10], Step [245/1079], Loss: 0.1418\n",
      "Epoch [1/10], Step [246/1079], Loss: 0.1500\n",
      "Epoch [1/10], Step [247/1079], Loss: 0.0789\n",
      "Epoch [1/10], Step [248/1079], Loss: 0.2302\n",
      "Epoch [1/10], Step [249/1079], Loss: 0.0537\n",
      "Epoch [1/10], Step [250/1079], Loss: 0.0913\n",
      "Epoch [1/10], Step [251/1079], Loss: 0.1125\n",
      "Epoch [1/10], Step [252/1079], Loss: 0.1751\n",
      "Epoch [1/10], Step [253/1079], Loss: 0.1092\n",
      "Epoch [1/10], Step [254/1079], Loss: 0.0543\n",
      "Epoch [1/10], Step [255/1079], Loss: 0.0810\n",
      "Epoch [1/10], Step [256/1079], Loss: 0.2046\n",
      "Epoch [1/10], Step [257/1079], Loss: 0.1205\n",
      "Epoch [1/10], Step [258/1079], Loss: 0.0462\n",
      "Epoch [1/10], Step [259/1079], Loss: 0.2085\n",
      "Epoch [1/10], Step [260/1079], Loss: 0.2449\n",
      "Epoch [1/10], Step [261/1079], Loss: 0.1697\n",
      "Epoch [1/10], Step [262/1079], Loss: 0.1550\n",
      "Epoch [1/10], Step [263/1079], Loss: 0.1443\n",
      "Epoch [1/10], Step [264/1079], Loss: 0.0689\n",
      "Epoch [1/10], Step [265/1079], Loss: 0.1807\n",
      "Epoch [1/10], Step [266/1079], Loss: 0.3094\n",
      "Epoch [1/10], Step [267/1079], Loss: 0.1267\n",
      "Epoch [1/10], Step [268/1079], Loss: 0.0752\n",
      "Epoch [1/10], Step [269/1079], Loss: 0.2525\n",
      "Epoch [1/10], Step [270/1079], Loss: 0.1091\n",
      "Epoch [1/10], Step [271/1079], Loss: 0.1247\n",
      "Epoch [1/10], Step [272/1079], Loss: 0.1484\n",
      "Epoch [1/10], Step [273/1079], Loss: 0.1524\n",
      "Epoch [1/10], Step [274/1079], Loss: 0.0175\n",
      "Epoch [1/10], Step [275/1079], Loss: 0.4912\n",
      "Epoch [1/10], Step [276/1079], Loss: 0.0875\n",
      "Epoch [1/10], Step [277/1079], Loss: 0.3236\n",
      "Epoch [1/10], Step [278/1079], Loss: 0.0889\n",
      "Epoch [1/10], Step [279/1079], Loss: 0.1287\n",
      "Epoch [1/10], Step [280/1079], Loss: 0.1132\n",
      "Epoch [1/10], Step [281/1079], Loss: 0.1657\n",
      "Epoch [1/10], Step [282/1079], Loss: 0.0625\n",
      "Epoch [1/10], Step [283/1079], Loss: 0.1542\n",
      "Epoch [1/10], Step [284/1079], Loss: 0.1607\n",
      "Epoch [1/10], Step [285/1079], Loss: 0.1701\n",
      "Epoch [1/10], Step [286/1079], Loss: 0.1887\n",
      "Epoch [1/10], Step [287/1079], Loss: 0.1125\n",
      "Epoch [1/10], Step [288/1079], Loss: 0.1504\n",
      "Epoch [1/10], Step [289/1079], Loss: 0.0997\n",
      "Epoch [1/10], Step [290/1079], Loss: 0.1304\n",
      "Epoch [1/10], Step [291/1079], Loss: 0.1194\n",
      "Epoch [1/10], Step [292/1079], Loss: 0.2118\n",
      "Epoch [1/10], Step [293/1079], Loss: 0.1376\n",
      "Epoch [1/10], Step [294/1079], Loss: 0.0865\n",
      "Epoch [1/10], Step [295/1079], Loss: 0.1544\n",
      "Epoch [1/10], Step [296/1079], Loss: 0.1613\n",
      "Epoch [1/10], Step [297/1079], Loss: 0.0661\n",
      "Epoch [1/10], Step [298/1079], Loss: 0.1578\n",
      "Epoch [1/10], Step [299/1079], Loss: 0.0666\n",
      "Epoch [1/10], Step [300/1079], Loss: 0.1569\n",
      "Epoch [1/10], Step [301/1079], Loss: 0.1544\n",
      "Epoch [1/10], Step [302/1079], Loss: 0.0888\n",
      "Epoch [1/10], Step [303/1079], Loss: 0.1018\n",
      "Epoch [1/10], Step [304/1079], Loss: 0.0786\n",
      "Epoch [1/10], Step [305/1079], Loss: 0.1163\n",
      "Epoch [1/10], Step [306/1079], Loss: 0.1610\n",
      "Epoch [1/10], Step [307/1079], Loss: 0.1661\n",
      "Epoch [1/10], Step [308/1079], Loss: 0.1308\n",
      "Epoch [1/10], Step [309/1079], Loss: 0.1737\n",
      "Epoch [1/10], Step [310/1079], Loss: 0.2239\n",
      "Epoch [1/10], Step [311/1079], Loss: 0.1241\n",
      "Epoch [1/10], Step [312/1079], Loss: 0.1888\n",
      "Epoch [1/10], Step [313/1079], Loss: 0.1363\n",
      "Epoch [1/10], Step [314/1079], Loss: 0.3625\n",
      "Epoch [1/10], Step [315/1079], Loss: 0.1574\n",
      "Epoch [1/10], Step [316/1079], Loss: 0.1387\n",
      "Epoch [1/10], Step [317/1079], Loss: 0.2391\n",
      "Epoch [1/10], Step [318/1079], Loss: 0.0784\n",
      "Epoch [1/10], Step [319/1079], Loss: 0.0332\n",
      "Epoch [1/10], Step [320/1079], Loss: 0.0367\n",
      "Epoch [1/10], Step [321/1079], Loss: 0.0746\n",
      "Epoch [1/10], Step [322/1079], Loss: 0.0889\n",
      "Epoch [1/10], Step [323/1079], Loss: 0.0793\n",
      "Epoch [1/10], Step [324/1079], Loss: 0.1291\n",
      "Epoch [1/10], Step [325/1079], Loss: 0.0887\n",
      "Epoch [1/10], Step [326/1079], Loss: 0.1763\n",
      "Epoch [1/10], Step [327/1079], Loss: 0.1415\n",
      "Epoch [1/10], Step [328/1079], Loss: 0.1123\n",
      "Epoch [1/10], Step [329/1079], Loss: 0.0567\n",
      "Epoch [1/10], Step [330/1079], Loss: 0.0356\n",
      "Epoch [1/10], Step [331/1079], Loss: 0.2022\n",
      "Epoch [1/10], Step [332/1079], Loss: 0.0692\n",
      "Epoch [1/10], Step [333/1079], Loss: 0.0817\n",
      "Epoch [1/10], Step [334/1079], Loss: 0.1737\n",
      "Epoch [1/10], Step [335/1079], Loss: 0.0931\n",
      "Epoch [1/10], Step [336/1079], Loss: 0.1222\n",
      "Epoch [1/10], Step [337/1079], Loss: 0.1863\n",
      "Epoch [1/10], Step [338/1079], Loss: 0.1148\n",
      "Epoch [1/10], Step [339/1079], Loss: 0.2162\n",
      "Epoch [1/10], Step [340/1079], Loss: 0.1334\n",
      "Epoch [1/10], Step [341/1079], Loss: 0.0261\n",
      "Epoch [1/10], Step [342/1079], Loss: 0.0362\n",
      "Epoch [1/10], Step [343/1079], Loss: 0.1189\n",
      "Epoch [1/10], Step [344/1079], Loss: 0.0632\n",
      "Epoch [1/10], Step [345/1079], Loss: 0.0367\n",
      "Epoch [1/10], Step [346/1079], Loss: 0.0795\n",
      "Epoch [1/10], Step [347/1079], Loss: 0.1113\n",
      "Epoch [1/10], Step [348/1079], Loss: 0.1216\n",
      "Epoch [1/10], Step [349/1079], Loss: 0.0671\n",
      "Epoch [1/10], Step [350/1079], Loss: 0.0934\n",
      "Epoch [1/10], Step [351/1079], Loss: 0.2557\n",
      "Epoch [1/10], Step [352/1079], Loss: 0.1739\n",
      "Epoch [1/10], Step [353/1079], Loss: 0.1145\n",
      "Epoch [1/10], Step [354/1079], Loss: 0.0964\n",
      "Epoch [1/10], Step [355/1079], Loss: 0.1006\n",
      "Epoch [1/10], Step [356/1079], Loss: 0.0717\n",
      "Epoch [1/10], Step [357/1079], Loss: 0.1009\n",
      "Epoch [1/10], Step [358/1079], Loss: 0.2716\n",
      "Epoch [1/10], Step [359/1079], Loss: 0.1109\n",
      "Epoch [1/10], Step [360/1079], Loss: 0.1462\n",
      "Epoch [1/10], Step [361/1079], Loss: 0.1784\n",
      "Epoch [1/10], Step [362/1079], Loss: 0.0801\n",
      "Epoch [1/10], Step [363/1079], Loss: 0.0986\n",
      "Epoch [1/10], Step [364/1079], Loss: 0.0665\n",
      "Epoch [1/10], Step [365/1079], Loss: 0.0723\n",
      "Epoch [1/10], Step [366/1079], Loss: 0.0951\n",
      "Epoch [1/10], Step [367/1079], Loss: 0.0619\n",
      "Epoch [1/10], Step [368/1079], Loss: 0.1012\n",
      "Epoch [1/10], Step [369/1079], Loss: 0.3086\n",
      "Epoch [1/10], Step [370/1079], Loss: 0.2025\n",
      "Epoch [1/10], Step [371/1079], Loss: 0.0549\n",
      "Epoch [1/10], Step [372/1079], Loss: 0.1767\n",
      "Epoch [1/10], Step [373/1079], Loss: 0.0453\n",
      "Epoch [1/10], Step [374/1079], Loss: 0.1375\n",
      "Epoch [1/10], Step [375/1079], Loss: 0.1206\n",
      "Epoch [1/10], Step [376/1079], Loss: 0.1960\n",
      "Epoch [1/10], Step [377/1079], Loss: 0.0853\n",
      "Epoch [1/10], Step [378/1079], Loss: 0.1652\n",
      "Epoch [1/10], Step [379/1079], Loss: 0.1314\n",
      "Epoch [1/10], Step [380/1079], Loss: 0.1274\n",
      "Epoch [1/10], Step [381/1079], Loss: 0.1255\n",
      "Epoch [1/10], Step [382/1079], Loss: 0.1049\n",
      "Epoch [1/10], Step [383/1079], Loss: 0.0625\n",
      "Epoch [1/10], Step [384/1079], Loss: 0.1407\n",
      "Epoch [1/10], Step [385/1079], Loss: 0.1271\n",
      "Epoch [1/10], Step [386/1079], Loss: 0.0239\n",
      "Epoch [1/10], Step [387/1079], Loss: 0.0738\n",
      "Epoch [1/10], Step [388/1079], Loss: 0.1408\n",
      "Epoch [1/10], Step [389/1079], Loss: 0.2459\n",
      "Epoch [1/10], Step [390/1079], Loss: 0.0415\n",
      "Epoch [1/10], Step [391/1079], Loss: 0.1537\n",
      "Epoch [1/10], Step [392/1079], Loss: 0.2109\n",
      "Epoch [1/10], Step [393/1079], Loss: 0.0901\n",
      "Epoch [1/10], Step [394/1079], Loss: 0.0527\n",
      "Epoch [1/10], Step [395/1079], Loss: 0.1632\n",
      "Epoch [1/10], Step [396/1079], Loss: 0.1919\n",
      "Epoch [1/10], Step [397/1079], Loss: 0.0281\n",
      "Epoch [1/10], Step [398/1079], Loss: 0.1581\n",
      "Epoch [1/10], Step [399/1079], Loss: 0.1418\n",
      "Epoch [1/10], Step [400/1079], Loss: 0.2275\n",
      "Epoch [1/10], Step [401/1079], Loss: 0.0481\n",
      "Epoch [1/10], Step [402/1079], Loss: 0.2271\n",
      "Epoch [1/10], Step [403/1079], Loss: 0.0400\n",
      "Epoch [1/10], Step [404/1079], Loss: 0.0419\n",
      "Epoch [1/10], Step [405/1079], Loss: 0.2123\n",
      "Epoch [1/10], Step [406/1079], Loss: 0.1189\n",
      "Epoch [1/10], Step [407/1079], Loss: 0.1199\n",
      "Epoch [1/10], Step [408/1079], Loss: 0.1677\n",
      "Epoch [1/10], Step [409/1079], Loss: 0.1694\n",
      "Epoch [1/10], Step [410/1079], Loss: 0.1645\n",
      "Epoch [1/10], Step [411/1079], Loss: 0.0794\n",
      "Epoch [1/10], Step [412/1079], Loss: 0.1122\n",
      "Epoch [1/10], Step [413/1079], Loss: 0.1306\n",
      "Epoch [1/10], Step [414/1079], Loss: 0.0768\n",
      "Epoch [1/10], Step [415/1079], Loss: 0.0598\n",
      "Epoch [1/10], Step [416/1079], Loss: 0.1049\n",
      "Epoch [1/10], Step [417/1079], Loss: 0.2739\n",
      "Epoch [1/10], Step [418/1079], Loss: 0.0544\n",
      "Epoch [1/10], Step [419/1079], Loss: 0.1506\n",
      "Epoch [1/10], Step [420/1079], Loss: 0.1311\n",
      "Epoch [1/10], Step [421/1079], Loss: 0.0506\n",
      "Epoch [1/10], Step [422/1079], Loss: 0.0395\n",
      "Epoch [1/10], Step [423/1079], Loss: 0.1223\n",
      "Epoch [1/10], Step [424/1079], Loss: 0.0884\n",
      "Epoch [1/10], Step [425/1079], Loss: 0.0530\n",
      "Epoch [1/10], Step [426/1079], Loss: 0.0469\n",
      "Epoch [1/10], Step [427/1079], Loss: 0.0570\n",
      "Epoch [1/10], Step [428/1079], Loss: 0.1132\n",
      "Epoch [1/10], Step [429/1079], Loss: 0.2811\n",
      "Epoch [1/10], Step [430/1079], Loss: 0.0362\n",
      "Epoch [1/10], Step [431/1079], Loss: 0.0956\n",
      "Epoch [1/10], Step [432/1079], Loss: 0.1814\n",
      "Epoch [1/10], Step [433/1079], Loss: 0.1149\n",
      "Epoch [1/10], Step [434/1079], Loss: 0.2135\n",
      "Epoch [1/10], Step [435/1079], Loss: 0.0513\n",
      "Epoch [1/10], Step [436/1079], Loss: 0.1366\n",
      "Epoch [1/10], Step [437/1079], Loss: 0.0309\n",
      "Epoch [1/10], Step [438/1079], Loss: 0.0793\n",
      "Epoch [1/10], Step [439/1079], Loss: 0.0623\n",
      "Epoch [1/10], Step [440/1079], Loss: 0.0558\n",
      "Epoch [1/10], Step [441/1079], Loss: 0.1331\n",
      "Epoch [1/10], Step [442/1079], Loss: 0.1387\n",
      "Epoch [1/10], Step [443/1079], Loss: 0.0703\n",
      "Epoch [1/10], Step [444/1079], Loss: 0.0588\n",
      "Epoch [1/10], Step [445/1079], Loss: 0.1762\n",
      "Epoch [1/10], Step [446/1079], Loss: 0.0853\n",
      "Epoch [1/10], Step [447/1079], Loss: 0.0459\n",
      "Epoch [1/10], Step [448/1079], Loss: 0.0549\n",
      "Epoch [1/10], Step [449/1079], Loss: 0.1926\n",
      "Epoch [1/10], Step [450/1079], Loss: 0.0905\n",
      "Epoch [1/10], Step [451/1079], Loss: 0.1326\n",
      "Epoch [1/10], Step [452/1079], Loss: 0.1370\n",
      "Epoch [1/10], Step [453/1079], Loss: 0.1668\n",
      "Epoch [1/10], Step [454/1079], Loss: 0.0641\n",
      "Epoch [1/10], Step [455/1079], Loss: 0.0476\n",
      "Epoch [1/10], Step [456/1079], Loss: 0.0759\n",
      "Epoch [1/10], Step [457/1079], Loss: 0.1545\n",
      "Epoch [1/10], Step [458/1079], Loss: 0.0999\n",
      "Epoch [1/10], Step [459/1079], Loss: 0.0755\n",
      "Epoch [1/10], Step [460/1079], Loss: 0.1233\n",
      "Epoch [1/10], Step [461/1079], Loss: 0.0359\n",
      "Epoch [1/10], Step [462/1079], Loss: 0.1091\n",
      "Epoch [1/10], Step [463/1079], Loss: 0.0255\n",
      "Epoch [1/10], Step [464/1079], Loss: 0.0865\n",
      "Epoch [1/10], Step [465/1079], Loss: 0.0661\n",
      "Epoch [1/10], Step [466/1079], Loss: 0.0281\n",
      "Epoch [1/10], Step [467/1079], Loss: 0.0905\n",
      "Epoch [1/10], Step [468/1079], Loss: 0.0221\n",
      "Epoch [1/10], Step [469/1079], Loss: 0.0236\n",
      "Epoch [1/10], Step [470/1079], Loss: 0.0617\n",
      "Epoch [1/10], Step [471/1079], Loss: 0.1210\n",
      "Epoch [1/10], Step [472/1079], Loss: 0.0888\n",
      "Epoch [1/10], Step [473/1079], Loss: 0.0324\n",
      "Epoch [1/10], Step [474/1079], Loss: 0.0598\n",
      "Epoch [1/10], Step [475/1079], Loss: 0.1383\n",
      "Epoch [1/10], Step [476/1079], Loss: 0.1827\n",
      "Epoch [1/10], Step [477/1079], Loss: 0.0367\n",
      "Epoch [1/10], Step [478/1079], Loss: 0.0233\n",
      "Epoch [1/10], Step [479/1079], Loss: 0.1276\n",
      "Epoch [1/10], Step [480/1079], Loss: 0.0910\n",
      "Epoch [1/10], Step [481/1079], Loss: 0.1905\n",
      "Epoch [1/10], Step [482/1079], Loss: 0.2463\n",
      "Epoch [1/10], Step [483/1079], Loss: 0.1101\n",
      "Epoch [1/10], Step [484/1079], Loss: 0.0418\n",
      "Epoch [1/10], Step [485/1079], Loss: 0.0818\n",
      "Epoch [1/10], Step [486/1079], Loss: 0.0373\n",
      "Epoch [1/10], Step [487/1079], Loss: 0.1530\n",
      "Epoch [1/10], Step [488/1079], Loss: 0.1612\n",
      "Epoch [1/10], Step [489/1079], Loss: 0.0097\n",
      "Epoch [1/10], Step [490/1079], Loss: 0.0908\n",
      "Epoch [1/10], Step [491/1079], Loss: 0.0994\n",
      "Epoch [1/10], Step [492/1079], Loss: 0.0745\n",
      "Epoch [1/10], Step [493/1079], Loss: 0.0498\n",
      "Epoch [1/10], Step [494/1079], Loss: 0.1496\n",
      "Epoch [1/10], Step [495/1079], Loss: 0.0155\n",
      "Epoch [1/10], Step [496/1079], Loss: 0.0315\n",
      "Epoch [1/10], Step [497/1079], Loss: 0.0785\n",
      "Epoch [1/10], Step [498/1079], Loss: 0.0772\n",
      "Epoch [1/10], Step [499/1079], Loss: 0.0517\n",
      "Epoch [1/10], Step [500/1079], Loss: 0.0572\n",
      "Epoch [1/10], Step [501/1079], Loss: 0.0183\n",
      "Epoch [1/10], Step [502/1079], Loss: 0.0817\n",
      "Epoch [1/10], Step [503/1079], Loss: 0.1101\n",
      "Epoch [1/10], Step [504/1079], Loss: 0.0497\n",
      "Epoch [1/10], Step [505/1079], Loss: 0.0162\n",
      "Epoch [1/10], Step [506/1079], Loss: 0.0849\n",
      "Epoch [1/10], Step [507/1079], Loss: 0.1107\n",
      "Epoch [1/10], Step [508/1079], Loss: 0.1050\n",
      "Epoch [1/10], Step [509/1079], Loss: 0.0690\n",
      "Epoch [1/10], Step [510/1079], Loss: 0.0231\n",
      "Epoch [1/10], Step [511/1079], Loss: 0.1048\n",
      "Epoch [1/10], Step [512/1079], Loss: 0.0752\n",
      "Epoch [1/10], Step [513/1079], Loss: 0.0464\n",
      "Epoch [1/10], Step [514/1079], Loss: 0.0514\n",
      "Epoch [1/10], Step [515/1079], Loss: 0.2108\n",
      "Epoch [1/10], Step [516/1079], Loss: 0.1386\n",
      "Epoch [1/10], Step [517/1079], Loss: 0.0509\n",
      "Epoch [1/10], Step [518/1079], Loss: 0.0329\n",
      "Epoch [1/10], Step [519/1079], Loss: 0.0701\n",
      "Epoch [1/10], Step [520/1079], Loss: 0.3010\n",
      "Epoch [1/10], Step [521/1079], Loss: 0.1306\n",
      "Epoch [1/10], Step [522/1079], Loss: 0.0465\n",
      "Epoch [1/10], Step [523/1079], Loss: 0.1137\n",
      "Epoch [1/10], Step [524/1079], Loss: 0.0428\n",
      "Epoch [1/10], Step [525/1079], Loss: 0.0543\n",
      "Epoch [1/10], Step [526/1079], Loss: 0.1181\n",
      "Epoch [1/10], Step [527/1079], Loss: 0.1174\n",
      "Epoch [1/10], Step [528/1079], Loss: 0.0345\n",
      "Epoch [1/10], Step [529/1079], Loss: 0.1068\n",
      "Epoch [1/10], Step [530/1079], Loss: 0.0239\n",
      "Epoch [1/10], Step [531/1079], Loss: 0.0539\n",
      "Epoch [1/10], Step [532/1079], Loss: 0.0277\n",
      "Epoch [1/10], Step [533/1079], Loss: 0.0740\n",
      "Epoch [1/10], Step [534/1079], Loss: 0.1077\n",
      "Epoch [1/10], Step [535/1079], Loss: 0.0684\n",
      "Epoch [1/10], Step [536/1079], Loss: 0.1263\n",
      "Epoch [1/10], Step [537/1079], Loss: 0.0120\n",
      "Epoch [1/10], Step [538/1079], Loss: 0.0527\n",
      "Epoch [1/10], Step [539/1079], Loss: 0.0638\n",
      "Epoch [1/10], Step [540/1079], Loss: 0.1308\n",
      "Epoch [1/10], Step [541/1079], Loss: 0.0380\n",
      "Epoch [1/10], Step [542/1079], Loss: 0.0512\n",
      "Epoch [1/10], Step [543/1079], Loss: 0.1103\n",
      "Epoch [1/10], Step [544/1079], Loss: 0.0487\n",
      "Epoch [1/10], Step [545/1079], Loss: 0.0279\n",
      "Epoch [1/10], Step [546/1079], Loss: 0.0792\n",
      "Epoch [1/10], Step [547/1079], Loss: 0.0660\n",
      "Epoch [1/10], Step [548/1079], Loss: 0.0949\n",
      "Epoch [1/10], Step [549/1079], Loss: 0.0632\n",
      "Epoch [1/10], Step [550/1079], Loss: 0.0931\n",
      "Epoch [1/10], Step [551/1079], Loss: 0.0765\n",
      "Epoch [1/10], Step [552/1079], Loss: 0.0298\n",
      "Epoch [1/10], Step [553/1079], Loss: 0.0258\n",
      "Epoch [1/10], Step [554/1079], Loss: 0.1437\n",
      "Epoch [1/10], Step [555/1079], Loss: 0.2028\n",
      "Epoch [1/10], Step [556/1079], Loss: 0.1465\n",
      "Epoch [1/10], Step [557/1079], Loss: 0.0648\n",
      "Epoch [1/10], Step [558/1079], Loss: 0.0247\n",
      "Epoch [1/10], Step [559/1079], Loss: 0.0834\n",
      "Epoch [1/10], Step [560/1079], Loss: 0.0803\n",
      "Epoch [1/10], Step [561/1079], Loss: 0.0885\n",
      "Epoch [1/10], Step [562/1079], Loss: 0.1665\n",
      "Epoch [1/10], Step [563/1079], Loss: 0.2179\n",
      "Epoch [1/10], Step [564/1079], Loss: 0.0932\n",
      "Epoch [1/10], Step [565/1079], Loss: 0.0806\n",
      "Epoch [1/10], Step [566/1079], Loss: 0.1678\n",
      "Epoch [1/10], Step [567/1079], Loss: 0.1170\n",
      "Epoch [1/10], Step [568/1079], Loss: 0.0475\n",
      "Epoch [1/10], Step [569/1079], Loss: 0.0665\n",
      "Epoch [1/10], Step [570/1079], Loss: 0.1679\n",
      "Epoch [1/10], Step [571/1079], Loss: 0.0434\n",
      "Epoch [1/10], Step [572/1079], Loss: 0.0772\n",
      "Epoch [1/10], Step [573/1079], Loss: 0.0350\n",
      "Epoch [1/10], Step [574/1079], Loss: 0.1567\n",
      "Epoch [1/10], Step [575/1079], Loss: 0.0793\n",
      "Epoch [1/10], Step [576/1079], Loss: 0.0500\n",
      "Epoch [1/10], Step [577/1079], Loss: 0.2078\n",
      "Epoch [1/10], Step [578/1079], Loss: 0.0600\n",
      "Epoch [1/10], Step [579/1079], Loss: 0.0161\n",
      "Epoch [1/10], Step [580/1079], Loss: 0.0779\n",
      "Epoch [1/10], Step [581/1079], Loss: 0.0846\n",
      "Epoch [1/10], Step [582/1079], Loss: 0.0138\n",
      "Epoch [1/10], Step [583/1079], Loss: 0.0351\n",
      "Epoch [1/10], Step [584/1079], Loss: 0.0803\n",
      "Epoch [1/10], Step [585/1079], Loss: 0.1167\n",
      "Epoch [1/10], Step [586/1079], Loss: 0.0351\n",
      "Epoch [1/10], Step [587/1079], Loss: 0.0538\n",
      "Epoch [1/10], Step [588/1079], Loss: 0.0676\n",
      "Epoch [1/10], Step [589/1079], Loss: 0.0483\n",
      "Epoch [1/10], Step [590/1079], Loss: 0.1405\n",
      "Epoch [1/10], Step [591/1079], Loss: 0.1458\n",
      "Epoch [1/10], Step [592/1079], Loss: 0.0703\n",
      "Epoch [1/10], Step [593/1079], Loss: 0.0889\n",
      "Epoch [1/10], Step [594/1079], Loss: 0.0940\n",
      "Epoch [1/10], Step [595/1079], Loss: 0.0307\n",
      "Epoch [1/10], Step [596/1079], Loss: 0.1634\n",
      "Epoch [1/10], Step [597/1079], Loss: 0.0573\n",
      "Epoch [1/10], Step [598/1079], Loss: 0.0969\n",
      "Epoch [1/10], Step [599/1079], Loss: 0.1258\n",
      "Epoch [1/10], Step [600/1079], Loss: 0.0635\n",
      "Epoch [1/10], Step [601/1079], Loss: 0.0356\n",
      "Epoch [1/10], Step [602/1079], Loss: 0.0534\n",
      "Epoch [1/10], Step [603/1079], Loss: 0.0345\n",
      "Epoch [1/10], Step [604/1079], Loss: 0.0529\n",
      "Epoch [1/10], Step [605/1079], Loss: 0.1583\n",
      "Epoch [1/10], Step [606/1079], Loss: 0.0139\n",
      "Epoch [1/10], Step [607/1079], Loss: 0.0204\n",
      "Epoch [1/10], Step [608/1079], Loss: 0.0261\n",
      "Epoch [1/10], Step [609/1079], Loss: 0.0404\n",
      "Epoch [1/10], Step [610/1079], Loss: 0.0239\n",
      "Epoch [1/10], Step [611/1079], Loss: 0.0701\n",
      "Epoch [1/10], Step [612/1079], Loss: 0.1005\n",
      "Epoch [1/10], Step [613/1079], Loss: 0.0189\n",
      "Epoch [1/10], Step [614/1079], Loss: 0.0177\n",
      "Epoch [1/10], Step [615/1079], Loss: 0.2178\n",
      "Epoch [1/10], Step [616/1079], Loss: 0.0658\n",
      "Epoch [1/10], Step [617/1079], Loss: 0.2543\n",
      "Epoch [1/10], Step [618/1079], Loss: 0.1168\n",
      "Epoch [1/10], Step [619/1079], Loss: 0.1215\n",
      "Epoch [1/10], Step [620/1079], Loss: 0.0378\n",
      "Epoch [1/10], Step [621/1079], Loss: 0.0329\n",
      "Epoch [1/10], Step [622/1079], Loss: 0.1384\n",
      "Epoch [1/10], Step [623/1079], Loss: 0.0644\n",
      "Epoch [1/10], Step [624/1079], Loss: 0.0572\n",
      "Epoch [1/10], Step [625/1079], Loss: 0.0927\n",
      "Epoch [1/10], Step [626/1079], Loss: 0.1949\n",
      "Epoch [1/10], Step [627/1079], Loss: 0.2015\n",
      "Epoch [1/10], Step [628/1079], Loss: 0.0478\n",
      "Epoch [1/10], Step [629/1079], Loss: 0.1478\n",
      "Epoch [1/10], Step [630/1079], Loss: 0.0562\n",
      "Epoch [1/10], Step [631/1079], Loss: 0.0764\n",
      "Epoch [1/10], Step [632/1079], Loss: 0.0572\n",
      "Epoch [1/10], Step [633/1079], Loss: 0.0564\n",
      "Epoch [1/10], Step [634/1079], Loss: 0.0182\n",
      "Epoch [1/10], Step [635/1079], Loss: 0.1832\n",
      "Epoch [1/10], Step [636/1079], Loss: 0.0593\n",
      "Epoch [1/10], Step [637/1079], Loss: 0.0242\n",
      "Epoch [1/10], Step [638/1079], Loss: 0.2079\n",
      "Epoch [1/10], Step [639/1079], Loss: 0.1118\n",
      "Epoch [1/10], Step [640/1079], Loss: 0.0596\n",
      "Epoch [1/10], Step [641/1079], Loss: 0.1100\n",
      "Epoch [1/10], Step [642/1079], Loss: 0.1141\n",
      "Epoch [1/10], Step [643/1079], Loss: 0.1257\n",
      "Epoch [1/10], Step [644/1079], Loss: 0.2283\n",
      "Epoch [1/10], Step [645/1079], Loss: 0.0541\n",
      "Epoch [1/10], Step [646/1079], Loss: 0.1172\n",
      "Epoch [1/10], Step [647/1079], Loss: 0.0789\n",
      "Epoch [1/10], Step [648/1079], Loss: 0.0528\n",
      "Epoch [1/10], Step [649/1079], Loss: 0.1166\n",
      "Epoch [1/10], Step [650/1079], Loss: 0.0445\n",
      "Epoch [1/10], Step [651/1079], Loss: 0.0510\n",
      "Epoch [1/10], Step [652/1079], Loss: 0.0772\n",
      "Epoch [1/10], Step [653/1079], Loss: 0.0660\n",
      "Epoch [1/10], Step [654/1079], Loss: 0.1017\n",
      "Epoch [1/10], Step [655/1079], Loss: 0.0348\n",
      "Epoch [1/10], Step [656/1079], Loss: 0.0830\n",
      "Epoch [1/10], Step [657/1079], Loss: 0.0462\n",
      "Epoch [1/10], Step [658/1079], Loss: 0.1145\n",
      "Epoch [1/10], Step [659/1079], Loss: 0.0798\n",
      "Epoch [1/10], Step [660/1079], Loss: 0.1582\n",
      "Epoch [1/10], Step [661/1079], Loss: 0.0304\n",
      "Epoch [1/10], Step [662/1079], Loss: 0.0382\n",
      "Epoch [1/10], Step [663/1079], Loss: 0.1429\n",
      "Epoch [1/10], Step [664/1079], Loss: 0.0166\n",
      "Epoch [1/10], Step [665/1079], Loss: 0.0346\n",
      "Epoch [1/10], Step [666/1079], Loss: 0.0459\n",
      "Epoch [1/10], Step [667/1079], Loss: 0.0214\n",
      "Epoch [1/10], Step [668/1079], Loss: 0.0302\n",
      "Epoch [1/10], Step [669/1079], Loss: 0.0410\n",
      "Epoch [1/10], Step [670/1079], Loss: 0.0243\n",
      "Epoch [1/10], Step [671/1079], Loss: 0.0414\n",
      "Epoch [1/10], Step [672/1079], Loss: 0.2281\n",
      "Epoch [1/10], Step [673/1079], Loss: 0.0276\n",
      "Epoch [1/10], Step [674/1079], Loss: 0.0211\n",
      "Epoch [1/10], Step [675/1079], Loss: 0.2611\n",
      "Epoch [1/10], Step [676/1079], Loss: 0.2108\n",
      "Epoch [1/10], Step [677/1079], Loss: 0.0612\n",
      "Epoch [1/10], Step [678/1079], Loss: 0.1502\n",
      "Epoch [1/10], Step [679/1079], Loss: 0.0476\n",
      "Epoch [1/10], Step [680/1079], Loss: 0.1039\n",
      "Epoch [1/10], Step [681/1079], Loss: 0.0649\n",
      "Epoch [1/10], Step [682/1079], Loss: 0.0598\n",
      "Epoch [1/10], Step [683/1079], Loss: 0.0241\n",
      "Epoch [1/10], Step [684/1079], Loss: 0.0289\n",
      "Epoch [1/10], Step [685/1079], Loss: 0.0185\n",
      "Epoch [1/10], Step [686/1079], Loss: 0.0496\n",
      "Epoch [1/10], Step [687/1079], Loss: 0.0789\n",
      "Epoch [1/10], Step [688/1079], Loss: 0.0231\n",
      "Epoch [1/10], Step [689/1079], Loss: 0.0218\n",
      "Epoch [1/10], Step [690/1079], Loss: 0.1267\n",
      "Epoch [1/10], Step [691/1079], Loss: 0.1564\n",
      "Epoch [1/10], Step [692/1079], Loss: 0.0615\n",
      "Epoch [1/10], Step [693/1079], Loss: 0.0408\n",
      "Epoch [1/10], Step [694/1079], Loss: 0.0443\n",
      "Epoch [1/10], Step [695/1079], Loss: 0.0695\n",
      "Epoch [1/10], Step [696/1079], Loss: 0.1436\n",
      "Epoch [1/10], Step [697/1079], Loss: 0.0328\n",
      "Epoch [1/10], Step [698/1079], Loss: 0.0540\n",
      "Epoch [1/10], Step [699/1079], Loss: 0.0392\n",
      "Epoch [1/10], Step [700/1079], Loss: 0.0345\n",
      "Epoch [1/10], Step [701/1079], Loss: 0.0647\n",
      "Epoch [1/10], Step [702/1079], Loss: 0.1391\n",
      "Epoch [1/10], Step [703/1079], Loss: 0.0874\n",
      "Epoch [1/10], Step [704/1079], Loss: 0.0174\n",
      "Epoch [1/10], Step [705/1079], Loss: 0.0420\n",
      "Epoch [1/10], Step [706/1079], Loss: 0.0940\n",
      "Epoch [1/10], Step [707/1079], Loss: 0.0819\n",
      "Epoch [1/10], Step [708/1079], Loss: 0.0322\n",
      "Epoch [1/10], Step [709/1079], Loss: 0.2647\n",
      "Epoch [1/10], Step [710/1079], Loss: 0.0105\n",
      "Epoch [1/10], Step [711/1079], Loss: 0.0553\n",
      "Epoch [1/10], Step [712/1079], Loss: 0.0731\n",
      "Epoch [1/10], Step [713/1079], Loss: 0.0498\n",
      "Epoch [1/10], Step [714/1079], Loss: 0.1589\n",
      "Epoch [1/10], Step [715/1079], Loss: 0.0673\n",
      "Epoch [1/10], Step [716/1079], Loss: 0.0829\n",
      "Epoch [1/10], Step [717/1079], Loss: 0.0273\n",
      "Epoch [1/10], Step [718/1079], Loss: 0.0304\n",
      "Epoch [1/10], Step [719/1079], Loss: 0.0282\n",
      "Epoch [1/10], Step [720/1079], Loss: 0.0173\n",
      "Epoch [1/10], Step [721/1079], Loss: 0.0523\n",
      "Epoch [1/10], Step [722/1079], Loss: 0.0488\n",
      "Epoch [1/10], Step [723/1079], Loss: 0.0853\n",
      "Epoch [1/10], Step [724/1079], Loss: 0.0140\n",
      "Epoch [1/10], Step [725/1079], Loss: 0.1408\n",
      "Epoch [1/10], Step [726/1079], Loss: 0.0253\n",
      "Epoch [1/10], Step [727/1079], Loss: 0.0142\n",
      "Epoch [1/10], Step [728/1079], Loss: 0.0458\n",
      "Epoch [1/10], Step [729/1079], Loss: 0.0059\n",
      "Epoch [1/10], Step [730/1079], Loss: 0.0322\n",
      "Epoch [1/10], Step [731/1079], Loss: 0.0289\n",
      "Epoch [1/10], Step [732/1079], Loss: 0.0766\n",
      "Epoch [1/10], Step [733/1079], Loss: 0.0641\n",
      "Epoch [1/10], Step [734/1079], Loss: 0.1364\n",
      "Epoch [1/10], Step [735/1079], Loss: 0.1418\n",
      "Epoch [1/10], Step [736/1079], Loss: 0.0343\n",
      "Epoch [1/10], Step [737/1079], Loss: 0.0463\n",
      "Epoch [1/10], Step [738/1079], Loss: 0.0517\n",
      "Epoch [1/10], Step [739/1079], Loss: 0.0260\n",
      "Epoch [1/10], Step [740/1079], Loss: 0.0825\n",
      "Epoch [1/10], Step [741/1079], Loss: 0.1415\n",
      "Epoch [1/10], Step [742/1079], Loss: 0.0507\n",
      "Epoch [1/10], Step [743/1079], Loss: 0.0619\n",
      "Epoch [1/10], Step [744/1079], Loss: 0.1435\n",
      "Epoch [1/10], Step [745/1079], Loss: 0.0720\n",
      "Epoch [1/10], Step [746/1079], Loss: 0.0662\n",
      "Epoch [1/10], Step [747/1079], Loss: 0.0403\n",
      "Epoch [1/10], Step [748/1079], Loss: 0.0315\n",
      "Epoch [1/10], Step [749/1079], Loss: 0.0931\n",
      "Epoch [1/10], Step [750/1079], Loss: 0.0505\n",
      "Epoch [1/10], Step [751/1079], Loss: 0.1538\n",
      "Epoch [1/10], Step [752/1079], Loss: 0.0477\n",
      "Epoch [1/10], Step [753/1079], Loss: 0.0839\n",
      "Epoch [1/10], Step [754/1079], Loss: 0.0438\n",
      "Epoch [1/10], Step [755/1079], Loss: 0.0209\n",
      "Epoch [1/10], Step [756/1079], Loss: 0.0990\n",
      "Epoch [1/10], Step [757/1079], Loss: 0.0194\n",
      "Epoch [1/10], Step [758/1079], Loss: 0.0632\n",
      "Epoch [1/10], Step [759/1079], Loss: 0.0939\n",
      "Epoch [1/10], Step [760/1079], Loss: 0.0359\n",
      "Epoch [1/10], Step [761/1079], Loss: 0.1082\n",
      "Epoch [1/10], Step [762/1079], Loss: 0.0908\n",
      "Epoch [1/10], Step [763/1079], Loss: 0.0359\n",
      "Epoch [1/10], Step [764/1079], Loss: 0.0256\n",
      "Epoch [1/10], Step [765/1079], Loss: 0.0298\n",
      "Epoch [1/10], Step [766/1079], Loss: 0.0172\n",
      "Epoch [1/10], Step [767/1079], Loss: 0.1511\n",
      "Epoch [1/10], Step [768/1079], Loss: 0.1136\n",
      "Epoch [1/10], Step [769/1079], Loss: 0.1060\n",
      "Epoch [1/10], Step [770/1079], Loss: 0.0343\n",
      "Epoch [1/10], Step [771/1079], Loss: 0.1390\n",
      "Epoch [1/10], Step [772/1079], Loss: 0.0543\n",
      "Epoch [1/10], Step [773/1079], Loss: 0.0801\n",
      "Epoch [1/10], Step [774/1079], Loss: 0.0737\n",
      "Epoch [1/10], Step [775/1079], Loss: 0.0278\n",
      "Epoch [1/10], Step [776/1079], Loss: 0.1238\n",
      "Epoch [1/10], Step [777/1079], Loss: 0.0606\n",
      "Epoch [1/10], Step [778/1079], Loss: 0.0242\n",
      "Epoch [1/10], Step [779/1079], Loss: 0.0435\n",
      "Epoch [1/10], Step [780/1079], Loss: 0.0479\n",
      "Epoch [1/10], Step [781/1079], Loss: 0.0222\n",
      "Epoch [1/10], Step [782/1079], Loss: 0.1000\n",
      "Epoch [1/10], Step [783/1079], Loss: 0.0696\n",
      "Epoch [1/10], Step [784/1079], Loss: 0.0203\n",
      "Epoch [1/10], Step [785/1079], Loss: 0.0155\n",
      "Epoch [1/10], Step [786/1079], Loss: 0.0337\n",
      "Epoch [1/10], Step [787/1079], Loss: 0.0296\n",
      "Epoch [1/10], Step [788/1079], Loss: 0.0289\n",
      "Epoch [1/10], Step [789/1079], Loss: 0.0283\n",
      "Epoch [1/10], Step [790/1079], Loss: 0.0176\n",
      "Epoch [1/10], Step [791/1079], Loss: 0.0716\n",
      "Epoch [1/10], Step [792/1079], Loss: 0.0811\n",
      "Epoch [1/10], Step [793/1079], Loss: 0.0986\n",
      "Epoch [1/10], Step [794/1079], Loss: 0.0661\n",
      "Epoch [1/10], Step [795/1079], Loss: 0.0231\n",
      "Epoch [1/10], Step [796/1079], Loss: 0.0931\n",
      "Epoch [1/10], Step [797/1079], Loss: 0.0282\n",
      "Epoch [1/10], Step [798/1079], Loss: 0.0700\n",
      "Epoch [1/10], Step [799/1079], Loss: 0.0155\n",
      "Epoch [1/10], Step [800/1079], Loss: 0.0286\n",
      "Epoch [1/10], Step [801/1079], Loss: 0.0091\n",
      "Epoch [1/10], Step [802/1079], Loss: 0.0573\n",
      "Epoch [1/10], Step [803/1079], Loss: 0.1132\n",
      "Epoch [1/10], Step [804/1079], Loss: 0.0395\n",
      "Epoch [1/10], Step [805/1079], Loss: 0.1197\n",
      "Epoch [1/10], Step [806/1079], Loss: 0.0884\n",
      "Epoch [1/10], Step [807/1079], Loss: 0.0203\n",
      "Epoch [1/10], Step [808/1079], Loss: 0.1283\n",
      "Epoch [1/10], Step [809/1079], Loss: 0.0541\n",
      "Epoch [1/10], Step [810/1079], Loss: 0.0422\n",
      "Epoch [1/10], Step [811/1079], Loss: 0.0407\n",
      "Epoch [1/10], Step [812/1079], Loss: 0.0729\n",
      "Epoch [1/10], Step [813/1079], Loss: 0.1165\n",
      "Epoch [1/10], Step [814/1079], Loss: 0.0409\n",
      "Epoch [1/10], Step [815/1079], Loss: 0.0576\n",
      "Epoch [1/10], Step [816/1079], Loss: 0.0529\n",
      "Epoch [1/10], Step [817/1079], Loss: 0.0654\n",
      "Epoch [1/10], Step [818/1079], Loss: 0.1239\n",
      "Epoch [1/10], Step [819/1079], Loss: 0.0939\n",
      "Epoch [1/10], Step [820/1079], Loss: 0.0237\n",
      "Epoch [1/10], Step [821/1079], Loss: 0.0418\n",
      "Epoch [1/10], Step [822/1079], Loss: 0.1219\n",
      "Epoch [1/10], Step [823/1079], Loss: 0.0402\n",
      "Epoch [1/10], Step [824/1079], Loss: 0.0778\n",
      "Epoch [1/10], Step [825/1079], Loss: 0.0274\n",
      "Epoch [1/10], Step [826/1079], Loss: 0.1215\n",
      "Epoch [1/10], Step [827/1079], Loss: 0.0203\n",
      "Epoch [1/10], Step [828/1079], Loss: 0.0485\n",
      "Epoch [1/10], Step [829/1079], Loss: 0.0243\n",
      "Epoch [1/10], Step [830/1079], Loss: 0.1002\n",
      "Epoch [1/10], Step [831/1079], Loss: 0.2643\n",
      "Epoch [1/10], Step [832/1079], Loss: 0.0180\n",
      "Epoch [1/10], Step [833/1079], Loss: 0.0984\n",
      "Epoch [1/10], Step [834/1079], Loss: 0.0705\n",
      "Epoch [1/10], Step [835/1079], Loss: 0.0286\n",
      "Epoch [1/10], Step [836/1079], Loss: 0.1219\n",
      "Epoch [1/10], Step [837/1079], Loss: 0.0105\n",
      "Epoch [1/10], Step [838/1079], Loss: 0.0638\n",
      "Epoch [1/10], Step [839/1079], Loss: 0.1132\n",
      "Epoch [1/10], Step [840/1079], Loss: 0.0121\n",
      "Epoch [1/10], Step [841/1079], Loss: 0.1615\n",
      "Epoch [1/10], Step [842/1079], Loss: 0.0504\n",
      "Epoch [1/10], Step [843/1079], Loss: 0.0686\n",
      "Epoch [1/10], Step [844/1079], Loss: 0.0292\n",
      "Epoch [1/10], Step [845/1079], Loss: 0.0549\n",
      "Epoch [1/10], Step [846/1079], Loss: 0.1278\n",
      "Epoch [1/10], Step [847/1079], Loss: 0.0698\n",
      "Epoch [1/10], Step [848/1079], Loss: 0.0478\n",
      "Epoch [1/10], Step [849/1079], Loss: 0.1115\n",
      "Epoch [1/10], Step [850/1079], Loss: 0.1214\n",
      "Epoch [1/10], Step [851/1079], Loss: 0.0232\n",
      "Epoch [1/10], Step [852/1079], Loss: 0.0569\n",
      "Epoch [1/10], Step [853/1079], Loss: 0.0554\n",
      "Epoch [1/10], Step [854/1079], Loss: 0.0461\n",
      "Epoch [1/10], Step [855/1079], Loss: 0.1402\n",
      "Epoch [1/10], Step [856/1079], Loss: 0.0884\n",
      "Epoch [1/10], Step [857/1079], Loss: 0.0091\n",
      "Epoch [1/10], Step [858/1079], Loss: 0.0107\n",
      "Epoch [1/10], Step [859/1079], Loss: 0.0739\n",
      "Epoch [1/10], Step [860/1079], Loss: 0.0146\n",
      "Epoch [1/10], Step [861/1079], Loss: 0.0197\n",
      "Epoch [1/10], Step [862/1079], Loss: 0.1298\n",
      "Epoch [1/10], Step [863/1079], Loss: 0.0445\n",
      "Epoch [1/10], Step [864/1079], Loss: 0.2425\n",
      "Epoch [1/10], Step [865/1079], Loss: 0.0603\n",
      "Epoch [1/10], Step [866/1079], Loss: 0.0116\n",
      "Epoch [1/10], Step [867/1079], Loss: 0.0381\n",
      "Epoch [1/10], Step [868/1079], Loss: 0.0370\n",
      "Epoch [1/10], Step [869/1079], Loss: 0.0250\n",
      "Epoch [1/10], Step [870/1079], Loss: 0.0703\n",
      "Epoch [1/10], Step [871/1079], Loss: 0.0533\n",
      "Epoch [1/10], Step [872/1079], Loss: 0.0451\n",
      "Epoch [1/10], Step [873/1079], Loss: 0.0800\n",
      "Epoch [1/10], Step [874/1079], Loss: 0.1600\n",
      "Epoch [1/10], Step [875/1079], Loss: 0.0582\n",
      "Epoch [1/10], Step [876/1079], Loss: 0.0568\n",
      "Epoch [1/10], Step [877/1079], Loss: 0.0887\n",
      "Epoch [1/10], Step [878/1079], Loss: 0.0800\n",
      "Epoch [1/10], Step [879/1079], Loss: 0.0231\n",
      "Epoch [1/10], Step [880/1079], Loss: 0.0511\n",
      "Epoch [1/10], Step [881/1079], Loss: 0.0227\n",
      "Epoch [1/10], Step [882/1079], Loss: 0.1075\n",
      "Epoch [1/10], Step [883/1079], Loss: 0.0880\n",
      "Epoch [1/10], Step [884/1079], Loss: 0.0616\n",
      "Epoch [1/10], Step [885/1079], Loss: 0.0371\n",
      "Epoch [1/10], Step [886/1079], Loss: 0.1520\n",
      "Epoch [1/10], Step [887/1079], Loss: 0.0467\n",
      "Epoch [1/10], Step [888/1079], Loss: 0.0564\n",
      "Epoch [1/10], Step [889/1079], Loss: 0.0789\n",
      "Epoch [1/10], Step [890/1079], Loss: 0.0794\n",
      "Epoch [1/10], Step [891/1079], Loss: 0.0759\n",
      "Epoch [1/10], Step [892/1079], Loss: 0.0212\n",
      "Epoch [1/10], Step [893/1079], Loss: 0.1173\n",
      "Epoch [1/10], Step [894/1079], Loss: 0.0450\n",
      "Epoch [1/10], Step [895/1079], Loss: 0.1185\n",
      "Epoch [1/10], Step [896/1079], Loss: 0.0482\n",
      "Epoch [1/10], Step [897/1079], Loss: 0.0243\n",
      "Epoch [1/10], Step [898/1079], Loss: 0.0176\n",
      "Epoch [1/10], Step [899/1079], Loss: 0.0414\n",
      "Epoch [1/10], Step [900/1079], Loss: 0.0261\n",
      "Epoch [1/10], Step [901/1079], Loss: 0.0628\n",
      "Epoch [1/10], Step [902/1079], Loss: 0.1032\n",
      "Epoch [1/10], Step [903/1079], Loss: 0.1862\n",
      "Epoch [1/10], Step [904/1079], Loss: 0.0095\n",
      "Epoch [1/10], Step [905/1079], Loss: 0.0397\n",
      "Epoch [1/10], Step [906/1079], Loss: 0.0226\n",
      "Epoch [1/10], Step [907/1079], Loss: 0.0318\n",
      "Epoch [1/10], Step [908/1079], Loss: 0.0323\n",
      "Epoch [1/10], Step [909/1079], Loss: 0.0222\n",
      "Epoch [1/10], Step [910/1079], Loss: 0.0462\n",
      "Epoch [1/10], Step [911/1079], Loss: 0.0447\n",
      "Epoch [1/10], Step [912/1079], Loss: 0.0552\n",
      "Epoch [1/10], Step [913/1079], Loss: 0.0283\n",
      "Epoch [1/10], Step [914/1079], Loss: 0.0217\n",
      "Epoch [1/10], Step [915/1079], Loss: 0.0226\n",
      "Epoch [1/10], Step [916/1079], Loss: 0.0486\n",
      "Epoch [1/10], Step [917/1079], Loss: 0.0818\n",
      "Epoch [1/10], Step [918/1079], Loss: 0.0772\n",
      "Epoch [1/10], Step [919/1079], Loss: 0.0684\n",
      "Epoch [1/10], Step [920/1079], Loss: 0.0394\n",
      "Epoch [1/10], Step [921/1079], Loss: 0.0124\n",
      "Epoch [1/10], Step [922/1079], Loss: 0.0844\n",
      "Epoch [1/10], Step [923/1079], Loss: 0.0507\n",
      "Epoch [1/10], Step [924/1079], Loss: 0.0860\n",
      "Epoch [1/10], Step [925/1079], Loss: 0.0066\n",
      "Epoch [1/10], Step [926/1079], Loss: 0.2274\n",
      "Epoch [1/10], Step [927/1079], Loss: 0.1249\n",
      "Epoch [1/10], Step [928/1079], Loss: 0.1750\n",
      "Epoch [1/10], Step [929/1079], Loss: 0.0327\n",
      "Epoch [1/10], Step [930/1079], Loss: 0.1024\n",
      "Epoch [1/10], Step [931/1079], Loss: 0.0308\n",
      "Epoch [1/10], Step [932/1079], Loss: 0.0095\n",
      "Epoch [1/10], Step [933/1079], Loss: 0.0249\n",
      "Epoch [1/10], Step [934/1079], Loss: 0.0622\n",
      "Epoch [1/10], Step [935/1079], Loss: 0.1534\n",
      "Epoch [1/10], Step [936/1079], Loss: 0.0215\n",
      "Epoch [1/10], Step [937/1079], Loss: 0.1340\n",
      "Epoch [1/10], Step [938/1079], Loss: 0.1110\n",
      "Epoch [1/10], Step [939/1079], Loss: 0.1242\n",
      "Epoch [1/10], Step [940/1079], Loss: 0.0759\n",
      "Epoch [1/10], Step [941/1079], Loss: 0.1610\n",
      "Epoch [1/10], Step [942/1079], Loss: 0.0403\n",
      "Epoch [1/10], Step [943/1079], Loss: 0.0569\n",
      "Epoch [1/10], Step [944/1079], Loss: 0.0175\n",
      "Epoch [1/10], Step [945/1079], Loss: 0.0445\n",
      "Epoch [1/10], Step [946/1079], Loss: 0.0307\n",
      "Epoch [1/10], Step [947/1079], Loss: 0.0450\n",
      "Epoch [1/10], Step [948/1079], Loss: 0.0645\n",
      "Epoch [1/10], Step [949/1079], Loss: 0.0207\n",
      "Epoch [1/10], Step [950/1079], Loss: 0.0541\n",
      "Epoch [1/10], Step [951/1079], Loss: 0.0162\n",
      "Epoch [1/10], Step [952/1079], Loss: 0.0257\n",
      "Epoch [1/10], Step [953/1079], Loss: 0.0354\n",
      "Epoch [1/10], Step [954/1079], Loss: 0.0124\n",
      "Epoch [1/10], Step [955/1079], Loss: 0.0578\n",
      "Epoch [1/10], Step [956/1079], Loss: 0.0654\n",
      "Epoch [1/10], Step [957/1079], Loss: 0.0762\n",
      "Epoch [1/10], Step [958/1079], Loss: 0.0083\n",
      "Epoch [1/10], Step [959/1079], Loss: 0.0550\n",
      "Epoch [1/10], Step [960/1079], Loss: 0.0955\n",
      "Epoch [1/10], Step [961/1079], Loss: 0.0881\n",
      "Epoch [1/10], Step [962/1079], Loss: 0.0485\n",
      "Epoch [1/10], Step [963/1079], Loss: 0.0262\n",
      "Epoch [1/10], Step [964/1079], Loss: 0.0280\n",
      "Epoch [1/10], Step [965/1079], Loss: 0.1636\n",
      "Epoch [1/10], Step [966/1079], Loss: 0.0584\n",
      "Epoch [1/10], Step [967/1079], Loss: 0.0625\n",
      "Epoch [1/10], Step [968/1079], Loss: 0.0283\n",
      "Epoch [1/10], Step [969/1079], Loss: 0.0178\n",
      "Epoch [1/10], Step [970/1079], Loss: 0.0100\n",
      "Epoch [1/10], Step [971/1079], Loss: 0.0687\n",
      "Epoch [1/10], Step [972/1079], Loss: 0.1914\n",
      "Epoch [1/10], Step [973/1079], Loss: 0.0436\n",
      "Epoch [1/10], Step [974/1079], Loss: 0.0412\n",
      "Epoch [1/10], Step [975/1079], Loss: 0.1489\n",
      "Epoch [1/10], Step [976/1079], Loss: 0.0228\n",
      "Epoch [1/10], Step [977/1079], Loss: 0.0091\n",
      "Epoch [1/10], Step [978/1079], Loss: 0.0553\n",
      "Epoch [1/10], Step [979/1079], Loss: 0.0240\n",
      "Epoch [1/10], Step [980/1079], Loss: 0.0337\n",
      "Epoch [1/10], Step [981/1079], Loss: 0.0464\n",
      "Epoch [1/10], Step [982/1079], Loss: 0.0567\n",
      "Epoch [1/10], Step [983/1079], Loss: 0.0783\n",
      "Epoch [1/10], Step [984/1079], Loss: 0.1195\n",
      "Epoch [1/10], Step [985/1079], Loss: 0.0157\n",
      "Epoch [1/10], Step [986/1079], Loss: 0.0768\n",
      "Epoch [1/10], Step [987/1079], Loss: 0.0398\n",
      "Epoch [1/10], Step [988/1079], Loss: 0.0529\n",
      "Epoch [1/10], Step [989/1079], Loss: 0.2320\n",
      "Epoch [1/10], Step [990/1079], Loss: 0.0482\n",
      "Epoch [1/10], Step [991/1079], Loss: 0.0349\n",
      "Epoch [1/10], Step [992/1079], Loss: 0.0683\n",
      "Epoch [1/10], Step [993/1079], Loss: 0.0477\n",
      "Epoch [1/10], Step [994/1079], Loss: 0.0585\n",
      "Epoch [1/10], Step [995/1079], Loss: 0.0582\n",
      "Epoch [1/10], Step [996/1079], Loss: 0.0370\n",
      "Epoch [1/10], Step [997/1079], Loss: 0.0646\n",
      "Epoch [1/10], Step [998/1079], Loss: 0.1027\n",
      "Epoch [1/10], Step [999/1079], Loss: 0.0317\n",
      "Epoch [1/10], Step [1000/1079], Loss: 0.0332\n",
      "Epoch [1/10], Step [1001/1079], Loss: 0.1082\n",
      "Epoch [1/10], Step [1002/1079], Loss: 0.0208\n",
      "Epoch [1/10], Step [1003/1079], Loss: 0.0177\n",
      "Epoch [1/10], Step [1004/1079], Loss: 0.0767\n",
      "Epoch [1/10], Step [1005/1079], Loss: 0.0495\n",
      "Epoch [1/10], Step [1006/1079], Loss: 0.2294\n",
      "Epoch [1/10], Step [1007/1079], Loss: 0.0745\n",
      "Epoch [1/10], Step [1008/1079], Loss: 0.0340\n",
      "Epoch [1/10], Step [1009/1079], Loss: 0.0944\n",
      "Epoch [1/10], Step [1010/1079], Loss: 0.0639\n",
      "Epoch [1/10], Step [1011/1079], Loss: 0.1932\n",
      "Epoch [1/10], Step [1012/1079], Loss: 0.0239\n",
      "Epoch [1/10], Step [1013/1079], Loss: 0.0212\n",
      "Epoch [1/10], Step [1014/1079], Loss: 0.0561\n",
      "Epoch [1/10], Step [1015/1079], Loss: 0.0795\n",
      "Epoch [1/10], Step [1016/1079], Loss: 0.0168\n",
      "Epoch [1/10], Step [1017/1079], Loss: 0.2387\n",
      "Epoch [1/10], Step [1018/1079], Loss: 0.0403\n",
      "Epoch [1/10], Step [1019/1079], Loss: 0.0221\n",
      "Epoch [1/10], Step [1020/1079], Loss: 0.1113\n",
      "Epoch [1/10], Step [1021/1079], Loss: 0.0199\n",
      "Epoch [1/10], Step [1022/1079], Loss: 0.1405\n",
      "Epoch [1/10], Step [1023/1079], Loss: 0.1225\n",
      "Epoch [1/10], Step [1024/1079], Loss: 0.0149\n",
      "Epoch [1/10], Step [1025/1079], Loss: 0.0283\n",
      "Epoch [1/10], Step [1026/1079], Loss: 0.1613\n",
      "Epoch [1/10], Step [1027/1079], Loss: 0.0227\n",
      "Epoch [1/10], Step [1028/1079], Loss: 0.0904\n",
      "Epoch [1/10], Step [1029/1079], Loss: 0.0129\n",
      "Epoch [1/10], Step [1030/1079], Loss: 0.0187\n",
      "Epoch [1/10], Step [1031/1079], Loss: 0.0733\n",
      "Epoch [1/10], Step [1032/1079], Loss: 0.0192\n",
      "Epoch [1/10], Step [1033/1079], Loss: 0.0517\n",
      "Epoch [1/10], Step [1034/1079], Loss: 0.0697\n",
      "Epoch [1/10], Step [1035/1079], Loss: 0.0075\n",
      "Epoch [1/10], Step [1036/1079], Loss: 0.0223\n",
      "Epoch [1/10], Step [1037/1079], Loss: 0.0196\n",
      "Epoch [1/10], Step [1038/1079], Loss: 0.0775\n",
      "Epoch [1/10], Step [1039/1079], Loss: 0.0182\n",
      "Epoch [1/10], Step [1040/1079], Loss: 0.0672\n",
      "Epoch [1/10], Step [1041/1079], Loss: 0.0102\n",
      "Epoch [1/10], Step [1042/1079], Loss: 0.1096\n",
      "Epoch [1/10], Step [1043/1079], Loss: 0.0484\n",
      "Epoch [1/10], Step [1044/1079], Loss: 0.0653\n",
      "Epoch [1/10], Step [1045/1079], Loss: 0.0755\n",
      "Epoch [1/10], Step [1046/1079], Loss: 0.0106\n",
      "Epoch [1/10], Step [1047/1079], Loss: 0.0908\n",
      "Epoch [1/10], Step [1048/1079], Loss: 0.1338\n",
      "Epoch [1/10], Step [1049/1079], Loss: 0.0462\n",
      "Epoch [1/10], Step [1050/1079], Loss: 0.0653\n",
      "Epoch [1/10], Step [1051/1079], Loss: 0.0592\n",
      "Epoch [1/10], Step [1052/1079], Loss: 0.1458\n",
      "Epoch [1/10], Step [1053/1079], Loss: 0.0665\n",
      "Epoch [1/10], Step [1054/1079], Loss: 0.1017\n",
      "Epoch [1/10], Step [1055/1079], Loss: 0.0043\n",
      "Epoch [1/10], Step [1056/1079], Loss: 0.1042\n",
      "Epoch [1/10], Step [1057/1079], Loss: 0.0737\n",
      "Epoch [1/10], Step [1058/1079], Loss: 0.0777\n",
      "Epoch [1/10], Step [1059/1079], Loss: 0.1167\n",
      "Epoch [1/10], Step [1060/1079], Loss: 0.0804\n",
      "Epoch [1/10], Step [1061/1079], Loss: 0.0102\n",
      "Epoch [1/10], Step [1062/1079], Loss: 0.0233\n",
      "Epoch [1/10], Step [1063/1079], Loss: 0.0391\n",
      "Epoch [1/10], Step [1064/1079], Loss: 0.0362\n",
      "Epoch [1/10], Step [1065/1079], Loss: 0.0716\n",
      "Epoch [1/10], Step [1066/1079], Loss: 0.1380\n",
      "Epoch [1/10], Step [1067/1079], Loss: 0.0238\n",
      "Epoch [1/10], Step [1068/1079], Loss: 0.0645\n",
      "Epoch [1/10], Step [1069/1079], Loss: 0.0724\n",
      "Epoch [1/10], Step [1070/1079], Loss: 0.0423\n",
      "Epoch [1/10], Step [1071/1079], Loss: 0.0301\n",
      "Epoch [1/10], Step [1072/1079], Loss: 0.0376\n",
      "Epoch [1/10], Step [1073/1079], Loss: 0.0074\n",
      "Epoch [1/10], Step [1074/1079], Loss: 0.2386\n",
      "Epoch [1/10], Step [1075/1079], Loss: 0.0701\n",
      "Epoch [1/10], Step [1076/1079], Loss: 0.0072\n",
      "Epoch [1/10], Step [1077/1079], Loss: 0.0234\n",
      "Epoch [1/10], Step [1078/1079], Loss: 0.0247\n",
      "Epoch [1/10], Step [1079/1079], Loss: 0.0228\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [1/1079], Loss: 0.0578\n",
      "Epoch [2/10], Step [2/1079], Loss: 0.0167\n",
      "Epoch [2/10], Step [3/1079], Loss: 0.0279\n",
      "Epoch [2/10], Step [4/1079], Loss: 0.0170\n",
      "Epoch [2/10], Step [5/1079], Loss: 0.0586\n",
      "Epoch [2/10], Step [6/1079], Loss: 0.0795\n",
      "Epoch [2/10], Step [7/1079], Loss: 0.0200\n",
      "Epoch [2/10], Step [8/1079], Loss: 0.0448\n",
      "Epoch [2/10], Step [9/1079], Loss: 0.0407\n",
      "Epoch [2/10], Step [10/1079], Loss: 0.0640\n",
      "Epoch [2/10], Step [11/1079], Loss: 0.0165\n",
      "Epoch [2/10], Step [12/1079], Loss: 0.0241\n",
      "Epoch [2/10], Step [13/1079], Loss: 0.0545\n",
      "Epoch [2/10], Step [14/1079], Loss: 0.0057\n",
      "Epoch [2/10], Step [15/1079], Loss: 0.0382\n",
      "Epoch [2/10], Step [16/1079], Loss: 0.0489\n",
      "Epoch [2/10], Step [17/1079], Loss: 0.0336\n",
      "Epoch [2/10], Step [18/1079], Loss: 0.0226\n",
      "Epoch [2/10], Step [19/1079], Loss: 0.0453\n",
      "Epoch [2/10], Step [20/1079], Loss: 0.0772\n",
      "Epoch [2/10], Step [21/1079], Loss: 0.0522\n",
      "Epoch [2/10], Step [22/1079], Loss: 0.0646\n",
      "Epoch [2/10], Step [23/1079], Loss: 0.0734\n",
      "Epoch [2/10], Step [24/1079], Loss: 0.0325\n",
      "Epoch [2/10], Step [25/1079], Loss: 0.0060\n",
      "Epoch [2/10], Step [26/1079], Loss: 0.1297\n",
      "Epoch [2/10], Step [27/1079], Loss: 0.0313\n",
      "Epoch [2/10], Step [28/1079], Loss: 0.0213\n",
      "Epoch [2/10], Step [29/1079], Loss: 0.0227\n",
      "Epoch [2/10], Step [30/1079], Loss: 0.1557\n",
      "Epoch [2/10], Step [31/1079], Loss: 0.0250\n",
      "Epoch [2/10], Step [32/1079], Loss: 0.1244\n",
      "Epoch [2/10], Step [33/1079], Loss: 0.0030\n",
      "Epoch [2/10], Step [34/1079], Loss: 0.0639\n",
      "Epoch [2/10], Step [35/1079], Loss: 0.0163\n",
      "Epoch [2/10], Step [36/1079], Loss: 0.0096\n",
      "Epoch [2/10], Step [37/1079], Loss: 0.0050\n",
      "Epoch [2/10], Step [38/1079], Loss: 0.0031\n",
      "Epoch [2/10], Step [39/1079], Loss: 0.0309\n",
      "Epoch [2/10], Step [40/1079], Loss: 0.1118\n",
      "Epoch [2/10], Step [41/1079], Loss: 0.0229\n",
      "Epoch [2/10], Step [42/1079], Loss: 0.0646\n",
      "Epoch [2/10], Step [43/1079], Loss: 0.0570\n",
      "Epoch [2/10], Step [44/1079], Loss: 0.0271\n",
      "Epoch [2/10], Step [45/1079], Loss: 0.0649\n",
      "Epoch [2/10], Step [46/1079], Loss: 0.1056\n",
      "Epoch [2/10], Step [47/1079], Loss: 0.0641\n",
      "Epoch [2/10], Step [48/1079], Loss: 0.0321\n",
      "Epoch [2/10], Step [49/1079], Loss: 0.0350\n",
      "Epoch [2/10], Step [50/1079], Loss: 0.0158\n",
      "Epoch [2/10], Step [51/1079], Loss: 0.0192\n",
      "Epoch [2/10], Step [52/1079], Loss: 0.0202\n",
      "Epoch [2/10], Step [53/1079], Loss: 0.0842\n",
      "Epoch [2/10], Step [54/1079], Loss: 0.1147\n",
      "Epoch [2/10], Step [55/1079], Loss: 0.0205\n",
      "Epoch [2/10], Step [56/1079], Loss: 0.0165\n",
      "Epoch [2/10], Step [57/1079], Loss: 0.0456\n",
      "Epoch [2/10], Step [58/1079], Loss: 0.1320\n",
      "Epoch [2/10], Step [59/1079], Loss: 0.1311\n",
      "Epoch [2/10], Step [60/1079], Loss: 0.0152\n",
      "Epoch [2/10], Step [61/1079], Loss: 0.0270\n",
      "Epoch [2/10], Step [62/1079], Loss: 0.0136\n",
      "Epoch [2/10], Step [63/1079], Loss: 0.0153\n",
      "Epoch [2/10], Step [64/1079], Loss: 0.0096\n",
      "Epoch [2/10], Step [65/1079], Loss: 0.0422\n",
      "Epoch [2/10], Step [66/1079], Loss: 0.0085\n",
      "Epoch [2/10], Step [67/1079], Loss: 0.0628\n",
      "Epoch [2/10], Step [68/1079], Loss: 0.0857\n",
      "Epoch [2/10], Step [69/1079], Loss: 0.0328\n",
      "Epoch [2/10], Step [70/1079], Loss: 0.0329\n",
      "Epoch [2/10], Step [71/1079], Loss: 0.0607\n",
      "Epoch [2/10], Step [72/1079], Loss: 0.0302\n",
      "Epoch [2/10], Step [73/1079], Loss: 0.0212\n",
      "Epoch [2/10], Step [74/1079], Loss: 0.0351\n",
      "Epoch [2/10], Step [75/1079], Loss: 0.0263\n",
      "Epoch [2/10], Step [76/1079], Loss: 0.0257\n",
      "Epoch [2/10], Step [77/1079], Loss: 0.0038\n",
      "Epoch [2/10], Step [78/1079], Loss: 0.0070\n",
      "Epoch [2/10], Step [79/1079], Loss: 0.0884\n",
      "Epoch [2/10], Step [80/1079], Loss: 0.0229\n",
      "Epoch [2/10], Step [81/1079], Loss: 0.0639\n",
      "Epoch [2/10], Step [82/1079], Loss: 0.0409\n",
      "Epoch [2/10], Step [83/1079], Loss: 0.0786\n",
      "Epoch [2/10], Step [84/1079], Loss: 0.0266\n",
      "Epoch [2/10], Step [85/1079], Loss: 0.0351\n",
      "Epoch [2/10], Step [86/1079], Loss: 0.1654\n",
      "Epoch [2/10], Step [87/1079], Loss: 0.0338\n",
      "Epoch [2/10], Step [88/1079], Loss: 0.0373\n",
      "Epoch [2/10], Step [89/1079], Loss: 0.0310\n",
      "Epoch [2/10], Step [90/1079], Loss: 0.0534\n",
      "Epoch [2/10], Step [91/1079], Loss: 0.1442\n",
      "Epoch [2/10], Step [92/1079], Loss: 0.0549\n",
      "Epoch [2/10], Step [93/1079], Loss: 0.0680\n",
      "Epoch [2/10], Step [94/1079], Loss: 0.0750\n",
      "Epoch [2/10], Step [95/1079], Loss: 0.0152\n",
      "Epoch [2/10], Step [96/1079], Loss: 0.0797\n",
      "Epoch [2/10], Step [97/1079], Loss: 0.1430\n",
      "Epoch [2/10], Step [98/1079], Loss: 0.0217\n",
      "Epoch [2/10], Step [99/1079], Loss: 0.0433\n",
      "Epoch [2/10], Step [100/1079], Loss: 0.0037\n",
      "Epoch [2/10], Step [101/1079], Loss: 0.1121\n",
      "Epoch [2/10], Step [102/1079], Loss: 0.0543\n",
      "Epoch [2/10], Step [103/1079], Loss: 0.0059\n",
      "Epoch [2/10], Step [104/1079], Loss: 0.0753\n",
      "Epoch [2/10], Step [105/1079], Loss: 0.0315\n",
      "Epoch [2/10], Step [106/1079], Loss: 0.0276\n",
      "Epoch [2/10], Step [107/1079], Loss: 0.0449\n",
      "Epoch [2/10], Step [108/1079], Loss: 0.0362\n",
      "Epoch [2/10], Step [109/1079], Loss: 0.0572\n",
      "Epoch [2/10], Step [110/1079], Loss: 0.0367\n",
      "Epoch [2/10], Step [111/1079], Loss: 0.0059\n",
      "Epoch [2/10], Step [112/1079], Loss: 0.0254\n",
      "Epoch [2/10], Step [113/1079], Loss: 0.0505\n",
      "Epoch [2/10], Step [114/1079], Loss: 0.0940\n",
      "Epoch [2/10], Step [115/1079], Loss: 0.0291\n",
      "Epoch [2/10], Step [116/1079], Loss: 0.2014\n",
      "Epoch [2/10], Step [117/1079], Loss: 0.0773\n",
      "Epoch [2/10], Step [118/1079], Loss: 0.1199\n",
      "Epoch [2/10], Step [119/1079], Loss: 0.0026\n",
      "Epoch [2/10], Step [120/1079], Loss: 0.1070\n",
      "Epoch [2/10], Step [121/1079], Loss: 0.0164\n",
      "Epoch [2/10], Step [122/1079], Loss: 0.1435\n",
      "Epoch [2/10], Step [123/1079], Loss: 0.0680\n",
      "Epoch [2/10], Step [124/1079], Loss: 0.0952\n",
      "Epoch [2/10], Step [125/1079], Loss: 0.1051\n",
      "Epoch [2/10], Step [126/1079], Loss: 0.0110\n",
      "Epoch [2/10], Step [127/1079], Loss: 0.2197\n",
      "Epoch [2/10], Step [128/1079], Loss: 0.0354\n",
      "Epoch [2/10], Step [129/1079], Loss: 0.1123\n",
      "Epoch [2/10], Step [130/1079], Loss: 0.0189\n",
      "Epoch [2/10], Step [131/1079], Loss: 0.0527\n",
      "Epoch [2/10], Step [132/1079], Loss: 0.0804\n",
      "Epoch [2/10], Step [133/1079], Loss: 0.0099\n",
      "Epoch [2/10], Step [134/1079], Loss: 0.3128\n",
      "Epoch [2/10], Step [135/1079], Loss: 0.0052\n",
      "Epoch [2/10], Step [136/1079], Loss: 0.2129\n",
      "Epoch [2/10], Step [137/1079], Loss: 0.1271\n",
      "Epoch [2/10], Step [138/1079], Loss: 0.0077\n",
      "Epoch [2/10], Step [139/1079], Loss: 0.1004\n",
      "Epoch [2/10], Step [140/1079], Loss: 0.0329\n",
      "Epoch [2/10], Step [141/1079], Loss: 0.0599\n",
      "Epoch [2/10], Step [142/1079], Loss: 0.0809\n",
      "Epoch [2/10], Step [143/1079], Loss: 0.0472\n",
      "Epoch [2/10], Step [144/1079], Loss: 0.0274\n",
      "Epoch [2/10], Step [145/1079], Loss: 0.0821\n",
      "Epoch [2/10], Step [146/1079], Loss: 0.0101\n",
      "Epoch [2/10], Step [147/1079], Loss: 0.0534\n",
      "Epoch [2/10], Step [148/1079], Loss: 0.0561\n",
      "Epoch [2/10], Step [149/1079], Loss: 0.0172\n",
      "Epoch [2/10], Step [150/1079], Loss: 0.0267\n",
      "Epoch [2/10], Step [151/1079], Loss: 0.0211\n",
      "Epoch [2/10], Step [152/1079], Loss: 0.0392\n",
      "Epoch [2/10], Step [153/1079], Loss: 0.0185\n",
      "Epoch [2/10], Step [154/1079], Loss: 0.0640\n",
      "Epoch [2/10], Step [155/1079], Loss: 0.1264\n",
      "Epoch [2/10], Step [156/1079], Loss: 0.0400\n",
      "Epoch [2/10], Step [157/1079], Loss: 0.0192\n",
      "Epoch [2/10], Step [158/1079], Loss: 0.0186\n",
      "Epoch [2/10], Step [159/1079], Loss: 0.0604\n",
      "Epoch [2/10], Step [160/1079], Loss: 0.0486\n",
      "Epoch [2/10], Step [161/1079], Loss: 0.0498\n",
      "Epoch [2/10], Step [162/1079], Loss: 0.0575\n",
      "Epoch [2/10], Step [163/1079], Loss: 0.0361\n",
      "Epoch [2/10], Step [164/1079], Loss: 0.0555\n",
      "Epoch [2/10], Step [165/1079], Loss: 0.0329\n",
      "Epoch [2/10], Step [166/1079], Loss: 0.0890\n",
      "Epoch [2/10], Step [167/1079], Loss: 0.0061\n",
      "Epoch [2/10], Step [168/1079], Loss: 0.0498\n",
      "Epoch [2/10], Step [169/1079], Loss: 0.0413\n",
      "Epoch [2/10], Step [170/1079], Loss: 0.1095\n",
      "Epoch [2/10], Step [171/1079], Loss: 0.0224\n",
      "Epoch [2/10], Step [172/1079], Loss: 0.0059\n",
      "Epoch [2/10], Step [173/1079], Loss: 0.0957\n",
      "Epoch [2/10], Step [174/1079], Loss: 0.0499\n",
      "Epoch [2/10], Step [175/1079], Loss: 0.1171\n",
      "Epoch [2/10], Step [176/1079], Loss: 0.0684\n",
      "Epoch [2/10], Step [177/1079], Loss: 0.0391\n",
      "Epoch [2/10], Step [178/1079], Loss: 0.0080\n",
      "Epoch [2/10], Step [179/1079], Loss: 0.0191\n",
      "Epoch [2/10], Step [180/1079], Loss: 0.0237\n",
      "Epoch [2/10], Step [181/1079], Loss: 0.0157\n",
      "Epoch [2/10], Step [182/1079], Loss: 0.0932\n",
      "Epoch [2/10], Step [183/1079], Loss: 0.1175\n",
      "Epoch [2/10], Step [184/1079], Loss: 0.0076\n",
      "Epoch [2/10], Step [185/1079], Loss: 0.0186\n",
      "Epoch [2/10], Step [186/1079], Loss: 0.1103\n",
      "Epoch [2/10], Step [187/1079], Loss: 0.0236\n",
      "Epoch [2/10], Step [188/1079], Loss: 0.0362\n",
      "Epoch [2/10], Step [189/1079], Loss: 0.0288\n",
      "Epoch [2/10], Step [190/1079], Loss: 0.0240\n",
      "Epoch [2/10], Step [191/1079], Loss: 0.0338\n",
      "Epoch [2/10], Step [192/1079], Loss: 0.0485\n",
      "Epoch [2/10], Step [193/1079], Loss: 0.0377\n",
      "Epoch [2/10], Step [194/1079], Loss: 0.0769\n",
      "Epoch [2/10], Step [195/1079], Loss: 0.0222\n",
      "Epoch [2/10], Step [196/1079], Loss: 0.0089\n",
      "Epoch [2/10], Step [197/1079], Loss: 0.0084\n",
      "Epoch [2/10], Step [198/1079], Loss: 0.1583\n",
      "Epoch [2/10], Step [199/1079], Loss: 0.0186\n",
      "Epoch [2/10], Step [200/1079], Loss: 0.1156\n",
      "Epoch [2/10], Step [201/1079], Loss: 0.0115\n",
      "Epoch [2/10], Step [202/1079], Loss: 0.0265\n",
      "Epoch [2/10], Step [203/1079], Loss: 0.0069\n",
      "Epoch [2/10], Step [204/1079], Loss: 0.0115\n",
      "Epoch [2/10], Step [205/1079], Loss: 0.0128\n",
      "Epoch [2/10], Step [206/1079], Loss: 0.0069\n",
      "Epoch [2/10], Step [207/1079], Loss: 0.0253\n",
      "Epoch [2/10], Step [208/1079], Loss: 0.0050\n",
      "Epoch [2/10], Step [209/1079], Loss: 0.0377\n",
      "Epoch [2/10], Step [210/1079], Loss: 0.0281\n",
      "Epoch [2/10], Step [211/1079], Loss: 0.0572\n",
      "Epoch [2/10], Step [212/1079], Loss: 0.1162\n",
      "Epoch [2/10], Step [213/1079], Loss: 0.0253\n",
      "Epoch [2/10], Step [214/1079], Loss: 0.1288\n",
      "Epoch [2/10], Step [215/1079], Loss: 0.0908\n",
      "Epoch [2/10], Step [216/1079], Loss: 0.0223\n",
      "Epoch [2/10], Step [217/1079], Loss: 0.0202\n",
      "Epoch [2/10], Step [218/1079], Loss: 0.0072\n",
      "Epoch [2/10], Step [219/1079], Loss: 0.0329\n",
      "Epoch [2/10], Step [220/1079], Loss: 0.0274\n",
      "Epoch [2/10], Step [221/1079], Loss: 0.0024\n",
      "Epoch [2/10], Step [222/1079], Loss: 0.0840\n",
      "Epoch [2/10], Step [223/1079], Loss: 0.1265\n",
      "Epoch [2/10], Step [224/1079], Loss: 0.0065\n",
      "Epoch [2/10], Step [225/1079], Loss: 0.0011\n",
      "Epoch [2/10], Step [226/1079], Loss: 0.0740\n",
      "Epoch [2/10], Step [227/1079], Loss: 0.0222\n",
      "Epoch [2/10], Step [228/1079], Loss: 0.0473\n",
      "Epoch [2/10], Step [229/1079], Loss: 0.1210\n",
      "Epoch [2/10], Step [230/1079], Loss: 0.0739\n",
      "Epoch [2/10], Step [231/1079], Loss: 0.0072\n",
      "Epoch [2/10], Step [232/1079], Loss: 0.0511\n",
      "Epoch [2/10], Step [233/1079], Loss: 0.0484\n",
      "Epoch [2/10], Step [234/1079], Loss: 0.0395\n",
      "Epoch [2/10], Step [235/1079], Loss: 0.0163\n",
      "Epoch [2/10], Step [236/1079], Loss: 0.0129\n",
      "Epoch [2/10], Step [237/1079], Loss: 0.0754\n",
      "Epoch [2/10], Step [238/1079], Loss: 0.0094\n",
      "Epoch [2/10], Step [239/1079], Loss: 0.0596\n",
      "Epoch [2/10], Step [240/1079], Loss: 0.0643\n",
      "Epoch [2/10], Step [241/1079], Loss: 0.1396\n",
      "Epoch [2/10], Step [242/1079], Loss: 0.0208\n",
      "Epoch [2/10], Step [243/1079], Loss: 0.0180\n",
      "Epoch [2/10], Step [244/1079], Loss: 0.0066\n",
      "Epoch [2/10], Step [245/1079], Loss: 0.0055\n",
      "Epoch [2/10], Step [246/1079], Loss: 0.0433\n",
      "Epoch [2/10], Step [247/1079], Loss: 0.0432\n",
      "Epoch [2/10], Step [248/1079], Loss: 0.0996\n",
      "Epoch [2/10], Step [249/1079], Loss: 0.0266\n",
      "Epoch [2/10], Step [250/1079], Loss: 0.1516\n",
      "Epoch [2/10], Step [251/1079], Loss: 0.2036\n",
      "Epoch [2/10], Step [252/1079], Loss: 0.0394\n",
      "Epoch [2/10], Step [253/1079], Loss: 0.0916\n",
      "Epoch [2/10], Step [254/1079], Loss: 0.0269\n",
      "Epoch [2/10], Step [255/1079], Loss: 0.0480\n",
      "Epoch [2/10], Step [256/1079], Loss: 0.0542\n",
      "Epoch [2/10], Step [257/1079], Loss: 0.1325\n",
      "Epoch [2/10], Step [258/1079], Loss: 0.1106\n",
      "Epoch [2/10], Step [259/1079], Loss: 0.0444\n",
      "Epoch [2/10], Step [260/1079], Loss: 0.0852\n",
      "Epoch [2/10], Step [261/1079], Loss: 0.0589\n",
      "Epoch [2/10], Step [262/1079], Loss: 0.1362\n",
      "Epoch [2/10], Step [263/1079], Loss: 0.0180\n",
      "Epoch [2/10], Step [264/1079], Loss: 0.0588\n",
      "Epoch [2/10], Step [265/1079], Loss: 0.0226\n",
      "Epoch [2/10], Step [266/1079], Loss: 0.0393\n",
      "Epoch [2/10], Step [267/1079], Loss: 0.0320\n",
      "Epoch [2/10], Step [268/1079], Loss: 0.0414\n",
      "Epoch [2/10], Step [269/1079], Loss: 0.0595\n",
      "Epoch [2/10], Step [270/1079], Loss: 0.0508\n",
      "Epoch [2/10], Step [271/1079], Loss: 0.0748\n",
      "Epoch [2/10], Step [272/1079], Loss: 0.0056\n",
      "Epoch [2/10], Step [273/1079], Loss: 0.0046\n",
      "Epoch [2/10], Step [274/1079], Loss: 0.0857\n",
      "Epoch [2/10], Step [275/1079], Loss: 0.0632\n",
      "Epoch [2/10], Step [276/1079], Loss: 0.0251\n",
      "Epoch [2/10], Step [277/1079], Loss: 0.0228\n",
      "Epoch [2/10], Step [278/1079], Loss: 0.0223\n",
      "Epoch [2/10], Step [279/1079], Loss: 0.0822\n",
      "Epoch [2/10], Step [280/1079], Loss: 0.0417\n",
      "Epoch [2/10], Step [281/1079], Loss: 0.0075\n",
      "Epoch [2/10], Step [282/1079], Loss: 0.0073\n",
      "Epoch [2/10], Step [283/1079], Loss: 0.0559\n",
      "Epoch [2/10], Step [284/1079], Loss: 0.0531\n",
      "Epoch [2/10], Step [285/1079], Loss: 0.0319\n",
      "Epoch [2/10], Step [286/1079], Loss: 0.0669\n",
      "Epoch [2/10], Step [287/1079], Loss: 0.1211\n",
      "Epoch [2/10], Step [288/1079], Loss: 0.0203\n",
      "Epoch [2/10], Step [289/1079], Loss: 0.0213\n",
      "Epoch [2/10], Step [290/1079], Loss: 0.1401\n",
      "Epoch [2/10], Step [291/1079], Loss: 0.0311\n",
      "Epoch [2/10], Step [292/1079], Loss: 0.1273\n",
      "Epoch [2/10], Step [293/1079], Loss: 0.0812\n",
      "Epoch [2/10], Step [294/1079], Loss: 0.0530\n",
      "Epoch [2/10], Step [295/1079], Loss: 0.0385\n",
      "Epoch [2/10], Step [296/1079], Loss: 0.0684\n",
      "Epoch [2/10], Step [297/1079], Loss: 0.0426\n",
      "Epoch [2/10], Step [298/1079], Loss: 0.0128\n",
      "Epoch [2/10], Step [299/1079], Loss: 0.0112\n",
      "Epoch [2/10], Step [300/1079], Loss: 0.0191\n",
      "Epoch [2/10], Step [301/1079], Loss: 0.0079\n",
      "Epoch [2/10], Step [302/1079], Loss: 0.0332\n",
      "Epoch [2/10], Step [303/1079], Loss: 0.0336\n",
      "Epoch [2/10], Step [304/1079], Loss: 0.0721\n",
      "Epoch [2/10], Step [305/1079], Loss: 0.0862\n",
      "Epoch [2/10], Step [306/1079], Loss: 0.0129\n",
      "Epoch [2/10], Step [307/1079], Loss: 0.0699\n",
      "Epoch [2/10], Step [308/1079], Loss: 0.0694\n",
      "Epoch [2/10], Step [309/1079], Loss: 0.0249\n",
      "Epoch [2/10], Step [310/1079], Loss: 0.0976\n",
      "Epoch [2/10], Step [311/1079], Loss: 0.0373\n",
      "Epoch [2/10], Step [312/1079], Loss: 0.0523\n",
      "Epoch [2/10], Step [313/1079], Loss: 0.0453\n",
      "Epoch [2/10], Step [314/1079], Loss: 0.0142\n",
      "Epoch [2/10], Step [315/1079], Loss: 0.0134\n",
      "Epoch [2/10], Step [316/1079], Loss: 0.0537\n",
      "Epoch [2/10], Step [317/1079], Loss: 0.0499\n",
      "Epoch [2/10], Step [318/1079], Loss: 0.0559\n",
      "Epoch [2/10], Step [319/1079], Loss: 0.0435\n",
      "Epoch [2/10], Step [320/1079], Loss: 0.0265\n",
      "Epoch [2/10], Step [321/1079], Loss: 0.0161\n",
      "Epoch [2/10], Step [322/1079], Loss: 0.0027\n",
      "Epoch [2/10], Step [323/1079], Loss: 0.0310\n",
      "Epoch [2/10], Step [324/1079], Loss: 0.0079\n",
      "Epoch [2/10], Step [325/1079], Loss: 0.0080\n",
      "Epoch [2/10], Step [326/1079], Loss: 0.0079\n",
      "Epoch [2/10], Step [327/1079], Loss: 0.0479\n",
      "Epoch [2/10], Step [328/1079], Loss: 0.0225\n",
      "Epoch [2/10], Step [329/1079], Loss: 0.0759\n",
      "Epoch [2/10], Step [330/1079], Loss: 0.0098\n",
      "Epoch [2/10], Step [331/1079], Loss: 0.0098\n",
      "Epoch [2/10], Step [332/1079], Loss: 0.0104\n",
      "Epoch [2/10], Step [333/1079], Loss: 0.0622\n",
      "Epoch [2/10], Step [334/1079], Loss: 0.0241\n",
      "Epoch [2/10], Step [335/1079], Loss: 0.0048\n",
      "Epoch [2/10], Step [336/1079], Loss: 0.0634\n",
      "Epoch [2/10], Step [337/1079], Loss: 0.2035\n",
      "Epoch [2/10], Step [338/1079], Loss: 0.0580\n",
      "Epoch [2/10], Step [339/1079], Loss: 0.0230\n",
      "Epoch [2/10], Step [340/1079], Loss: 0.0185\n",
      "Epoch [2/10], Step [341/1079], Loss: 0.0391\n",
      "Epoch [2/10], Step [342/1079], Loss: 0.0093\n",
      "Epoch [2/10], Step [343/1079], Loss: 0.0115\n",
      "Epoch [2/10], Step [344/1079], Loss: 0.0497\n",
      "Epoch [2/10], Step [345/1079], Loss: 0.0288\n",
      "Epoch [2/10], Step [346/1079], Loss: 0.0177\n",
      "Epoch [2/10], Step [347/1079], Loss: 0.1165\n",
      "Epoch [2/10], Step [348/1079], Loss: 0.0444\n",
      "Epoch [2/10], Step [349/1079], Loss: 0.1391\n",
      "Epoch [2/10], Step [350/1079], Loss: 0.0896\n",
      "Epoch [2/10], Step [351/1079], Loss: 0.0058\n",
      "Epoch [2/10], Step [352/1079], Loss: 0.0169\n",
      "Epoch [2/10], Step [353/1079], Loss: 0.0067\n",
      "Epoch [2/10], Step [354/1079], Loss: 0.0298\n",
      "Epoch [2/10], Step [355/1079], Loss: 0.0290\n",
      "Epoch [2/10], Step [356/1079], Loss: 0.0396\n",
      "Epoch [2/10], Step [357/1079], Loss: 0.0103\n",
      "Epoch [2/10], Step [358/1079], Loss: 0.0295\n",
      "Epoch [2/10], Step [359/1079], Loss: 0.0310\n",
      "Epoch [2/10], Step [360/1079], Loss: 0.0815\n",
      "Epoch [2/10], Step [361/1079], Loss: 0.1194\n",
      "Epoch [2/10], Step [362/1079], Loss: 0.1230\n",
      "Epoch [2/10], Step [363/1079], Loss: 0.0199\n",
      "Epoch [2/10], Step [364/1079], Loss: 0.0108\n",
      "Epoch [2/10], Step [365/1079], Loss: 0.0401\n",
      "Epoch [2/10], Step [366/1079], Loss: 0.0227\n",
      "Epoch [2/10], Step [367/1079], Loss: 0.0492\n",
      "Epoch [2/10], Step [368/1079], Loss: 0.0273\n",
      "Epoch [2/10], Step [369/1079], Loss: 0.0712\n",
      "Epoch [2/10], Step [370/1079], Loss: 0.0462\n",
      "Epoch [2/10], Step [371/1079], Loss: 0.2320\n",
      "Epoch [2/10], Step [372/1079], Loss: 0.1008\n",
      "Epoch [2/10], Step [373/1079], Loss: 0.0683\n",
      "Epoch [2/10], Step [374/1079], Loss: 0.0988\n",
      "Epoch [2/10], Step [375/1079], Loss: 0.0151\n",
      "Epoch [2/10], Step [376/1079], Loss: 0.0134\n",
      "Epoch [2/10], Step [377/1079], Loss: 0.0046\n",
      "Epoch [2/10], Step [378/1079], Loss: 0.0193\n",
      "Epoch [2/10], Step [379/1079], Loss: 0.0890\n",
      "Epoch [2/10], Step [380/1079], Loss: 0.0287\n",
      "Epoch [2/10], Step [381/1079], Loss: 0.0120\n",
      "Epoch [2/10], Step [382/1079], Loss: 0.0885\n",
      "Epoch [2/10], Step [383/1079], Loss: 0.0935\n",
      "Epoch [2/10], Step [384/1079], Loss: 0.0115\n",
      "Epoch [2/10], Step [385/1079], Loss: 0.0525\n",
      "Epoch [2/10], Step [386/1079], Loss: 0.3008\n",
      "Epoch [2/10], Step [387/1079], Loss: 0.0582\n",
      "Epoch [2/10], Step [388/1079], Loss: 0.0249\n",
      "Epoch [2/10], Step [389/1079], Loss: 0.0832\n",
      "Epoch [2/10], Step [390/1079], Loss: 0.0961\n",
      "Epoch [2/10], Step [391/1079], Loss: 0.0503\n",
      "Epoch [2/10], Step [392/1079], Loss: 0.0366\n",
      "Epoch [2/10], Step [393/1079], Loss: 0.0129\n",
      "Epoch [2/10], Step [394/1079], Loss: 0.2069\n",
      "Epoch [2/10], Step [395/1079], Loss: 0.0524\n",
      "Epoch [2/10], Step [396/1079], Loss: 0.0442\n",
      "Epoch [2/10], Step [397/1079], Loss: 0.0344\n",
      "Epoch [2/10], Step [398/1079], Loss: 0.0122\n",
      "Epoch [2/10], Step [399/1079], Loss: 0.0447\n",
      "Epoch [2/10], Step [400/1079], Loss: 0.0306\n",
      "Epoch [2/10], Step [401/1079], Loss: 0.0569\n",
      "Epoch [2/10], Step [402/1079], Loss: 0.0323\n",
      "Epoch [2/10], Step [403/1079], Loss: 0.0406\n",
      "Epoch [2/10], Step [404/1079], Loss: 0.0060\n",
      "Epoch [2/10], Step [405/1079], Loss: 0.0105\n",
      "Epoch [2/10], Step [406/1079], Loss: 0.0468\n",
      "Epoch [2/10], Step [407/1079], Loss: 0.0573\n",
      "Epoch [2/10], Step [408/1079], Loss: 0.0872\n",
      "Epoch [2/10], Step [409/1079], Loss: 0.0434\n",
      "Epoch [2/10], Step [410/1079], Loss: 0.0274\n",
      "Epoch [2/10], Step [411/1079], Loss: 0.1322\n",
      "Epoch [2/10], Step [412/1079], Loss: 0.0302\n",
      "Epoch [2/10], Step [413/1079], Loss: 0.0546\n",
      "Epoch [2/10], Step [414/1079], Loss: 0.0199\n",
      "Epoch [2/10], Step [415/1079], Loss: 0.0050\n",
      "Epoch [2/10], Step [416/1079], Loss: 0.0678\n",
      "Epoch [2/10], Step [417/1079], Loss: 0.0622\n",
      "Epoch [2/10], Step [418/1079], Loss: 0.0112\n",
      "Epoch [2/10], Step [419/1079], Loss: 0.0399\n",
      "Epoch [2/10], Step [420/1079], Loss: 0.1010\n",
      "Epoch [2/10], Step [421/1079], Loss: 0.0747\n",
      "Epoch [2/10], Step [422/1079], Loss: 0.0072\n",
      "Epoch [2/10], Step [423/1079], Loss: 0.0213\n",
      "Epoch [2/10], Step [424/1079], Loss: 0.0202\n",
      "Epoch [2/10], Step [425/1079], Loss: 0.0080\n",
      "Epoch [2/10], Step [426/1079], Loss: 0.0201\n",
      "Epoch [2/10], Step [427/1079], Loss: 0.0743\n",
      "Epoch [2/10], Step [428/1079], Loss: 0.0162\n",
      "Epoch [2/10], Step [429/1079], Loss: 0.0545\n",
      "Epoch [2/10], Step [430/1079], Loss: 0.1027\n",
      "Epoch [2/10], Step [431/1079], Loss: 0.0467\n",
      "Epoch [2/10], Step [432/1079], Loss: 0.0036\n",
      "Epoch [2/10], Step [433/1079], Loss: 0.0717\n",
      "Epoch [2/10], Step [434/1079], Loss: 0.0617\n",
      "Epoch [2/10], Step [435/1079], Loss: 0.2346\n",
      "Epoch [2/10], Step [436/1079], Loss: 0.0908\n",
      "Epoch [2/10], Step [437/1079], Loss: 0.0309\n",
      "Epoch [2/10], Step [438/1079], Loss: 0.0200\n",
      "Epoch [2/10], Step [439/1079], Loss: 0.1201\n",
      "Epoch [2/10], Step [440/1079], Loss: 0.0281\n",
      "Epoch [2/10], Step [441/1079], Loss: 0.0071\n",
      "Epoch [2/10], Step [442/1079], Loss: 0.0118\n",
      "Epoch [2/10], Step [443/1079], Loss: 0.0888\n",
      "Epoch [2/10], Step [444/1079], Loss: 0.0779\n",
      "Epoch [2/10], Step [445/1079], Loss: 0.0843\n",
      "Epoch [2/10], Step [446/1079], Loss: 0.1891\n",
      "Epoch [2/10], Step [447/1079], Loss: 0.0158\n",
      "Epoch [2/10], Step [448/1079], Loss: 0.0461\n",
      "Epoch [2/10], Step [449/1079], Loss: 0.0232\n",
      "Epoch [2/10], Step [450/1079], Loss: 0.0725\n",
      "Epoch [2/10], Step [451/1079], Loss: 0.0078\n",
      "Epoch [2/10], Step [452/1079], Loss: 0.0571\n",
      "Epoch [2/10], Step [453/1079], Loss: 0.0229\n",
      "Epoch [2/10], Step [454/1079], Loss: 0.1021\n",
      "Epoch [2/10], Step [455/1079], Loss: 0.0210\n",
      "Epoch [2/10], Step [456/1079], Loss: 0.0753\n",
      "Epoch [2/10], Step [457/1079], Loss: 0.0033\n",
      "Epoch [2/10], Step [458/1079], Loss: 0.0179\n",
      "Epoch [2/10], Step [459/1079], Loss: 0.0240\n",
      "Epoch [2/10], Step [460/1079], Loss: 0.1424\n",
      "Epoch [2/10], Step [461/1079], Loss: 0.0103\n",
      "Epoch [2/10], Step [462/1079], Loss: 0.0901\n",
      "Epoch [2/10], Step [463/1079], Loss: 0.1012\n",
      "Epoch [2/10], Step [464/1079], Loss: 0.0187\n",
      "Epoch [2/10], Step [465/1079], Loss: 0.0207\n",
      "Epoch [2/10], Step [466/1079], Loss: 0.0414\n",
      "Epoch [2/10], Step [467/1079], Loss: 0.0076\n",
      "Epoch [2/10], Step [468/1079], Loss: 0.0140\n",
      "Epoch [2/10], Step [469/1079], Loss: 0.0093\n",
      "Epoch [2/10], Step [470/1079], Loss: 0.0059\n",
      "Epoch [2/10], Step [471/1079], Loss: 0.1273\n",
      "Epoch [2/10], Step [472/1079], Loss: 0.0051\n",
      "Epoch [2/10], Step [473/1079], Loss: 0.1003\n",
      "Epoch [2/10], Step [474/1079], Loss: 0.0288\n",
      "Epoch [2/10], Step [475/1079], Loss: 0.0410\n",
      "Epoch [2/10], Step [476/1079], Loss: 0.0161\n",
      "Epoch [2/10], Step [477/1079], Loss: 0.1893\n",
      "Epoch [2/10], Step [478/1079], Loss: 0.0175\n",
      "Epoch [2/10], Step [479/1079], Loss: 0.1680\n",
      "Epoch [2/10], Step [480/1079], Loss: 0.0553\n",
      "Epoch [2/10], Step [481/1079], Loss: 0.0577\n",
      "Epoch [2/10], Step [482/1079], Loss: 0.0107\n",
      "Epoch [2/10], Step [483/1079], Loss: 0.0088\n",
      "Epoch [2/10], Step [484/1079], Loss: 0.0278\n",
      "Epoch [2/10], Step [485/1079], Loss: 0.0245\n",
      "Epoch [2/10], Step [486/1079], Loss: 0.0941\n",
      "Epoch [2/10], Step [487/1079], Loss: 0.0583\n",
      "Epoch [2/10], Step [488/1079], Loss: 0.0398\n",
      "Epoch [2/10], Step [489/1079], Loss: 0.0206\n",
      "Epoch [2/10], Step [490/1079], Loss: 0.0099\n",
      "Epoch [2/10], Step [491/1079], Loss: 0.0921\n",
      "Epoch [2/10], Step [492/1079], Loss: 0.0089\n",
      "Epoch [2/10], Step [493/1079], Loss: 0.0128\n",
      "Epoch [2/10], Step [494/1079], Loss: 0.1427\n",
      "Epoch [2/10], Step [495/1079], Loss: 0.0212\n",
      "Epoch [2/10], Step [496/1079], Loss: 0.0444\n",
      "Epoch [2/10], Step [497/1079], Loss: 0.0208\n",
      "Epoch [2/10], Step [498/1079], Loss: 0.0134\n",
      "Epoch [2/10], Step [499/1079], Loss: 0.0553\n",
      "Epoch [2/10], Step [500/1079], Loss: 0.0177\n",
      "Epoch [2/10], Step [501/1079], Loss: 0.0642\n",
      "Epoch [2/10], Step [502/1079], Loss: 0.0246\n",
      "Epoch [2/10], Step [503/1079], Loss: 0.0373\n",
      "Epoch [2/10], Step [504/1079], Loss: 0.0219\n",
      "Epoch [2/10], Step [505/1079], Loss: 0.0172\n",
      "Epoch [2/10], Step [506/1079], Loss: 0.0104\n",
      "Epoch [2/10], Step [507/1079], Loss: 0.0253\n",
      "Epoch [2/10], Step [508/1079], Loss: 0.0053\n",
      "Epoch [2/10], Step [509/1079], Loss: 0.0069\n",
      "Epoch [2/10], Step [510/1079], Loss: 0.0083\n",
      "Epoch [2/10], Step [511/1079], Loss: 0.0637\n",
      "Epoch [2/10], Step [512/1079], Loss: 0.0203\n",
      "Epoch [2/10], Step [513/1079], Loss: 0.0187\n",
      "Epoch [2/10], Step [514/1079], Loss: 0.0196\n",
      "Epoch [2/10], Step [515/1079], Loss: 0.0245\n",
      "Epoch [2/10], Step [516/1079], Loss: 0.0376\n",
      "Epoch [2/10], Step [517/1079], Loss: 0.0063\n",
      "Epoch [2/10], Step [518/1079], Loss: 0.0838\n",
      "Epoch [2/10], Step [519/1079], Loss: 0.0446\n",
      "Epoch [2/10], Step [520/1079], Loss: 0.0150\n",
      "Epoch [2/10], Step [521/1079], Loss: 0.0033\n",
      "Epoch [2/10], Step [522/1079], Loss: 0.0845\n",
      "Epoch [2/10], Step [523/1079], Loss: 0.0688\n",
      "Epoch [2/10], Step [524/1079], Loss: 0.0041\n",
      "Epoch [2/10], Step [525/1079], Loss: 0.0104\n",
      "Epoch [2/10], Step [526/1079], Loss: 0.0274\n",
      "Epoch [2/10], Step [527/1079], Loss: 0.0047\n",
      "Epoch [2/10], Step [528/1079], Loss: 0.0784\n",
      "Epoch [2/10], Step [529/1079], Loss: 0.0916\n",
      "Epoch [2/10], Step [530/1079], Loss: 0.0041\n",
      "Epoch [2/10], Step [531/1079], Loss: 0.0250\n",
      "Epoch [2/10], Step [532/1079], Loss: 0.0937\n",
      "Epoch [2/10], Step [533/1079], Loss: 0.1609\n",
      "Epoch [2/10], Step [534/1079], Loss: 0.0984\n",
      "Epoch [2/10], Step [535/1079], Loss: 0.0207\n",
      "Epoch [2/10], Step [536/1079], Loss: 0.1640\n",
      "Epoch [2/10], Step [537/1079], Loss: 0.0097\n",
      "Epoch [2/10], Step [538/1079], Loss: 0.1375\n",
      "Epoch [2/10], Step [539/1079], Loss: 0.0498\n",
      "Epoch [2/10], Step [540/1079], Loss: 0.0216\n",
      "Epoch [2/10], Step [541/1079], Loss: 0.0837\n",
      "Epoch [2/10], Step [542/1079], Loss: 0.0148\n",
      "Epoch [2/10], Step [543/1079], Loss: 0.0124\n",
      "Epoch [2/10], Step [544/1079], Loss: 0.0305\n",
      "Epoch [2/10], Step [545/1079], Loss: 0.0121\n",
      "Epoch [2/10], Step [546/1079], Loss: 0.0234\n",
      "Epoch [2/10], Step [547/1079], Loss: 0.0030\n",
      "Epoch [2/10], Step [548/1079], Loss: 0.0281\n",
      "Epoch [2/10], Step [549/1079], Loss: 0.0209\n",
      "Epoch [2/10], Step [550/1079], Loss: 0.0295\n",
      "Epoch [2/10], Step [551/1079], Loss: 0.0322\n",
      "Epoch [2/10], Step [552/1079], Loss: 0.1217\n",
      "Epoch [2/10], Step [553/1079], Loss: 0.0875\n",
      "Epoch [2/10], Step [554/1079], Loss: 0.0115\n",
      "Epoch [2/10], Step [555/1079], Loss: 0.0080\n",
      "Epoch [2/10], Step [556/1079], Loss: 0.0381\n",
      "Epoch [2/10], Step [557/1079], Loss: 0.0609\n",
      "Epoch [2/10], Step [558/1079], Loss: 0.0906\n",
      "Epoch [2/10], Step [559/1079], Loss: 0.0087\n",
      "Epoch [2/10], Step [560/1079], Loss: 0.0298\n",
      "Epoch [2/10], Step [561/1079], Loss: 0.0422\n",
      "Epoch [2/10], Step [562/1079], Loss: 0.0516\n",
      "Epoch [2/10], Step [563/1079], Loss: 0.0135\n",
      "Epoch [2/10], Step [564/1079], Loss: 0.0134\n",
      "Epoch [2/10], Step [565/1079], Loss: 0.0805\n",
      "Epoch [2/10], Step [566/1079], Loss: 0.0444\n",
      "Epoch [2/10], Step [567/1079], Loss: 0.0427\n",
      "Epoch [2/10], Step [568/1079], Loss: 0.0833\n",
      "Epoch [2/10], Step [569/1079], Loss: 0.0807\n",
      "Epoch [2/10], Step [570/1079], Loss: 0.0465\n",
      "Epoch [2/10], Step [571/1079], Loss: 0.0119\n",
      "Epoch [2/10], Step [572/1079], Loss: 0.0753\n",
      "Epoch [2/10], Step [573/1079], Loss: 0.0208\n",
      "Epoch [2/10], Step [574/1079], Loss: 0.0191\n",
      "Epoch [2/10], Step [575/1079], Loss: 0.0101\n",
      "Epoch [2/10], Step [576/1079], Loss: 0.1221\n",
      "Epoch [2/10], Step [577/1079], Loss: 0.0386\n",
      "Epoch [2/10], Step [578/1079], Loss: 0.0412\n",
      "Epoch [2/10], Step [579/1079], Loss: 0.0111\n",
      "Epoch [2/10], Step [580/1079], Loss: 0.1959\n",
      "Epoch [2/10], Step [581/1079], Loss: 0.0671\n",
      "Epoch [2/10], Step [582/1079], Loss: 0.0744\n",
      "Epoch [2/10], Step [583/1079], Loss: 0.0786\n",
      "Epoch [2/10], Step [584/1079], Loss: 0.0035\n",
      "Epoch [2/10], Step [585/1079], Loss: 0.0203\n",
      "Epoch [2/10], Step [586/1079], Loss: 0.0259\n",
      "Epoch [2/10], Step [587/1079], Loss: 0.0364\n",
      "Epoch [2/10], Step [588/1079], Loss: 0.1769\n",
      "Epoch [2/10], Step [589/1079], Loss: 0.0653\n",
      "Epoch [2/10], Step [590/1079], Loss: 0.0233\n",
      "Epoch [2/10], Step [591/1079], Loss: 0.0166\n",
      "Epoch [2/10], Step [592/1079], Loss: 0.0250\n",
      "Epoch [2/10], Step [593/1079], Loss: 0.0079\n",
      "Epoch [2/10], Step [594/1079], Loss: 0.0115\n",
      "Epoch [2/10], Step [595/1079], Loss: 0.0648\n",
      "Epoch [2/10], Step [596/1079], Loss: 0.0161\n",
      "Epoch [2/10], Step [597/1079], Loss: 0.0081\n",
      "Epoch [2/10], Step [598/1079], Loss: 0.0198\n",
      "Epoch [2/10], Step [599/1079], Loss: 0.0407\n",
      "Epoch [2/10], Step [600/1079], Loss: 0.0222\n",
      "Epoch [2/10], Step [601/1079], Loss: 0.0276\n",
      "Epoch [2/10], Step [602/1079], Loss: 0.0316\n",
      "Epoch [2/10], Step [603/1079], Loss: 0.0412\n",
      "Epoch [2/10], Step [604/1079], Loss: 0.0046\n",
      "Epoch [2/10], Step [605/1079], Loss: 0.0217\n",
      "Epoch [2/10], Step [606/1079], Loss: 0.0318\n",
      "Epoch [2/10], Step [607/1079], Loss: 0.0219\n",
      "Epoch [2/10], Step [608/1079], Loss: 0.0661\n",
      "Epoch [2/10], Step [609/1079], Loss: 0.0083\n",
      "Epoch [2/10], Step [610/1079], Loss: 0.0196\n",
      "Epoch [2/10], Step [611/1079], Loss: 0.0130\n",
      "Epoch [2/10], Step [612/1079], Loss: 0.1277\n",
      "Epoch [2/10], Step [613/1079], Loss: 0.0697\n",
      "Epoch [2/10], Step [614/1079], Loss: 0.0187\n",
      "Epoch [2/10], Step [615/1079], Loss: 0.0154\n",
      "Epoch [2/10], Step [616/1079], Loss: 0.0222\n",
      "Epoch [2/10], Step [617/1079], Loss: 0.1332\n",
      "Epoch [2/10], Step [618/1079], Loss: 0.0387\n",
      "Epoch [2/10], Step [619/1079], Loss: 0.0503\n",
      "Epoch [2/10], Step [620/1079], Loss: 0.0108\n",
      "Epoch [2/10], Step [621/1079], Loss: 0.0830\n",
      "Epoch [2/10], Step [622/1079], Loss: 0.0027\n",
      "Epoch [2/10], Step [623/1079], Loss: 0.0220\n",
      "Epoch [2/10], Step [624/1079], Loss: 0.0112\n",
      "Epoch [2/10], Step [625/1079], Loss: 0.0382\n",
      "Epoch [2/10], Step [626/1079], Loss: 0.0929\n",
      "Epoch [2/10], Step [627/1079], Loss: 0.0132\n",
      "Epoch [2/10], Step [628/1079], Loss: 0.1954\n",
      "Epoch [2/10], Step [629/1079], Loss: 0.2220\n",
      "Epoch [2/10], Step [630/1079], Loss: 0.0751\n",
      "Epoch [2/10], Step [631/1079], Loss: 0.0343\n",
      "Epoch [2/10], Step [632/1079], Loss: 0.0256\n",
      "Epoch [2/10], Step [633/1079], Loss: 0.0254\n",
      "Epoch [2/10], Step [634/1079], Loss: 0.0200\n",
      "Epoch [2/10], Step [635/1079], Loss: 0.0187\n",
      "Epoch [2/10], Step [636/1079], Loss: 0.0230\n",
      "Epoch [2/10], Step [637/1079], Loss: 0.0391\n",
      "Epoch [2/10], Step [638/1079], Loss: 0.0164\n",
      "Epoch [2/10], Step [639/1079], Loss: 0.1216\n",
      "Epoch [2/10], Step [640/1079], Loss: 0.0245\n",
      "Epoch [2/10], Step [641/1079], Loss: 0.0372\n",
      "Epoch [2/10], Step [642/1079], Loss: 0.0312\n",
      "Epoch [2/10], Step [643/1079], Loss: 0.0520\n",
      "Epoch [2/10], Step [644/1079], Loss: 0.0486\n",
      "Epoch [2/10], Step [645/1079], Loss: 0.0120\n",
      "Epoch [2/10], Step [646/1079], Loss: 0.0736\n",
      "Epoch [2/10], Step [647/1079], Loss: 0.0306\n",
      "Epoch [2/10], Step [648/1079], Loss: 0.0721\n",
      "Epoch [2/10], Step [649/1079], Loss: 0.0640\n",
      "Epoch [2/10], Step [650/1079], Loss: 0.0887\n",
      "Epoch [2/10], Step [651/1079], Loss: 0.0569\n",
      "Epoch [2/10], Step [652/1079], Loss: 0.0164\n",
      "Epoch [2/10], Step [653/1079], Loss: 0.0395\n",
      "Epoch [2/10], Step [654/1079], Loss: 0.0106\n",
      "Epoch [2/10], Step [655/1079], Loss: 0.0337\n",
      "Epoch [2/10], Step [656/1079], Loss: 0.0845\n",
      "Epoch [2/10], Step [657/1079], Loss: 0.0292\n",
      "Epoch [2/10], Step [658/1079], Loss: 0.0241\n",
      "Epoch [2/10], Step [659/1079], Loss: 0.0091\n",
      "Epoch [2/10], Step [660/1079], Loss: 0.0471\n",
      "Epoch [2/10], Step [661/1079], Loss: 0.0037\n",
      "Epoch [2/10], Step [662/1079], Loss: 0.1032\n",
      "Epoch [2/10], Step [663/1079], Loss: 0.0359\n",
      "Epoch [2/10], Step [664/1079], Loss: 0.0375\n",
      "Epoch [2/10], Step [665/1079], Loss: 0.0438\n",
      "Epoch [2/10], Step [666/1079], Loss: 0.0314\n",
      "Epoch [2/10], Step [667/1079], Loss: 0.0752\n",
      "Epoch [2/10], Step [668/1079], Loss: 0.0030\n",
      "Epoch [2/10], Step [669/1079], Loss: 0.0902\n",
      "Epoch [2/10], Step [670/1079], Loss: 0.0333\n",
      "Epoch [2/10], Step [671/1079], Loss: 0.0163\n",
      "Epoch [2/10], Step [672/1079], Loss: 0.0248\n",
      "Epoch [2/10], Step [673/1079], Loss: 0.0495\n",
      "Epoch [2/10], Step [674/1079], Loss: 0.0185\n",
      "Epoch [2/10], Step [675/1079], Loss: 0.0289\n",
      "Epoch [2/10], Step [676/1079], Loss: 0.0187\n",
      "Epoch [2/10], Step [677/1079], Loss: 0.0156\n",
      "Epoch [2/10], Step [678/1079], Loss: 0.0028\n",
      "Epoch [2/10], Step [679/1079], Loss: 0.0119\n",
      "Epoch [2/10], Step [680/1079], Loss: 0.0381\n",
      "Epoch [2/10], Step [681/1079], Loss: 0.0194\n",
      "Epoch [2/10], Step [682/1079], Loss: 0.0339\n",
      "Epoch [2/10], Step [683/1079], Loss: 0.0105\n",
      "Epoch [2/10], Step [684/1079], Loss: 0.0780\n",
      "Epoch [2/10], Step [685/1079], Loss: 0.0605\n",
      "Epoch [2/10], Step [686/1079], Loss: 0.0253\n",
      "Epoch [2/10], Step [687/1079], Loss: 0.0529\n",
      "Epoch [2/10], Step [688/1079], Loss: 0.0053\n",
      "Epoch [2/10], Step [689/1079], Loss: 0.0327\n",
      "Epoch [2/10], Step [690/1079], Loss: 0.0476\n",
      "Epoch [2/10], Step [691/1079], Loss: 0.0131\n",
      "Epoch [2/10], Step [692/1079], Loss: 0.1371\n",
      "Epoch [2/10], Step [693/1079], Loss: 0.1224\n",
      "Epoch [2/10], Step [694/1079], Loss: 0.0155\n",
      "Epoch [2/10], Step [695/1079], Loss: 0.1090\n",
      "Epoch [2/10], Step [696/1079], Loss: 0.0109\n",
      "Epoch [2/10], Step [697/1079], Loss: 0.0135\n",
      "Epoch [2/10], Step [698/1079], Loss: 0.0475\n",
      "Epoch [2/10], Step [699/1079], Loss: 0.0272\n",
      "Epoch [2/10], Step [700/1079], Loss: 0.0724\n",
      "Epoch [2/10], Step [701/1079], Loss: 0.0477\n",
      "Epoch [2/10], Step [702/1079], Loss: 0.0045\n",
      "Epoch [2/10], Step [703/1079], Loss: 0.0121\n",
      "Epoch [2/10], Step [704/1079], Loss: 0.0197\n",
      "Epoch [2/10], Step [705/1079], Loss: 0.0166\n",
      "Epoch [2/10], Step [706/1079], Loss: 0.0097\n",
      "Epoch [2/10], Step [707/1079], Loss: 0.0257\n",
      "Epoch [2/10], Step [708/1079], Loss: 0.0097\n",
      "Epoch [2/10], Step [709/1079], Loss: 0.0374\n",
      "Epoch [2/10], Step [710/1079], Loss: 0.0082\n",
      "Epoch [2/10], Step [711/1079], Loss: 0.0078\n",
      "Epoch [2/10], Step [712/1079], Loss: 0.1621\n",
      "Epoch [2/10], Step [713/1079], Loss: 0.0778\n",
      "Epoch [2/10], Step [714/1079], Loss: 0.0560\n",
      "Epoch [2/10], Step [715/1079], Loss: 0.0062\n",
      "Epoch [2/10], Step [716/1079], Loss: 0.0305\n",
      "Epoch [2/10], Step [717/1079], Loss: 0.0120\n",
      "Epoch [2/10], Step [718/1079], Loss: 0.0940\n",
      "Epoch [2/10], Step [719/1079], Loss: 0.0166\n",
      "Epoch [2/10], Step [720/1079], Loss: 0.0076\n",
      "Epoch [2/10], Step [721/1079], Loss: 0.0221\n",
      "Epoch [2/10], Step [722/1079], Loss: 0.0155\n",
      "Epoch [2/10], Step [723/1079], Loss: 0.0199\n",
      "Epoch [2/10], Step [724/1079], Loss: 0.0306\n",
      "Epoch [2/10], Step [725/1079], Loss: 0.0267\n",
      "Epoch [2/10], Step [726/1079], Loss: 0.0249\n",
      "Epoch [2/10], Step [727/1079], Loss: 0.0739\n",
      "Epoch [2/10], Step [728/1079], Loss: 0.0326\n",
      "Epoch [2/10], Step [729/1079], Loss: 0.0162\n",
      "Epoch [2/10], Step [730/1079], Loss: 0.1132\n",
      "Epoch [2/10], Step [731/1079], Loss: 0.0107\n",
      "Epoch [2/10], Step [732/1079], Loss: 0.0182\n",
      "Epoch [2/10], Step [733/1079], Loss: 0.0032\n",
      "Epoch [2/10], Step [734/1079], Loss: 0.0111\n",
      "Epoch [2/10], Step [735/1079], Loss: 0.0012\n",
      "Epoch [2/10], Step [736/1079], Loss: 0.0292\n",
      "Epoch [2/10], Step [737/1079], Loss: 0.0198\n",
      "Epoch [2/10], Step [738/1079], Loss: 0.0613\n",
      "Epoch [2/10], Step [739/1079], Loss: 0.0662\n",
      "Epoch [2/10], Step [740/1079], Loss: 0.0086\n",
      "Epoch [2/10], Step [741/1079], Loss: 0.0181\n",
      "Epoch [2/10], Step [742/1079], Loss: 0.0095\n",
      "Epoch [2/10], Step [743/1079], Loss: 0.0243\n",
      "Epoch [2/10], Step [744/1079], Loss: 0.0111\n",
      "Epoch [2/10], Step [745/1079], Loss: 0.0027\n",
      "Epoch [2/10], Step [746/1079], Loss: 0.0076\n",
      "Epoch [2/10], Step [747/1079], Loss: 0.0062\n",
      "Epoch [2/10], Step [748/1079], Loss: 0.1113\n",
      "Epoch [2/10], Step [749/1079], Loss: 0.0055\n",
      "Epoch [2/10], Step [750/1079], Loss: 0.1938\n",
      "Epoch [2/10], Step [751/1079], Loss: 0.0055\n",
      "Epoch [2/10], Step [752/1079], Loss: 0.0382\n",
      "Epoch [2/10], Step [753/1079], Loss: 0.0403\n",
      "Epoch [2/10], Step [754/1079], Loss: 0.0160\n",
      "Epoch [2/10], Step [755/1079], Loss: 0.0173\n",
      "Epoch [2/10], Step [756/1079], Loss: 0.0079\n",
      "Epoch [2/10], Step [757/1079], Loss: 0.0124\n",
      "Epoch [2/10], Step [758/1079], Loss: 0.1425\n",
      "Epoch [2/10], Step [759/1079], Loss: 0.0254\n",
      "Epoch [2/10], Step [760/1079], Loss: 0.0062\n",
      "Epoch [2/10], Step [761/1079], Loss: 0.0155\n",
      "Epoch [2/10], Step [762/1079], Loss: 0.0167\n",
      "Epoch [2/10], Step [763/1079], Loss: 0.0122\n",
      "Epoch [2/10], Step [764/1079], Loss: 0.0035\n",
      "Epoch [2/10], Step [765/1079], Loss: 0.0095\n",
      "Epoch [2/10], Step [766/1079], Loss: 0.1840\n",
      "Epoch [2/10], Step [767/1079], Loss: 0.0038\n",
      "Epoch [2/10], Step [768/1079], Loss: 0.0522\n",
      "Epoch [2/10], Step [769/1079], Loss: 0.0084\n",
      "Epoch [2/10], Step [770/1079], Loss: 0.0365\n",
      "Epoch [2/10], Step [771/1079], Loss: 0.0111\n",
      "Epoch [2/10], Step [772/1079], Loss: 0.0151\n",
      "Epoch [2/10], Step [773/1079], Loss: 0.0675\n",
      "Epoch [2/10], Step [774/1079], Loss: 0.0682\n",
      "Epoch [2/10], Step [775/1079], Loss: 0.0662\n",
      "Epoch [2/10], Step [776/1079], Loss: 0.0484\n",
      "Epoch [2/10], Step [777/1079], Loss: 0.0190\n",
      "Epoch [2/10], Step [778/1079], Loss: 0.0142\n",
      "Epoch [2/10], Step [779/1079], Loss: 0.0922\n",
      "Epoch [2/10], Step [780/1079], Loss: 0.0064\n",
      "Epoch [2/10], Step [781/1079], Loss: 0.0304\n",
      "Epoch [2/10], Step [782/1079], Loss: 0.0317\n",
      "Epoch [2/10], Step [783/1079], Loss: 0.0668\n",
      "Epoch [2/10], Step [784/1079], Loss: 0.0787\n",
      "Epoch [2/10], Step [785/1079], Loss: 0.0349\n",
      "Epoch [2/10], Step [786/1079], Loss: 0.1038\n",
      "Epoch [2/10], Step [787/1079], Loss: 0.1773\n",
      "Epoch [2/10], Step [788/1079], Loss: 0.0671\n",
      "Epoch [2/10], Step [789/1079], Loss: 0.0090\n",
      "Epoch [2/10], Step [790/1079], Loss: 0.0507\n",
      "Epoch [2/10], Step [791/1079], Loss: 0.0125\n",
      "Epoch [2/10], Step [792/1079], Loss: 0.0051\n",
      "Epoch [2/10], Step [793/1079], Loss: 0.0918\n",
      "Epoch [2/10], Step [794/1079], Loss: 0.0151\n",
      "Epoch [2/10], Step [795/1079], Loss: 0.0157\n",
      "Epoch [2/10], Step [796/1079], Loss: 0.0488\n",
      "Epoch [2/10], Step [797/1079], Loss: 0.0064\n",
      "Epoch [2/10], Step [798/1079], Loss: 0.0080\n",
      "Epoch [2/10], Step [799/1079], Loss: 0.0404\n",
      "Epoch [2/10], Step [800/1079], Loss: 0.0335\n",
      "Epoch [2/10], Step [801/1079], Loss: 0.0044\n",
      "Epoch [2/10], Step [802/1079], Loss: 0.0308\n",
      "Epoch [2/10], Step [803/1079], Loss: 0.0161\n",
      "Epoch [2/10], Step [804/1079], Loss: 0.0124\n",
      "Epoch [2/10], Step [805/1079], Loss: 0.0268\n",
      "Epoch [2/10], Step [806/1079], Loss: 0.0271\n",
      "Epoch [2/10], Step [807/1079], Loss: 0.0164\n",
      "Epoch [2/10], Step [808/1079], Loss: 0.0169\n",
      "Epoch [2/10], Step [809/1079], Loss: 0.0346\n",
      "Epoch [2/10], Step [810/1079], Loss: 0.0329\n",
      "Epoch [2/10], Step [811/1079], Loss: 0.0058\n",
      "Epoch [2/10], Step [812/1079], Loss: 0.1067\n",
      "Epoch [2/10], Step [813/1079], Loss: 0.0052\n",
      "Epoch [2/10], Step [814/1079], Loss: 0.0586\n",
      "Epoch [2/10], Step [815/1079], Loss: 0.0128\n",
      "Epoch [2/10], Step [816/1079], Loss: 0.0869\n",
      "Epoch [2/10], Step [817/1079], Loss: 0.0015\n",
      "Epoch [2/10], Step [818/1079], Loss: 0.0495\n",
      "Epoch [2/10], Step [819/1079], Loss: 0.0060\n",
      "Epoch [2/10], Step [820/1079], Loss: 0.0380\n",
      "Epoch [2/10], Step [821/1079], Loss: 0.0027\n",
      "Epoch [2/10], Step [822/1079], Loss: 0.0184\n",
      "Epoch [2/10], Step [823/1079], Loss: 0.0064\n",
      "Epoch [2/10], Step [824/1079], Loss: 0.0296\n",
      "Epoch [2/10], Step [825/1079], Loss: 0.0338\n",
      "Epoch [2/10], Step [826/1079], Loss: 0.0646\n",
      "Epoch [2/10], Step [827/1079], Loss: 0.0024\n",
      "Epoch [2/10], Step [828/1079], Loss: 0.0168\n",
      "Epoch [2/10], Step [829/1079], Loss: 0.0619\n",
      "Epoch [2/10], Step [830/1079], Loss: 0.0044\n",
      "Epoch [2/10], Step [831/1079], Loss: 0.0639\n",
      "Epoch [2/10], Step [832/1079], Loss: 0.0040\n",
      "Epoch [2/10], Step [833/1079], Loss: 0.0137\n",
      "Epoch [2/10], Step [834/1079], Loss: 0.0070\n",
      "Epoch [2/10], Step [835/1079], Loss: 0.1617\n",
      "Epoch [2/10], Step [836/1079], Loss: 0.0069\n",
      "Epoch [2/10], Step [837/1079], Loss: 0.0750\n",
      "Epoch [2/10], Step [838/1079], Loss: 0.0079\n",
      "Epoch [2/10], Step [839/1079], Loss: 0.0561\n",
      "Epoch [2/10], Step [840/1079], Loss: 0.0250\n",
      "Epoch [2/10], Step [841/1079], Loss: 0.1272\n",
      "Epoch [2/10], Step [842/1079], Loss: 0.0226\n",
      "Epoch [2/10], Step [843/1079], Loss: 0.0723\n",
      "Epoch [2/10], Step [844/1079], Loss: 0.1307\n",
      "Epoch [2/10], Step [845/1079], Loss: 0.0092\n",
      "Epoch [2/10], Step [846/1079], Loss: 0.0777\n",
      "Epoch [2/10], Step [847/1079], Loss: 0.0349\n",
      "Epoch [2/10], Step [848/1079], Loss: 0.0734\n",
      "Epoch [2/10], Step [849/1079], Loss: 0.0066\n",
      "Epoch [2/10], Step [850/1079], Loss: 0.0791\n",
      "Epoch [2/10], Step [851/1079], Loss: 0.0810\n",
      "Epoch [2/10], Step [852/1079], Loss: 0.1341\n",
      "Epoch [2/10], Step [853/1079], Loss: 0.0773\n",
      "Epoch [2/10], Step [854/1079], Loss: 0.0563\n",
      "Epoch [2/10], Step [855/1079], Loss: 0.0912\n",
      "Epoch [2/10], Step [856/1079], Loss: 0.0120\n",
      "Epoch [2/10], Step [857/1079], Loss: 0.0062\n",
      "Epoch [2/10], Step [858/1079], Loss: 0.0126\n",
      "Epoch [2/10], Step [859/1079], Loss: 0.0231\n",
      "Epoch [2/10], Step [860/1079], Loss: 0.0467\n",
      "Epoch [2/10], Step [861/1079], Loss: 0.1717\n",
      "Epoch [2/10], Step [862/1079], Loss: 0.0601\n",
      "Epoch [2/10], Step [863/1079], Loss: 0.0387\n",
      "Epoch [2/10], Step [864/1079], Loss: 0.0057\n",
      "Epoch [2/10], Step [865/1079], Loss: 0.0142\n",
      "Epoch [2/10], Step [866/1079], Loss: 0.0372\n",
      "Epoch [2/10], Step [867/1079], Loss: 0.0557\n",
      "Epoch [2/10], Step [868/1079], Loss: 0.0082\n",
      "Epoch [2/10], Step [869/1079], Loss: 0.0597\n",
      "Epoch [2/10], Step [870/1079], Loss: 0.0420\n",
      "Epoch [2/10], Step [871/1079], Loss: 0.0208\n",
      "Epoch [2/10], Step [872/1079], Loss: 0.0105\n",
      "Epoch [2/10], Step [873/1079], Loss: 0.0135\n",
      "Epoch [2/10], Step [874/1079], Loss: 0.0137\n",
      "Epoch [2/10], Step [875/1079], Loss: 0.1965\n",
      "Epoch [2/10], Step [876/1079], Loss: 0.1249\n",
      "Epoch [2/10], Step [877/1079], Loss: 0.0275\n",
      "Epoch [2/10], Step [878/1079], Loss: 0.0236\n",
      "Epoch [2/10], Step [879/1079], Loss: 0.0882\n",
      "Epoch [2/10], Step [880/1079], Loss: 0.0106\n",
      "Epoch [2/10], Step [881/1079], Loss: 0.0983\n",
      "Epoch [2/10], Step [882/1079], Loss: 0.0367\n",
      "Epoch [2/10], Step [883/1079], Loss: 0.0062\n",
      "Epoch [2/10], Step [884/1079], Loss: 0.0514\n",
      "Epoch [2/10], Step [885/1079], Loss: 0.0190\n",
      "Epoch [2/10], Step [886/1079], Loss: 0.0353\n",
      "Epoch [2/10], Step [887/1079], Loss: 0.0409\n",
      "Epoch [2/10], Step [888/1079], Loss: 0.0599\n",
      "Epoch [2/10], Step [889/1079], Loss: 0.0789\n",
      "Epoch [2/10], Step [890/1079], Loss: 0.0325\n",
      "Epoch [2/10], Step [891/1079], Loss: 0.0310\n",
      "Epoch [2/10], Step [892/1079], Loss: 0.0500\n",
      "Epoch [2/10], Step [893/1079], Loss: 0.0673\n",
      "Epoch [2/10], Step [894/1079], Loss: 0.0322\n",
      "Epoch [2/10], Step [895/1079], Loss: 0.0075\n",
      "Epoch [2/10], Step [896/1079], Loss: 0.0371\n",
      "Epoch [2/10], Step [897/1079], Loss: 0.0863\n",
      "Epoch [2/10], Step [898/1079], Loss: 0.0161\n",
      "Epoch [2/10], Step [899/1079], Loss: 0.0256\n",
      "Epoch [2/10], Step [900/1079], Loss: 0.0130\n",
      "Epoch [2/10], Step [901/1079], Loss: 0.0056\n",
      "Epoch [2/10], Step [902/1079], Loss: 0.0695\n",
      "Epoch [2/10], Step [903/1079], Loss: 0.0603\n",
      "Epoch [2/10], Step [904/1079], Loss: 0.0421\n",
      "Epoch [2/10], Step [905/1079], Loss: 0.0480\n",
      "Epoch [2/10], Step [906/1079], Loss: 0.0581\n",
      "Epoch [2/10], Step [907/1079], Loss: 0.0165\n",
      "Epoch [2/10], Step [908/1079], Loss: 0.0136\n",
      "Epoch [2/10], Step [909/1079], Loss: 0.0081\n",
      "Epoch [2/10], Step [910/1079], Loss: 0.0101\n",
      "Epoch [2/10], Step [911/1079], Loss: 0.0159\n",
      "Epoch [2/10], Step [912/1079], Loss: 0.0170\n",
      "Epoch [2/10], Step [913/1079], Loss: 0.0267\n",
      "Epoch [2/10], Step [914/1079], Loss: 0.0439\n",
      "Epoch [2/10], Step [915/1079], Loss: 0.0664\n",
      "Epoch [2/10], Step [916/1079], Loss: 0.0629\n",
      "Epoch [2/10], Step [917/1079], Loss: 0.0125\n",
      "Epoch [2/10], Step [918/1079], Loss: 0.0307\n",
      "Epoch [2/10], Step [919/1079], Loss: 0.0241\n",
      "Epoch [2/10], Step [920/1079], Loss: 0.0172\n",
      "Epoch [2/10], Step [921/1079], Loss: 0.0266\n",
      "Epoch [2/10], Step [922/1079], Loss: 0.0466\n",
      "Epoch [2/10], Step [923/1079], Loss: 0.0136\n",
      "Epoch [2/10], Step [924/1079], Loss: 0.1049\n",
      "Epoch [2/10], Step [925/1079], Loss: 0.0120\n",
      "Epoch [2/10], Step [926/1079], Loss: 0.0024\n",
      "Epoch [2/10], Step [927/1079], Loss: 0.0040\n",
      "Epoch [2/10], Step [928/1079], Loss: 0.0024\n",
      "Epoch [2/10], Step [929/1079], Loss: 0.0442\n",
      "Epoch [2/10], Step [930/1079], Loss: 0.0796\n",
      "Epoch [2/10], Step [931/1079], Loss: 0.0256\n",
      "Epoch [2/10], Step [932/1079], Loss: 0.0140\n",
      "Epoch [2/10], Step [933/1079], Loss: 0.0025\n",
      "Epoch [2/10], Step [934/1079], Loss: 0.0521\n",
      "Epoch [2/10], Step [935/1079], Loss: 0.0101\n",
      "Epoch [2/10], Step [936/1079], Loss: 0.0037\n",
      "Epoch [2/10], Step [937/1079], Loss: 0.0111\n",
      "Epoch [2/10], Step [938/1079], Loss: 0.0095\n",
      "Epoch [2/10], Step [939/1079], Loss: 0.0481\n",
      "Epoch [2/10], Step [940/1079], Loss: 0.1078\n",
      "Epoch [2/10], Step [941/1079], Loss: 0.0597\n",
      "Epoch [2/10], Step [942/1079], Loss: 0.0019\n",
      "Epoch [2/10], Step [943/1079], Loss: 0.1028\n",
      "Epoch [2/10], Step [944/1079], Loss: 0.0159\n",
      "Epoch [2/10], Step [945/1079], Loss: 0.1135\n",
      "Epoch [2/10], Step [946/1079], Loss: 0.0013\n",
      "Epoch [2/10], Step [947/1079], Loss: 0.0467\n",
      "Epoch [2/10], Step [948/1079], Loss: 0.0196\n",
      "Epoch [2/10], Step [949/1079], Loss: 0.0053\n",
      "Epoch [2/10], Step [950/1079], Loss: 0.0121\n",
      "Epoch [2/10], Step [951/1079], Loss: 0.2814\n",
      "Epoch [2/10], Step [952/1079], Loss: 0.0049\n",
      "Epoch [2/10], Step [953/1079], Loss: 0.0029\n",
      "Epoch [2/10], Step [954/1079], Loss: 0.1214\n",
      "Epoch [2/10], Step [955/1079], Loss: 0.1055\n",
      "Epoch [2/10], Step [956/1079], Loss: 0.0447\n",
      "Epoch [2/10], Step [957/1079], Loss: 0.0095\n",
      "Epoch [2/10], Step [958/1079], Loss: 0.0283\n",
      "Epoch [2/10], Step [959/1079], Loss: 0.1377\n",
      "Epoch [2/10], Step [960/1079], Loss: 0.0237\n",
      "Epoch [2/10], Step [961/1079], Loss: 0.0067\n",
      "Epoch [2/10], Step [962/1079], Loss: 0.0855\n",
      "Epoch [2/10], Step [963/1079], Loss: 0.0058\n",
      "Epoch [2/10], Step [964/1079], Loss: 0.0073\n",
      "Epoch [2/10], Step [965/1079], Loss: 0.0162\n",
      "Epoch [2/10], Step [966/1079], Loss: 0.0705\n",
      "Epoch [2/10], Step [967/1079], Loss: 0.0678\n",
      "Epoch [2/10], Step [968/1079], Loss: 0.0266\n",
      "Epoch [2/10], Step [969/1079], Loss: 0.0251\n",
      "Epoch [2/10], Step [970/1079], Loss: 0.0233\n",
      "Epoch [2/10], Step [971/1079], Loss: 0.0964\n",
      "Epoch [2/10], Step [972/1079], Loss: 0.0082\n",
      "Epoch [2/10], Step [973/1079], Loss: 0.0477\n",
      "Epoch [2/10], Step [974/1079], Loss: 0.0044\n",
      "Epoch [2/10], Step [975/1079], Loss: 0.0093\n",
      "Epoch [2/10], Step [976/1079], Loss: 0.0150\n",
      "Epoch [2/10], Step [977/1079], Loss: 0.0194\n",
      "Epoch [2/10], Step [978/1079], Loss: 0.0550\n",
      "Epoch [2/10], Step [979/1079], Loss: 0.0879\n",
      "Epoch [2/10], Step [980/1079], Loss: 0.0807\n",
      "Epoch [2/10], Step [981/1079], Loss: 0.0059\n",
      "Epoch [2/10], Step [982/1079], Loss: 0.0184\n",
      "Epoch [2/10], Step [983/1079], Loss: 0.0208\n",
      "Epoch [2/10], Step [984/1079], Loss: 0.0171\n",
      "Epoch [2/10], Step [985/1079], Loss: 0.0072\n",
      "Epoch [2/10], Step [986/1079], Loss: 0.0182\n",
      "Epoch [2/10], Step [987/1079], Loss: 0.0053\n",
      "Epoch [2/10], Step [988/1079], Loss: 0.0305\n",
      "Epoch [2/10], Step [989/1079], Loss: 0.0481\n",
      "Epoch [2/10], Step [990/1079], Loss: 0.0673\n",
      "Epoch [2/10], Step [991/1079], Loss: 0.0484\n",
      "Epoch [2/10], Step [992/1079], Loss: 0.0065\n",
      "Epoch [2/10], Step [993/1079], Loss: 0.0030\n",
      "Epoch [2/10], Step [994/1079], Loss: 0.0236\n",
      "Epoch [2/10], Step [995/1079], Loss: 0.0600\n",
      "Epoch [2/10], Step [996/1079], Loss: 0.0162\n",
      "Epoch [2/10], Step [997/1079], Loss: 0.0441\n",
      "Epoch [2/10], Step [998/1079], Loss: 0.0397\n",
      "Epoch [2/10], Step [999/1079], Loss: 0.0344\n",
      "Epoch [2/10], Step [1000/1079], Loss: 0.1054\n",
      "Epoch [2/10], Step [1001/1079], Loss: 0.1529\n",
      "Epoch [2/10], Step [1002/1079], Loss: 0.0845\n",
      "Epoch [2/10], Step [1003/1079], Loss: 0.0289\n",
      "Epoch [2/10], Step [1004/1079], Loss: 0.0647\n",
      "Epoch [2/10], Step [1005/1079], Loss: 0.0211\n",
      "Epoch [2/10], Step [1006/1079], Loss: 0.0200\n",
      "Epoch [2/10], Step [1007/1079], Loss: 0.1877\n",
      "Epoch [2/10], Step [1008/1079], Loss: 0.0377\n",
      "Epoch [2/10], Step [1009/1079], Loss: 0.0175\n",
      "Epoch [2/10], Step [1010/1079], Loss: 0.0698\n",
      "Epoch [2/10], Step [1011/1079], Loss: 0.0082\n",
      "Epoch [2/10], Step [1012/1079], Loss: 0.0117\n",
      "Epoch [2/10], Step [1013/1079], Loss: 0.0030\n",
      "Epoch [2/10], Step [1014/1079], Loss: 0.0101\n",
      "Epoch [2/10], Step [1015/1079], Loss: 0.0591\n",
      "Epoch [2/10], Step [1016/1079], Loss: 0.0195\n",
      "Epoch [2/10], Step [1017/1079], Loss: 0.0435\n",
      "Epoch [2/10], Step [1018/1079], Loss: 0.0543\n",
      "Epoch [2/10], Step [1019/1079], Loss: 0.1911\n",
      "Epoch [2/10], Step [1020/1079], Loss: 0.0510\n",
      "Epoch [2/10], Step [1021/1079], Loss: 0.0414\n",
      "Epoch [2/10], Step [1022/1079], Loss: 0.0328\n",
      "Epoch [2/10], Step [1023/1079], Loss: 0.0153\n",
      "Epoch [2/10], Step [1024/1079], Loss: 0.0108\n",
      "Epoch [2/10], Step [1025/1079], Loss: 0.0426\n",
      "Epoch [2/10], Step [1026/1079], Loss: 0.0460\n",
      "Epoch [2/10], Step [1027/1079], Loss: 0.0615\n",
      "Epoch [2/10], Step [1028/1079], Loss: 0.0471\n",
      "Epoch [2/10], Step [1029/1079], Loss: 0.0885\n",
      "Epoch [2/10], Step [1030/1079], Loss: 0.0212\n",
      "Epoch [2/10], Step [1031/1079], Loss: 0.0254\n",
      "Epoch [2/10], Step [1032/1079], Loss: 0.0441\n",
      "Epoch [2/10], Step [1033/1079], Loss: 0.0397\n",
      "Epoch [2/10], Step [1034/1079], Loss: 0.0698\n",
      "Epoch [2/10], Step [1035/1079], Loss: 0.0455\n",
      "Epoch [2/10], Step [1036/1079], Loss: 0.0054\n",
      "Epoch [2/10], Step [1037/1079], Loss: 0.0580\n",
      "Epoch [2/10], Step [1038/1079], Loss: 0.0063\n",
      "Epoch [2/10], Step [1039/1079], Loss: 0.0863\n",
      "Epoch [2/10], Step [1040/1079], Loss: 0.0121\n",
      "Epoch [2/10], Step [1041/1079], Loss: 0.0150\n",
      "Epoch [2/10], Step [1042/1079], Loss: 0.0236\n",
      "Epoch [2/10], Step [1043/1079], Loss: 0.0072\n",
      "Epoch [2/10], Step [1044/1079], Loss: 0.0264\n",
      "Epoch [2/10], Step [1045/1079], Loss: 0.0034\n",
      "Epoch [2/10], Step [1046/1079], Loss: 0.0553\n",
      "Epoch [2/10], Step [1047/1079], Loss: 0.1482\n",
      "Epoch [2/10], Step [1048/1079], Loss: 0.0108\n",
      "Epoch [2/10], Step [1049/1079], Loss: 0.0090\n",
      "Epoch [2/10], Step [1050/1079], Loss: 0.0749\n",
      "Epoch [2/10], Step [1051/1079], Loss: 0.0048\n",
      "Epoch [2/10], Step [1052/1079], Loss: 0.0279\n",
      "Epoch [2/10], Step [1053/1079], Loss: 0.0705\n",
      "Epoch [2/10], Step [1054/1079], Loss: 0.0109\n",
      "Epoch [2/10], Step [1055/1079], Loss: 0.1462\n",
      "Epoch [2/10], Step [1056/1079], Loss: 0.0507\n",
      "Epoch [2/10], Step [1057/1079], Loss: 0.0285\n",
      "Epoch [2/10], Step [1058/1079], Loss: 0.1394\n",
      "Epoch [2/10], Step [1059/1079], Loss: 0.0041\n",
      "Epoch [2/10], Step [1060/1079], Loss: 0.0238\n",
      "Epoch [2/10], Step [1061/1079], Loss: 0.0460\n",
      "Epoch [2/10], Step [1062/1079], Loss: 0.0486\n",
      "Epoch [2/10], Step [1063/1079], Loss: 0.0040\n",
      "Epoch [2/10], Step [1064/1079], Loss: 0.0414\n",
      "Epoch [2/10], Step [1065/1079], Loss: 0.0129\n",
      "Epoch [2/10], Step [1066/1079], Loss: 0.0190\n",
      "Epoch [2/10], Step [1067/1079], Loss: 0.0049\n",
      "Epoch [2/10], Step [1068/1079], Loss: 0.0129\n",
      "Epoch [2/10], Step [1069/1079], Loss: 0.0874\n",
      "Epoch [2/10], Step [1070/1079], Loss: 0.0065\n",
      "Epoch [2/10], Step [1071/1079], Loss: 0.0213\n",
      "Epoch [2/10], Step [1072/1079], Loss: 0.0128\n",
      "Epoch [2/10], Step [1073/1079], Loss: 0.0765\n",
      "Epoch [2/10], Step [1074/1079], Loss: 0.1123\n",
      "Epoch [2/10], Step [1075/1079], Loss: 0.0525\n",
      "Epoch [2/10], Step [1076/1079], Loss: 0.0645\n",
      "Epoch [2/10], Step [1077/1079], Loss: 0.0873\n",
      "Epoch [2/10], Step [1078/1079], Loss: 0.0442\n",
      "Epoch [2/10], Step [1079/1079], Loss: 0.1367\n",
      "Epoch [3/10], Step [1/1079], Loss: 0.0137\n",
      "Epoch [3/10], Step [2/1079], Loss: 0.0103\n",
      "Epoch [3/10], Step [3/1079], Loss: 0.0431\n",
      "Epoch [3/10], Step [4/1079], Loss: 0.0052\n",
      "Epoch [3/10], Step [5/1079], Loss: 0.0156\n",
      "Epoch [3/10], Step [6/1079], Loss: 0.0109\n",
      "Epoch [3/10], Step [7/1079], Loss: 0.0643\n",
      "Epoch [3/10], Step [8/1079], Loss: 0.0990\n",
      "Epoch [3/10], Step [9/1079], Loss: 0.0945\n",
      "Epoch [3/10], Step [10/1079], Loss: 0.0440\n",
      "Epoch [3/10], Step [11/1079], Loss: 0.0479\n",
      "Epoch [3/10], Step [12/1079], Loss: 0.0377\n",
      "Epoch [3/10], Step [13/1079], Loss: 0.0113\n",
      "Epoch [3/10], Step [14/1079], Loss: 0.0340\n",
      "Epoch [3/10], Step [15/1079], Loss: 0.0929\n",
      "Epoch [3/10], Step [16/1079], Loss: 0.0038\n",
      "Epoch [3/10], Step [17/1079], Loss: 0.0108\n",
      "Epoch [3/10], Step [18/1079], Loss: 0.0347\n",
      "Epoch [3/10], Step [19/1079], Loss: 0.0034\n",
      "Epoch [3/10], Step [20/1079], Loss: 0.0155\n",
      "Epoch [3/10], Step [21/1079], Loss: 0.0576\n",
      "Epoch [3/10], Step [22/1079], Loss: 0.0082\n",
      "Epoch [3/10], Step [23/1079], Loss: 0.0366\n",
      "Epoch [3/10], Step [24/1079], Loss: 0.0256\n",
      "Epoch [3/10], Step [25/1079], Loss: 0.0344\n",
      "Epoch [3/10], Step [26/1079], Loss: 0.0114\n",
      "Epoch [3/10], Step [27/1079], Loss: 0.0184\n",
      "Epoch [3/10], Step [28/1079], Loss: 0.0056\n",
      "Epoch [3/10], Step [29/1079], Loss: 0.0069\n",
      "Epoch [3/10], Step [30/1079], Loss: 0.0183\n",
      "Epoch [3/10], Step [31/1079], Loss: 0.0031\n",
      "Epoch [3/10], Step [32/1079], Loss: 0.0357\n",
      "Epoch [3/10], Step [33/1079], Loss: 0.0165\n",
      "Epoch [3/10], Step [34/1079], Loss: 0.0280\n",
      "Epoch [3/10], Step [35/1079], Loss: 0.0255\n",
      "Epoch [3/10], Step [36/1079], Loss: 0.0069\n",
      "Epoch [3/10], Step [37/1079], Loss: 0.0426\n",
      "Epoch [3/10], Step [38/1079], Loss: 0.0056\n",
      "Epoch [3/10], Step [39/1079], Loss: 0.0914\n",
      "Epoch [3/10], Step [40/1079], Loss: 0.0851\n",
      "Epoch [3/10], Step [41/1079], Loss: 0.0274\n",
      "Epoch [3/10], Step [42/1079], Loss: 0.0057\n",
      "Epoch [3/10], Step [43/1079], Loss: 0.0373\n",
      "Epoch [3/10], Step [44/1079], Loss: 0.0132\n",
      "Epoch [3/10], Step [45/1079], Loss: 0.1970\n",
      "Epoch [3/10], Step [46/1079], Loss: 0.0206\n",
      "Epoch [3/10], Step [47/1079], Loss: 0.0119\n",
      "Epoch [3/10], Step [48/1079], Loss: 0.0236\n",
      "Epoch [3/10], Step [49/1079], Loss: 0.0388\n",
      "Epoch [3/10], Step [50/1079], Loss: 0.0076\n",
      "Epoch [3/10], Step [51/1079], Loss: 0.0058\n",
      "Epoch [3/10], Step [52/1079], Loss: 0.0496\n",
      "Epoch [3/10], Step [53/1079], Loss: 0.0142\n",
      "Epoch [3/10], Step [54/1079], Loss: 0.0039\n",
      "Epoch [3/10], Step [55/1079], Loss: 0.0708\n",
      "Epoch [3/10], Step [56/1079], Loss: 0.0359\n",
      "Epoch [3/10], Step [57/1079], Loss: 0.0220\n",
      "Epoch [3/10], Step [58/1079], Loss: 0.0314\n",
      "Epoch [3/10], Step [59/1079], Loss: 0.0059\n",
      "Epoch [3/10], Step [60/1079], Loss: 0.0356\n",
      "Epoch [3/10], Step [61/1079], Loss: 0.0850\n",
      "Epoch [3/10], Step [62/1079], Loss: 0.0194\n",
      "Epoch [3/10], Step [63/1079], Loss: 0.0608\n",
      "Epoch [3/10], Step [64/1079], Loss: 0.1228\n",
      "Epoch [3/10], Step [65/1079], Loss: 0.0120\n",
      "Epoch [3/10], Step [66/1079], Loss: 0.0097\n",
      "Epoch [3/10], Step [67/1079], Loss: 0.0280\n",
      "Epoch [3/10], Step [68/1079], Loss: 0.0231\n",
      "Epoch [3/10], Step [69/1079], Loss: 0.0105\n",
      "Epoch [3/10], Step [70/1079], Loss: 0.0388\n",
      "Epoch [3/10], Step [71/1079], Loss: 0.0620\n",
      "Epoch [3/10], Step [72/1079], Loss: 0.0339\n",
      "Epoch [3/10], Step [73/1079], Loss: 0.0083\n",
      "Epoch [3/10], Step [74/1079], Loss: 0.0415\n",
      "Epoch [3/10], Step [75/1079], Loss: 0.0518\n",
      "Epoch [3/10], Step [76/1079], Loss: 0.0235\n",
      "Epoch [3/10], Step [77/1079], Loss: 0.0165\n",
      "Epoch [3/10], Step [78/1079], Loss: 0.0290\n",
      "Epoch [3/10], Step [79/1079], Loss: 0.0206\n",
      "Epoch [3/10], Step [80/1079], Loss: 0.0430\n",
      "Epoch [3/10], Step [81/1079], Loss: 0.0249\n",
      "Epoch [3/10], Step [82/1079], Loss: 0.0149\n",
      "Epoch [3/10], Step [83/1079], Loss: 0.0303\n",
      "Epoch [3/10], Step [84/1079], Loss: 0.0358\n",
      "Epoch [3/10], Step [85/1079], Loss: 0.0247\n",
      "Epoch [3/10], Step [86/1079], Loss: 0.0154\n",
      "Epoch [3/10], Step [87/1079], Loss: 0.0108\n",
      "Epoch [3/10], Step [88/1079], Loss: 0.0018\n",
      "Epoch [3/10], Step [89/1079], Loss: 0.0276\n",
      "Epoch [3/10], Step [90/1079], Loss: 0.1239\n",
      "Epoch [3/10], Step [91/1079], Loss: 0.0859\n",
      "Epoch [3/10], Step [92/1079], Loss: 0.0021\n",
      "Epoch [3/10], Step [93/1079], Loss: 0.0773\n",
      "Epoch [3/10], Step [94/1079], Loss: 0.0220\n",
      "Epoch [3/10], Step [95/1079], Loss: 0.0613\n",
      "Epoch [3/10], Step [96/1079], Loss: 0.0703\n",
      "Epoch [3/10], Step [97/1079], Loss: 0.0399\n",
      "Epoch [3/10], Step [98/1079], Loss: 0.0081\n",
      "Epoch [3/10], Step [99/1079], Loss: 0.0165\n",
      "Epoch [3/10], Step [100/1079], Loss: 0.0059\n",
      "Epoch [3/10], Step [101/1079], Loss: 0.0638\n",
      "Epoch [3/10], Step [102/1079], Loss: 0.1795\n",
      "Epoch [3/10], Step [103/1079], Loss: 0.0230\n",
      "Epoch [3/10], Step [104/1079], Loss: 0.0192\n",
      "Epoch [3/10], Step [105/1079], Loss: 0.0090\n",
      "Epoch [3/10], Step [106/1079], Loss: 0.0422\n",
      "Epoch [3/10], Step [107/1079], Loss: 0.0223\n",
      "Epoch [3/10], Step [108/1079], Loss: 0.0077\n",
      "Epoch [3/10], Step [109/1079], Loss: 0.1180\n",
      "Epoch [3/10], Step [110/1079], Loss: 0.0053\n",
      "Epoch [3/10], Step [111/1079], Loss: 0.0054\n",
      "Epoch [3/10], Step [112/1079], Loss: 0.1604\n",
      "Epoch [3/10], Step [113/1079], Loss: 0.0247\n",
      "Epoch [3/10], Step [114/1079], Loss: 0.0770\n",
      "Epoch [3/10], Step [115/1079], Loss: 0.0582\n",
      "Epoch [3/10], Step [116/1079], Loss: 0.0186\n",
      "Epoch [3/10], Step [117/1079], Loss: 0.0032\n",
      "Epoch [3/10], Step [118/1079], Loss: 0.0083\n",
      "Epoch [3/10], Step [119/1079], Loss: 0.0193\n",
      "Epoch [3/10], Step [120/1079], Loss: 0.0058\n",
      "Epoch [3/10], Step [121/1079], Loss: 0.0648\n",
      "Epoch [3/10], Step [122/1079], Loss: 0.0072\n",
      "Epoch [3/10], Step [123/1079], Loss: 0.0223\n",
      "Epoch [3/10], Step [124/1079], Loss: 0.0251\n",
      "Epoch [3/10], Step [125/1079], Loss: 0.0095\n",
      "Epoch [3/10], Step [126/1079], Loss: 0.0034\n",
      "Epoch [3/10], Step [127/1079], Loss: 0.0283\n",
      "Epoch [3/10], Step [128/1079], Loss: 0.0036\n",
      "Epoch [3/10], Step [129/1079], Loss: 0.0094\n",
      "Epoch [3/10], Step [130/1079], Loss: 0.0134\n",
      "Epoch [3/10], Step [131/1079], Loss: 0.0131\n",
      "Epoch [3/10], Step [132/1079], Loss: 0.0110\n",
      "Epoch [3/10], Step [133/1079], Loss: 0.0245\n",
      "Epoch [3/10], Step [134/1079], Loss: 0.0064\n",
      "Epoch [3/10], Step [135/1079], Loss: 0.0009\n",
      "Epoch [3/10], Step [136/1079], Loss: 0.1385\n",
      "Epoch [3/10], Step [137/1079], Loss: 0.0174\n",
      "Epoch [3/10], Step [138/1079], Loss: 0.0008\n",
      "Epoch [3/10], Step [139/1079], Loss: 0.1830\n",
      "Epoch [3/10], Step [140/1079], Loss: 0.0306\n",
      "Epoch [3/10], Step [141/1079], Loss: 0.0093\n",
      "Epoch [3/10], Step [142/1079], Loss: 0.0140\n",
      "Epoch [3/10], Step [143/1079], Loss: 0.0169\n",
      "Epoch [3/10], Step [144/1079], Loss: 0.0895\n",
      "Epoch [3/10], Step [145/1079], Loss: 0.0895\n",
      "Epoch [3/10], Step [146/1079], Loss: 0.0147\n",
      "Epoch [3/10], Step [147/1079], Loss: 0.0014\n",
      "Epoch [3/10], Step [148/1079], Loss: 0.0127\n",
      "Epoch [3/10], Step [149/1079], Loss: 0.0314\n",
      "Epoch [3/10], Step [150/1079], Loss: 0.0129\n",
      "Epoch [3/10], Step [151/1079], Loss: 0.0017\n",
      "Epoch [3/10], Step [152/1079], Loss: 0.0582\n",
      "Epoch [3/10], Step [153/1079], Loss: 0.0033\n",
      "Epoch [3/10], Step [154/1079], Loss: 0.0096\n",
      "Epoch [3/10], Step [155/1079], Loss: 0.1041\n",
      "Epoch [3/10], Step [156/1079], Loss: 0.0111\n",
      "Epoch [3/10], Step [157/1079], Loss: 0.0132\n",
      "Epoch [3/10], Step [158/1079], Loss: 0.0147\n",
      "Epoch [3/10], Step [159/1079], Loss: 0.0704\n",
      "Epoch [3/10], Step [160/1079], Loss: 0.0595\n",
      "Epoch [3/10], Step [161/1079], Loss: 0.0717\n",
      "Epoch [3/10], Step [162/1079], Loss: 0.0503\n",
      "Epoch [3/10], Step [163/1079], Loss: 0.0239\n",
      "Epoch [3/10], Step [164/1079], Loss: 0.0091\n",
      "Epoch [3/10], Step [165/1079], Loss: 0.0426\n",
      "Epoch [3/10], Step [166/1079], Loss: 0.0589\n",
      "Epoch [3/10], Step [167/1079], Loss: 0.0079\n",
      "Epoch [3/10], Step [168/1079], Loss: 0.0794\n",
      "Epoch [3/10], Step [169/1079], Loss: 0.0124\n",
      "Epoch [3/10], Step [170/1079], Loss: 0.0603\n",
      "Epoch [3/10], Step [171/1079], Loss: 0.1489\n",
      "Epoch [3/10], Step [172/1079], Loss: 0.0277\n",
      "Epoch [3/10], Step [173/1079], Loss: 0.0127\n",
      "Epoch [3/10], Step [174/1079], Loss: 0.0965\n",
      "Epoch [3/10], Step [175/1079], Loss: 0.0139\n",
      "Epoch [3/10], Step [176/1079], Loss: 0.0017\n",
      "Epoch [3/10], Step [177/1079], Loss: 0.0282\n",
      "Epoch [3/10], Step [178/1079], Loss: 0.0792\n",
      "Epoch [3/10], Step [179/1079], Loss: 0.0735\n",
      "Epoch [3/10], Step [180/1079], Loss: 0.0076\n",
      "Epoch [3/10], Step [181/1079], Loss: 0.0160\n",
      "Epoch [3/10], Step [182/1079], Loss: 0.0299\n",
      "Epoch [3/10], Step [183/1079], Loss: 0.0045\n",
      "Epoch [3/10], Step [184/1079], Loss: 0.0066\n",
      "Epoch [3/10], Step [185/1079], Loss: 0.1249\n",
      "Epoch [3/10], Step [186/1079], Loss: 0.0610\n",
      "Epoch [3/10], Step [187/1079], Loss: 0.0059\n",
      "Epoch [3/10], Step [188/1079], Loss: 0.0043\n",
      "Epoch [3/10], Step [189/1079], Loss: 0.0420\n",
      "Epoch [3/10], Step [190/1079], Loss: 0.0048\n",
      "Epoch [3/10], Step [191/1079], Loss: 0.0885\n",
      "Epoch [3/10], Step [192/1079], Loss: 0.0314\n",
      "Epoch [3/10], Step [193/1079], Loss: 0.0247\n",
      "Epoch [3/10], Step [194/1079], Loss: 0.0247\n",
      "Epoch [3/10], Step [195/1079], Loss: 0.0097\n",
      "Epoch [3/10], Step [196/1079], Loss: 0.0133\n",
      "Epoch [3/10], Step [197/1079], Loss: 0.0201\n",
      "Epoch [3/10], Step [198/1079], Loss: 0.0128\n",
      "Epoch [3/10], Step [199/1079], Loss: 0.0074\n",
      "Epoch [3/10], Step [200/1079], Loss: 0.0072\n",
      "Epoch [3/10], Step [201/1079], Loss: 0.0427\n",
      "Epoch [3/10], Step [202/1079], Loss: 0.0198\n",
      "Epoch [3/10], Step [203/1079], Loss: 0.0133\n",
      "Epoch [3/10], Step [204/1079], Loss: 0.0455\n",
      "Epoch [3/10], Step [205/1079], Loss: 0.0664\n",
      "Epoch [3/10], Step [206/1079], Loss: 0.0067\n",
      "Epoch [3/10], Step [207/1079], Loss: 0.0096\n",
      "Epoch [3/10], Step [208/1079], Loss: 0.0263\n",
      "Epoch [3/10], Step [209/1079], Loss: 0.0050\n",
      "Epoch [3/10], Step [210/1079], Loss: 0.0302\n",
      "Epoch [3/10], Step [211/1079], Loss: 0.0276\n",
      "Epoch [3/10], Step [212/1079], Loss: 0.0113\n",
      "Epoch [3/10], Step [213/1079], Loss: 0.0361\n",
      "Epoch [3/10], Step [214/1079], Loss: 0.0271\n",
      "Epoch [3/10], Step [215/1079], Loss: 0.0371\n",
      "Epoch [3/10], Step [216/1079], Loss: 0.0127\n",
      "Epoch [3/10], Step [217/1079], Loss: 0.0022\n",
      "Epoch [3/10], Step [218/1079], Loss: 0.0110\n",
      "Epoch [3/10], Step [219/1079], Loss: 0.0303\n",
      "Epoch [3/10], Step [220/1079], Loss: 0.0500\n",
      "Epoch [3/10], Step [221/1079], Loss: 0.0712\n",
      "Epoch [3/10], Step [222/1079], Loss: 0.0063\n",
      "Epoch [3/10], Step [223/1079], Loss: 0.0513\n",
      "Epoch [3/10], Step [224/1079], Loss: 0.0950\n",
      "Epoch [3/10], Step [225/1079], Loss: 0.0684\n",
      "Epoch [3/10], Step [226/1079], Loss: 0.0106\n",
      "Epoch [3/10], Step [227/1079], Loss: 0.0237\n",
      "Epoch [3/10], Step [228/1079], Loss: 0.0213\n",
      "Epoch [3/10], Step [229/1079], Loss: 0.0407\n",
      "Epoch [3/10], Step [230/1079], Loss: 0.0090\n",
      "Epoch [3/10], Step [231/1079], Loss: 0.0750\n",
      "Epoch [3/10], Step [232/1079], Loss: 0.0096\n",
      "Epoch [3/10], Step [233/1079], Loss: 0.0171\n",
      "Epoch [3/10], Step [234/1079], Loss: 0.0218\n",
      "Epoch [3/10], Step [235/1079], Loss: 0.0139\n",
      "Epoch [3/10], Step [236/1079], Loss: 0.0086\n",
      "Epoch [3/10], Step [237/1079], Loss: 0.0038\n",
      "Epoch [3/10], Step [238/1079], Loss: 0.0393\n",
      "Epoch [3/10], Step [239/1079], Loss: 0.0152\n",
      "Epoch [3/10], Step [240/1079], Loss: 0.0054\n",
      "Epoch [3/10], Step [241/1079], Loss: 0.0087\n",
      "Epoch [3/10], Step [242/1079], Loss: 0.0311\n",
      "Epoch [3/10], Step [243/1079], Loss: 0.0013\n",
      "Epoch [3/10], Step [244/1079], Loss: 0.0025\n",
      "Epoch [3/10], Step [245/1079], Loss: 0.0143\n",
      "Epoch [3/10], Step [246/1079], Loss: 0.0558\n",
      "Epoch [3/10], Step [247/1079], Loss: 0.0797\n",
      "Epoch [3/10], Step [248/1079], Loss: 0.0620\n",
      "Epoch [3/10], Step [249/1079], Loss: 0.0031\n",
      "Epoch [3/10], Step [250/1079], Loss: 0.0968\n",
      "Epoch [3/10], Step [251/1079], Loss: 0.1070\n",
      "Epoch [3/10], Step [252/1079], Loss: 0.1012\n",
      "Epoch [3/10], Step [253/1079], Loss: 0.0764\n",
      "Epoch [3/10], Step [254/1079], Loss: 0.0302\n",
      "Epoch [3/10], Step [255/1079], Loss: 0.1190\n",
      "Epoch [3/10], Step [256/1079], Loss: 0.0096\n",
      "Epoch [3/10], Step [257/1079], Loss: 0.0093\n",
      "Epoch [3/10], Step [258/1079], Loss: 0.0225\n",
      "Epoch [3/10], Step [259/1079], Loss: 0.0023\n",
      "Epoch [3/10], Step [260/1079], Loss: 0.0103\n",
      "Epoch [3/10], Step [261/1079], Loss: 0.0205\n",
      "Epoch [3/10], Step [262/1079], Loss: 0.0193\n",
      "Epoch [3/10], Step [263/1079], Loss: 0.0104\n",
      "Epoch [3/10], Step [264/1079], Loss: 0.0385\n",
      "Epoch [3/10], Step [265/1079], Loss: 0.0096\n",
      "Epoch [3/10], Step [266/1079], Loss: 0.0309\n",
      "Epoch [3/10], Step [267/1079], Loss: 0.0719\n",
      "Epoch [3/10], Step [268/1079], Loss: 0.0110\n",
      "Epoch [3/10], Step [269/1079], Loss: 0.0037\n",
      "Epoch [3/10], Step [270/1079], Loss: 0.0067\n",
      "Epoch [3/10], Step [271/1079], Loss: 0.0121\n",
      "Epoch [3/10], Step [272/1079], Loss: 0.0060\n",
      "Epoch [3/10], Step [273/1079], Loss: 0.0083\n",
      "Epoch [3/10], Step [274/1079], Loss: 0.0166\n",
      "Epoch [3/10], Step [275/1079], Loss: 0.0028\n",
      "Epoch [3/10], Step [276/1079], Loss: 0.0466\n",
      "Epoch [3/10], Step [277/1079], Loss: 0.0678\n",
      "Epoch [3/10], Step [278/1079], Loss: 0.0580\n",
      "Epoch [3/10], Step [279/1079], Loss: 0.0086\n",
      "Epoch [3/10], Step [280/1079], Loss: 0.0052\n",
      "Epoch [3/10], Step [281/1079], Loss: 0.0433\n",
      "Epoch [3/10], Step [282/1079], Loss: 0.0237\n",
      "Epoch [3/10], Step [283/1079], Loss: 0.0105\n",
      "Epoch [3/10], Step [284/1079], Loss: 0.0102\n",
      "Epoch [3/10], Step [285/1079], Loss: 0.0456\n",
      "Epoch [3/10], Step [286/1079], Loss: 0.0105\n",
      "Epoch [3/10], Step [287/1079], Loss: 0.0097\n",
      "Epoch [3/10], Step [288/1079], Loss: 0.0146\n",
      "Epoch [3/10], Step [289/1079], Loss: 0.0667\n",
      "Epoch [3/10], Step [290/1079], Loss: 0.0321\n",
      "Epoch [3/10], Step [291/1079], Loss: 0.0099\n",
      "Epoch [3/10], Step [292/1079], Loss: 0.0521\n",
      "Epoch [3/10], Step [293/1079], Loss: 0.0295\n",
      "Epoch [3/10], Step [294/1079], Loss: 0.0035\n",
      "Epoch [3/10], Step [295/1079], Loss: 0.0033\n",
      "Epoch [3/10], Step [296/1079], Loss: 0.0142\n",
      "Epoch [3/10], Step [297/1079], Loss: 0.0154\n",
      "Epoch [3/10], Step [298/1079], Loss: 0.0036\n",
      "Epoch [3/10], Step [299/1079], Loss: 0.0158\n",
      "Epoch [3/10], Step [300/1079], Loss: 0.0116\n",
      "Epoch [3/10], Step [301/1079], Loss: 0.0048\n",
      "Epoch [3/10], Step [302/1079], Loss: 0.0052\n",
      "Epoch [3/10], Step [303/1079], Loss: 0.0139\n",
      "Epoch [3/10], Step [304/1079], Loss: 0.0720\n",
      "Epoch [3/10], Step [305/1079], Loss: 0.0250\n",
      "Epoch [3/10], Step [306/1079], Loss: 0.0782\n",
      "Epoch [3/10], Step [307/1079], Loss: 0.0230\n",
      "Epoch [3/10], Step [308/1079], Loss: 0.0540\n",
      "Epoch [3/10], Step [309/1079], Loss: 0.0062\n",
      "Epoch [3/10], Step [310/1079], Loss: 0.0055\n",
      "Epoch [3/10], Step [311/1079], Loss: 0.0031\n",
      "Epoch [3/10], Step [312/1079], Loss: 0.0063\n",
      "Epoch [3/10], Step [313/1079], Loss: 0.0208\n",
      "Epoch [3/10], Step [314/1079], Loss: 0.0123\n",
      "Epoch [3/10], Step [315/1079], Loss: 0.0522\n",
      "Epoch [3/10], Step [316/1079], Loss: 0.0448\n",
      "Epoch [3/10], Step [317/1079], Loss: 0.0338\n",
      "Epoch [3/10], Step [318/1079], Loss: 0.0019\n",
      "Epoch [3/10], Step [319/1079], Loss: 0.0869\n",
      "Epoch [3/10], Step [320/1079], Loss: 0.0079\n",
      "Epoch [3/10], Step [321/1079], Loss: 0.0074\n",
      "Epoch [3/10], Step [322/1079], Loss: 0.0024\n",
      "Epoch [3/10], Step [323/1079], Loss: 0.1135\n",
      "Epoch [3/10], Step [324/1079], Loss: 0.0630\n",
      "Epoch [3/10], Step [325/1079], Loss: 0.0094\n",
      "Epoch [3/10], Step [326/1079], Loss: 0.0025\n",
      "Epoch [3/10], Step [327/1079], Loss: 0.0120\n",
      "Epoch [3/10], Step [328/1079], Loss: 0.0946\n",
      "Epoch [3/10], Step [329/1079], Loss: 0.0223\n",
      "Epoch [3/10], Step [330/1079], Loss: 0.0136\n",
      "Epoch [3/10], Step [331/1079], Loss: 0.0615\n",
      "Epoch [3/10], Step [332/1079], Loss: 0.0095\n",
      "Epoch [3/10], Step [333/1079], Loss: 0.0282\n",
      "Epoch [3/10], Step [334/1079], Loss: 0.0049\n",
      "Epoch [3/10], Step [335/1079], Loss: 0.0170\n",
      "Epoch [3/10], Step [336/1079], Loss: 0.0145\n",
      "Epoch [3/10], Step [337/1079], Loss: 0.0016\n",
      "Epoch [3/10], Step [338/1079], Loss: 0.0114\n",
      "Epoch [3/10], Step [339/1079], Loss: 0.0320\n",
      "Epoch [3/10], Step [340/1079], Loss: 0.0164\n",
      "Epoch [3/10], Step [341/1079], Loss: 0.0156\n",
      "Epoch [3/10], Step [342/1079], Loss: 0.0045\n",
      "Epoch [3/10], Step [343/1079], Loss: 0.0158\n",
      "Epoch [3/10], Step [344/1079], Loss: 0.1239\n",
      "Epoch [3/10], Step [345/1079], Loss: 0.0048\n",
      "Epoch [3/10], Step [346/1079], Loss: 0.0331\n",
      "Epoch [3/10], Step [347/1079], Loss: 0.0207\n",
      "Epoch [3/10], Step [348/1079], Loss: 0.0005\n",
      "Epoch [3/10], Step [349/1079], Loss: 0.0051\n",
      "Epoch [3/10], Step [350/1079], Loss: 0.0088\n",
      "Epoch [3/10], Step [351/1079], Loss: 0.0284\n",
      "Epoch [3/10], Step [352/1079], Loss: 0.0011\n",
      "Epoch [3/10], Step [353/1079], Loss: 0.0072\n",
      "Epoch [3/10], Step [354/1079], Loss: 0.0067\n",
      "Epoch [3/10], Step [355/1079], Loss: 0.0103\n",
      "Epoch [3/10], Step [356/1079], Loss: 0.0246\n",
      "Epoch [3/10], Step [357/1079], Loss: 0.0311\n",
      "Epoch [3/10], Step [358/1079], Loss: 0.0049\n",
      "Epoch [3/10], Step [359/1079], Loss: 0.0048\n",
      "Epoch [3/10], Step [360/1079], Loss: 0.0418\n",
      "Epoch [3/10], Step [361/1079], Loss: 0.0349\n",
      "Epoch [3/10], Step [362/1079], Loss: 0.0346\n",
      "Epoch [3/10], Step [363/1079], Loss: 0.0036\n",
      "Epoch [3/10], Step [364/1079], Loss: 0.1300\n",
      "Epoch [3/10], Step [365/1079], Loss: 0.0112\n",
      "Epoch [3/10], Step [366/1079], Loss: 0.1341\n",
      "Epoch [3/10], Step [367/1079], Loss: 0.0173\n",
      "Epoch [3/10], Step [368/1079], Loss: 0.0061\n",
      "Epoch [3/10], Step [369/1079], Loss: 0.1315\n",
      "Epoch [3/10], Step [370/1079], Loss: 0.0575\n",
      "Epoch [3/10], Step [371/1079], Loss: 0.0308\n",
      "Epoch [3/10], Step [372/1079], Loss: 0.0336\n",
      "Epoch [3/10], Step [373/1079], Loss: 0.0578\n",
      "Epoch [3/10], Step [374/1079], Loss: 0.0101\n",
      "Epoch [3/10], Step [375/1079], Loss: 0.0054\n",
      "Epoch [3/10], Step [376/1079], Loss: 0.0060\n",
      "Epoch [3/10], Step [377/1079], Loss: 0.0617\n",
      "Epoch [3/10], Step [378/1079], Loss: 0.0365\n",
      "Epoch [3/10], Step [379/1079], Loss: 0.0336\n",
      "Epoch [3/10], Step [380/1079], Loss: 0.0020\n",
      "Epoch [3/10], Step [381/1079], Loss: 0.0043\n",
      "Epoch [3/10], Step [382/1079], Loss: 0.0271\n",
      "Epoch [3/10], Step [383/1079], Loss: 0.0044\n",
      "Epoch [3/10], Step [384/1079], Loss: 0.0114\n",
      "Epoch [3/10], Step [385/1079], Loss: 0.0348\n",
      "Epoch [3/10], Step [386/1079], Loss: 0.0004\n",
      "Epoch [3/10], Step [387/1079], Loss: 0.2029\n",
      "Epoch [3/10], Step [388/1079], Loss: 0.0112\n",
      "Epoch [3/10], Step [389/1079], Loss: 0.0190\n",
      "Epoch [3/10], Step [390/1079], Loss: 0.0865\n",
      "Epoch [3/10], Step [391/1079], Loss: 0.0184\n",
      "Epoch [3/10], Step [392/1079], Loss: 0.0136\n",
      "Epoch [3/10], Step [393/1079], Loss: 0.0147\n",
      "Epoch [3/10], Step [394/1079], Loss: 0.0142\n",
      "Epoch [3/10], Step [395/1079], Loss: 0.0447\n",
      "Epoch [3/10], Step [396/1079], Loss: 0.0058\n",
      "Epoch [3/10], Step [397/1079], Loss: 0.0591\n",
      "Epoch [3/10], Step [398/1079], Loss: 0.0339\n",
      "Epoch [3/10], Step [399/1079], Loss: 0.0028\n",
      "Epoch [3/10], Step [400/1079], Loss: 0.0292\n",
      "Epoch [3/10], Step [401/1079], Loss: 0.0340\n",
      "Epoch [3/10], Step [402/1079], Loss: 0.0214\n",
      "Epoch [3/10], Step [403/1079], Loss: 0.0301\n",
      "Epoch [3/10], Step [404/1079], Loss: 0.0053\n",
      "Epoch [3/10], Step [405/1079], Loss: 0.0147\n",
      "Epoch [3/10], Step [406/1079], Loss: 0.0144\n",
      "Epoch [3/10], Step [407/1079], Loss: 0.0162\n",
      "Epoch [3/10], Step [408/1079], Loss: 0.0037\n",
      "Epoch [3/10], Step [409/1079], Loss: 0.0008\n",
      "Epoch [3/10], Step [410/1079], Loss: 0.0444\n",
      "Epoch [3/10], Step [411/1079], Loss: 0.0741\n",
      "Epoch [3/10], Step [412/1079], Loss: 0.0364\n",
      "Epoch [3/10], Step [413/1079], Loss: 0.0240\n",
      "Epoch [3/10], Step [414/1079], Loss: 0.0380\n",
      "Epoch [3/10], Step [415/1079], Loss: 0.0020\n",
      "Epoch [3/10], Step [416/1079], Loss: 0.0026\n",
      "Epoch [3/10], Step [417/1079], Loss: 0.0675\n",
      "Epoch [3/10], Step [418/1079], Loss: 0.0028\n",
      "Epoch [3/10], Step [419/1079], Loss: 0.1041\n",
      "Epoch [3/10], Step [420/1079], Loss: 0.0019\n",
      "Epoch [3/10], Step [421/1079], Loss: 0.0178\n",
      "Epoch [3/10], Step [422/1079], Loss: 0.0170\n",
      "Epoch [3/10], Step [423/1079], Loss: 0.0012\n",
      "Epoch [3/10], Step [424/1079], Loss: 0.0017\n",
      "Epoch [3/10], Step [425/1079], Loss: 0.0941\n",
      "Epoch [3/10], Step [426/1079], Loss: 0.0166\n",
      "Epoch [3/10], Step [427/1079], Loss: 0.0219\n",
      "Epoch [3/10], Step [428/1079], Loss: 0.0042\n",
      "Epoch [3/10], Step [429/1079], Loss: 0.0058\n",
      "Epoch [3/10], Step [430/1079], Loss: 0.0013\n",
      "Epoch [3/10], Step [431/1079], Loss: 0.0038\n",
      "Epoch [3/10], Step [432/1079], Loss: 0.0048\n",
      "Epoch [3/10], Step [433/1079], Loss: 0.0006\n",
      "Epoch [3/10], Step [434/1079], Loss: 0.0114\n",
      "Epoch [3/10], Step [435/1079], Loss: 0.0032\n",
      "Epoch [3/10], Step [436/1079], Loss: 0.0418\n",
      "Epoch [3/10], Step [437/1079], Loss: 0.0067\n",
      "Epoch [3/10], Step [438/1079], Loss: 0.0184\n",
      "Epoch [3/10], Step [439/1079], Loss: 0.0842\n",
      "Epoch [3/10], Step [440/1079], Loss: 0.0404\n",
      "Epoch [3/10], Step [441/1079], Loss: 0.0072\n",
      "Epoch [3/10], Step [442/1079], Loss: 0.0233\n",
      "Epoch [3/10], Step [443/1079], Loss: 0.0059\n",
      "Epoch [3/10], Step [444/1079], Loss: 0.0352\n",
      "Epoch [3/10], Step [445/1079], Loss: 0.0043\n",
      "Epoch [3/10], Step [446/1079], Loss: 0.0027\n",
      "Epoch [3/10], Step [447/1079], Loss: 0.0411\n",
      "Epoch [3/10], Step [448/1079], Loss: 0.0291\n",
      "Epoch [3/10], Step [449/1079], Loss: 0.0142\n",
      "Epoch [3/10], Step [450/1079], Loss: 0.0733\n",
      "Epoch [3/10], Step [451/1079], Loss: 0.0898\n",
      "Epoch [3/10], Step [452/1079], Loss: 0.0239\n",
      "Epoch [3/10], Step [453/1079], Loss: 0.0534\n",
      "Epoch [3/10], Step [454/1079], Loss: 0.1151\n",
      "Epoch [3/10], Step [455/1079], Loss: 0.0047\n",
      "Epoch [3/10], Step [456/1079], Loss: 0.0037\n",
      "Epoch [3/10], Step [457/1079], Loss: 0.0252\n",
      "Epoch [3/10], Step [458/1079], Loss: 0.0216\n",
      "Epoch [3/10], Step [459/1079], Loss: 0.0047\n",
      "Epoch [3/10], Step [460/1079], Loss: 0.0143\n",
      "Epoch [3/10], Step [461/1079], Loss: 0.0976\n",
      "Epoch [3/10], Step [462/1079], Loss: 0.0207\n",
      "Epoch [3/10], Step [463/1079], Loss: 0.0040\n",
      "Epoch [3/10], Step [464/1079], Loss: 0.1071\n",
      "Epoch [3/10], Step [465/1079], Loss: 0.1724\n",
      "Epoch [3/10], Step [466/1079], Loss: 0.0633\n",
      "Epoch [3/10], Step [467/1079], Loss: 0.1128\n",
      "Epoch [3/10], Step [468/1079], Loss: 0.0031\n",
      "Epoch [3/10], Step [469/1079], Loss: 0.0203\n",
      "Epoch [3/10], Step [470/1079], Loss: 0.0018\n",
      "Epoch [3/10], Step [471/1079], Loss: 0.0345\n",
      "Epoch [3/10], Step [472/1079], Loss: 0.0139\n",
      "Epoch [3/10], Step [473/1079], Loss: 0.0029\n",
      "Epoch [3/10], Step [474/1079], Loss: 0.0111\n",
      "Epoch [3/10], Step [475/1079], Loss: 0.1797\n",
      "Epoch [3/10], Step [476/1079], Loss: 0.0078\n",
      "Epoch [3/10], Step [477/1079], Loss: 0.0081\n",
      "Epoch [3/10], Step [478/1079], Loss: 0.0080\n",
      "Epoch [3/10], Step [479/1079], Loss: 0.0049\n",
      "Epoch [3/10], Step [480/1079], Loss: 0.0721\n",
      "Epoch [3/10], Step [481/1079], Loss: 0.0127\n",
      "Epoch [3/10], Step [482/1079], Loss: 0.0681\n",
      "Epoch [3/10], Step [483/1079], Loss: 0.0058\n",
      "Epoch [3/10], Step [484/1079], Loss: 0.0083\n",
      "Epoch [3/10], Step [485/1079], Loss: 0.1304\n",
      "Epoch [3/10], Step [486/1079], Loss: 0.1022\n",
      "Epoch [3/10], Step [487/1079], Loss: 0.1407\n",
      "Epoch [3/10], Step [488/1079], Loss: 0.0109\n",
      "Epoch [3/10], Step [489/1079], Loss: 0.0278\n",
      "Epoch [3/10], Step [490/1079], Loss: 0.0534\n",
      "Epoch [3/10], Step [491/1079], Loss: 0.0622\n",
      "Epoch [3/10], Step [492/1079], Loss: 0.0032\n",
      "Epoch [3/10], Step [493/1079], Loss: 0.0514\n",
      "Epoch [3/10], Step [494/1079], Loss: 0.0047\n",
      "Epoch [3/10], Step [495/1079], Loss: 0.0273\n",
      "Epoch [3/10], Step [496/1079], Loss: 0.0293\n",
      "Epoch [3/10], Step [497/1079], Loss: 0.0843\n",
      "Epoch [3/10], Step [498/1079], Loss: 0.0129\n",
      "Epoch [3/10], Step [499/1079], Loss: 0.0691\n",
      "Epoch [3/10], Step [500/1079], Loss: 0.0216\n",
      "Epoch [3/10], Step [501/1079], Loss: 0.0289\n",
      "Epoch [3/10], Step [502/1079], Loss: 0.0559\n",
      "Epoch [3/10], Step [503/1079], Loss: 0.0075\n",
      "Epoch [3/10], Step [504/1079], Loss: 0.0788\n",
      "Epoch [3/10], Step [505/1079], Loss: 0.0052\n",
      "Epoch [3/10], Step [506/1079], Loss: 0.0137\n",
      "Epoch [3/10], Step [507/1079], Loss: 0.0743\n",
      "Epoch [3/10], Step [508/1079], Loss: 0.0017\n",
      "Epoch [3/10], Step [509/1079], Loss: 0.0051\n",
      "Epoch [3/10], Step [510/1079], Loss: 0.0591\n",
      "Epoch [3/10], Step [511/1079], Loss: 0.0103\n",
      "Epoch [3/10], Step [512/1079], Loss: 0.0070\n",
      "Epoch [3/10], Step [513/1079], Loss: 0.0129\n",
      "Epoch [3/10], Step [514/1079], Loss: 0.0059\n",
      "Epoch [3/10], Step [515/1079], Loss: 0.0306\n",
      "Epoch [3/10], Step [516/1079], Loss: 0.0415\n",
      "Epoch [3/10], Step [517/1079], Loss: 0.0032\n",
      "Epoch [3/10], Step [518/1079], Loss: 0.0044\n",
      "Epoch [3/10], Step [519/1079], Loss: 0.0069\n",
      "Epoch [3/10], Step [520/1079], Loss: 0.0073\n",
      "Epoch [3/10], Step [521/1079], Loss: 0.0257\n",
      "Epoch [3/10], Step [522/1079], Loss: 0.0305\n",
      "Epoch [3/10], Step [523/1079], Loss: 0.0907\n",
      "Epoch [3/10], Step [524/1079], Loss: 0.0122\n",
      "Epoch [3/10], Step [525/1079], Loss: 0.0285\n",
      "Epoch [3/10], Step [526/1079], Loss: 0.0008\n",
      "Epoch [3/10], Step [527/1079], Loss: 0.0028\n",
      "Epoch [3/10], Step [528/1079], Loss: 0.0216\n",
      "Epoch [3/10], Step [529/1079], Loss: 0.0034\n",
      "Epoch [3/10], Step [530/1079], Loss: 0.0037\n",
      "Epoch [3/10], Step [531/1079], Loss: 0.1029\n",
      "Epoch [3/10], Step [532/1079], Loss: 0.0409\n",
      "Epoch [3/10], Step [533/1079], Loss: 0.1434\n",
      "Epoch [3/10], Step [534/1079], Loss: 0.0334\n",
      "Epoch [3/10], Step [535/1079], Loss: 0.0601\n",
      "Epoch [3/10], Step [536/1079], Loss: 0.0381\n",
      "Epoch [3/10], Step [537/1079], Loss: 0.0007\n",
      "Epoch [3/10], Step [538/1079], Loss: 0.0124\n",
      "Epoch [3/10], Step [539/1079], Loss: 0.0959\n",
      "Epoch [3/10], Step [540/1079], Loss: 0.0356\n",
      "Epoch [3/10], Step [541/1079], Loss: 0.1363\n",
      "Epoch [3/10], Step [542/1079], Loss: 0.0264\n",
      "Epoch [3/10], Step [543/1079], Loss: 0.0056\n",
      "Epoch [3/10], Step [544/1079], Loss: 0.0048\n",
      "Epoch [3/10], Step [545/1079], Loss: 0.0503\n",
      "Epoch [3/10], Step [546/1079], Loss: 0.0150\n",
      "Epoch [3/10], Step [547/1079], Loss: 0.1485\n",
      "Epoch [3/10], Step [548/1079], Loss: 0.0027\n",
      "Epoch [3/10], Step [549/1079], Loss: 0.0651\n",
      "Epoch [3/10], Step [550/1079], Loss: 0.0301\n",
      "Epoch [3/10], Step [551/1079], Loss: 0.1167\n",
      "Epoch [3/10], Step [552/1079], Loss: 0.0131\n",
      "Epoch [3/10], Step [553/1079], Loss: 0.0265\n",
      "Epoch [3/10], Step [554/1079], Loss: 0.0261\n",
      "Epoch [3/10], Step [555/1079], Loss: 0.0258\n",
      "Epoch [3/10], Step [556/1079], Loss: 0.0331\n",
      "Epoch [3/10], Step [557/1079], Loss: 0.0087\n",
      "Epoch [3/10], Step [558/1079], Loss: 0.0562\n",
      "Epoch [3/10], Step [559/1079], Loss: 0.0670\n",
      "Epoch [3/10], Step [560/1079], Loss: 0.0429\n",
      "Epoch [3/10], Step [561/1079], Loss: 0.0121\n",
      "Epoch [3/10], Step [562/1079], Loss: 0.0232\n",
      "Epoch [3/10], Step [563/1079], Loss: 0.0793\n",
      "Epoch [3/10], Step [564/1079], Loss: 0.0947\n",
      "Epoch [3/10], Step [565/1079], Loss: 0.0248\n",
      "Epoch [3/10], Step [566/1079], Loss: 0.0871\n",
      "Epoch [3/10], Step [567/1079], Loss: 0.0042\n",
      "Epoch [3/10], Step [568/1079], Loss: 0.0196\n",
      "Epoch [3/10], Step [569/1079], Loss: 0.0452\n",
      "Epoch [3/10], Step [570/1079], Loss: 0.0076\n",
      "Epoch [3/10], Step [571/1079], Loss: 0.0143\n",
      "Epoch [3/10], Step [572/1079], Loss: 0.0082\n",
      "Epoch [3/10], Step [573/1079], Loss: 0.0257\n",
      "Epoch [3/10], Step [574/1079], Loss: 0.0147\n",
      "Epoch [3/10], Step [575/1079], Loss: 0.0819\n",
      "Epoch [3/10], Step [576/1079], Loss: 0.0206\n",
      "Epoch [3/10], Step [577/1079], Loss: 0.0099\n",
      "Epoch [3/10], Step [578/1079], Loss: 0.0089\n",
      "Epoch [3/10], Step [579/1079], Loss: 0.0391\n",
      "Epoch [3/10], Step [580/1079], Loss: 0.0388\n",
      "Epoch [3/10], Step [581/1079], Loss: 0.0089\n",
      "Epoch [3/10], Step [582/1079], Loss: 0.0029\n",
      "Epoch [3/10], Step [583/1079], Loss: 0.0408\n",
      "Epoch [3/10], Step [584/1079], Loss: 0.0451\n",
      "Epoch [3/10], Step [585/1079], Loss: 0.0162\n",
      "Epoch [3/10], Step [586/1079], Loss: 0.1115\n",
      "Epoch [3/10], Step [587/1079], Loss: 0.0120\n",
      "Epoch [3/10], Step [588/1079], Loss: 0.0063\n",
      "Epoch [3/10], Step [589/1079], Loss: 0.0155\n",
      "Epoch [3/10], Step [590/1079], Loss: 0.0424\n",
      "Epoch [3/10], Step [591/1079], Loss: 0.0059\n",
      "Epoch [3/10], Step [592/1079], Loss: 0.0046\n",
      "Epoch [3/10], Step [593/1079], Loss: 0.0118\n",
      "Epoch [3/10], Step [594/1079], Loss: 0.0464\n",
      "Epoch [3/10], Step [595/1079], Loss: 0.0082\n",
      "Epoch [3/10], Step [596/1079], Loss: 0.0685\n",
      "Epoch [3/10], Step [597/1079], Loss: 0.0027\n",
      "Epoch [3/10], Step [598/1079], Loss: 0.0034\n",
      "Epoch [3/10], Step [599/1079], Loss: 0.0029\n",
      "Epoch [3/10], Step [600/1079], Loss: 0.0037\n",
      "Epoch [3/10], Step [601/1079], Loss: 0.0189\n",
      "Epoch [3/10], Step [602/1079], Loss: 0.0605\n",
      "Epoch [3/10], Step [603/1079], Loss: 0.0475\n",
      "Epoch [3/10], Step [604/1079], Loss: 0.0305\n",
      "Epoch [3/10], Step [605/1079], Loss: 0.0308\n",
      "Epoch [3/10], Step [606/1079], Loss: 0.0033\n",
      "Epoch [3/10], Step [607/1079], Loss: 0.0194\n",
      "Epoch [3/10], Step [608/1079], Loss: 0.0381\n",
      "Epoch [3/10], Step [609/1079], Loss: 0.0267\n",
      "Epoch [3/10], Step [610/1079], Loss: 0.0042\n",
      "Epoch [3/10], Step [611/1079], Loss: 0.0471\n",
      "Epoch [3/10], Step [612/1079], Loss: 0.0336\n",
      "Epoch [3/10], Step [613/1079], Loss: 0.0028\n",
      "Epoch [3/10], Step [614/1079], Loss: 0.0143\n",
      "Epoch [3/10], Step [615/1079], Loss: 0.0380\n",
      "Epoch [3/10], Step [616/1079], Loss: 0.0264\n",
      "Epoch [3/10], Step [617/1079], Loss: 0.1176\n",
      "Epoch [3/10], Step [618/1079], Loss: 0.0089\n",
      "Epoch [3/10], Step [619/1079], Loss: 0.0180\n",
      "Epoch [3/10], Step [620/1079], Loss: 0.0396\n",
      "Epoch [3/10], Step [621/1079], Loss: 0.0204\n",
      "Epoch [3/10], Step [622/1079], Loss: 0.0205\n",
      "Epoch [3/10], Step [623/1079], Loss: 0.0007\n",
      "Epoch [3/10], Step [624/1079], Loss: 0.0694\n",
      "Epoch [3/10], Step [625/1079], Loss: 0.0142\n",
      "Epoch [3/10], Step [626/1079], Loss: 0.0389\n",
      "Epoch [3/10], Step [627/1079], Loss: 0.0354\n",
      "Epoch [3/10], Step [628/1079], Loss: 0.0213\n",
      "Epoch [3/10], Step [629/1079], Loss: 0.0091\n",
      "Epoch [3/10], Step [630/1079], Loss: 0.0320\n",
      "Epoch [3/10], Step [631/1079], Loss: 0.0291\n",
      "Epoch [3/10], Step [632/1079], Loss: 0.0104\n",
      "Epoch [3/10], Step [633/1079], Loss: 0.0019\n",
      "Epoch [3/10], Step [634/1079], Loss: 0.0223\n",
      "Epoch [3/10], Step [635/1079], Loss: 0.0103\n",
      "Epoch [3/10], Step [636/1079], Loss: 0.0088\n",
      "Epoch [3/10], Step [637/1079], Loss: 0.0091\n",
      "Epoch [3/10], Step [638/1079], Loss: 0.0328\n",
      "Epoch [3/10], Step [639/1079], Loss: 0.0965\n",
      "Epoch [3/10], Step [640/1079], Loss: 0.0163\n",
      "Epoch [3/10], Step [641/1079], Loss: 0.1099\n",
      "Epoch [3/10], Step [642/1079], Loss: 0.0013\n",
      "Epoch [3/10], Step [643/1079], Loss: 0.0145\n",
      "Epoch [3/10], Step [644/1079], Loss: 0.0389\n",
      "Epoch [3/10], Step [645/1079], Loss: 0.0050\n",
      "Epoch [3/10], Step [646/1079], Loss: 0.0067\n",
      "Epoch [3/10], Step [647/1079], Loss: 0.0188\n",
      "Epoch [3/10], Step [648/1079], Loss: 0.0331\n",
      "Epoch [3/10], Step [649/1079], Loss: 0.0364\n",
      "Epoch [3/10], Step [650/1079], Loss: 0.0324\n",
      "Epoch [3/10], Step [651/1079], Loss: 0.0361\n",
      "Epoch [3/10], Step [652/1079], Loss: 0.0305\n",
      "Epoch [3/10], Step [653/1079], Loss: 0.0282\n",
      "Epoch [3/10], Step [654/1079], Loss: 0.0064\n",
      "Epoch [3/10], Step [655/1079], Loss: 0.0098\n",
      "Epoch [3/10], Step [656/1079], Loss: 0.0036\n",
      "Epoch [3/10], Step [657/1079], Loss: 0.0147\n",
      "Epoch [3/10], Step [658/1079], Loss: 0.0474\n",
      "Epoch [3/10], Step [659/1079], Loss: 0.1716\n",
      "Epoch [3/10], Step [660/1079], Loss: 0.0062\n",
      "Epoch [3/10], Step [661/1079], Loss: 0.0209\n",
      "Epoch [3/10], Step [662/1079], Loss: 0.0106\n",
      "Epoch [3/10], Step [663/1079], Loss: 0.0364\n",
      "Epoch [3/10], Step [664/1079], Loss: 0.0074\n",
      "Epoch [3/10], Step [665/1079], Loss: 0.0275\n",
      "Epoch [3/10], Step [666/1079], Loss: 0.0394\n",
      "Epoch [3/10], Step [667/1079], Loss: 0.0733\n",
      "Epoch [3/10], Step [668/1079], Loss: 0.0601\n",
      "Epoch [3/10], Step [669/1079], Loss: 0.0200\n",
      "Epoch [3/10], Step [670/1079], Loss: 0.0096\n",
      "Epoch [3/10], Step [671/1079], Loss: 0.1049\n",
      "Epoch [3/10], Step [672/1079], Loss: 0.0240\n",
      "Epoch [3/10], Step [673/1079], Loss: 0.0150\n",
      "Epoch [3/10], Step [674/1079], Loss: 0.0208\n",
      "Epoch [3/10], Step [675/1079], Loss: 0.0184\n",
      "Epoch [3/10], Step [676/1079], Loss: 0.0381\n",
      "Epoch [3/10], Step [677/1079], Loss: 0.0054\n",
      "Epoch [3/10], Step [678/1079], Loss: 0.0185\n",
      "Epoch [3/10], Step [679/1079], Loss: 0.0634\n",
      "Epoch [3/10], Step [680/1079], Loss: 0.0172\n",
      "Epoch [3/10], Step [681/1079], Loss: 0.0474\n",
      "Epoch [3/10], Step [682/1079], Loss: 0.0465\n",
      "Epoch [3/10], Step [683/1079], Loss: 0.0043\n",
      "Epoch [3/10], Step [684/1079], Loss: 0.0350\n",
      "Epoch [3/10], Step [685/1079], Loss: 0.0425\n",
      "Epoch [3/10], Step [686/1079], Loss: 0.0087\n",
      "Epoch [3/10], Step [687/1079], Loss: 0.0007\n",
      "Epoch [3/10], Step [688/1079], Loss: 0.0027\n",
      "Epoch [3/10], Step [689/1079], Loss: 0.0301\n",
      "Epoch [3/10], Step [690/1079], Loss: 0.0023\n",
      "Epoch [3/10], Step [691/1079], Loss: 0.0041\n",
      "Epoch [3/10], Step [692/1079], Loss: 0.0273\n",
      "Epoch [3/10], Step [693/1079], Loss: 0.0017\n",
      "Epoch [3/10], Step [694/1079], Loss: 0.0326\n",
      "Epoch [3/10], Step [695/1079], Loss: 0.0140\n",
      "Epoch [3/10], Step [696/1079], Loss: 0.0540\n",
      "Epoch [3/10], Step [697/1079], Loss: 0.0237\n",
      "Epoch [3/10], Step [698/1079], Loss: 0.0370\n",
      "Epoch [3/10], Step [699/1079], Loss: 0.0249\n",
      "Epoch [3/10], Step [700/1079], Loss: 0.0643\n",
      "Epoch [3/10], Step [701/1079], Loss: 0.0283\n",
      "Epoch [3/10], Step [702/1079], Loss: 0.0035\n",
      "Epoch [3/10], Step [703/1079], Loss: 0.0020\n",
      "Epoch [3/10], Step [704/1079], Loss: 0.0359\n",
      "Epoch [3/10], Step [705/1079], Loss: 0.0478\n",
      "Epoch [3/10], Step [706/1079], Loss: 0.0850\n",
      "Epoch [3/10], Step [707/1079], Loss: 0.0506\n",
      "Epoch [3/10], Step [708/1079], Loss: 0.0066\n",
      "Epoch [3/10], Step [709/1079], Loss: 0.0088\n",
      "Epoch [3/10], Step [710/1079], Loss: 0.0672\n",
      "Epoch [3/10], Step [711/1079], Loss: 0.0020\n",
      "Epoch [3/10], Step [712/1079], Loss: 0.0158\n",
      "Epoch [3/10], Step [713/1079], Loss: 0.0175\n",
      "Epoch [3/10], Step [714/1079], Loss: 0.0249\n",
      "Epoch [3/10], Step [715/1079], Loss: 0.0087\n",
      "Epoch [3/10], Step [716/1079], Loss: 0.0011\n",
      "Epoch [3/10], Step [717/1079], Loss: 0.0087\n",
      "Epoch [3/10], Step [718/1079], Loss: 0.0563\n",
      "Epoch [3/10], Step [719/1079], Loss: 0.0107\n",
      "Epoch [3/10], Step [720/1079], Loss: 0.0638\n",
      "Epoch [3/10], Step [721/1079], Loss: 0.0890\n",
      "Epoch [3/10], Step [722/1079], Loss: 0.0899\n",
      "Epoch [3/10], Step [723/1079], Loss: 0.0169\n",
      "Epoch [3/10], Step [724/1079], Loss: 0.0508\n",
      "Epoch [3/10], Step [725/1079], Loss: 0.0084\n",
      "Epoch [3/10], Step [726/1079], Loss: 0.0793\n",
      "Epoch [3/10], Step [727/1079], Loss: 0.1279\n",
      "Epoch [3/10], Step [728/1079], Loss: 0.0047\n",
      "Epoch [3/10], Step [729/1079], Loss: 0.0277\n",
      "Epoch [3/10], Step [730/1079], Loss: 0.0100\n",
      "Epoch [3/10], Step [731/1079], Loss: 0.0262\n",
      "Epoch [3/10], Step [732/1079], Loss: 0.0269\n",
      "Epoch [3/10], Step [733/1079], Loss: 0.0569\n",
      "Epoch [3/10], Step [734/1079], Loss: 0.0504\n",
      "Epoch [3/10], Step [735/1079], Loss: 0.0199\n",
      "Epoch [3/10], Step [736/1079], Loss: 0.0080\n",
      "Epoch [3/10], Step [737/1079], Loss: 0.0030\n",
      "Epoch [3/10], Step [738/1079], Loss: 0.0869\n",
      "Epoch [3/10], Step [739/1079], Loss: 0.0199\n",
      "Epoch [3/10], Step [740/1079], Loss: 0.0190\n",
      "Epoch [3/10], Step [741/1079], Loss: 0.0206\n",
      "Epoch [3/10], Step [742/1079], Loss: 0.0065\n",
      "Epoch [3/10], Step [743/1079], Loss: 0.0821\n",
      "Epoch [3/10], Step [744/1079], Loss: 0.0302\n",
      "Epoch [3/10], Step [745/1079], Loss: 0.0056\n",
      "Epoch [3/10], Step [746/1079], Loss: 0.0264\n",
      "Epoch [3/10], Step [747/1079], Loss: 0.1737\n",
      "Epoch [3/10], Step [748/1079], Loss: 0.0043\n",
      "Epoch [3/10], Step [749/1079], Loss: 0.0195\n",
      "Epoch [3/10], Step [750/1079], Loss: 0.0246\n",
      "Epoch [3/10], Step [751/1079], Loss: 0.0061\n",
      "Epoch [3/10], Step [752/1079], Loss: 0.0164\n",
      "Epoch [3/10], Step [753/1079], Loss: 0.0312\n",
      "Epoch [3/10], Step [754/1079], Loss: 0.0190\n",
      "Epoch [3/10], Step [755/1079], Loss: 0.1034\n",
      "Epoch [3/10], Step [756/1079], Loss: 0.0053\n",
      "Epoch [3/10], Step [757/1079], Loss: 0.0121\n",
      "Epoch [3/10], Step [758/1079], Loss: 0.0567\n",
      "Epoch [3/10], Step [759/1079], Loss: 0.0145\n",
      "Epoch [3/10], Step [760/1079], Loss: 0.0068\n",
      "Epoch [3/10], Step [761/1079], Loss: 0.0075\n",
      "Epoch [3/10], Step [762/1079], Loss: 0.0060\n",
      "Epoch [3/10], Step [763/1079], Loss: 0.1010\n",
      "Epoch [3/10], Step [764/1079], Loss: 0.0251\n",
      "Epoch [3/10], Step [765/1079], Loss: 0.0098\n",
      "Epoch [3/10], Step [766/1079], Loss: 0.0149\n",
      "Epoch [3/10], Step [767/1079], Loss: 0.0084\n",
      "Epoch [3/10], Step [768/1079], Loss: 0.0024\n",
      "Epoch [3/10], Step [769/1079], Loss: 0.0258\n",
      "Epoch [3/10], Step [770/1079], Loss: 0.0244\n",
      "Epoch [3/10], Step [771/1079], Loss: 0.0281\n",
      "Epoch [3/10], Step [772/1079], Loss: 0.1048\n",
      "Epoch [3/10], Step [773/1079], Loss: 0.0397\n",
      "Epoch [3/10], Step [774/1079], Loss: 0.0141\n",
      "Epoch [3/10], Step [775/1079], Loss: 0.0014\n",
      "Epoch [3/10], Step [776/1079], Loss: 0.0530\n",
      "Epoch [3/10], Step [777/1079], Loss: 0.1055\n",
      "Epoch [3/10], Step [778/1079], Loss: 0.0163\n",
      "Epoch [3/10], Step [779/1079], Loss: 0.0788\n",
      "Epoch [3/10], Step [780/1079], Loss: 0.0672\n",
      "Epoch [3/10], Step [781/1079], Loss: 0.0062\n",
      "Epoch [3/10], Step [782/1079], Loss: 0.0428\n",
      "Epoch [3/10], Step [783/1079], Loss: 0.0264\n",
      "Epoch [3/10], Step [784/1079], Loss: 0.0054\n",
      "Epoch [3/10], Step [785/1079], Loss: 0.0407\n",
      "Epoch [3/10], Step [786/1079], Loss: 0.0057\n",
      "Epoch [3/10], Step [787/1079], Loss: 0.0192\n",
      "Epoch [3/10], Step [788/1079], Loss: 0.0613\n",
      "Epoch [3/10], Step [789/1079], Loss: 0.0160\n",
      "Epoch [3/10], Step [790/1079], Loss: 0.0172\n",
      "Epoch [3/10], Step [791/1079], Loss: 0.0114\n",
      "Epoch [3/10], Step [792/1079], Loss: 0.1406\n",
      "Epoch [3/10], Step [793/1079], Loss: 0.0212\n",
      "Epoch [3/10], Step [794/1079], Loss: 0.0303\n",
      "Epoch [3/10], Step [795/1079], Loss: 0.0102\n",
      "Epoch [3/10], Step [796/1079], Loss: 0.0335\n",
      "Epoch [3/10], Step [797/1079], Loss: 0.0283\n",
      "Epoch [3/10], Step [798/1079], Loss: 0.0061\n",
      "Epoch [3/10], Step [799/1079], Loss: 0.0569\n",
      "Epoch [3/10], Step [800/1079], Loss: 0.0258\n",
      "Epoch [3/10], Step [801/1079], Loss: 0.0045\n",
      "Epoch [3/10], Step [802/1079], Loss: 0.0223\n",
      "Epoch [3/10], Step [803/1079], Loss: 0.0080\n",
      "Epoch [3/10], Step [804/1079], Loss: 0.0108\n",
      "Epoch [3/10], Step [805/1079], Loss: 0.0079\n",
      "Epoch [3/10], Step [806/1079], Loss: 0.0115\n",
      "Epoch [3/10], Step [807/1079], Loss: 0.0081\n",
      "Epoch [3/10], Step [808/1079], Loss: 0.0871\n",
      "Epoch [3/10], Step [809/1079], Loss: 0.0366\n",
      "Epoch [3/10], Step [810/1079], Loss: 0.0136\n",
      "Epoch [3/10], Step [811/1079], Loss: 0.0038\n",
      "Epoch [3/10], Step [812/1079], Loss: 0.1143\n",
      "Epoch [3/10], Step [813/1079], Loss: 0.0337\n",
      "Epoch [3/10], Step [814/1079], Loss: 0.0030\n",
      "Epoch [3/10], Step [815/1079], Loss: 0.0626\n",
      "Epoch [3/10], Step [816/1079], Loss: 0.0708\n",
      "Epoch [3/10], Step [817/1079], Loss: 0.0307\n",
      "Epoch [3/10], Step [818/1079], Loss: 0.0629\n",
      "Epoch [3/10], Step [819/1079], Loss: 0.0121\n",
      "Epoch [3/10], Step [820/1079], Loss: 0.0056\n",
      "Epoch [3/10], Step [821/1079], Loss: 0.0763\n",
      "Epoch [3/10], Step [822/1079], Loss: 0.0033\n",
      "Epoch [3/10], Step [823/1079], Loss: 0.0209\n",
      "Epoch [3/10], Step [824/1079], Loss: 0.0459\n",
      "Epoch [3/10], Step [825/1079], Loss: 0.0146\n",
      "Epoch [3/10], Step [826/1079], Loss: 0.0080\n",
      "Epoch [3/10], Step [827/1079], Loss: 0.0409\n",
      "Epoch [3/10], Step [828/1079], Loss: 0.1121\n",
      "Epoch [3/10], Step [829/1079], Loss: 0.0211\n",
      "Epoch [3/10], Step [830/1079], Loss: 0.0060\n",
      "Epoch [3/10], Step [831/1079], Loss: 0.0709\n",
      "Epoch [3/10], Step [832/1079], Loss: 0.0411\n",
      "Epoch [3/10], Step [833/1079], Loss: 0.0217\n",
      "Epoch [3/10], Step [834/1079], Loss: 0.0136\n",
      "Epoch [3/10], Step [835/1079], Loss: 0.0200\n",
      "Epoch [3/10], Step [836/1079], Loss: 0.0281\n",
      "Epoch [3/10], Step [837/1079], Loss: 0.2120\n",
      "Epoch [3/10], Step [838/1079], Loss: 0.0132\n",
      "Epoch [3/10], Step [839/1079], Loss: 0.0204\n",
      "Epoch [3/10], Step [840/1079], Loss: 0.0067\n",
      "Epoch [3/10], Step [841/1079], Loss: 0.0112\n",
      "Epoch [3/10], Step [842/1079], Loss: 0.0171\n",
      "Epoch [3/10], Step [843/1079], Loss: 0.0020\n",
      "Epoch [3/10], Step [844/1079], Loss: 0.0126\n",
      "Epoch [3/10], Step [845/1079], Loss: 0.0421\n",
      "Epoch [3/10], Step [846/1079], Loss: 0.0950\n",
      "Epoch [3/10], Step [847/1079], Loss: 0.0117\n",
      "Epoch [3/10], Step [848/1079], Loss: 0.0359\n",
      "Epoch [3/10], Step [849/1079], Loss: 0.0621\n",
      "Epoch [3/10], Step [850/1079], Loss: 0.0883\n",
      "Epoch [3/10], Step [851/1079], Loss: 0.0485\n",
      "Epoch [3/10], Step [852/1079], Loss: 0.0057\n",
      "Epoch [3/10], Step [853/1079], Loss: 0.0383\n",
      "Epoch [3/10], Step [854/1079], Loss: 0.0668\n",
      "Epoch [3/10], Step [855/1079], Loss: 0.0233\n",
      "Epoch [3/10], Step [856/1079], Loss: 0.0232\n",
      "Epoch [3/10], Step [857/1079], Loss: 0.0247\n",
      "Epoch [3/10], Step [858/1079], Loss: 0.0027\n",
      "Epoch [3/10], Step [859/1079], Loss: 0.0089\n",
      "Epoch [3/10], Step [860/1079], Loss: 0.0035\n",
      "Epoch [3/10], Step [861/1079], Loss: 0.0081\n",
      "Epoch [3/10], Step [862/1079], Loss: 0.0447\n",
      "Epoch [3/10], Step [863/1079], Loss: 0.0316\n",
      "Epoch [3/10], Step [864/1079], Loss: 0.0015\n",
      "Epoch [3/10], Step [865/1079], Loss: 0.0530\n",
      "Epoch [3/10], Step [866/1079], Loss: 0.0027\n",
      "Epoch [3/10], Step [867/1079], Loss: 0.0111\n",
      "Epoch [3/10], Step [868/1079], Loss: 0.0065\n",
      "Epoch [3/10], Step [869/1079], Loss: 0.0032\n",
      "Epoch [3/10], Step [870/1079], Loss: 0.0418\n",
      "Epoch [3/10], Step [871/1079], Loss: 0.0670\n",
      "Epoch [3/10], Step [872/1079], Loss: 0.0018\n",
      "Epoch [3/10], Step [873/1079], Loss: 0.1526\n",
      "Epoch [3/10], Step [874/1079], Loss: 0.0242\n",
      "Epoch [3/10], Step [875/1079], Loss: 0.0235\n",
      "Epoch [3/10], Step [876/1079], Loss: 0.1288\n",
      "Epoch [3/10], Step [877/1079], Loss: 0.0090\n",
      "Epoch [3/10], Step [878/1079], Loss: 0.0018\n",
      "Epoch [3/10], Step [879/1079], Loss: 0.0048\n",
      "Epoch [3/10], Step [880/1079], Loss: 0.0108\n",
      "Epoch [3/10], Step [881/1079], Loss: 0.0033\n",
      "Epoch [3/10], Step [882/1079], Loss: 0.0252\n",
      "Epoch [3/10], Step [883/1079], Loss: 0.0163\n",
      "Epoch [3/10], Step [884/1079], Loss: 0.0199\n",
      "Epoch [3/10], Step [885/1079], Loss: 0.0174\n",
      "Epoch [3/10], Step [886/1079], Loss: 0.0088\n",
      "Epoch [3/10], Step [887/1079], Loss: 0.0861\n",
      "Epoch [3/10], Step [888/1079], Loss: 0.0409\n",
      "Epoch [3/10], Step [889/1079], Loss: 0.0021\n",
      "Epoch [3/10], Step [890/1079], Loss: 0.0029\n",
      "Epoch [3/10], Step [891/1079], Loss: 0.0106\n",
      "Epoch [3/10], Step [892/1079], Loss: 0.0528\n",
      "Epoch [3/10], Step [893/1079], Loss: 0.0392\n",
      "Epoch [3/10], Step [894/1079], Loss: 0.0033\n",
      "Epoch [3/10], Step [895/1079], Loss: 0.0734\n",
      "Epoch [3/10], Step [896/1079], Loss: 0.0162\n",
      "Epoch [3/10], Step [897/1079], Loss: 0.0044\n",
      "Epoch [3/10], Step [898/1079], Loss: 0.0888\n",
      "Epoch [3/10], Step [899/1079], Loss: 0.0630\n",
      "Epoch [3/10], Step [900/1079], Loss: 0.0048\n",
      "Epoch [3/10], Step [901/1079], Loss: 0.0021\n",
      "Epoch [3/10], Step [902/1079], Loss: 0.0037\n",
      "Epoch [3/10], Step [903/1079], Loss: 0.0106\n",
      "Epoch [3/10], Step [904/1079], Loss: 0.0143\n",
      "Epoch [3/10], Step [905/1079], Loss: 0.0425\n",
      "Epoch [3/10], Step [906/1079], Loss: 0.0358\n",
      "Epoch [3/10], Step [907/1079], Loss: 0.0153\n",
      "Epoch [3/10], Step [908/1079], Loss: 0.0200\n",
      "Epoch [3/10], Step [909/1079], Loss: 0.0024\n",
      "Epoch [3/10], Step [910/1079], Loss: 0.0024\n",
      "Epoch [3/10], Step [911/1079], Loss: 0.0831\n",
      "Epoch [3/10], Step [912/1079], Loss: 0.0031\n",
      "Epoch [3/10], Step [913/1079], Loss: 0.0073\n",
      "Epoch [3/10], Step [914/1079], Loss: 0.0169\n",
      "Epoch [3/10], Step [915/1079], Loss: 0.0347\n",
      "Epoch [3/10], Step [916/1079], Loss: 0.1066\n",
      "Epoch [3/10], Step [917/1079], Loss: 0.0176\n",
      "Epoch [3/10], Step [918/1079], Loss: 0.0041\n",
      "Epoch [3/10], Step [919/1079], Loss: 0.0097\n",
      "Epoch [3/10], Step [920/1079], Loss: 0.0398\n",
      "Epoch [3/10], Step [921/1079], Loss: 0.0379\n",
      "Epoch [3/10], Step [922/1079], Loss: 0.0109\n",
      "Epoch [3/10], Step [923/1079], Loss: 0.0054\n",
      "Epoch [3/10], Step [924/1079], Loss: 0.0054\n",
      "Epoch [3/10], Step [925/1079], Loss: 0.0060\n",
      "Epoch [3/10], Step [926/1079], Loss: 0.0750\n",
      "Epoch [3/10], Step [927/1079], Loss: 0.0398\n",
      "Epoch [3/10], Step [928/1079], Loss: 0.0614\n",
      "Epoch [3/10], Step [929/1079], Loss: 0.0705\n",
      "Epoch [3/10], Step [930/1079], Loss: 0.0019\n",
      "Epoch [3/10], Step [931/1079], Loss: 0.0451\n",
      "Epoch [3/10], Step [932/1079], Loss: 0.0672\n",
      "Epoch [3/10], Step [933/1079], Loss: 0.0706\n",
      "Epoch [3/10], Step [934/1079], Loss: 0.0247\n",
      "Epoch [3/10], Step [935/1079], Loss: 0.0015\n",
      "Epoch [3/10], Step [936/1079], Loss: 0.0047\n",
      "Epoch [3/10], Step [937/1079], Loss: 0.0127\n",
      "Epoch [3/10], Step [938/1079], Loss: 0.0208\n",
      "Epoch [3/10], Step [939/1079], Loss: 0.0997\n",
      "Epoch [3/10], Step [940/1079], Loss: 0.0046\n",
      "Epoch [3/10], Step [941/1079], Loss: 0.0047\n",
      "Epoch [3/10], Step [942/1079], Loss: 0.0305\n",
      "Epoch [3/10], Step [943/1079], Loss: 0.0424\n",
      "Epoch [3/10], Step [944/1079], Loss: 0.0264\n",
      "Epoch [3/10], Step [945/1079], Loss: 0.0122\n",
      "Epoch [3/10], Step [946/1079], Loss: 0.0960\n",
      "Epoch [3/10], Step [947/1079], Loss: 0.0088\n",
      "Epoch [3/10], Step [948/1079], Loss: 0.0704\n",
      "Epoch [3/10], Step [949/1079], Loss: 0.0232\n",
      "Epoch [3/10], Step [950/1079], Loss: 0.0041\n",
      "Epoch [3/10], Step [951/1079], Loss: 0.0869\n",
      "Epoch [3/10], Step [952/1079], Loss: 0.0048\n",
      "Epoch [3/10], Step [953/1079], Loss: 0.0017\n",
      "Epoch [3/10], Step [954/1079], Loss: 0.0321\n",
      "Epoch [3/10], Step [955/1079], Loss: 0.0996\n",
      "Epoch [3/10], Step [956/1079], Loss: 0.0283\n",
      "Epoch [3/10], Step [957/1079], Loss: 0.0046\n",
      "Epoch [3/10], Step [958/1079], Loss: 0.0573\n",
      "Epoch [3/10], Step [959/1079], Loss: 0.0038\n",
      "Epoch [3/10], Step [960/1079], Loss: 0.0127\n",
      "Epoch [3/10], Step [961/1079], Loss: 0.0517\n",
      "Epoch [3/10], Step [962/1079], Loss: 0.0115\n",
      "Epoch [3/10], Step [963/1079], Loss: 0.0098\n",
      "Epoch [3/10], Step [964/1079], Loss: 0.2948\n",
      "Epoch [3/10], Step [965/1079], Loss: 0.0126\n",
      "Epoch [3/10], Step [966/1079], Loss: 0.0079\n",
      "Epoch [3/10], Step [967/1079], Loss: 0.0129\n",
      "Epoch [3/10], Step [968/1079], Loss: 0.0168\n",
      "Epoch [3/10], Step [969/1079], Loss: 0.0117\n",
      "Epoch [3/10], Step [970/1079], Loss: 0.0588\n",
      "Epoch [3/10], Step [971/1079], Loss: 0.0013\n",
      "Epoch [3/10], Step [972/1079], Loss: 0.0019\n",
      "Epoch [3/10], Step [973/1079], Loss: 0.0029\n",
      "Epoch [3/10], Step [974/1079], Loss: 0.0127\n",
      "Epoch [3/10], Step [975/1079], Loss: 0.0128\n",
      "Epoch [3/10], Step [976/1079], Loss: 0.0042\n",
      "Epoch [3/10], Step [977/1079], Loss: 0.0040\n",
      "Epoch [3/10], Step [978/1079], Loss: 0.0083\n",
      "Epoch [3/10], Step [979/1079], Loss: 0.0105\n",
      "Epoch [3/10], Step [980/1079], Loss: 0.0231\n",
      "Epoch [3/10], Step [981/1079], Loss: 0.0575\n",
      "Epoch [3/10], Step [982/1079], Loss: 0.0124\n",
      "Epoch [3/10], Step [983/1079], Loss: 0.0413\n",
      "Epoch [3/10], Step [984/1079], Loss: 0.0561\n",
      "Epoch [3/10], Step [985/1079], Loss: 0.0396\n",
      "Epoch [3/10], Step [986/1079], Loss: 0.0460\n",
      "Epoch [3/10], Step [987/1079], Loss: 0.0072\n",
      "Epoch [3/10], Step [988/1079], Loss: 0.0096\n",
      "Epoch [3/10], Step [989/1079], Loss: 0.1116\n",
      "Epoch [3/10], Step [990/1079], Loss: 0.0149\n",
      "Epoch [3/10], Step [991/1079], Loss: 0.0412\n",
      "Epoch [3/10], Step [992/1079], Loss: 0.0446\n",
      "Epoch [3/10], Step [993/1079], Loss: 0.1005\n",
      "Epoch [3/10], Step [994/1079], Loss: 0.0213\n",
      "Epoch [3/10], Step [995/1079], Loss: 0.1082\n",
      "Epoch [3/10], Step [996/1079], Loss: 0.0695\n",
      "Epoch [3/10], Step [997/1079], Loss: 0.0061\n",
      "Epoch [3/10], Step [998/1079], Loss: 0.0105\n",
      "Epoch [3/10], Step [999/1079], Loss: 0.0019\n",
      "Epoch [3/10], Step [1000/1079], Loss: 0.0023\n",
      "Epoch [3/10], Step [1001/1079], Loss: 0.0205\n",
      "Epoch [3/10], Step [1002/1079], Loss: 0.0177\n",
      "Epoch [3/10], Step [1003/1079], Loss: 0.0940\n",
      "Epoch [3/10], Step [1004/1079], Loss: 0.0509\n",
      "Epoch [3/10], Step [1005/1079], Loss: 0.0454\n",
      "Epoch [3/10], Step [1006/1079], Loss: 0.0052\n",
      "Epoch [3/10], Step [1007/1079], Loss: 0.0082\n",
      "Epoch [3/10], Step [1008/1079], Loss: 0.0162\n",
      "Epoch [3/10], Step [1009/1079], Loss: 0.0105\n",
      "Epoch [3/10], Step [1010/1079], Loss: 0.0241\n",
      "Epoch [3/10], Step [1011/1079], Loss: 0.0742\n",
      "Epoch [3/10], Step [1012/1079], Loss: 0.0102\n",
      "Epoch [3/10], Step [1013/1079], Loss: 0.0435\n",
      "Epoch [3/10], Step [1014/1079], Loss: 0.0233\n",
      "Epoch [3/10], Step [1015/1079], Loss: 0.0072\n",
      "Epoch [3/10], Step [1016/1079], Loss: 0.0019\n",
      "Epoch [3/10], Step [1017/1079], Loss: 0.1028\n",
      "Epoch [3/10], Step [1018/1079], Loss: 0.0065\n",
      "Epoch [3/10], Step [1019/1079], Loss: 0.0540\n",
      "Epoch [3/10], Step [1020/1079], Loss: 0.0102\n",
      "Epoch [3/10], Step [1021/1079], Loss: 0.0021\n",
      "Epoch [3/10], Step [1022/1079], Loss: 0.0110\n",
      "Epoch [3/10], Step [1023/1079], Loss: 0.0149\n",
      "Epoch [3/10], Step [1024/1079], Loss: 0.0017\n",
      "Epoch [3/10], Step [1025/1079], Loss: 0.0366\n",
      "Epoch [3/10], Step [1026/1079], Loss: 0.0375\n",
      "Epoch [3/10], Step [1027/1079], Loss: 0.0092\n",
      "Epoch [3/10], Step [1028/1079], Loss: 0.0053\n",
      "Epoch [3/10], Step [1029/1079], Loss: 0.0062\n",
      "Epoch [3/10], Step [1030/1079], Loss: 0.0056\n",
      "Epoch [3/10], Step [1031/1079], Loss: 0.0194\n",
      "Epoch [3/10], Step [1032/1079], Loss: 0.0220\n",
      "Epoch [3/10], Step [1033/1079], Loss: 0.0066\n",
      "Epoch [3/10], Step [1034/1079], Loss: 0.0052\n",
      "Epoch [3/10], Step [1035/1079], Loss: 0.0844\n",
      "Epoch [3/10], Step [1036/1079], Loss: 0.0029\n",
      "Epoch [3/10], Step [1037/1079], Loss: 0.1302\n",
      "Epoch [3/10], Step [1038/1079], Loss: 0.0010\n",
      "Epoch [3/10], Step [1039/1079], Loss: 0.0045\n",
      "Epoch [3/10], Step [1040/1079], Loss: 0.0403\n",
      "Epoch [3/10], Step [1041/1079], Loss: 0.0140\n",
      "Epoch [3/10], Step [1042/1079], Loss: 0.0034\n",
      "Epoch [3/10], Step [1043/1079], Loss: 0.0173\n",
      "Epoch [3/10], Step [1044/1079], Loss: 0.0036\n",
      "Epoch [3/10], Step [1045/1079], Loss: 0.0338\n",
      "Epoch [3/10], Step [1046/1079], Loss: 0.0128\n",
      "Epoch [3/10], Step [1047/1079], Loss: 0.0130\n",
      "Epoch [3/10], Step [1048/1079], Loss: 0.1426\n",
      "Epoch [3/10], Step [1049/1079], Loss: 0.0137\n",
      "Epoch [3/10], Step [1050/1079], Loss: 0.0539\n",
      "Epoch [3/10], Step [1051/1079], Loss: 0.0015\n",
      "Epoch [3/10], Step [1052/1079], Loss: 0.0096\n",
      "Epoch [3/10], Step [1053/1079], Loss: 0.0030\n",
      "Epoch [3/10], Step [1054/1079], Loss: 0.0117\n",
      "Epoch [3/10], Step [1055/1079], Loss: 0.0459\n",
      "Epoch [3/10], Step [1056/1079], Loss: 0.0080\n",
      "Epoch [3/10], Step [1057/1079], Loss: 0.0021\n",
      "Epoch [3/10], Step [1058/1079], Loss: 0.0295\n",
      "Epoch [3/10], Step [1059/1079], Loss: 0.0073\n",
      "Epoch [3/10], Step [1060/1079], Loss: 0.0624\n",
      "Epoch [3/10], Step [1061/1079], Loss: 0.0032\n",
      "Epoch [3/10], Step [1062/1079], Loss: 0.0023\n",
      "Epoch [3/10], Step [1063/1079], Loss: 0.0069\n",
      "Epoch [3/10], Step [1064/1079], Loss: 0.0048\n",
      "Epoch [3/10], Step [1065/1079], Loss: 0.0342\n",
      "Epoch [3/10], Step [1066/1079], Loss: 0.0036\n",
      "Epoch [3/10], Step [1067/1079], Loss: 0.0499\n",
      "Epoch [3/10], Step [1068/1079], Loss: 0.0337\n",
      "Epoch [3/10], Step [1069/1079], Loss: 0.0010\n",
      "Epoch [3/10], Step [1070/1079], Loss: 0.0310\n",
      "Epoch [3/10], Step [1071/1079], Loss: 0.0026\n",
      "Epoch [3/10], Step [1072/1079], Loss: 0.0216\n",
      "Epoch [3/10], Step [1073/1079], Loss: 0.1100\n",
      "Epoch [3/10], Step [1074/1079], Loss: 0.0139\n",
      "Epoch [3/10], Step [1075/1079], Loss: 0.0571\n",
      "Epoch [3/10], Step [1076/1079], Loss: 0.0083\n",
      "Epoch [3/10], Step [1077/1079], Loss: 0.0005\n",
      "Epoch [3/10], Step [1078/1079], Loss: 0.0086\n",
      "Epoch [3/10], Step [1079/1079], Loss: 0.0001\n",
      "Epoch [4/10], Step [1/1079], Loss: 0.0053\n",
      "Epoch [4/10], Step [2/1079], Loss: 0.0276\n",
      "Epoch [4/10], Step [3/1079], Loss: 0.0052\n",
      "Epoch [4/10], Step [4/1079], Loss: 0.0108\n",
      "Epoch [4/10], Step [5/1079], Loss: 0.0023\n",
      "Epoch [4/10], Step [6/1079], Loss: 0.0096\n",
      "Epoch [4/10], Step [7/1079], Loss: 0.0022\n",
      "Epoch [4/10], Step [8/1079], Loss: 0.0066\n",
      "Epoch [4/10], Step [9/1079], Loss: 0.0197\n",
      "Epoch [4/10], Step [10/1079], Loss: 0.0026\n",
      "Epoch [4/10], Step [11/1079], Loss: 0.0066\n",
      "Epoch [4/10], Step [12/1079], Loss: 0.0104\n",
      "Epoch [4/10], Step [13/1079], Loss: 0.0572\n",
      "Epoch [4/10], Step [14/1079], Loss: 0.1134\n",
      "Epoch [4/10], Step [15/1079], Loss: 0.0005\n",
      "Epoch [4/10], Step [16/1079], Loss: 0.0015\n",
      "Epoch [4/10], Step [17/1079], Loss: 0.0060\n",
      "Epoch [4/10], Step [18/1079], Loss: 0.0018\n",
      "Epoch [4/10], Step [19/1079], Loss: 0.0008\n",
      "Epoch [4/10], Step [20/1079], Loss: 0.1590\n",
      "Epoch [4/10], Step [21/1079], Loss: 0.0036\n",
      "Epoch [4/10], Step [22/1079], Loss: 0.0042\n",
      "Epoch [4/10], Step [23/1079], Loss: 0.0066\n",
      "Epoch [4/10], Step [24/1079], Loss: 0.0030\n",
      "Epoch [4/10], Step [25/1079], Loss: 0.0042\n",
      "Epoch [4/10], Step [26/1079], Loss: 0.0107\n",
      "Epoch [4/10], Step [27/1079], Loss: 0.0055\n",
      "Epoch [4/10], Step [28/1079], Loss: 0.0078\n",
      "Epoch [4/10], Step [29/1079], Loss: 0.0170\n",
      "Epoch [4/10], Step [30/1079], Loss: 0.0428\n",
      "Epoch [4/10], Step [31/1079], Loss: 0.0346\n",
      "Epoch [4/10], Step [32/1079], Loss: 0.0109\n",
      "Epoch [4/10], Step [33/1079], Loss: 0.0033\n",
      "Epoch [4/10], Step [34/1079], Loss: 0.0008\n",
      "Epoch [4/10], Step [35/1079], Loss: 0.0029\n",
      "Epoch [4/10], Step [36/1079], Loss: 0.0053\n",
      "Epoch [4/10], Step [37/1079], Loss: 0.0016\n",
      "Epoch [4/10], Step [38/1079], Loss: 0.0621\n",
      "Epoch [4/10], Step [39/1079], Loss: 0.0046\n",
      "Epoch [4/10], Step [40/1079], Loss: 0.0674\n",
      "Epoch [4/10], Step [41/1079], Loss: 0.0033\n",
      "Epoch [4/10], Step [42/1079], Loss: 0.0665\n",
      "Epoch [4/10], Step [43/1079], Loss: 0.0006\n",
      "Epoch [4/10], Step [44/1079], Loss: 0.0006\n",
      "Epoch [4/10], Step [45/1079], Loss: 0.0069\n",
      "Epoch [4/10], Step [46/1079], Loss: 0.0047\n",
      "Epoch [4/10], Step [47/1079], Loss: 0.0148\n",
      "Epoch [4/10], Step [48/1079], Loss: 0.0069\n",
      "Epoch [4/10], Step [49/1079], Loss: 0.0343\n",
      "Epoch [4/10], Step [50/1079], Loss: 0.0039\n",
      "Epoch [4/10], Step [51/1079], Loss: 0.0217\n",
      "Epoch [4/10], Step [52/1079], Loss: 0.0011\n",
      "Epoch [4/10], Step [53/1079], Loss: 0.0036\n",
      "Epoch [4/10], Step [54/1079], Loss: 0.0319\n",
      "Epoch [4/10], Step [55/1079], Loss: 0.0079\n",
      "Epoch [4/10], Step [56/1079], Loss: 0.0024\n",
      "Epoch [4/10], Step [57/1079], Loss: 0.0052\n",
      "Epoch [4/10], Step [58/1079], Loss: 0.0025\n",
      "Epoch [4/10], Step [59/1079], Loss: 0.0012\n",
      "Epoch [4/10], Step [60/1079], Loss: 0.0015\n",
      "Epoch [4/10], Step [61/1079], Loss: 0.0048\n",
      "Epoch [4/10], Step [62/1079], Loss: 0.0287\n",
      "Epoch [4/10], Step [63/1079], Loss: 0.0394\n",
      "Epoch [4/10], Step [64/1079], Loss: 0.0214\n",
      "Epoch [4/10], Step [65/1079], Loss: 0.0097\n",
      "Epoch [4/10], Step [66/1079], Loss: 0.0144\n",
      "Epoch [4/10], Step [67/1079], Loss: 0.0013\n",
      "Epoch [4/10], Step [68/1079], Loss: 0.0648\n",
      "Epoch [4/10], Step [69/1079], Loss: 0.0074\n",
      "Epoch [4/10], Step [70/1079], Loss: 0.0030\n",
      "Epoch [4/10], Step [71/1079], Loss: 0.0101\n",
      "Epoch [4/10], Step [72/1079], Loss: 0.0102\n",
      "Epoch [4/10], Step [73/1079], Loss: 0.0023\n",
      "Epoch [4/10], Step [74/1079], Loss: 0.0434\n",
      "Epoch [4/10], Step [75/1079], Loss: 0.0014\n",
      "Epoch [4/10], Step [76/1079], Loss: 0.0017\n",
      "Epoch [4/10], Step [77/1079], Loss: 0.0037\n",
      "Epoch [4/10], Step [78/1079], Loss: 0.0149\n",
      "Epoch [4/10], Step [79/1079], Loss: 0.0195\n",
      "Epoch [4/10], Step [80/1079], Loss: 0.0073\n",
      "Epoch [4/10], Step [81/1079], Loss: 0.0030\n",
      "Epoch [4/10], Step [82/1079], Loss: 0.0034\n",
      "Epoch [4/10], Step [83/1079], Loss: 0.0034\n",
      "Epoch [4/10], Step [84/1079], Loss: 0.0145\n",
      "Epoch [4/10], Step [85/1079], Loss: 0.0205\n",
      "Epoch [4/10], Step [86/1079], Loss: 0.1092\n",
      "Epoch [4/10], Step [87/1079], Loss: 0.0693\n",
      "Epoch [4/10], Step [88/1079], Loss: 0.0031\n",
      "Epoch [4/10], Step [89/1079], Loss: 0.0083\n",
      "Epoch [4/10], Step [90/1079], Loss: 0.0134\n",
      "Epoch [4/10], Step [91/1079], Loss: 0.0547\n",
      "Epoch [4/10], Step [92/1079], Loss: 0.0458\n",
      "Epoch [4/10], Step [93/1079], Loss: 0.0043\n",
      "Epoch [4/10], Step [94/1079], Loss: 0.0331\n",
      "Epoch [4/10], Step [95/1079], Loss: 0.0008\n",
      "Epoch [4/10], Step [96/1079], Loss: 0.0225\n",
      "Epoch [4/10], Step [97/1079], Loss: 0.0116\n",
      "Epoch [4/10], Step [98/1079], Loss: 0.0192\n",
      "Epoch [4/10], Step [99/1079], Loss: 0.0021\n",
      "Epoch [4/10], Step [100/1079], Loss: 0.1865\n",
      "Epoch [4/10], Step [101/1079], Loss: 0.0187\n",
      "Epoch [4/10], Step [102/1079], Loss: 0.0320\n",
      "Epoch [4/10], Step [103/1079], Loss: 0.0061\n",
      "Epoch [4/10], Step [104/1079], Loss: 0.0411\n",
      "Epoch [4/10], Step [105/1079], Loss: 0.0200\n",
      "Epoch [4/10], Step [106/1079], Loss: 0.0061\n",
      "Epoch [4/10], Step [107/1079], Loss: 0.0431\n",
      "Epoch [4/10], Step [108/1079], Loss: 0.0020\n",
      "Epoch [4/10], Step [109/1079], Loss: 0.0246\n",
      "Epoch [4/10], Step [110/1079], Loss: 0.0046\n",
      "Epoch [4/10], Step [111/1079], Loss: 0.0348\n",
      "Epoch [4/10], Step [112/1079], Loss: 0.0235\n",
      "Epoch [4/10], Step [113/1079], Loss: 0.0206\n",
      "Epoch [4/10], Step [114/1079], Loss: 0.0207\n",
      "Epoch [4/10], Step [115/1079], Loss: 0.0071\n",
      "Epoch [4/10], Step [116/1079], Loss: 0.0459\n",
      "Epoch [4/10], Step [117/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [118/1079], Loss: 0.0037\n",
      "Epoch [4/10], Step [119/1079], Loss: 0.1157\n",
      "Epoch [4/10], Step [120/1079], Loss: 0.0228\n",
      "Epoch [4/10], Step [121/1079], Loss: 0.0049\n",
      "Epoch [4/10], Step [122/1079], Loss: 0.0066\n",
      "Epoch [4/10], Step [123/1079], Loss: 0.2026\n",
      "Epoch [4/10], Step [124/1079], Loss: 0.0906\n",
      "Epoch [4/10], Step [125/1079], Loss: 0.0216\n",
      "Epoch [4/10], Step [126/1079], Loss: 0.0051\n",
      "Epoch [4/10], Step [127/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [128/1079], Loss: 0.0245\n",
      "Epoch [4/10], Step [129/1079], Loss: 0.0005\n",
      "Epoch [4/10], Step [130/1079], Loss: 0.0093\n",
      "Epoch [4/10], Step [131/1079], Loss: 0.0235\n",
      "Epoch [4/10], Step [132/1079], Loss: 0.0019\n",
      "Epoch [4/10], Step [133/1079], Loss: 0.0508\n",
      "Epoch [4/10], Step [134/1079], Loss: 0.0103\n",
      "Epoch [4/10], Step [135/1079], Loss: 0.0009\n",
      "Epoch [4/10], Step [136/1079], Loss: 0.0062\n",
      "Epoch [4/10], Step [137/1079], Loss: 0.0041\n",
      "Epoch [4/10], Step [138/1079], Loss: 0.0079\n",
      "Epoch [4/10], Step [139/1079], Loss: 0.0193\n",
      "Epoch [4/10], Step [140/1079], Loss: 0.0163\n",
      "Epoch [4/10], Step [141/1079], Loss: 0.0035\n",
      "Epoch [4/10], Step [142/1079], Loss: 0.0043\n",
      "Epoch [4/10], Step [143/1079], Loss: 0.0075\n",
      "Epoch [4/10], Step [144/1079], Loss: 0.0117\n",
      "Epoch [4/10], Step [145/1079], Loss: 0.0033\n",
      "Epoch [4/10], Step [146/1079], Loss: 0.0061\n",
      "Epoch [4/10], Step [147/1079], Loss: 0.0405\n",
      "Epoch [4/10], Step [148/1079], Loss: 0.0193\n",
      "Epoch [4/10], Step [149/1079], Loss: 0.0102\n",
      "Epoch [4/10], Step [150/1079], Loss: 0.0124\n",
      "Epoch [4/10], Step [151/1079], Loss: 0.0595\n",
      "Epoch [4/10], Step [152/1079], Loss: 0.0052\n",
      "Epoch [4/10], Step [153/1079], Loss: 0.0123\n",
      "Epoch [4/10], Step [154/1079], Loss: 0.0009\n",
      "Epoch [4/10], Step [155/1079], Loss: 0.0208\n",
      "Epoch [4/10], Step [156/1079], Loss: 0.0198\n",
      "Epoch [4/10], Step [157/1079], Loss: 0.0230\n",
      "Epoch [4/10], Step [158/1079], Loss: 0.0089\n",
      "Epoch [4/10], Step [159/1079], Loss: 0.0208\n",
      "Epoch [4/10], Step [160/1079], Loss: 0.0238\n",
      "Epoch [4/10], Step [161/1079], Loss: 0.0032\n",
      "Epoch [4/10], Step [162/1079], Loss: 0.0144\n",
      "Epoch [4/10], Step [163/1079], Loss: 0.0497\n",
      "Epoch [4/10], Step [164/1079], Loss: 0.0034\n",
      "Epoch [4/10], Step [165/1079], Loss: 0.0410\n",
      "Epoch [4/10], Step [166/1079], Loss: 0.0013\n",
      "Epoch [4/10], Step [167/1079], Loss: 0.0171\n",
      "Epoch [4/10], Step [168/1079], Loss: 0.0032\n",
      "Epoch [4/10], Step [169/1079], Loss: 0.0052\n",
      "Epoch [4/10], Step [170/1079], Loss: 0.0432\n",
      "Epoch [4/10], Step [171/1079], Loss: 0.0051\n",
      "Epoch [4/10], Step [172/1079], Loss: 0.0421\n",
      "Epoch [4/10], Step [173/1079], Loss: 0.0168\n",
      "Epoch [4/10], Step [174/1079], Loss: 0.0078\n",
      "Epoch [4/10], Step [175/1079], Loss: 0.0204\n",
      "Epoch [4/10], Step [176/1079], Loss: 0.0019\n",
      "Epoch [4/10], Step [177/1079], Loss: 0.0014\n",
      "Epoch [4/10], Step [178/1079], Loss: 0.0066\n",
      "Epoch [4/10], Step [179/1079], Loss: 0.0240\n",
      "Epoch [4/10], Step [180/1079], Loss: 0.0104\n",
      "Epoch [4/10], Step [181/1079], Loss: 0.0015\n",
      "Epoch [4/10], Step [182/1079], Loss: 0.0186\n",
      "Epoch [4/10], Step [183/1079], Loss: 0.0115\n",
      "Epoch [4/10], Step [184/1079], Loss: 0.0556\n",
      "Epoch [4/10], Step [185/1079], Loss: 0.0262\n",
      "Epoch [4/10], Step [186/1079], Loss: 0.0180\n",
      "Epoch [4/10], Step [187/1079], Loss: 0.0023\n",
      "Epoch [4/10], Step [188/1079], Loss: 0.0249\n",
      "Epoch [4/10], Step [189/1079], Loss: 0.0238\n",
      "Epoch [4/10], Step [190/1079], Loss: 0.0034\n",
      "Epoch [4/10], Step [191/1079], Loss: 0.0028\n",
      "Epoch [4/10], Step [192/1079], Loss: 0.0120\n",
      "Epoch [4/10], Step [193/1079], Loss: 0.0058\n",
      "Epoch [4/10], Step [194/1079], Loss: 0.1019\n",
      "Epoch [4/10], Step [195/1079], Loss: 0.0709\n",
      "Epoch [4/10], Step [196/1079], Loss: 0.0118\n",
      "Epoch [4/10], Step [197/1079], Loss: 0.0041\n",
      "Epoch [4/10], Step [198/1079], Loss: 0.0001\n",
      "Epoch [4/10], Step [199/1079], Loss: 0.0343\n",
      "Epoch [4/10], Step [200/1079], Loss: 0.0147\n",
      "Epoch [4/10], Step [201/1079], Loss: 0.0078\n",
      "Epoch [4/10], Step [202/1079], Loss: 0.0020\n",
      "Epoch [4/10], Step [203/1079], Loss: 0.0540\n",
      "Epoch [4/10], Step [204/1079], Loss: 0.0014\n",
      "Epoch [4/10], Step [205/1079], Loss: 0.0148\n",
      "Epoch [4/10], Step [206/1079], Loss: 0.0357\n",
      "Epoch [4/10], Step [207/1079], Loss: 0.0043\n",
      "Epoch [4/10], Step [208/1079], Loss: 0.0029\n",
      "Epoch [4/10], Step [209/1079], Loss: 0.1036\n",
      "Epoch [4/10], Step [210/1079], Loss: 0.0167\n",
      "Epoch [4/10], Step [211/1079], Loss: 0.0018\n",
      "Epoch [4/10], Step [212/1079], Loss: 0.0023\n",
      "Epoch [4/10], Step [213/1079], Loss: 0.0056\n",
      "Epoch [4/10], Step [214/1079], Loss: 0.0454\n",
      "Epoch [4/10], Step [215/1079], Loss: 0.0516\n",
      "Epoch [4/10], Step [216/1079], Loss: 0.0454\n",
      "Epoch [4/10], Step [217/1079], Loss: 0.0092\n",
      "Epoch [4/10], Step [218/1079], Loss: 0.0043\n",
      "Epoch [4/10], Step [219/1079], Loss: 0.0339\n",
      "Epoch [4/10], Step [220/1079], Loss: 0.0102\n",
      "Epoch [4/10], Step [221/1079], Loss: 0.0024\n",
      "Epoch [4/10], Step [222/1079], Loss: 0.0973\n",
      "Epoch [4/10], Step [223/1079], Loss: 0.0019\n",
      "Epoch [4/10], Step [224/1079], Loss: 0.0556\n",
      "Epoch [4/10], Step [225/1079], Loss: 0.0070\n",
      "Epoch [4/10], Step [226/1079], Loss: 0.0413\n",
      "Epoch [4/10], Step [227/1079], Loss: 0.0144\n",
      "Epoch [4/10], Step [228/1079], Loss: 0.0024\n",
      "Epoch [4/10], Step [229/1079], Loss: 0.0325\n",
      "Epoch [4/10], Step [230/1079], Loss: 0.0111\n",
      "Epoch [4/10], Step [231/1079], Loss: 0.0021\n",
      "Epoch [4/10], Step [232/1079], Loss: 0.0789\n",
      "Epoch [4/10], Step [233/1079], Loss: 0.0188\n",
      "Epoch [4/10], Step [234/1079], Loss: 0.0088\n",
      "Epoch [4/10], Step [235/1079], Loss: 0.0026\n",
      "Epoch [4/10], Step [236/1079], Loss: 0.0114\n",
      "Epoch [4/10], Step [237/1079], Loss: 0.0264\n",
      "Epoch [4/10], Step [238/1079], Loss: 0.0748\n",
      "Epoch [4/10], Step [239/1079], Loss: 0.0633\n",
      "Epoch [4/10], Step [240/1079], Loss: 0.0570\n",
      "Epoch [4/10], Step [241/1079], Loss: 0.0390\n",
      "Epoch [4/10], Step [242/1079], Loss: 0.0146\n",
      "Epoch [4/10], Step [243/1079], Loss: 0.0042\n",
      "Epoch [4/10], Step [244/1079], Loss: 0.0054\n",
      "Epoch [4/10], Step [245/1079], Loss: 0.0033\n",
      "Epoch [4/10], Step [246/1079], Loss: 0.0061\n",
      "Epoch [4/10], Step [247/1079], Loss: 0.0190\n",
      "Epoch [4/10], Step [248/1079], Loss: 0.0637\n",
      "Epoch [4/10], Step [249/1079], Loss: 0.0344\n",
      "Epoch [4/10], Step [250/1079], Loss: 0.0544\n",
      "Epoch [4/10], Step [251/1079], Loss: 0.0016\n",
      "Epoch [4/10], Step [252/1079], Loss: 0.0114\n",
      "Epoch [4/10], Step [253/1079], Loss: 0.0067\n",
      "Epoch [4/10], Step [254/1079], Loss: 0.0029\n",
      "Epoch [4/10], Step [255/1079], Loss: 0.0136\n",
      "Epoch [4/10], Step [256/1079], Loss: 0.0140\n",
      "Epoch [4/10], Step [257/1079], Loss: 0.0026\n",
      "Epoch [4/10], Step [258/1079], Loss: 0.0092\n",
      "Epoch [4/10], Step [259/1079], Loss: 0.0074\n",
      "Epoch [4/10], Step [260/1079], Loss: 0.0117\n",
      "Epoch [4/10], Step [261/1079], Loss: 0.0502\n",
      "Epoch [4/10], Step [262/1079], Loss: 0.0016\n",
      "Epoch [4/10], Step [263/1079], Loss: 0.0251\n",
      "Epoch [4/10], Step [264/1079], Loss: 0.0006\n",
      "Epoch [4/10], Step [265/1079], Loss: 0.0323\n",
      "Epoch [4/10], Step [266/1079], Loss: 0.0008\n",
      "Epoch [4/10], Step [267/1079], Loss: 0.0050\n",
      "Epoch [4/10], Step [268/1079], Loss: 0.0125\n",
      "Epoch [4/10], Step [269/1079], Loss: 0.0458\n",
      "Epoch [4/10], Step [270/1079], Loss: 0.0148\n",
      "Epoch [4/10], Step [271/1079], Loss: 0.0269\n",
      "Epoch [4/10], Step [272/1079], Loss: 0.0260\n",
      "Epoch [4/10], Step [273/1079], Loss: 0.0009\n",
      "Epoch [4/10], Step [274/1079], Loss: 0.0434\n",
      "Epoch [4/10], Step [275/1079], Loss: 0.0094\n",
      "Epoch [4/10], Step [276/1079], Loss: 0.0212\n",
      "Epoch [4/10], Step [277/1079], Loss: 0.0012\n",
      "Epoch [4/10], Step [278/1079], Loss: 0.0074\n",
      "Epoch [4/10], Step [279/1079], Loss: 0.0015\n",
      "Epoch [4/10], Step [280/1079], Loss: 0.0049\n",
      "Epoch [4/10], Step [281/1079], Loss: 0.0219\n",
      "Epoch [4/10], Step [282/1079], Loss: 0.0083\n",
      "Epoch [4/10], Step [283/1079], Loss: 0.0090\n",
      "Epoch [4/10], Step [284/1079], Loss: 0.0035\n",
      "Epoch [4/10], Step [285/1079], Loss: 0.0005\n",
      "Epoch [4/10], Step [286/1079], Loss: 0.0025\n",
      "Epoch [4/10], Step [287/1079], Loss: 0.0388\n",
      "Epoch [4/10], Step [288/1079], Loss: 0.0029\n",
      "Epoch [4/10], Step [289/1079], Loss: 0.0107\n",
      "Epoch [4/10], Step [290/1079], Loss: 0.0633\n",
      "Epoch [4/10], Step [291/1079], Loss: 0.0008\n",
      "Epoch [4/10], Step [292/1079], Loss: 0.0015\n",
      "Epoch [4/10], Step [293/1079], Loss: 0.0046\n",
      "Epoch [4/10], Step [294/1079], Loss: 0.0220\n",
      "Epoch [4/10], Step [295/1079], Loss: 0.0644\n",
      "Epoch [4/10], Step [296/1079], Loss: 0.0133\n",
      "Epoch [4/10], Step [297/1079], Loss: 0.0005\n",
      "Epoch [4/10], Step [298/1079], Loss: 0.0381\n",
      "Epoch [4/10], Step [299/1079], Loss: 0.0093\n",
      "Epoch [4/10], Step [300/1079], Loss: 0.0164\n",
      "Epoch [4/10], Step [301/1079], Loss: 0.0004\n",
      "Epoch [4/10], Step [302/1079], Loss: 0.0134\n",
      "Epoch [4/10], Step [303/1079], Loss: 0.0136\n",
      "Epoch [4/10], Step [304/1079], Loss: 0.0053\n",
      "Epoch [4/10], Step [305/1079], Loss: 0.0008\n",
      "Epoch [4/10], Step [306/1079], Loss: 0.0007\n",
      "Epoch [4/10], Step [307/1079], Loss: 0.0177\n",
      "Epoch [4/10], Step [308/1079], Loss: 0.0093\n",
      "Epoch [4/10], Step [309/1079], Loss: 0.0025\n",
      "Epoch [4/10], Step [310/1079], Loss: 0.0166\n",
      "Epoch [4/10], Step [311/1079], Loss: 0.0201\n",
      "Epoch [4/10], Step [312/1079], Loss: 0.0025\n",
      "Epoch [4/10], Step [313/1079], Loss: 0.0059\n",
      "Epoch [4/10], Step [314/1079], Loss: 0.0022\n",
      "Epoch [4/10], Step [315/1079], Loss: 0.0428\n",
      "Epoch [4/10], Step [316/1079], Loss: 0.0007\n",
      "Epoch [4/10], Step [317/1079], Loss: 0.0197\n",
      "Epoch [4/10], Step [318/1079], Loss: 0.0204\n",
      "Epoch [4/10], Step [319/1079], Loss: 0.0058\n",
      "Epoch [4/10], Step [320/1079], Loss: 0.0001\n",
      "Epoch [4/10], Step [321/1079], Loss: 0.0123\n",
      "Epoch [4/10], Step [322/1079], Loss: 0.0061\n",
      "Epoch [4/10], Step [323/1079], Loss: 0.0004\n",
      "Epoch [4/10], Step [324/1079], Loss: 0.0320\n",
      "Epoch [4/10], Step [325/1079], Loss: 0.0033\n",
      "Epoch [4/10], Step [326/1079], Loss: 0.0015\n",
      "Epoch [4/10], Step [327/1079], Loss: 0.0147\n",
      "Epoch [4/10], Step [328/1079], Loss: 0.0286\n",
      "Epoch [4/10], Step [329/1079], Loss: 0.0417\n",
      "Epoch [4/10], Step [330/1079], Loss: 0.0006\n",
      "Epoch [4/10], Step [331/1079], Loss: 0.0024\n",
      "Epoch [4/10], Step [332/1079], Loss: 0.0002\n",
      "Epoch [4/10], Step [333/1079], Loss: 0.0014\n",
      "Epoch [4/10], Step [334/1079], Loss: 0.0353\n",
      "Epoch [4/10], Step [335/1079], Loss: 0.0004\n",
      "Epoch [4/10], Step [336/1079], Loss: 0.0035\n",
      "Epoch [4/10], Step [337/1079], Loss: 0.0089\n",
      "Epoch [4/10], Step [338/1079], Loss: 0.0056\n",
      "Epoch [4/10], Step [339/1079], Loss: 0.0024\n",
      "Epoch [4/10], Step [340/1079], Loss: 0.0044\n",
      "Epoch [4/10], Step [341/1079], Loss: 0.0275\n",
      "Epoch [4/10], Step [342/1079], Loss: 0.1330\n",
      "Epoch [4/10], Step [343/1079], Loss: 0.0575\n",
      "Epoch [4/10], Step [344/1079], Loss: 0.0319\n",
      "Epoch [4/10], Step [345/1079], Loss: 0.0049\n",
      "Epoch [4/10], Step [346/1079], Loss: 0.0176\n",
      "Epoch [4/10], Step [347/1079], Loss: 0.0038\n",
      "Epoch [4/10], Step [348/1079], Loss: 0.0004\n",
      "Epoch [4/10], Step [349/1079], Loss: 0.0078\n",
      "Epoch [4/10], Step [350/1079], Loss: 0.0118\n",
      "Epoch [4/10], Step [351/1079], Loss: 0.0545\n",
      "Epoch [4/10], Step [352/1079], Loss: 0.0314\n",
      "Epoch [4/10], Step [353/1079], Loss: 0.0230\n",
      "Epoch [4/10], Step [354/1079], Loss: 0.0015\n",
      "Epoch [4/10], Step [355/1079], Loss: 0.0051\n",
      "Epoch [4/10], Step [356/1079], Loss: 0.0003\n",
      "Epoch [4/10], Step [357/1079], Loss: 0.0024\n",
      "Epoch [4/10], Step [358/1079], Loss: 0.0895\n",
      "Epoch [4/10], Step [359/1079], Loss: 0.0029\n",
      "Epoch [4/10], Step [360/1079], Loss: 0.0147\n",
      "Epoch [4/10], Step [361/1079], Loss: 0.0255\n",
      "Epoch [4/10], Step [362/1079], Loss: 0.0074\n",
      "Epoch [4/10], Step [363/1079], Loss: 0.0464\n",
      "Epoch [4/10], Step [364/1079], Loss: 0.0529\n",
      "Epoch [4/10], Step [365/1079], Loss: 0.0382\n",
      "Epoch [4/10], Step [366/1079], Loss: 0.0074\n",
      "Epoch [4/10], Step [367/1079], Loss: 0.0003\n",
      "Epoch [4/10], Step [368/1079], Loss: 0.0014\n",
      "Epoch [4/10], Step [369/1079], Loss: 0.0717\n",
      "Epoch [4/10], Step [370/1079], Loss: 0.0427\n",
      "Epoch [4/10], Step [371/1079], Loss: 0.0330\n",
      "Epoch [4/10], Step [372/1079], Loss: 0.0034\n",
      "Epoch [4/10], Step [373/1079], Loss: 0.0013\n",
      "Epoch [4/10], Step [374/1079], Loss: 0.0574\n",
      "Epoch [4/10], Step [375/1079], Loss: 0.0268\n",
      "Epoch [4/10], Step [376/1079], Loss: 0.0033\n",
      "Epoch [4/10], Step [377/1079], Loss: 0.0088\n",
      "Epoch [4/10], Step [378/1079], Loss: 0.0699\n",
      "Epoch [4/10], Step [379/1079], Loss: 0.0175\n",
      "Epoch [4/10], Step [380/1079], Loss: 0.0224\n",
      "Epoch [4/10], Step [381/1079], Loss: 0.0981\n",
      "Epoch [4/10], Step [382/1079], Loss: 0.0015\n",
      "Epoch [4/10], Step [383/1079], Loss: 0.0146\n",
      "Epoch [4/10], Step [384/1079], Loss: 0.0566\n",
      "Epoch [4/10], Step [385/1079], Loss: 0.0064\n",
      "Epoch [4/10], Step [386/1079], Loss: 0.0035\n",
      "Epoch [4/10], Step [387/1079], Loss: 0.0004\n",
      "Epoch [4/10], Step [388/1079], Loss: 0.0443\n",
      "Epoch [4/10], Step [389/1079], Loss: 0.0367\n",
      "Epoch [4/10], Step [390/1079], Loss: 0.0504\n",
      "Epoch [4/10], Step [391/1079], Loss: 0.0107\n",
      "Epoch [4/10], Step [392/1079], Loss: 0.0792\n",
      "Epoch [4/10], Step [393/1079], Loss: 0.1204\n",
      "Epoch [4/10], Step [394/1079], Loss: 0.0084\n",
      "Epoch [4/10], Step [395/1079], Loss: 0.0260\n",
      "Epoch [4/10], Step [396/1079], Loss: 0.0059\n",
      "Epoch [4/10], Step [397/1079], Loss: 0.0065\n",
      "Epoch [4/10], Step [398/1079], Loss: 0.0058\n",
      "Epoch [4/10], Step [399/1079], Loss: 0.0014\n",
      "Epoch [4/10], Step [400/1079], Loss: 0.0011\n",
      "Epoch [4/10], Step [401/1079], Loss: 0.1953\n",
      "Epoch [4/10], Step [402/1079], Loss: 0.0035\n",
      "Epoch [4/10], Step [403/1079], Loss: 0.0047\n",
      "Epoch [4/10], Step [404/1079], Loss: 0.1918\n",
      "Epoch [4/10], Step [405/1079], Loss: 0.0211\n",
      "Epoch [4/10], Step [406/1079], Loss: 0.0202\n",
      "Epoch [4/10], Step [407/1079], Loss: 0.0051\n",
      "Epoch [4/10], Step [408/1079], Loss: 0.0034\n",
      "Epoch [4/10], Step [409/1079], Loss: 0.0409\n",
      "Epoch [4/10], Step [410/1079], Loss: 0.0055\n",
      "Epoch [4/10], Step [411/1079], Loss: 0.0116\n",
      "Epoch [4/10], Step [412/1079], Loss: 0.0211\n",
      "Epoch [4/10], Step [413/1079], Loss: 0.0240\n",
      "Epoch [4/10], Step [414/1079], Loss: 0.0531\n",
      "Epoch [4/10], Step [415/1079], Loss: 0.0063\n",
      "Epoch [4/10], Step [416/1079], Loss: 0.0332\n",
      "Epoch [4/10], Step [417/1079], Loss: 0.0024\n",
      "Epoch [4/10], Step [418/1079], Loss: 0.0084\n",
      "Epoch [4/10], Step [419/1079], Loss: 0.0103\n",
      "Epoch [4/10], Step [420/1079], Loss: 0.0502\n",
      "Epoch [4/10], Step [421/1079], Loss: 0.0439\n",
      "Epoch [4/10], Step [422/1079], Loss: 0.0181\n",
      "Epoch [4/10], Step [423/1079], Loss: 0.0516\n",
      "Epoch [4/10], Step [424/1079], Loss: 0.0027\n",
      "Epoch [4/10], Step [425/1079], Loss: 0.0088\n",
      "Epoch [4/10], Step [426/1079], Loss: 0.0024\n",
      "Epoch [4/10], Step [427/1079], Loss: 0.0016\n",
      "Epoch [4/10], Step [428/1079], Loss: 0.1005\n",
      "Epoch [4/10], Step [429/1079], Loss: 0.0046\n",
      "Epoch [4/10], Step [430/1079], Loss: 0.0032\n",
      "Epoch [4/10], Step [431/1079], Loss: 0.0304\n",
      "Epoch [4/10], Step [432/1079], Loss: 0.0134\n",
      "Epoch [4/10], Step [433/1079], Loss: 0.0016\n",
      "Epoch [4/10], Step [434/1079], Loss: 0.0020\n",
      "Epoch [4/10], Step [435/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [436/1079], Loss: 0.0406\n",
      "Epoch [4/10], Step [437/1079], Loss: 0.0031\n",
      "Epoch [4/10], Step [438/1079], Loss: 0.0030\n",
      "Epoch [4/10], Step [439/1079], Loss: 0.0249\n",
      "Epoch [4/10], Step [440/1079], Loss: 0.0072\n",
      "Epoch [4/10], Step [441/1079], Loss: 0.0234\n",
      "Epoch [4/10], Step [442/1079], Loss: 0.0304\n",
      "Epoch [4/10], Step [443/1079], Loss: 0.0437\n",
      "Epoch [4/10], Step [444/1079], Loss: 0.0046\n",
      "Epoch [4/10], Step [445/1079], Loss: 0.0259\n",
      "Epoch [4/10], Step [446/1079], Loss: 0.0151\n",
      "Epoch [4/10], Step [447/1079], Loss: 0.0053\n",
      "Epoch [4/10], Step [448/1079], Loss: 0.0367\n",
      "Epoch [4/10], Step [449/1079], Loss: 0.0265\n",
      "Epoch [4/10], Step [450/1079], Loss: 0.0139\n",
      "Epoch [4/10], Step [451/1079], Loss: 0.0005\n",
      "Epoch [4/10], Step [452/1079], Loss: 0.0020\n",
      "Epoch [4/10], Step [453/1079], Loss: 0.0110\n",
      "Epoch [4/10], Step [454/1079], Loss: 0.0086\n",
      "Epoch [4/10], Step [455/1079], Loss: 0.0069\n",
      "Epoch [4/10], Step [456/1079], Loss: 0.0635\n",
      "Epoch [4/10], Step [457/1079], Loss: 0.0173\n",
      "Epoch [4/10], Step [458/1079], Loss: 0.0039\n",
      "Epoch [4/10], Step [459/1079], Loss: 0.0173\n",
      "Epoch [4/10], Step [460/1079], Loss: 0.0045\n",
      "Epoch [4/10], Step [461/1079], Loss: 0.0012\n",
      "Epoch [4/10], Step [462/1079], Loss: 0.0033\n",
      "Epoch [4/10], Step [463/1079], Loss: 0.0322\n",
      "Epoch [4/10], Step [464/1079], Loss: 0.0060\n",
      "Epoch [4/10], Step [465/1079], Loss: 0.0712\n",
      "Epoch [4/10], Step [466/1079], Loss: 0.0538\n",
      "Epoch [4/10], Step [467/1079], Loss: 0.0425\n",
      "Epoch [4/10], Step [468/1079], Loss: 0.0082\n",
      "Epoch [4/10], Step [469/1079], Loss: 0.0302\n",
      "Epoch [4/10], Step [470/1079], Loss: 0.0163\n",
      "Epoch [4/10], Step [471/1079], Loss: 0.0097\n",
      "Epoch [4/10], Step [472/1079], Loss: 0.0264\n",
      "Epoch [4/10], Step [473/1079], Loss: 0.0032\n",
      "Epoch [4/10], Step [474/1079], Loss: 0.0165\n",
      "Epoch [4/10], Step [475/1079], Loss: 0.0417\n",
      "Epoch [4/10], Step [476/1079], Loss: 0.0033\n",
      "Epoch [4/10], Step [477/1079], Loss: 0.0461\n",
      "Epoch [4/10], Step [478/1079], Loss: 0.0205\n",
      "Epoch [4/10], Step [479/1079], Loss: 0.0030\n",
      "Epoch [4/10], Step [480/1079], Loss: 0.0524\n",
      "Epoch [4/10], Step [481/1079], Loss: 0.0131\n",
      "Epoch [4/10], Step [482/1079], Loss: 0.0064\n",
      "Epoch [4/10], Step [483/1079], Loss: 0.0258\n",
      "Epoch [4/10], Step [484/1079], Loss: 0.0211\n",
      "Epoch [4/10], Step [485/1079], Loss: 0.0130\n",
      "Epoch [4/10], Step [486/1079], Loss: 0.0126\n",
      "Epoch [4/10], Step [487/1079], Loss: 0.0093\n",
      "Epoch [4/10], Step [488/1079], Loss: 0.0103\n",
      "Epoch [4/10], Step [489/1079], Loss: 0.0018\n",
      "Epoch [4/10], Step [490/1079], Loss: 0.0559\n",
      "Epoch [4/10], Step [491/1079], Loss: 0.0003\n",
      "Epoch [4/10], Step [492/1079], Loss: 0.0066\n",
      "Epoch [4/10], Step [493/1079], Loss: 0.0287\n",
      "Epoch [4/10], Step [494/1079], Loss: 0.0054\n",
      "Epoch [4/10], Step [495/1079], Loss: 0.0006\n",
      "Epoch [4/10], Step [496/1079], Loss: 0.0068\n",
      "Epoch [4/10], Step [497/1079], Loss: 0.0304\n",
      "Epoch [4/10], Step [498/1079], Loss: 0.1217\n",
      "Epoch [4/10], Step [499/1079], Loss: 0.0050\n",
      "Epoch [4/10], Step [500/1079], Loss: 0.0117\n",
      "Epoch [4/10], Step [501/1079], Loss: 0.0127\n",
      "Epoch [4/10], Step [502/1079], Loss: 0.0014\n",
      "Epoch [4/10], Step [503/1079], Loss: 0.0025\n",
      "Epoch [4/10], Step [504/1079], Loss: 0.1343\n",
      "Epoch [4/10], Step [505/1079], Loss: 0.1332\n",
      "Epoch [4/10], Step [506/1079], Loss: 0.0079\n",
      "Epoch [4/10], Step [507/1079], Loss: 0.0065\n",
      "Epoch [4/10], Step [508/1079], Loss: 0.0053\n",
      "Epoch [4/10], Step [509/1079], Loss: 0.0051\n",
      "Epoch [4/10], Step [510/1079], Loss: 0.0408\n",
      "Epoch [4/10], Step [511/1079], Loss: 0.0011\n",
      "Epoch [4/10], Step [512/1079], Loss: 0.0020\n",
      "Epoch [4/10], Step [513/1079], Loss: 0.0014\n",
      "Epoch [4/10], Step [514/1079], Loss: 0.0026\n",
      "Epoch [4/10], Step [515/1079], Loss: 0.0025\n",
      "Epoch [4/10], Step [516/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [517/1079], Loss: 0.0052\n",
      "Epoch [4/10], Step [518/1079], Loss: 0.0165\n",
      "Epoch [4/10], Step [519/1079], Loss: 0.0006\n",
      "Epoch [4/10], Step [520/1079], Loss: 0.0226\n",
      "Epoch [4/10], Step [521/1079], Loss: 0.0176\n",
      "Epoch [4/10], Step [522/1079], Loss: 0.0345\n",
      "Epoch [4/10], Step [523/1079], Loss: 0.0724\n",
      "Epoch [4/10], Step [524/1079], Loss: 0.0031\n",
      "Epoch [4/10], Step [525/1079], Loss: 0.0036\n",
      "Epoch [4/10], Step [526/1079], Loss: 0.0103\n",
      "Epoch [4/10], Step [527/1079], Loss: 0.0178\n",
      "Epoch [4/10], Step [528/1079], Loss: 0.0056\n",
      "Epoch [4/10], Step [529/1079], Loss: 0.0139\n",
      "Epoch [4/10], Step [530/1079], Loss: 0.1081\n",
      "Epoch [4/10], Step [531/1079], Loss: 0.0062\n",
      "Epoch [4/10], Step [532/1079], Loss: 0.0235\n",
      "Epoch [4/10], Step [533/1079], Loss: 0.0048\n",
      "Epoch [4/10], Step [534/1079], Loss: 0.0145\n",
      "Epoch [4/10], Step [535/1079], Loss: 0.0159\n",
      "Epoch [4/10], Step [536/1079], Loss: 0.0091\n",
      "Epoch [4/10], Step [537/1079], Loss: 0.0020\n",
      "Epoch [4/10], Step [538/1079], Loss: 0.0029\n",
      "Epoch [4/10], Step [539/1079], Loss: 0.1153\n",
      "Epoch [4/10], Step [540/1079], Loss: 0.0463\n",
      "Epoch [4/10], Step [541/1079], Loss: 0.0104\n",
      "Epoch [4/10], Step [542/1079], Loss: 0.0460\n",
      "Epoch [4/10], Step [543/1079], Loss: 0.0118\n",
      "Epoch [4/10], Step [544/1079], Loss: 0.0172\n",
      "Epoch [4/10], Step [545/1079], Loss: 0.0051\n",
      "Epoch [4/10], Step [546/1079], Loss: 0.0034\n",
      "Epoch [4/10], Step [547/1079], Loss: 0.0056\n",
      "Epoch [4/10], Step [548/1079], Loss: 0.0006\n",
      "Epoch [4/10], Step [549/1079], Loss: 0.0072\n",
      "Epoch [4/10], Step [550/1079], Loss: 0.0016\n",
      "Epoch [4/10], Step [551/1079], Loss: 0.0620\n",
      "Epoch [4/10], Step [552/1079], Loss: 0.0591\n",
      "Epoch [4/10], Step [553/1079], Loss: 0.0009\n",
      "Epoch [4/10], Step [554/1079], Loss: 0.0744\n",
      "Epoch [4/10], Step [555/1079], Loss: 0.0286\n",
      "Epoch [4/10], Step [556/1079], Loss: 0.0135\n",
      "Epoch [4/10], Step [557/1079], Loss: 0.0009\n",
      "Epoch [4/10], Step [558/1079], Loss: 0.0062\n",
      "Epoch [4/10], Step [559/1079], Loss: 0.0013\n",
      "Epoch [4/10], Step [560/1079], Loss: 0.0590\n",
      "Epoch [4/10], Step [561/1079], Loss: 0.0069\n",
      "Epoch [4/10], Step [562/1079], Loss: 0.0079\n",
      "Epoch [4/10], Step [563/1079], Loss: 0.0138\n",
      "Epoch [4/10], Step [564/1079], Loss: 0.0038\n",
      "Epoch [4/10], Step [565/1079], Loss: 0.0033\n",
      "Epoch [4/10], Step [566/1079], Loss: 0.0065\n",
      "Epoch [4/10], Step [567/1079], Loss: 0.0266\n",
      "Epoch [4/10], Step [568/1079], Loss: 0.0088\n",
      "Epoch [4/10], Step [569/1079], Loss: 0.0134\n",
      "Epoch [4/10], Step [570/1079], Loss: 0.0010\n",
      "Epoch [4/10], Step [571/1079], Loss: 0.0319\n",
      "Epoch [4/10], Step [572/1079], Loss: 0.0265\n",
      "Epoch [4/10], Step [573/1079], Loss: 0.0050\n",
      "Epoch [4/10], Step [574/1079], Loss: 0.0332\n",
      "Epoch [4/10], Step [575/1079], Loss: 0.0197\n",
      "Epoch [4/10], Step [576/1079], Loss: 0.0778\n",
      "Epoch [4/10], Step [577/1079], Loss: 0.0361\n",
      "Epoch [4/10], Step [578/1079], Loss: 0.0020\n",
      "Epoch [4/10], Step [579/1079], Loss: 0.0246\n",
      "Epoch [4/10], Step [580/1079], Loss: 0.0170\n",
      "Epoch [4/10], Step [581/1079], Loss: 0.0053\n",
      "Epoch [4/10], Step [582/1079], Loss: 0.1040\n",
      "Epoch [4/10], Step [583/1079], Loss: 0.0065\n",
      "Epoch [4/10], Step [584/1079], Loss: 0.0012\n",
      "Epoch [4/10], Step [585/1079], Loss: 0.0011\n",
      "Epoch [4/10], Step [586/1079], Loss: 0.0166\n",
      "Epoch [4/10], Step [587/1079], Loss: 0.0100\n",
      "Epoch [4/10], Step [588/1079], Loss: 0.0623\n",
      "Epoch [4/10], Step [589/1079], Loss: 0.0027\n",
      "Epoch [4/10], Step [590/1079], Loss: 0.0021\n",
      "Epoch [4/10], Step [591/1079], Loss: 0.0065\n",
      "Epoch [4/10], Step [592/1079], Loss: 0.0516\n",
      "Epoch [4/10], Step [593/1079], Loss: 0.0023\n",
      "Epoch [4/10], Step [594/1079], Loss: 0.0022\n",
      "Epoch [4/10], Step [595/1079], Loss: 0.0400\n",
      "Epoch [4/10], Step [596/1079], Loss: 0.0099\n",
      "Epoch [4/10], Step [597/1079], Loss: 0.0188\n",
      "Epoch [4/10], Step [598/1079], Loss: 0.0178\n",
      "Epoch [4/10], Step [599/1079], Loss: 0.0646\n",
      "Epoch [4/10], Step [600/1079], Loss: 0.1402\n",
      "Epoch [4/10], Step [601/1079], Loss: 0.0089\n",
      "Epoch [4/10], Step [602/1079], Loss: 0.0082\n",
      "Epoch [4/10], Step [603/1079], Loss: 0.0015\n",
      "Epoch [4/10], Step [604/1079], Loss: 0.0090\n",
      "Epoch [4/10], Step [605/1079], Loss: 0.0691\n",
      "Epoch [4/10], Step [606/1079], Loss: 0.0250\n",
      "Epoch [4/10], Step [607/1079], Loss: 0.0026\n",
      "Epoch [4/10], Step [608/1079], Loss: 0.0658\n",
      "Epoch [4/10], Step [609/1079], Loss: 0.0127\n",
      "Epoch [4/10], Step [610/1079], Loss: 0.0291\n",
      "Epoch [4/10], Step [611/1079], Loss: 0.0035\n",
      "Epoch [4/10], Step [612/1079], Loss: 0.0202\n",
      "Epoch [4/10], Step [613/1079], Loss: 0.0338\n",
      "Epoch [4/10], Step [614/1079], Loss: 0.0552\n",
      "Epoch [4/10], Step [615/1079], Loss: 0.0926\n",
      "Epoch [4/10], Step [616/1079], Loss: 0.0084\n",
      "Epoch [4/10], Step [617/1079], Loss: 0.0031\n",
      "Epoch [4/10], Step [618/1079], Loss: 0.0016\n",
      "Epoch [4/10], Step [619/1079], Loss: 0.0029\n",
      "Epoch [4/10], Step [620/1079], Loss: 0.2298\n",
      "Epoch [4/10], Step [621/1079], Loss: 0.0101\n",
      "Epoch [4/10], Step [622/1079], Loss: 0.0251\n",
      "Epoch [4/10], Step [623/1079], Loss: 0.0054\n",
      "Epoch [4/10], Step [624/1079], Loss: 0.0026\n",
      "Epoch [4/10], Step [625/1079], Loss: 0.0634\n",
      "Epoch [4/10], Step [626/1079], Loss: 0.0005\n",
      "Epoch [4/10], Step [627/1079], Loss: 0.0110\n",
      "Epoch [4/10], Step [628/1079], Loss: 0.0228\n",
      "Epoch [4/10], Step [629/1079], Loss: 0.0081\n",
      "Epoch [4/10], Step [630/1079], Loss: 0.0777\n",
      "Epoch [4/10], Step [631/1079], Loss: 0.0431\n",
      "Epoch [4/10], Step [632/1079], Loss: 0.0087\n",
      "Epoch [4/10], Step [633/1079], Loss: 0.0053\n",
      "Epoch [4/10], Step [634/1079], Loss: 0.0129\n",
      "Epoch [4/10], Step [635/1079], Loss: 0.0110\n",
      "Epoch [4/10], Step [636/1079], Loss: 0.0108\n",
      "Epoch [4/10], Step [637/1079], Loss: 0.0030\n",
      "Epoch [4/10], Step [638/1079], Loss: 0.0030\n",
      "Epoch [4/10], Step [639/1079], Loss: 0.0130\n",
      "Epoch [4/10], Step [640/1079], Loss: 0.0106\n",
      "Epoch [4/10], Step [641/1079], Loss: 0.0463\n",
      "Epoch [4/10], Step [642/1079], Loss: 0.0914\n",
      "Epoch [4/10], Step [643/1079], Loss: 0.0222\n",
      "Epoch [4/10], Step [644/1079], Loss: 0.0010\n",
      "Epoch [4/10], Step [645/1079], Loss: 0.0340\n",
      "Epoch [4/10], Step [646/1079], Loss: 0.0252\n",
      "Epoch [4/10], Step [647/1079], Loss: 0.0216\n",
      "Epoch [4/10], Step [648/1079], Loss: 0.0096\n",
      "Epoch [4/10], Step [649/1079], Loss: 0.0070\n",
      "Epoch [4/10], Step [650/1079], Loss: 0.0104\n",
      "Epoch [4/10], Step [651/1079], Loss: 0.0053\n",
      "Epoch [4/10], Step [652/1079], Loss: 0.0763\n",
      "Epoch [4/10], Step [653/1079], Loss: 0.0017\n",
      "Epoch [4/10], Step [654/1079], Loss: 0.1082\n",
      "Epoch [4/10], Step [655/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [656/1079], Loss: 0.0630\n",
      "Epoch [4/10], Step [657/1079], Loss: 0.0068\n",
      "Epoch [4/10], Step [658/1079], Loss: 0.0274\n",
      "Epoch [4/10], Step [659/1079], Loss: 0.0050\n",
      "Epoch [4/10], Step [660/1079], Loss: 0.0448\n",
      "Epoch [4/10], Step [661/1079], Loss: 0.0058\n",
      "Epoch [4/10], Step [662/1079], Loss: 0.0316\n",
      "Epoch [4/10], Step [663/1079], Loss: 0.0024\n",
      "Epoch [4/10], Step [664/1079], Loss: 0.0132\n",
      "Epoch [4/10], Step [665/1079], Loss: 0.0059\n",
      "Epoch [4/10], Step [666/1079], Loss: 0.0019\n",
      "Epoch [4/10], Step [667/1079], Loss: 0.0393\n",
      "Epoch [4/10], Step [668/1079], Loss: 0.0041\n",
      "Epoch [4/10], Step [669/1079], Loss: 0.0045\n",
      "Epoch [4/10], Step [670/1079], Loss: 0.0011\n",
      "Epoch [4/10], Step [671/1079], Loss: 0.0191\n",
      "Epoch [4/10], Step [672/1079], Loss: 0.0839\n",
      "Epoch [4/10], Step [673/1079], Loss: 0.0423\n",
      "Epoch [4/10], Step [674/1079], Loss: 0.0619\n",
      "Epoch [4/10], Step [675/1079], Loss: 0.1066\n",
      "Epoch [4/10], Step [676/1079], Loss: 0.0052\n",
      "Epoch [4/10], Step [677/1079], Loss: 0.0042\n",
      "Epoch [4/10], Step [678/1079], Loss: 0.0058\n",
      "Epoch [4/10], Step [679/1079], Loss: 0.0105\n",
      "Epoch [4/10], Step [680/1079], Loss: 0.0010\n",
      "Epoch [4/10], Step [681/1079], Loss: 0.0281\n",
      "Epoch [4/10], Step [682/1079], Loss: 0.0175\n",
      "Epoch [4/10], Step [683/1079], Loss: 0.0035\n",
      "Epoch [4/10], Step [684/1079], Loss: 0.0140\n",
      "Epoch [4/10], Step [685/1079], Loss: 0.0130\n",
      "Epoch [4/10], Step [686/1079], Loss: 0.0827\n",
      "Epoch [4/10], Step [687/1079], Loss: 0.0011\n",
      "Epoch [4/10], Step [688/1079], Loss: 0.0031\n",
      "Epoch [4/10], Step [689/1079], Loss: 0.0068\n",
      "Epoch [4/10], Step [690/1079], Loss: 0.0582\n",
      "Epoch [4/10], Step [691/1079], Loss: 0.0114\n",
      "Epoch [4/10], Step [692/1079], Loss: 0.0276\n",
      "Epoch [4/10], Step [693/1079], Loss: 0.0086\n",
      "Epoch [4/10], Step [694/1079], Loss: 0.0086\n",
      "Epoch [4/10], Step [695/1079], Loss: 0.0105\n",
      "Epoch [4/10], Step [696/1079], Loss: 0.0084\n",
      "Epoch [4/10], Step [697/1079], Loss: 0.0188\n",
      "Epoch [4/10], Step [698/1079], Loss: 0.0112\n",
      "Epoch [4/10], Step [699/1079], Loss: 0.0071\n",
      "Epoch [4/10], Step [700/1079], Loss: 0.0028\n",
      "Epoch [4/10], Step [701/1079], Loss: 0.2909\n",
      "Epoch [4/10], Step [702/1079], Loss: 0.0492\n",
      "Epoch [4/10], Step [703/1079], Loss: 0.0338\n",
      "Epoch [4/10], Step [704/1079], Loss: 0.0258\n",
      "Epoch [4/10], Step [705/1079], Loss: 0.0610\n",
      "Epoch [4/10], Step [706/1079], Loss: 0.0133\n",
      "Epoch [4/10], Step [707/1079], Loss: 0.0049\n",
      "Epoch [4/10], Step [708/1079], Loss: 0.0365\n",
      "Epoch [4/10], Step [709/1079], Loss: 0.0043\n",
      "Epoch [4/10], Step [710/1079], Loss: 0.0050\n",
      "Epoch [4/10], Step [711/1079], Loss: 0.0070\n",
      "Epoch [4/10], Step [712/1079], Loss: 0.0321\n",
      "Epoch [4/10], Step [713/1079], Loss: 0.0031\n",
      "Epoch [4/10], Step [714/1079], Loss: 0.0282\n",
      "Epoch [4/10], Step [715/1079], Loss: 0.0486\n",
      "Epoch [4/10], Step [716/1079], Loss: 0.0253\n",
      "Epoch [4/10], Step [717/1079], Loss: 0.0112\n",
      "Epoch [4/10], Step [718/1079], Loss: 0.0111\n",
      "Epoch [4/10], Step [719/1079], Loss: 0.0669\n",
      "Epoch [4/10], Step [720/1079], Loss: 0.0256\n",
      "Epoch [4/10], Step [721/1079], Loss: 0.0256\n",
      "Epoch [4/10], Step [722/1079], Loss: 0.0156\n",
      "Epoch [4/10], Step [723/1079], Loss: 0.0016\n",
      "Epoch [4/10], Step [724/1079], Loss: 0.0099\n",
      "Epoch [4/10], Step [725/1079], Loss: 0.0150\n",
      "Epoch [4/10], Step [726/1079], Loss: 0.0091\n",
      "Epoch [4/10], Step [727/1079], Loss: 0.0022\n",
      "Epoch [4/10], Step [728/1079], Loss: 0.0010\n",
      "Epoch [4/10], Step [729/1079], Loss: 0.0412\n",
      "Epoch [4/10], Step [730/1079], Loss: 0.0050\n",
      "Epoch [4/10], Step [731/1079], Loss: 0.0362\n",
      "Epoch [4/10], Step [732/1079], Loss: 0.0420\n",
      "Epoch [4/10], Step [733/1079], Loss: 0.1297\n",
      "Epoch [4/10], Step [734/1079], Loss: 0.1272\n",
      "Epoch [4/10], Step [735/1079], Loss: 0.0154\n",
      "Epoch [4/10], Step [736/1079], Loss: 0.0346\n",
      "Epoch [4/10], Step [737/1079], Loss: 0.0013\n",
      "Epoch [4/10], Step [738/1079], Loss: 0.0167\n",
      "Epoch [4/10], Step [739/1079], Loss: 0.0019\n",
      "Epoch [4/10], Step [740/1079], Loss: 0.0202\n",
      "Epoch [4/10], Step [741/1079], Loss: 0.0992\n",
      "Epoch [4/10], Step [742/1079], Loss: 0.0161\n",
      "Epoch [4/10], Step [743/1079], Loss: 0.0088\n",
      "Epoch [4/10], Step [744/1079], Loss: 0.0053\n",
      "Epoch [4/10], Step [745/1079], Loss: 0.0044\n",
      "Epoch [4/10], Step [746/1079], Loss: 0.0045\n",
      "Epoch [4/10], Step [747/1079], Loss: 0.2055\n",
      "Epoch [4/10], Step [748/1079], Loss: 0.0156\n",
      "Epoch [4/10], Step [749/1079], Loss: 0.0092\n",
      "Epoch [4/10], Step [750/1079], Loss: 0.0346\n",
      "Epoch [4/10], Step [751/1079], Loss: 0.0747\n",
      "Epoch [4/10], Step [752/1079], Loss: 0.0122\n",
      "Epoch [4/10], Step [753/1079], Loss: 0.0144\n",
      "Epoch [4/10], Step [754/1079], Loss: 0.0157\n",
      "Epoch [4/10], Step [755/1079], Loss: 0.0043\n",
      "Epoch [4/10], Step [756/1079], Loss: 0.0053\n",
      "Epoch [4/10], Step [757/1079], Loss: 0.0058\n",
      "Epoch [4/10], Step [758/1079], Loss: 0.0046\n",
      "Epoch [4/10], Step [759/1079], Loss: 0.0018\n",
      "Epoch [4/10], Step [760/1079], Loss: 0.0072\n",
      "Epoch [4/10], Step [761/1079], Loss: 0.0061\n",
      "Epoch [4/10], Step [762/1079], Loss: 0.0472\n",
      "Epoch [4/10], Step [763/1079], Loss: 0.0173\n",
      "Epoch [4/10], Step [764/1079], Loss: 0.0011\n",
      "Epoch [4/10], Step [765/1079], Loss: 0.0862\n",
      "Epoch [4/10], Step [766/1079], Loss: 0.0242\n",
      "Epoch [4/10], Step [767/1079], Loss: 0.0576\n",
      "Epoch [4/10], Step [768/1079], Loss: 0.0111\n",
      "Epoch [4/10], Step [769/1079], Loss: 0.0007\n",
      "Epoch [4/10], Step [770/1079], Loss: 0.0068\n",
      "Epoch [4/10], Step [771/1079], Loss: 0.0020\n",
      "Epoch [4/10], Step [772/1079], Loss: 0.0533\n",
      "Epoch [4/10], Step [773/1079], Loss: 0.0250\n",
      "Epoch [4/10], Step [774/1079], Loss: 0.0032\n",
      "Epoch [4/10], Step [775/1079], Loss: 0.0057\n",
      "Epoch [4/10], Step [776/1079], Loss: 0.0428\n",
      "Epoch [4/10], Step [777/1079], Loss: 0.2054\n",
      "Epoch [4/10], Step [778/1079], Loss: 0.0418\n",
      "Epoch [4/10], Step [779/1079], Loss: 0.0591\n",
      "Epoch [4/10], Step [780/1079], Loss: 0.0235\n",
      "Epoch [4/10], Step [781/1079], Loss: 0.0115\n",
      "Epoch [4/10], Step [782/1079], Loss: 0.0123\n",
      "Epoch [4/10], Step [783/1079], Loss: 0.0223\n",
      "Epoch [4/10], Step [784/1079], Loss: 0.0749\n",
      "Epoch [4/10], Step [785/1079], Loss: 0.0071\n",
      "Epoch [4/10], Step [786/1079], Loss: 0.1920\n",
      "Epoch [4/10], Step [787/1079], Loss: 0.0545\n",
      "Epoch [4/10], Step [788/1079], Loss: 0.0274\n",
      "Epoch [4/10], Step [789/1079], Loss: 0.0069\n",
      "Epoch [4/10], Step [790/1079], Loss: 0.0057\n",
      "Epoch [4/10], Step [791/1079], Loss: 0.0204\n",
      "Epoch [4/10], Step [792/1079], Loss: 0.0021\n",
      "Epoch [4/10], Step [793/1079], Loss: 0.0071\n",
      "Epoch [4/10], Step [794/1079], Loss: 0.0177\n",
      "Epoch [4/10], Step [795/1079], Loss: 0.0481\n",
      "Epoch [4/10], Step [796/1079], Loss: 0.1019\n",
      "Epoch [4/10], Step [797/1079], Loss: 0.0340\n",
      "Epoch [4/10], Step [798/1079], Loss: 0.0398\n",
      "Epoch [4/10], Step [799/1079], Loss: 0.0029\n",
      "Epoch [4/10], Step [800/1079], Loss: 0.0385\n",
      "Epoch [4/10], Step [801/1079], Loss: 0.0105\n",
      "Epoch [4/10], Step [802/1079], Loss: 0.0973\n",
      "Epoch [4/10], Step [803/1079], Loss: 0.0948\n",
      "Epoch [4/10], Step [804/1079], Loss: 0.0092\n",
      "Epoch [4/10], Step [805/1079], Loss: 0.0023\n",
      "Epoch [4/10], Step [806/1079], Loss: 0.0100\n",
      "Epoch [4/10], Step [807/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [808/1079], Loss: 0.0181\n",
      "Epoch [4/10], Step [809/1079], Loss: 0.0061\n",
      "Epoch [4/10], Step [810/1079], Loss: 0.0280\n",
      "Epoch [4/10], Step [811/1079], Loss: 0.0068\n",
      "Epoch [4/10], Step [812/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [813/1079], Loss: 0.0299\n",
      "Epoch [4/10], Step [814/1079], Loss: 0.0214\n",
      "Epoch [4/10], Step [815/1079], Loss: 0.0399\n",
      "Epoch [4/10], Step [816/1079], Loss: 0.0117\n",
      "Epoch [4/10], Step [817/1079], Loss: 0.0084\n",
      "Epoch [4/10], Step [818/1079], Loss: 0.0182\n",
      "Epoch [4/10], Step [819/1079], Loss: 0.0060\n",
      "Epoch [4/10], Step [820/1079], Loss: 0.0089\n",
      "Epoch [4/10], Step [821/1079], Loss: 0.0741\n",
      "Epoch [4/10], Step [822/1079], Loss: 0.0080\n",
      "Epoch [4/10], Step [823/1079], Loss: 0.0026\n",
      "Epoch [4/10], Step [824/1079], Loss: 0.0114\n",
      "Epoch [4/10], Step [825/1079], Loss: 0.0006\n",
      "Epoch [4/10], Step [826/1079], Loss: 0.0082\n",
      "Epoch [4/10], Step [827/1079], Loss: 0.0054\n",
      "Epoch [4/10], Step [828/1079], Loss: 0.0260\n",
      "Epoch [4/10], Step [829/1079], Loss: 0.0010\n",
      "Epoch [4/10], Step [830/1079], Loss: 0.0249\n",
      "Epoch [4/10], Step [831/1079], Loss: 0.1165\n",
      "Epoch [4/10], Step [832/1079], Loss: 0.0060\n",
      "Epoch [4/10], Step [833/1079], Loss: 0.0458\n",
      "Epoch [4/10], Step [834/1079], Loss: 0.0587\n",
      "Epoch [4/10], Step [835/1079], Loss: 0.0012\n",
      "Epoch [4/10], Step [836/1079], Loss: 0.0017\n",
      "Epoch [4/10], Step [837/1079], Loss: 0.0333\n",
      "Epoch [4/10], Step [838/1079], Loss: 0.0174\n",
      "Epoch [4/10], Step [839/1079], Loss: 0.0312\n",
      "Epoch [4/10], Step [840/1079], Loss: 0.0411\n",
      "Epoch [4/10], Step [841/1079], Loss: 0.0291\n",
      "Epoch [4/10], Step [842/1079], Loss: 0.0241\n",
      "Epoch [4/10], Step [843/1079], Loss: 0.0182\n",
      "Epoch [4/10], Step [844/1079], Loss: 0.0037\n",
      "Epoch [4/10], Step [845/1079], Loss: 0.0207\n",
      "Epoch [4/10], Step [846/1079], Loss: 0.0071\n",
      "Epoch [4/10], Step [847/1079], Loss: 0.0274\n",
      "Epoch [4/10], Step [848/1079], Loss: 0.0487\n",
      "Epoch [4/10], Step [849/1079], Loss: 0.0157\n",
      "Epoch [4/10], Step [850/1079], Loss: 0.0256\n",
      "Epoch [4/10], Step [851/1079], Loss: 0.0205\n",
      "Epoch [4/10], Step [852/1079], Loss: 0.0160\n",
      "Epoch [4/10], Step [853/1079], Loss: 0.0184\n",
      "Epoch [4/10], Step [854/1079], Loss: 0.0316\n",
      "Epoch [4/10], Step [855/1079], Loss: 0.0080\n",
      "Epoch [4/10], Step [856/1079], Loss: 0.0084\n",
      "Epoch [4/10], Step [857/1079], Loss: 0.0019\n",
      "Epoch [4/10], Step [858/1079], Loss: 0.0052\n",
      "Epoch [4/10], Step [859/1079], Loss: 0.0036\n",
      "Epoch [4/10], Step [860/1079], Loss: 0.0241\n",
      "Epoch [4/10], Step [861/1079], Loss: 0.0068\n",
      "Epoch [4/10], Step [862/1079], Loss: 0.0025\n",
      "Epoch [4/10], Step [863/1079], Loss: 0.0346\n",
      "Epoch [4/10], Step [864/1079], Loss: 0.0461\n",
      "Epoch [4/10], Step [865/1079], Loss: 0.0029\n",
      "Epoch [4/10], Step [866/1079], Loss: 0.0033\n",
      "Epoch [4/10], Step [867/1079], Loss: 0.0221\n",
      "Epoch [4/10], Step [868/1079], Loss: 0.0673\n",
      "Epoch [4/10], Step [869/1079], Loss: 0.0122\n",
      "Epoch [4/10], Step [870/1079], Loss: 0.0013\n",
      "Epoch [4/10], Step [871/1079], Loss: 0.0165\n",
      "Epoch [4/10], Step [872/1079], Loss: 0.0538\n",
      "Epoch [4/10], Step [873/1079], Loss: 0.0120\n",
      "Epoch [4/10], Step [874/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [875/1079], Loss: 0.0093\n",
      "Epoch [4/10], Step [876/1079], Loss: 0.0087\n",
      "Epoch [4/10], Step [877/1079], Loss: 0.0649\n",
      "Epoch [4/10], Step [878/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [879/1079], Loss: 0.0721\n",
      "Epoch [4/10], Step [880/1079], Loss: 0.0033\n",
      "Epoch [4/10], Step [881/1079], Loss: 0.0193\n",
      "Epoch [4/10], Step [882/1079], Loss: 0.0136\n",
      "Epoch [4/10], Step [883/1079], Loss: 0.0485\n",
      "Epoch [4/10], Step [884/1079], Loss: 0.0038\n",
      "Epoch [4/10], Step [885/1079], Loss: 0.0095\n",
      "Epoch [4/10], Step [886/1079], Loss: 0.0549\n",
      "Epoch [4/10], Step [887/1079], Loss: 0.0428\n",
      "Epoch [4/10], Step [888/1079], Loss: 0.0610\n",
      "Epoch [4/10], Step [889/1079], Loss: 0.0587\n",
      "Epoch [4/10], Step [890/1079], Loss: 0.0013\n",
      "Epoch [4/10], Step [891/1079], Loss: 0.0153\n",
      "Epoch [4/10], Step [892/1079], Loss: 0.0095\n",
      "Epoch [4/10], Step [893/1079], Loss: 0.0088\n",
      "Epoch [4/10], Step [894/1079], Loss: 0.0082\n",
      "Epoch [4/10], Step [895/1079], Loss: 0.0099\n",
      "Epoch [4/10], Step [896/1079], Loss: 0.0718\n",
      "Epoch [4/10], Step [897/1079], Loss: 0.0033\n",
      "Epoch [4/10], Step [898/1079], Loss: 0.0161\n",
      "Epoch [4/10], Step [899/1079], Loss: 0.0102\n",
      "Epoch [4/10], Step [900/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [901/1079], Loss: 0.0057\n",
      "Epoch [4/10], Step [902/1079], Loss: 0.0011\n",
      "Epoch [4/10], Step [903/1079], Loss: 0.0028\n",
      "Epoch [4/10], Step [904/1079], Loss: 0.0293\n",
      "Epoch [4/10], Step [905/1079], Loss: 0.0053\n",
      "Epoch [4/10], Step [906/1079], Loss: 0.0079\n",
      "Epoch [4/10], Step [907/1079], Loss: 0.0055\n",
      "Epoch [4/10], Step [908/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [909/1079], Loss: 0.0910\n",
      "Epoch [4/10], Step [910/1079], Loss: 0.0031\n",
      "Epoch [4/10], Step [911/1079], Loss: 0.0004\n",
      "Epoch [4/10], Step [912/1079], Loss: 0.0012\n",
      "Epoch [4/10], Step [913/1079], Loss: 0.0539\n",
      "Epoch [4/10], Step [914/1079], Loss: 0.0026\n",
      "Epoch [4/10], Step [915/1079], Loss: 0.0076\n",
      "Epoch [4/10], Step [916/1079], Loss: 0.0252\n",
      "Epoch [4/10], Step [917/1079], Loss: 0.0009\n",
      "Epoch [4/10], Step [918/1079], Loss: 0.0065\n",
      "Epoch [4/10], Step [919/1079], Loss: 0.0315\n",
      "Epoch [4/10], Step [920/1079], Loss: 0.0185\n",
      "Epoch [4/10], Step [921/1079], Loss: 0.0066\n",
      "Epoch [4/10], Step [922/1079], Loss: 0.0010\n",
      "Epoch [4/10], Step [923/1079], Loss: 0.0096\n",
      "Epoch [4/10], Step [924/1079], Loss: 0.0049\n",
      "Epoch [4/10], Step [925/1079], Loss: 0.0208\n",
      "Epoch [4/10], Step [926/1079], Loss: 0.0021\n",
      "Epoch [4/10], Step [927/1079], Loss: 0.0016\n",
      "Epoch [4/10], Step [928/1079], Loss: 0.0019\n",
      "Epoch [4/10], Step [929/1079], Loss: 0.0266\n",
      "Epoch [4/10], Step [930/1079], Loss: 0.0139\n",
      "Epoch [4/10], Step [931/1079], Loss: 0.0061\n",
      "Epoch [4/10], Step [932/1079], Loss: 0.0160\n",
      "Epoch [4/10], Step [933/1079], Loss: 0.0835\n",
      "Epoch [4/10], Step [934/1079], Loss: 0.0018\n",
      "Epoch [4/10], Step [935/1079], Loss: 0.0913\n",
      "Epoch [4/10], Step [936/1079], Loss: 0.0038\n",
      "Epoch [4/10], Step [937/1079], Loss: 0.0097\n",
      "Epoch [4/10], Step [938/1079], Loss: 0.0020\n",
      "Epoch [4/10], Step [939/1079], Loss: 0.0137\n",
      "Epoch [4/10], Step [940/1079], Loss: 0.0098\n",
      "Epoch [4/10], Step [941/1079], Loss: 0.0057\n",
      "Epoch [4/10], Step [942/1079], Loss: 0.0357\n",
      "Epoch [4/10], Step [943/1079], Loss: 0.0172\n",
      "Epoch [4/10], Step [944/1079], Loss: 0.0092\n",
      "Epoch [4/10], Step [945/1079], Loss: 0.0643\n",
      "Epoch [4/10], Step [946/1079], Loss: 0.0553\n",
      "Epoch [4/10], Step [947/1079], Loss: 0.0056\n",
      "Epoch [4/10], Step [948/1079], Loss: 0.1571\n",
      "Epoch [4/10], Step [949/1079], Loss: 0.0074\n",
      "Epoch [4/10], Step [950/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [951/1079], Loss: 0.0015\n",
      "Epoch [4/10], Step [952/1079], Loss: 0.1096\n",
      "Epoch [4/10], Step [953/1079], Loss: 0.0039\n",
      "Epoch [4/10], Step [954/1079], Loss: 0.0065\n",
      "Epoch [4/10], Step [955/1079], Loss: 0.0016\n",
      "Epoch [4/10], Step [956/1079], Loss: 0.0060\n",
      "Epoch [4/10], Step [957/1079], Loss: 0.0112\n",
      "Epoch [4/10], Step [958/1079], Loss: 0.0226\n",
      "Epoch [4/10], Step [959/1079], Loss: 0.0264\n",
      "Epoch [4/10], Step [960/1079], Loss: 0.0683\n",
      "Epoch [4/10], Step [961/1079], Loss: 0.0104\n",
      "Epoch [4/10], Step [962/1079], Loss: 0.0456\n",
      "Epoch [4/10], Step [963/1079], Loss: 0.0230\n",
      "Epoch [4/10], Step [964/1079], Loss: 0.0226\n",
      "Epoch [4/10], Step [965/1079], Loss: 0.0687\n",
      "Epoch [4/10], Step [966/1079], Loss: 0.0048\n",
      "Epoch [4/10], Step [967/1079], Loss: 0.1004\n",
      "Epoch [4/10], Step [968/1079], Loss: 0.0053\n",
      "Epoch [4/10], Step [969/1079], Loss: 0.0177\n",
      "Epoch [4/10], Step [970/1079], Loss: 0.0377\n",
      "Epoch [4/10], Step [971/1079], Loss: 0.0624\n",
      "Epoch [4/10], Step [972/1079], Loss: 0.0162\n",
      "Epoch [4/10], Step [973/1079], Loss: 0.0177\n",
      "Epoch [4/10], Step [974/1079], Loss: 0.0027\n",
      "Epoch [4/10], Step [975/1079], Loss: 0.0066\n",
      "Epoch [4/10], Step [976/1079], Loss: 0.0126\n",
      "Epoch [4/10], Step [977/1079], Loss: 0.0051\n",
      "Epoch [4/10], Step [978/1079], Loss: 0.0164\n",
      "Epoch [4/10], Step [979/1079], Loss: 0.0006\n",
      "Epoch [4/10], Step [980/1079], Loss: 0.0214\n",
      "Epoch [4/10], Step [981/1079], Loss: 0.0069\n",
      "Epoch [4/10], Step [982/1079], Loss: 0.0318\n",
      "Epoch [4/10], Step [983/1079], Loss: 0.1042\n",
      "Epoch [4/10], Step [984/1079], Loss: 0.0061\n",
      "Epoch [4/10], Step [985/1079], Loss: 0.0461\n",
      "Epoch [4/10], Step [986/1079], Loss: 0.0654\n",
      "Epoch [4/10], Step [987/1079], Loss: 0.0383\n",
      "Epoch [4/10], Step [988/1079], Loss: 0.0074\n",
      "Epoch [4/10], Step [989/1079], Loss: 0.0664\n",
      "Epoch [4/10], Step [990/1079], Loss: 0.0767\n",
      "Epoch [4/10], Step [991/1079], Loss: 0.0047\n",
      "Epoch [4/10], Step [992/1079], Loss: 0.0326\n",
      "Epoch [4/10], Step [993/1079], Loss: 0.0022\n",
      "Epoch [4/10], Step [994/1079], Loss: 0.0050\n",
      "Epoch [4/10], Step [995/1079], Loss: 0.0234\n",
      "Epoch [4/10], Step [996/1079], Loss: 0.0025\n",
      "Epoch [4/10], Step [997/1079], Loss: 0.0363\n",
      "Epoch [4/10], Step [998/1079], Loss: 0.0597\n",
      "Epoch [4/10], Step [999/1079], Loss: 0.0275\n",
      "Epoch [4/10], Step [1000/1079], Loss: 0.0055\n",
      "Epoch [4/10], Step [1001/1079], Loss: 0.0040\n",
      "Epoch [4/10], Step [1002/1079], Loss: 0.0271\n",
      "Epoch [4/10], Step [1003/1079], Loss: 0.0423\n",
      "Epoch [4/10], Step [1004/1079], Loss: 0.0015\n",
      "Epoch [4/10], Step [1005/1079], Loss: 0.0087\n",
      "Epoch [4/10], Step [1006/1079], Loss: 0.0059\n",
      "Epoch [4/10], Step [1007/1079], Loss: 0.0087\n",
      "Epoch [4/10], Step [1008/1079], Loss: 0.0010\n",
      "Epoch [4/10], Step [1009/1079], Loss: 0.0100\n",
      "Epoch [4/10], Step [1010/1079], Loss: 0.0513\n",
      "Epoch [4/10], Step [1011/1079], Loss: 0.0030\n",
      "Epoch [4/10], Step [1012/1079], Loss: 0.0247\n",
      "Epoch [4/10], Step [1013/1079], Loss: 0.0103\n",
      "Epoch [4/10], Step [1014/1079], Loss: 0.0158\n",
      "Epoch [4/10], Step [1015/1079], Loss: 0.1452\n",
      "Epoch [4/10], Step [1016/1079], Loss: 0.1082\n",
      "Epoch [4/10], Step [1017/1079], Loss: 0.0026\n",
      "Epoch [4/10], Step [1018/1079], Loss: 0.0380\n",
      "Epoch [4/10], Step [1019/1079], Loss: 0.0021\n",
      "Epoch [4/10], Step [1020/1079], Loss: 0.0312\n",
      "Epoch [4/10], Step [1021/1079], Loss: 0.0122\n",
      "Epoch [4/10], Step [1022/1079], Loss: 0.0081\n",
      "Epoch [4/10], Step [1023/1079], Loss: 0.0173\n",
      "Epoch [4/10], Step [1024/1079], Loss: 0.0711\n",
      "Epoch [4/10], Step [1025/1079], Loss: 0.0029\n",
      "Epoch [4/10], Step [1026/1079], Loss: 0.0526\n",
      "Epoch [4/10], Step [1027/1079], Loss: 0.0022\n",
      "Epoch [4/10], Step [1028/1079], Loss: 0.0152\n",
      "Epoch [4/10], Step [1029/1079], Loss: 0.0344\n",
      "Epoch [4/10], Step [1030/1079], Loss: 0.0050\n",
      "Epoch [4/10], Step [1031/1079], Loss: 0.0018\n",
      "Epoch [4/10], Step [1032/1079], Loss: 0.0398\n",
      "Epoch [4/10], Step [1033/1079], Loss: 0.0020\n",
      "Epoch [4/10], Step [1034/1079], Loss: 0.0102\n",
      "Epoch [4/10], Step [1035/1079], Loss: 0.0368\n",
      "Epoch [4/10], Step [1036/1079], Loss: 0.0049\n",
      "Epoch [4/10], Step [1037/1079], Loss: 0.0436\n",
      "Epoch [4/10], Step [1038/1079], Loss: 0.0249\n",
      "Epoch [4/10], Step [1039/1079], Loss: 0.0047\n",
      "Epoch [4/10], Step [1040/1079], Loss: 0.0101\n",
      "Epoch [4/10], Step [1041/1079], Loss: 0.0171\n",
      "Epoch [4/10], Step [1042/1079], Loss: 0.1000\n",
      "Epoch [4/10], Step [1043/1079], Loss: 0.0011\n",
      "Epoch [4/10], Step [1044/1079], Loss: 0.0016\n",
      "Epoch [4/10], Step [1045/1079], Loss: 0.0034\n",
      "Epoch [4/10], Step [1046/1079], Loss: 0.0050\n",
      "Epoch [4/10], Step [1047/1079], Loss: 0.0184\n",
      "Epoch [4/10], Step [1048/1079], Loss: 0.0955\n",
      "Epoch [4/10], Step [1049/1079], Loss: 0.1084\n",
      "Epoch [4/10], Step [1050/1079], Loss: 0.0472\n",
      "Epoch [4/10], Step [1051/1079], Loss: 0.0304\n",
      "Epoch [4/10], Step [1052/1079], Loss: 0.0129\n",
      "Epoch [4/10], Step [1053/1079], Loss: 0.0100\n",
      "Epoch [4/10], Step [1054/1079], Loss: 0.0067\n",
      "Epoch [4/10], Step [1055/1079], Loss: 0.0042\n",
      "Epoch [4/10], Step [1056/1079], Loss: 0.0160\n",
      "Epoch [4/10], Step [1057/1079], Loss: 0.0715\n",
      "Epoch [4/10], Step [1058/1079], Loss: 0.0298\n",
      "Epoch [4/10], Step [1059/1079], Loss: 0.0079\n",
      "Epoch [4/10], Step [1060/1079], Loss: 0.0215\n",
      "Epoch [4/10], Step [1061/1079], Loss: 0.0068\n",
      "Epoch [4/10], Step [1062/1079], Loss: 0.0111\n",
      "Epoch [4/10], Step [1063/1079], Loss: 0.0020\n",
      "Epoch [4/10], Step [1064/1079], Loss: 0.0055\n",
      "Epoch [4/10], Step [1065/1079], Loss: 0.0764\n",
      "Epoch [4/10], Step [1066/1079], Loss: 0.0678\n",
      "Epoch [4/10], Step [1067/1079], Loss: 0.0231\n",
      "Epoch [4/10], Step [1068/1079], Loss: 0.0212\n",
      "Epoch [4/10], Step [1069/1079], Loss: 0.0113\n",
      "Epoch [4/10], Step [1070/1079], Loss: 0.0143\n",
      "Epoch [4/10], Step [1071/1079], Loss: 0.0165\n",
      "Epoch [4/10], Step [1072/1079], Loss: 0.0170\n",
      "Epoch [4/10], Step [1073/1079], Loss: 0.0240\n",
      "Epoch [4/10], Step [1074/1079], Loss: 0.0253\n",
      "Epoch [4/10], Step [1075/1079], Loss: 0.1927\n",
      "Epoch [4/10], Step [1076/1079], Loss: 0.0678\n",
      "Epoch [4/10], Step [1077/1079], Loss: 0.1220\n",
      "Epoch [4/10], Step [1078/1079], Loss: 0.0407\n",
      "Epoch [4/10], Step [1079/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [1/1079], Loss: 0.0105\n",
      "Epoch [5/10], Step [2/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [3/1079], Loss: 0.0173\n",
      "Epoch [5/10], Step [4/1079], Loss: 0.0027\n",
      "Epoch [5/10], Step [5/1079], Loss: 0.0098\n",
      "Epoch [5/10], Step [6/1079], Loss: 0.0243\n",
      "Epoch [5/10], Step [7/1079], Loss: 0.0111\n",
      "Epoch [5/10], Step [8/1079], Loss: 0.0155\n",
      "Epoch [5/10], Step [9/1079], Loss: 0.0053\n",
      "Epoch [5/10], Step [10/1079], Loss: 0.0101\n",
      "Epoch [5/10], Step [11/1079], Loss: 0.0041\n",
      "Epoch [5/10], Step [12/1079], Loss: 0.0195\n",
      "Epoch [5/10], Step [13/1079], Loss: 0.0139\n",
      "Epoch [5/10], Step [14/1079], Loss: 0.0083\n",
      "Epoch [5/10], Step [15/1079], Loss: 0.0745\n",
      "Epoch [5/10], Step [16/1079], Loss: 0.0155\n",
      "Epoch [5/10], Step [17/1079], Loss: 0.0060\n",
      "Epoch [5/10], Step [18/1079], Loss: 0.0057\n",
      "Epoch [5/10], Step [19/1079], Loss: 0.0078\n",
      "Epoch [5/10], Step [20/1079], Loss: 0.0011\n",
      "Epoch [5/10], Step [21/1079], Loss: 0.0057\n",
      "Epoch [5/10], Step [22/1079], Loss: 0.0066\n",
      "Epoch [5/10], Step [23/1079], Loss: 0.0143\n",
      "Epoch [5/10], Step [24/1079], Loss: 0.0582\n",
      "Epoch [5/10], Step [25/1079], Loss: 0.0099\n",
      "Epoch [5/10], Step [26/1079], Loss: 0.0129\n",
      "Epoch [5/10], Step [27/1079], Loss: 0.0037\n",
      "Epoch [5/10], Step [28/1079], Loss: 0.0066\n",
      "Epoch [5/10], Step [29/1079], Loss: 0.0079\n",
      "Epoch [5/10], Step [30/1079], Loss: 0.0043\n",
      "Epoch [5/10], Step [31/1079], Loss: 0.0028\n",
      "Epoch [5/10], Step [32/1079], Loss: 0.0008\n",
      "Epoch [5/10], Step [33/1079], Loss: 0.0053\n",
      "Epoch [5/10], Step [34/1079], Loss: 0.0491\n",
      "Epoch [5/10], Step [35/1079], Loss: 0.0169\n",
      "Epoch [5/10], Step [36/1079], Loss: 0.0130\n",
      "Epoch [5/10], Step [37/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [38/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [39/1079], Loss: 0.0130\n",
      "Epoch [5/10], Step [40/1079], Loss: 0.0115\n",
      "Epoch [5/10], Step [41/1079], Loss: 0.0029\n",
      "Epoch [5/10], Step [42/1079], Loss: 0.0160\n",
      "Epoch [5/10], Step [43/1079], Loss: 0.0026\n",
      "Epoch [5/10], Step [44/1079], Loss: 0.0060\n",
      "Epoch [5/10], Step [45/1079], Loss: 0.0018\n",
      "Epoch [5/10], Step [46/1079], Loss: 0.0113\n",
      "Epoch [5/10], Step [47/1079], Loss: 0.0064\n",
      "Epoch [5/10], Step [48/1079], Loss: 0.0118\n",
      "Epoch [5/10], Step [49/1079], Loss: 0.0281\n",
      "Epoch [5/10], Step [50/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [51/1079], Loss: 0.0230\n",
      "Epoch [5/10], Step [52/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [53/1079], Loss: 0.0066\n",
      "Epoch [5/10], Step [54/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [55/1079], Loss: 0.0105\n",
      "Epoch [5/10], Step [56/1079], Loss: 0.0078\n",
      "Epoch [5/10], Step [57/1079], Loss: 0.0094\n",
      "Epoch [5/10], Step [58/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [59/1079], Loss: 0.0066\n",
      "Epoch [5/10], Step [60/1079], Loss: 0.0253\n",
      "Epoch [5/10], Step [61/1079], Loss: 0.0048\n",
      "Epoch [5/10], Step [62/1079], Loss: 0.0027\n",
      "Epoch [5/10], Step [63/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [64/1079], Loss: 0.0031\n",
      "Epoch [5/10], Step [65/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [66/1079], Loss: 0.0153\n",
      "Epoch [5/10], Step [67/1079], Loss: 0.0064\n",
      "Epoch [5/10], Step [68/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [69/1079], Loss: 0.0813\n",
      "Epoch [5/10], Step [70/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [71/1079], Loss: 0.0013\n",
      "Epoch [5/10], Step [72/1079], Loss: 0.0046\n",
      "Epoch [5/10], Step [73/1079], Loss: 0.0036\n",
      "Epoch [5/10], Step [74/1079], Loss: 0.0019\n",
      "Epoch [5/10], Step [75/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [76/1079], Loss: 0.0138\n",
      "Epoch [5/10], Step [77/1079], Loss: 0.0078\n",
      "Epoch [5/10], Step [78/1079], Loss: 0.0124\n",
      "Epoch [5/10], Step [79/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [80/1079], Loss: 0.0064\n",
      "Epoch [5/10], Step [81/1079], Loss: 0.0052\n",
      "Epoch [5/10], Step [82/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [83/1079], Loss: 0.0016\n",
      "Epoch [5/10], Step [84/1079], Loss: 0.0455\n",
      "Epoch [5/10], Step [85/1079], Loss: 0.0141\n",
      "Epoch [5/10], Step [86/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [87/1079], Loss: 0.0161\n",
      "Epoch [5/10], Step [88/1079], Loss: 0.0202\n",
      "Epoch [5/10], Step [89/1079], Loss: 0.0781\n",
      "Epoch [5/10], Step [90/1079], Loss: 0.0134\n",
      "Epoch [5/10], Step [91/1079], Loss: 0.0303\n",
      "Epoch [5/10], Step [92/1079], Loss: 0.0233\n",
      "Epoch [5/10], Step [93/1079], Loss: 0.0097\n",
      "Epoch [5/10], Step [94/1079], Loss: 0.0051\n",
      "Epoch [5/10], Step [95/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [96/1079], Loss: 0.0068\n",
      "Epoch [5/10], Step [97/1079], Loss: 0.1222\n",
      "Epoch [5/10], Step [98/1079], Loss: 0.0008\n",
      "Epoch [5/10], Step [99/1079], Loss: 0.0261\n",
      "Epoch [5/10], Step [100/1079], Loss: 0.0469\n",
      "Epoch [5/10], Step [101/1079], Loss: 0.0011\n",
      "Epoch [5/10], Step [102/1079], Loss: 0.0033\n",
      "Epoch [5/10], Step [103/1079], Loss: 0.0116\n",
      "Epoch [5/10], Step [104/1079], Loss: 0.0209\n",
      "Epoch [5/10], Step [105/1079], Loss: 0.0255\n",
      "Epoch [5/10], Step [106/1079], Loss: 0.0031\n",
      "Epoch [5/10], Step [107/1079], Loss: 0.0092\n",
      "Epoch [5/10], Step [108/1079], Loss: 0.0011\n",
      "Epoch [5/10], Step [109/1079], Loss: 0.0027\n",
      "Epoch [5/10], Step [110/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [111/1079], Loss: 0.0151\n",
      "Epoch [5/10], Step [112/1079], Loss: 0.0324\n",
      "Epoch [5/10], Step [113/1079], Loss: 0.0432\n",
      "Epoch [5/10], Step [114/1079], Loss: 0.0151\n",
      "Epoch [5/10], Step [115/1079], Loss: 0.0231\n",
      "Epoch [5/10], Step [116/1079], Loss: 0.0200\n",
      "Epoch [5/10], Step [117/1079], Loss: 0.0043\n",
      "Epoch [5/10], Step [118/1079], Loss: 0.0067\n",
      "Epoch [5/10], Step [119/1079], Loss: 0.0036\n",
      "Epoch [5/10], Step [120/1079], Loss: 0.0049\n",
      "Epoch [5/10], Step [121/1079], Loss: 0.0130\n",
      "Epoch [5/10], Step [122/1079], Loss: 0.0338\n",
      "Epoch [5/10], Step [123/1079], Loss: 0.0147\n",
      "Epoch [5/10], Step [124/1079], Loss: 0.0194\n",
      "Epoch [5/10], Step [125/1079], Loss: 0.0020\n",
      "Epoch [5/10], Step [126/1079], Loss: 0.0358\n",
      "Epoch [5/10], Step [127/1079], Loss: 0.0016\n",
      "Epoch [5/10], Step [128/1079], Loss: 0.0210\n",
      "Epoch [5/10], Step [129/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [130/1079], Loss: 0.0444\n",
      "Epoch [5/10], Step [131/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [132/1079], Loss: 0.0026\n",
      "Epoch [5/10], Step [133/1079], Loss: 0.0085\n",
      "Epoch [5/10], Step [134/1079], Loss: 0.0013\n",
      "Epoch [5/10], Step [135/1079], Loss: 0.0156\n",
      "Epoch [5/10], Step [136/1079], Loss: 0.0041\n",
      "Epoch [5/10], Step [137/1079], Loss: 0.0006\n",
      "Epoch [5/10], Step [138/1079], Loss: 0.0495\n",
      "Epoch [5/10], Step [139/1079], Loss: 0.0223\n",
      "Epoch [5/10], Step [140/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [141/1079], Loss: 0.0008\n",
      "Epoch [5/10], Step [142/1079], Loss: 0.0213\n",
      "Epoch [5/10], Step [143/1079], Loss: 0.0095\n",
      "Epoch [5/10], Step [144/1079], Loss: 0.0077\n",
      "Epoch [5/10], Step [145/1079], Loss: 0.0323\n",
      "Epoch [5/10], Step [146/1079], Loss: 0.0270\n",
      "Epoch [5/10], Step [147/1079], Loss: 0.0073\n",
      "Epoch [5/10], Step [148/1079], Loss: 0.0031\n",
      "Epoch [5/10], Step [149/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [150/1079], Loss: 0.0277\n",
      "Epoch [5/10], Step [151/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [152/1079], Loss: 0.0440\n",
      "Epoch [5/10], Step [153/1079], Loss: 0.0358\n",
      "Epoch [5/10], Step [154/1079], Loss: 0.0042\n",
      "Epoch [5/10], Step [155/1079], Loss: 0.0519\n",
      "Epoch [5/10], Step [156/1079], Loss: 0.0503\n",
      "Epoch [5/10], Step [157/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [158/1079], Loss: 0.0722\n",
      "Epoch [5/10], Step [159/1079], Loss: 0.0629\n",
      "Epoch [5/10], Step [160/1079], Loss: 0.0157\n",
      "Epoch [5/10], Step [161/1079], Loss: 0.0041\n",
      "Epoch [5/10], Step [162/1079], Loss: 0.0022\n",
      "Epoch [5/10], Step [163/1079], Loss: 0.0385\n",
      "Epoch [5/10], Step [164/1079], Loss: 0.0235\n",
      "Epoch [5/10], Step [165/1079], Loss: 0.0039\n",
      "Epoch [5/10], Step [166/1079], Loss: 0.0062\n",
      "Epoch [5/10], Step [167/1079], Loss: 0.0596\n",
      "Epoch [5/10], Step [168/1079], Loss: 0.0060\n",
      "Epoch [5/10], Step [169/1079], Loss: 0.0103\n",
      "Epoch [5/10], Step [170/1079], Loss: 0.0484\n",
      "Epoch [5/10], Step [171/1079], Loss: 0.0352\n",
      "Epoch [5/10], Step [172/1079], Loss: 0.0011\n",
      "Epoch [5/10], Step [173/1079], Loss: 0.0336\n",
      "Epoch [5/10], Step [174/1079], Loss: 0.0052\n",
      "Epoch [5/10], Step [175/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [176/1079], Loss: 0.1027\n",
      "Epoch [5/10], Step [177/1079], Loss: 0.0434\n",
      "Epoch [5/10], Step [178/1079], Loss: 0.0271\n",
      "Epoch [5/10], Step [179/1079], Loss: 0.0059\n",
      "Epoch [5/10], Step [180/1079], Loss: 0.0469\n",
      "Epoch [5/10], Step [181/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [182/1079], Loss: 0.0177\n",
      "Epoch [5/10], Step [183/1079], Loss: 0.0018\n",
      "Epoch [5/10], Step [184/1079], Loss: 0.1280\n",
      "Epoch [5/10], Step [185/1079], Loss: 0.0027\n",
      "Epoch [5/10], Step [186/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [187/1079], Loss: 0.0167\n",
      "Epoch [5/10], Step [188/1079], Loss: 0.0335\n",
      "Epoch [5/10], Step [189/1079], Loss: 0.0016\n",
      "Epoch [5/10], Step [190/1079], Loss: 0.0579\n",
      "Epoch [5/10], Step [191/1079], Loss: 0.0234\n",
      "Epoch [5/10], Step [192/1079], Loss: 0.0074\n",
      "Epoch [5/10], Step [193/1079], Loss: 0.0162\n",
      "Epoch [5/10], Step [194/1079], Loss: 0.0078\n",
      "Epoch [5/10], Step [195/1079], Loss: 0.0026\n",
      "Epoch [5/10], Step [196/1079], Loss: 0.0416\n",
      "Epoch [5/10], Step [197/1079], Loss: 0.0056\n",
      "Epoch [5/10], Step [198/1079], Loss: 0.0073\n",
      "Epoch [5/10], Step [199/1079], Loss: 0.0634\n",
      "Epoch [5/10], Step [200/1079], Loss: 0.0113\n",
      "Epoch [5/10], Step [201/1079], Loss: 0.0087\n",
      "Epoch [5/10], Step [202/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [203/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [204/1079], Loss: 0.0027\n",
      "Epoch [5/10], Step [205/1079], Loss: 0.0332\n",
      "Epoch [5/10], Step [206/1079], Loss: 0.0053\n",
      "Epoch [5/10], Step [207/1079], Loss: 0.0028\n",
      "Epoch [5/10], Step [208/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [209/1079], Loss: 0.0122\n",
      "Epoch [5/10], Step [210/1079], Loss: 0.0044\n",
      "Epoch [5/10], Step [211/1079], Loss: 0.0757\n",
      "Epoch [5/10], Step [212/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [213/1079], Loss: 0.0700\n",
      "Epoch [5/10], Step [214/1079], Loss: 0.0117\n",
      "Epoch [5/10], Step [215/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [216/1079], Loss: 0.0129\n",
      "Epoch [5/10], Step [217/1079], Loss: 0.0020\n",
      "Epoch [5/10], Step [218/1079], Loss: 0.0019\n",
      "Epoch [5/10], Step [219/1079], Loss: 0.0121\n",
      "Epoch [5/10], Step [220/1079], Loss: 0.0033\n",
      "Epoch [5/10], Step [221/1079], Loss: 0.0220\n",
      "Epoch [5/10], Step [222/1079], Loss: 0.0021\n",
      "Epoch [5/10], Step [223/1079], Loss: 0.0067\n",
      "Epoch [5/10], Step [224/1079], Loss: 0.0168\n",
      "Epoch [5/10], Step [225/1079], Loss: 0.0006\n",
      "Epoch [5/10], Step [226/1079], Loss: 0.0178\n",
      "Epoch [5/10], Step [227/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [228/1079], Loss: 0.0065\n",
      "Epoch [5/10], Step [229/1079], Loss: 0.0010\n",
      "Epoch [5/10], Step [230/1079], Loss: 0.0081\n",
      "Epoch [5/10], Step [231/1079], Loss: 0.0065\n",
      "Epoch [5/10], Step [232/1079], Loss: 0.0059\n",
      "Epoch [5/10], Step [233/1079], Loss: 0.0109\n",
      "Epoch [5/10], Step [234/1079], Loss: 0.0090\n",
      "Epoch [5/10], Step [235/1079], Loss: 0.0074\n",
      "Epoch [5/10], Step [236/1079], Loss: 0.0023\n",
      "Epoch [5/10], Step [237/1079], Loss: 0.1362\n",
      "Epoch [5/10], Step [238/1079], Loss: 0.0038\n",
      "Epoch [5/10], Step [239/1079], Loss: 0.0127\n",
      "Epoch [5/10], Step [240/1079], Loss: 0.0343\n",
      "Epoch [5/10], Step [241/1079], Loss: 0.0442\n",
      "Epoch [5/10], Step [242/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [243/1079], Loss: 0.0018\n",
      "Epoch [5/10], Step [244/1079], Loss: 0.0379\n",
      "Epoch [5/10], Step [245/1079], Loss: 0.0417\n",
      "Epoch [5/10], Step [246/1079], Loss: 0.0011\n",
      "Epoch [5/10], Step [247/1079], Loss: 0.0101\n",
      "Epoch [5/10], Step [248/1079], Loss: 0.0246\n",
      "Epoch [5/10], Step [249/1079], Loss: 0.1209\n",
      "Epoch [5/10], Step [250/1079], Loss: 0.0312\n",
      "Epoch [5/10], Step [251/1079], Loss: 0.0026\n",
      "Epoch [5/10], Step [252/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [253/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [254/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [255/1079], Loss: 0.0013\n",
      "Epoch [5/10], Step [256/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [257/1079], Loss: 0.0315\n",
      "Epoch [5/10], Step [258/1079], Loss: 0.0177\n",
      "Epoch [5/10], Step [259/1079], Loss: 0.0319\n",
      "Epoch [5/10], Step [260/1079], Loss: 0.0008\n",
      "Epoch [5/10], Step [261/1079], Loss: 0.0032\n",
      "Epoch [5/10], Step [262/1079], Loss: 0.0577\n",
      "Epoch [5/10], Step [263/1079], Loss: 0.0293\n",
      "Epoch [5/10], Step [264/1079], Loss: 0.1791\n",
      "Epoch [5/10], Step [265/1079], Loss: 0.0375\n",
      "Epoch [5/10], Step [266/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [267/1079], Loss: 0.0029\n",
      "Epoch [5/10], Step [268/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [269/1079], Loss: 0.0061\n",
      "Epoch [5/10], Step [270/1079], Loss: 0.0405\n",
      "Epoch [5/10], Step [271/1079], Loss: 0.0075\n",
      "Epoch [5/10], Step [272/1079], Loss: 0.1424\n",
      "Epoch [5/10], Step [273/1079], Loss: 0.0192\n",
      "Epoch [5/10], Step [274/1079], Loss: 0.0010\n",
      "Epoch [5/10], Step [275/1079], Loss: 0.0016\n",
      "Epoch [5/10], Step [276/1079], Loss: 0.0023\n",
      "Epoch [5/10], Step [277/1079], Loss: 0.0277\n",
      "Epoch [5/10], Step [278/1079], Loss: 0.0016\n",
      "Epoch [5/10], Step [279/1079], Loss: 0.0312\n",
      "Epoch [5/10], Step [280/1079], Loss: 0.0080\n",
      "Epoch [5/10], Step [281/1079], Loss: 0.0298\n",
      "Epoch [5/10], Step [282/1079], Loss: 0.0054\n",
      "Epoch [5/10], Step [283/1079], Loss: 0.0020\n",
      "Epoch [5/10], Step [284/1079], Loss: 0.0279\n",
      "Epoch [5/10], Step [285/1079], Loss: 0.0376\n",
      "Epoch [5/10], Step [286/1079], Loss: 0.0036\n",
      "Epoch [5/10], Step [287/1079], Loss: 0.0176\n",
      "Epoch [5/10], Step [288/1079], Loss: 0.0008\n",
      "Epoch [5/10], Step [289/1079], Loss: 0.0666\n",
      "Epoch [5/10], Step [290/1079], Loss: 0.0259\n",
      "Epoch [5/10], Step [291/1079], Loss: 0.0047\n",
      "Epoch [5/10], Step [292/1079], Loss: 0.0253\n",
      "Epoch [5/10], Step [293/1079], Loss: 0.0074\n",
      "Epoch [5/10], Step [294/1079], Loss: 0.0148\n",
      "Epoch [5/10], Step [295/1079], Loss: 0.0024\n",
      "Epoch [5/10], Step [296/1079], Loss: 0.0082\n",
      "Epoch [5/10], Step [297/1079], Loss: 0.0035\n",
      "Epoch [5/10], Step [298/1079], Loss: 0.0143\n",
      "Epoch [5/10], Step [299/1079], Loss: 0.0505\n",
      "Epoch [5/10], Step [300/1079], Loss: 0.0037\n",
      "Epoch [5/10], Step [301/1079], Loss: 0.0068\n",
      "Epoch [5/10], Step [302/1079], Loss: 0.0037\n",
      "Epoch [5/10], Step [303/1079], Loss: 0.0023\n",
      "Epoch [5/10], Step [304/1079], Loss: 0.0125\n",
      "Epoch [5/10], Step [305/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [306/1079], Loss: 0.0124\n",
      "Epoch [5/10], Step [307/1079], Loss: 0.0145\n",
      "Epoch [5/10], Step [308/1079], Loss: 0.0016\n",
      "Epoch [5/10], Step [309/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [310/1079], Loss: 0.0141\n",
      "Epoch [5/10], Step [311/1079], Loss: 0.0055\n",
      "Epoch [5/10], Step [312/1079], Loss: 0.0484\n",
      "Epoch [5/10], Step [313/1079], Loss: 0.0177\n",
      "Epoch [5/10], Step [314/1079], Loss: 0.0908\n",
      "Epoch [5/10], Step [315/1079], Loss: 0.0033\n",
      "Epoch [5/10], Step [316/1079], Loss: 0.0125\n",
      "Epoch [5/10], Step [317/1079], Loss: 0.0465\n",
      "Epoch [5/10], Step [318/1079], Loss: 0.0142\n",
      "Epoch [5/10], Step [319/1079], Loss: 0.0150\n",
      "Epoch [5/10], Step [320/1079], Loss: 0.0706\n",
      "Epoch [5/10], Step [321/1079], Loss: 0.0043\n",
      "Epoch [5/10], Step [322/1079], Loss: 0.0181\n",
      "Epoch [5/10], Step [323/1079], Loss: 0.0033\n",
      "Epoch [5/10], Step [324/1079], Loss: 0.0030\n",
      "Epoch [5/10], Step [325/1079], Loss: 0.0244\n",
      "Epoch [5/10], Step [326/1079], Loss: 0.0488\n",
      "Epoch [5/10], Step [327/1079], Loss: 0.0071\n",
      "Epoch [5/10], Step [328/1079], Loss: 0.0010\n",
      "Epoch [5/10], Step [329/1079], Loss: 0.0208\n",
      "Epoch [5/10], Step [330/1079], Loss: 0.0191\n",
      "Epoch [5/10], Step [331/1079], Loss: 0.1530\n",
      "Epoch [5/10], Step [332/1079], Loss: 0.0144\n",
      "Epoch [5/10], Step [333/1079], Loss: 0.0025\n",
      "Epoch [5/10], Step [334/1079], Loss: 0.0025\n",
      "Epoch [5/10], Step [335/1079], Loss: 0.0051\n",
      "Epoch [5/10], Step [336/1079], Loss: 0.0197\n",
      "Epoch [5/10], Step [337/1079], Loss: 0.0039\n",
      "Epoch [5/10], Step [338/1079], Loss: 0.0059\n",
      "Epoch [5/10], Step [339/1079], Loss: 0.0881\n",
      "Epoch [5/10], Step [340/1079], Loss: 0.0369\n",
      "Epoch [5/10], Step [341/1079], Loss: 0.0462\n",
      "Epoch [5/10], Step [342/1079], Loss: 0.0013\n",
      "Epoch [5/10], Step [343/1079], Loss: 0.0119\n",
      "Epoch [5/10], Step [344/1079], Loss: 0.0853\n",
      "Epoch [5/10], Step [345/1079], Loss: 0.0364\n",
      "Epoch [5/10], Step [346/1079], Loss: 0.0037\n",
      "Epoch [5/10], Step [347/1079], Loss: 0.0011\n",
      "Epoch [5/10], Step [348/1079], Loss: 0.0087\n",
      "Epoch [5/10], Step [349/1079], Loss: 0.0148\n",
      "Epoch [5/10], Step [350/1079], Loss: 0.0127\n",
      "Epoch [5/10], Step [351/1079], Loss: 0.0604\n",
      "Epoch [5/10], Step [352/1079], Loss: 0.0032\n",
      "Epoch [5/10], Step [353/1079], Loss: 0.0070\n",
      "Epoch [5/10], Step [354/1079], Loss: 0.0021\n",
      "Epoch [5/10], Step [355/1079], Loss: 0.0020\n",
      "Epoch [5/10], Step [356/1079], Loss: 0.0025\n",
      "Epoch [5/10], Step [357/1079], Loss: 0.0111\n",
      "Epoch [5/10], Step [358/1079], Loss: 0.0297\n",
      "Epoch [5/10], Step [359/1079], Loss: 0.0070\n",
      "Epoch [5/10], Step [360/1079], Loss: 0.0214\n",
      "Epoch [5/10], Step [361/1079], Loss: 0.0253\n",
      "Epoch [5/10], Step [362/1079], Loss: 0.0750\n",
      "Epoch [5/10], Step [363/1079], Loss: 0.0162\n",
      "Epoch [5/10], Step [364/1079], Loss: 0.0648\n",
      "Epoch [5/10], Step [365/1079], Loss: 0.0603\n",
      "Epoch [5/10], Step [366/1079], Loss: 0.0069\n",
      "Epoch [5/10], Step [367/1079], Loss: 0.0064\n",
      "Epoch [5/10], Step [368/1079], Loss: 0.0040\n",
      "Epoch [5/10], Step [369/1079], Loss: 0.0021\n",
      "Epoch [5/10], Step [370/1079], Loss: 0.0080\n",
      "Epoch [5/10], Step [371/1079], Loss: 0.0261\n",
      "Epoch [5/10], Step [372/1079], Loss: 0.0580\n",
      "Epoch [5/10], Step [373/1079], Loss: 0.0451\n",
      "Epoch [5/10], Step [374/1079], Loss: 0.0049\n",
      "Epoch [5/10], Step [375/1079], Loss: 0.0051\n",
      "Epoch [5/10], Step [376/1079], Loss: 0.0153\n",
      "Epoch [5/10], Step [377/1079], Loss: 0.0477\n",
      "Epoch [5/10], Step [378/1079], Loss: 0.0170\n",
      "Epoch [5/10], Step [379/1079], Loss: 0.0059\n",
      "Epoch [5/10], Step [380/1079], Loss: 0.0023\n",
      "Epoch [5/10], Step [381/1079], Loss: 0.0044\n",
      "Epoch [5/10], Step [382/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [383/1079], Loss: 0.0054\n",
      "Epoch [5/10], Step [384/1079], Loss: 0.0184\n",
      "Epoch [5/10], Step [385/1079], Loss: 0.0256\n",
      "Epoch [5/10], Step [386/1079], Loss: 0.0140\n",
      "Epoch [5/10], Step [387/1079], Loss: 0.0273\n",
      "Epoch [5/10], Step [388/1079], Loss: 0.0029\n",
      "Epoch [5/10], Step [389/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [390/1079], Loss: 0.0841\n",
      "Epoch [5/10], Step [391/1079], Loss: 0.0141\n",
      "Epoch [5/10], Step [392/1079], Loss: 0.0100\n",
      "Epoch [5/10], Step [393/1079], Loss: 0.0301\n",
      "Epoch [5/10], Step [394/1079], Loss: 0.0077\n",
      "Epoch [5/10], Step [395/1079], Loss: 0.0018\n",
      "Epoch [5/10], Step [396/1079], Loss: 0.0034\n",
      "Epoch [5/10], Step [397/1079], Loss: 0.0502\n",
      "Epoch [5/10], Step [398/1079], Loss: 0.0090\n",
      "Epoch [5/10], Step [399/1079], Loss: 0.0020\n",
      "Epoch [5/10], Step [400/1079], Loss: 0.0099\n",
      "Epoch [5/10], Step [401/1079], Loss: 0.0038\n",
      "Epoch [5/10], Step [402/1079], Loss: 0.0123\n",
      "Epoch [5/10], Step [403/1079], Loss: 0.0065\n",
      "Epoch [5/10], Step [404/1079], Loss: 0.0021\n",
      "Epoch [5/10], Step [405/1079], Loss: 0.0027\n",
      "Epoch [5/10], Step [406/1079], Loss: 0.0011\n",
      "Epoch [5/10], Step [407/1079], Loss: 0.0108\n",
      "Epoch [5/10], Step [408/1079], Loss: 0.0509\n",
      "Epoch [5/10], Step [409/1079], Loss: 0.0921\n",
      "Epoch [5/10], Step [410/1079], Loss: 0.0174\n",
      "Epoch [5/10], Step [411/1079], Loss: 0.0045\n",
      "Epoch [5/10], Step [412/1079], Loss: 0.0019\n",
      "Epoch [5/10], Step [413/1079], Loss: 0.0102\n",
      "Epoch [5/10], Step [414/1079], Loss: 0.0028\n",
      "Epoch [5/10], Step [415/1079], Loss: 0.0103\n",
      "Epoch [5/10], Step [416/1079], Loss: 0.0201\n",
      "Epoch [5/10], Step [417/1079], Loss: 0.0410\n",
      "Epoch [5/10], Step [418/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [419/1079], Loss: 0.1420\n",
      "Epoch [5/10], Step [420/1079], Loss: 0.0071\n",
      "Epoch [5/10], Step [421/1079], Loss: 0.0133\n",
      "Epoch [5/10], Step [422/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [423/1079], Loss: 0.0032\n",
      "Epoch [5/10], Step [424/1079], Loss: 0.0074\n",
      "Epoch [5/10], Step [425/1079], Loss: 0.0865\n",
      "Epoch [5/10], Step [426/1079], Loss: 0.0013\n",
      "Epoch [5/10], Step [427/1079], Loss: 0.0029\n",
      "Epoch [5/10], Step [428/1079], Loss: 0.0460\n",
      "Epoch [5/10], Step [429/1079], Loss: 0.0013\n",
      "Epoch [5/10], Step [430/1079], Loss: 0.0732\n",
      "Epoch [5/10], Step [431/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [432/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [433/1079], Loss: 0.0283\n",
      "Epoch [5/10], Step [434/1079], Loss: 0.0021\n",
      "Epoch [5/10], Step [435/1079], Loss: 0.0427\n",
      "Epoch [5/10], Step [436/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [437/1079], Loss: 0.0213\n",
      "Epoch [5/10], Step [438/1079], Loss: 0.0178\n",
      "Epoch [5/10], Step [439/1079], Loss: 0.0156\n",
      "Epoch [5/10], Step [440/1079], Loss: 0.0293\n",
      "Epoch [5/10], Step [441/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [442/1079], Loss: 0.0043\n",
      "Epoch [5/10], Step [443/1079], Loss: 0.0339\n",
      "Epoch [5/10], Step [444/1079], Loss: 0.0275\n",
      "Epoch [5/10], Step [445/1079], Loss: 0.0133\n",
      "Epoch [5/10], Step [446/1079], Loss: 0.0173\n",
      "Epoch [5/10], Step [447/1079], Loss: 0.0036\n",
      "Epoch [5/10], Step [448/1079], Loss: 0.0445\n",
      "Epoch [5/10], Step [449/1079], Loss: 0.0157\n",
      "Epoch [5/10], Step [450/1079], Loss: 0.0051\n",
      "Epoch [5/10], Step [451/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [452/1079], Loss: 0.0030\n",
      "Epoch [5/10], Step [453/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [454/1079], Loss: 0.0046\n",
      "Epoch [5/10], Step [455/1079], Loss: 0.0026\n",
      "Epoch [5/10], Step [456/1079], Loss: 0.0431\n",
      "Epoch [5/10], Step [457/1079], Loss: 0.0488\n",
      "Epoch [5/10], Step [458/1079], Loss: 0.0179\n",
      "Epoch [5/10], Step [459/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [460/1079], Loss: 0.0141\n",
      "Epoch [5/10], Step [461/1079], Loss: 0.0236\n",
      "Epoch [5/10], Step [462/1079], Loss: 0.0267\n",
      "Epoch [5/10], Step [463/1079], Loss: 0.0110\n",
      "Epoch [5/10], Step [464/1079], Loss: 0.0474\n",
      "Epoch [5/10], Step [465/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [466/1079], Loss: 0.0135\n",
      "Epoch [5/10], Step [467/1079], Loss: 0.0043\n",
      "Epoch [5/10], Step [468/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [469/1079], Loss: 0.0042\n",
      "Epoch [5/10], Step [470/1079], Loss: 0.0135\n",
      "Epoch [5/10], Step [471/1079], Loss: 0.0053\n",
      "Epoch [5/10], Step [472/1079], Loss: 0.0574\n",
      "Epoch [5/10], Step [473/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [474/1079], Loss: 0.0041\n",
      "Epoch [5/10], Step [475/1079], Loss: 0.0044\n",
      "Epoch [5/10], Step [476/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [477/1079], Loss: 0.0001\n",
      "Epoch [5/10], Step [478/1079], Loss: 0.0051\n",
      "Epoch [5/10], Step [479/1079], Loss: 0.0042\n",
      "Epoch [5/10], Step [480/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [481/1079], Loss: 0.0139\n",
      "Epoch [5/10], Step [482/1079], Loss: 0.0100\n",
      "Epoch [5/10], Step [483/1079], Loss: 0.0252\n",
      "Epoch [5/10], Step [484/1079], Loss: 0.0118\n",
      "Epoch [5/10], Step [485/1079], Loss: 0.0134\n",
      "Epoch [5/10], Step [486/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [487/1079], Loss: 0.0027\n",
      "Epoch [5/10], Step [488/1079], Loss: 0.0117\n",
      "Epoch [5/10], Step [489/1079], Loss: 0.0071\n",
      "Epoch [5/10], Step [490/1079], Loss: 0.0350\n",
      "Epoch [5/10], Step [491/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [492/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [493/1079], Loss: 0.0023\n",
      "Epoch [5/10], Step [494/1079], Loss: 0.1088\n",
      "Epoch [5/10], Step [495/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [496/1079], Loss: 0.0183\n",
      "Epoch [5/10], Step [497/1079], Loss: 0.0033\n",
      "Epoch [5/10], Step [498/1079], Loss: 0.0138\n",
      "Epoch [5/10], Step [499/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [500/1079], Loss: 0.0074\n",
      "Epoch [5/10], Step [501/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [502/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [503/1079], Loss: 0.0104\n",
      "Epoch [5/10], Step [504/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [505/1079], Loss: 0.0203\n",
      "Epoch [5/10], Step [506/1079], Loss: 0.0135\n",
      "Epoch [5/10], Step [507/1079], Loss: 0.0028\n",
      "Epoch [5/10], Step [508/1079], Loss: 0.0302\n",
      "Epoch [5/10], Step [509/1079], Loss: 0.0006\n",
      "Epoch [5/10], Step [510/1079], Loss: 0.0038\n",
      "Epoch [5/10], Step [511/1079], Loss: 0.0025\n",
      "Epoch [5/10], Step [512/1079], Loss: 0.0119\n",
      "Epoch [5/10], Step [513/1079], Loss: 0.0026\n",
      "Epoch [5/10], Step [514/1079], Loss: 0.0358\n",
      "Epoch [5/10], Step [515/1079], Loss: 0.0034\n",
      "Epoch [5/10], Step [516/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [517/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [518/1079], Loss: 0.0026\n",
      "Epoch [5/10], Step [519/1079], Loss: 0.0278\n",
      "Epoch [5/10], Step [520/1079], Loss: 0.0039\n",
      "Epoch [5/10], Step [521/1079], Loss: 0.0170\n",
      "Epoch [5/10], Step [522/1079], Loss: 0.0025\n",
      "Epoch [5/10], Step [523/1079], Loss: 0.0157\n",
      "Epoch [5/10], Step [524/1079], Loss: 0.0022\n",
      "Epoch [5/10], Step [525/1079], Loss: 0.0065\n",
      "Epoch [5/10], Step [526/1079], Loss: 0.0071\n",
      "Epoch [5/10], Step [527/1079], Loss: 0.0105\n",
      "Epoch [5/10], Step [528/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [529/1079], Loss: 0.0046\n",
      "Epoch [5/10], Step [530/1079], Loss: 0.0018\n",
      "Epoch [5/10], Step [531/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [532/1079], Loss: 0.0197\n",
      "Epoch [5/10], Step [533/1079], Loss: 0.0114\n",
      "Epoch [5/10], Step [534/1079], Loss: 0.0198\n",
      "Epoch [5/10], Step [535/1079], Loss: 0.0074\n",
      "Epoch [5/10], Step [536/1079], Loss: 0.0177\n",
      "Epoch [5/10], Step [537/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [538/1079], Loss: 0.0097\n",
      "Epoch [5/10], Step [539/1079], Loss: 0.0507\n",
      "Epoch [5/10], Step [540/1079], Loss: 0.0668\n",
      "Epoch [5/10], Step [541/1079], Loss: 0.0107\n",
      "Epoch [5/10], Step [542/1079], Loss: 0.0006\n",
      "Epoch [5/10], Step [543/1079], Loss: 0.0055\n",
      "Epoch [5/10], Step [544/1079], Loss: 0.0013\n",
      "Epoch [5/10], Step [545/1079], Loss: 0.0230\n",
      "Epoch [5/10], Step [546/1079], Loss: 0.0068\n",
      "Epoch [5/10], Step [547/1079], Loss: 0.0260\n",
      "Epoch [5/10], Step [548/1079], Loss: 0.0953\n",
      "Epoch [5/10], Step [549/1079], Loss: 0.0024\n",
      "Epoch [5/10], Step [550/1079], Loss: 0.0273\n",
      "Epoch [5/10], Step [551/1079], Loss: 0.0237\n",
      "Epoch [5/10], Step [552/1079], Loss: 0.0020\n",
      "Epoch [5/10], Step [553/1079], Loss: 0.0213\n",
      "Epoch [5/10], Step [554/1079], Loss: 0.0042\n",
      "Epoch [5/10], Step [555/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [556/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [557/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [558/1079], Loss: 0.0075\n",
      "Epoch [5/10], Step [559/1079], Loss: 0.0037\n",
      "Epoch [5/10], Step [560/1079], Loss: 0.0010\n",
      "Epoch [5/10], Step [561/1079], Loss: 0.0361\n",
      "Epoch [5/10], Step [562/1079], Loss: 0.0052\n",
      "Epoch [5/10], Step [563/1079], Loss: 0.0122\n",
      "Epoch [5/10], Step [564/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [565/1079], Loss: 0.0024\n",
      "Epoch [5/10], Step [566/1079], Loss: 0.0026\n",
      "Epoch [5/10], Step [567/1079], Loss: 0.0002\n",
      "Epoch [5/10], Step [568/1079], Loss: 0.0229\n",
      "Epoch [5/10], Step [569/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [570/1079], Loss: 0.0045\n",
      "Epoch [5/10], Step [571/1079], Loss: 0.0019\n",
      "Epoch [5/10], Step [572/1079], Loss: 0.0008\n",
      "Epoch [5/10], Step [573/1079], Loss: 0.0253\n",
      "Epoch [5/10], Step [574/1079], Loss: 0.0146\n",
      "Epoch [5/10], Step [575/1079], Loss: 0.0001\n",
      "Epoch [5/10], Step [576/1079], Loss: 0.0030\n",
      "Epoch [5/10], Step [577/1079], Loss: 0.0244\n",
      "Epoch [5/10], Step [578/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [579/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [580/1079], Loss: 0.0158\n",
      "Epoch [5/10], Step [581/1079], Loss: 0.0008\n",
      "Epoch [5/10], Step [582/1079], Loss: 0.0036\n",
      "Epoch [5/10], Step [583/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [584/1079], Loss: 0.0055\n",
      "Epoch [5/10], Step [585/1079], Loss: 0.0025\n",
      "Epoch [5/10], Step [586/1079], Loss: 0.0001\n",
      "Epoch [5/10], Step [587/1079], Loss: 0.0136\n",
      "Epoch [5/10], Step [588/1079], Loss: 0.0940\n",
      "Epoch [5/10], Step [589/1079], Loss: 0.0146\n",
      "Epoch [5/10], Step [590/1079], Loss: 0.0175\n",
      "Epoch [5/10], Step [591/1079], Loss: 0.0520\n",
      "Epoch [5/10], Step [592/1079], Loss: 0.0524\n",
      "Epoch [5/10], Step [593/1079], Loss: 0.0029\n",
      "Epoch [5/10], Step [594/1079], Loss: 0.0046\n",
      "Epoch [5/10], Step [595/1079], Loss: 0.0848\n",
      "Epoch [5/10], Step [596/1079], Loss: 0.0072\n",
      "Epoch [5/10], Step [597/1079], Loss: 0.0073\n",
      "Epoch [5/10], Step [598/1079], Loss: 0.0209\n",
      "Epoch [5/10], Step [599/1079], Loss: 0.0049\n",
      "Epoch [5/10], Step [600/1079], Loss: 0.0039\n",
      "Epoch [5/10], Step [601/1079], Loss: 0.0022\n",
      "Epoch [5/10], Step [602/1079], Loss: 0.0002\n",
      "Epoch [5/10], Step [603/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [604/1079], Loss: 0.0184\n",
      "Epoch [5/10], Step [605/1079], Loss: 0.0002\n",
      "Epoch [5/10], Step [606/1079], Loss: 0.0090\n",
      "Epoch [5/10], Step [607/1079], Loss: 0.0336\n",
      "Epoch [5/10], Step [608/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [609/1079], Loss: 0.0002\n",
      "Epoch [5/10], Step [610/1079], Loss: 0.0077\n",
      "Epoch [5/10], Step [611/1079], Loss: 0.0035\n",
      "Epoch [5/10], Step [612/1079], Loss: 0.0040\n",
      "Epoch [5/10], Step [613/1079], Loss: 0.0010\n",
      "Epoch [5/10], Step [614/1079], Loss: 0.0002\n",
      "Epoch [5/10], Step [615/1079], Loss: 0.0051\n",
      "Epoch [5/10], Step [616/1079], Loss: 0.0030\n",
      "Epoch [5/10], Step [617/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [618/1079], Loss: 0.0144\n",
      "Epoch [5/10], Step [619/1079], Loss: 0.0030\n",
      "Epoch [5/10], Step [620/1079], Loss: 0.0073\n",
      "Epoch [5/10], Step [621/1079], Loss: 0.0019\n",
      "Epoch [5/10], Step [622/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [623/1079], Loss: 0.0064\n",
      "Epoch [5/10], Step [624/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [625/1079], Loss: 0.0028\n",
      "Epoch [5/10], Step [626/1079], Loss: 0.0231\n",
      "Epoch [5/10], Step [627/1079], Loss: 0.0390\n",
      "Epoch [5/10], Step [628/1079], Loss: 0.0056\n",
      "Epoch [5/10], Step [629/1079], Loss: 0.0029\n",
      "Epoch [5/10], Step [630/1079], Loss: 0.0414\n",
      "Epoch [5/10], Step [631/1079], Loss: 0.0011\n",
      "Epoch [5/10], Step [632/1079], Loss: 0.0027\n",
      "Epoch [5/10], Step [633/1079], Loss: 0.0056\n",
      "Epoch [5/10], Step [634/1079], Loss: 0.0006\n",
      "Epoch [5/10], Step [635/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [636/1079], Loss: 0.0050\n",
      "Epoch [5/10], Step [637/1079], Loss: 0.0644\n",
      "Epoch [5/10], Step [638/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [639/1079], Loss: 0.0169\n",
      "Epoch [5/10], Step [640/1079], Loss: 0.0460\n",
      "Epoch [5/10], Step [641/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [642/1079], Loss: 0.0106\n",
      "Epoch [5/10], Step [643/1079], Loss: 0.0022\n",
      "Epoch [5/10], Step [644/1079], Loss: 0.0010\n",
      "Epoch [5/10], Step [645/1079], Loss: 0.0102\n",
      "Epoch [5/10], Step [646/1079], Loss: 0.1074\n",
      "Epoch [5/10], Step [647/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [648/1079], Loss: 0.0094\n",
      "Epoch [5/10], Step [649/1079], Loss: 0.0886\n",
      "Epoch [5/10], Step [650/1079], Loss: 0.0111\n",
      "Epoch [5/10], Step [651/1079], Loss: 0.0306\n",
      "Epoch [5/10], Step [652/1079], Loss: 0.0303\n",
      "Epoch [5/10], Step [653/1079], Loss: 0.0123\n",
      "Epoch [5/10], Step [654/1079], Loss: 0.0031\n",
      "Epoch [5/10], Step [655/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [656/1079], Loss: 0.0302\n",
      "Epoch [5/10], Step [657/1079], Loss: 0.0956\n",
      "Epoch [5/10], Step [658/1079], Loss: 0.0788\n",
      "Epoch [5/10], Step [659/1079], Loss: 0.0267\n",
      "Epoch [5/10], Step [660/1079], Loss: 0.0282\n",
      "Epoch [5/10], Step [661/1079], Loss: 0.0045\n",
      "Epoch [5/10], Step [662/1079], Loss: 0.0024\n",
      "Epoch [5/10], Step [663/1079], Loss: 0.0042\n",
      "Epoch [5/10], Step [664/1079], Loss: 0.0429\n",
      "Epoch [5/10], Step [665/1079], Loss: 0.0671\n",
      "Epoch [5/10], Step [666/1079], Loss: 0.0029\n",
      "Epoch [5/10], Step [667/1079], Loss: 0.0134\n",
      "Epoch [5/10], Step [668/1079], Loss: 0.0452\n",
      "Epoch [5/10], Step [669/1079], Loss: 0.0043\n",
      "Epoch [5/10], Step [670/1079], Loss: 0.0560\n",
      "Epoch [5/10], Step [671/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [672/1079], Loss: 0.0033\n",
      "Epoch [5/10], Step [673/1079], Loss: 0.0008\n",
      "Epoch [5/10], Step [674/1079], Loss: 0.0123\n",
      "Epoch [5/10], Step [675/1079], Loss: 0.0261\n",
      "Epoch [5/10], Step [676/1079], Loss: 0.0078\n",
      "Epoch [5/10], Step [677/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [678/1079], Loss: 0.1126\n",
      "Epoch [5/10], Step [679/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [680/1079], Loss: 0.0347\n",
      "Epoch [5/10], Step [681/1079], Loss: 0.0259\n",
      "Epoch [5/10], Step [682/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [683/1079], Loss: 0.0316\n",
      "Epoch [5/10], Step [684/1079], Loss: 0.0188\n",
      "Epoch [5/10], Step [685/1079], Loss: 0.0353\n",
      "Epoch [5/10], Step [686/1079], Loss: 0.0367\n",
      "Epoch [5/10], Step [687/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [688/1079], Loss: 0.0529\n",
      "Epoch [5/10], Step [689/1079], Loss: 0.0032\n",
      "Epoch [5/10], Step [690/1079], Loss: 0.0074\n",
      "Epoch [5/10], Step [691/1079], Loss: 0.0090\n",
      "Epoch [5/10], Step [692/1079], Loss: 0.0221\n",
      "Epoch [5/10], Step [693/1079], Loss: 0.0077\n",
      "Epoch [5/10], Step [694/1079], Loss: 0.0056\n",
      "Epoch [5/10], Step [695/1079], Loss: 0.0020\n",
      "Epoch [5/10], Step [696/1079], Loss: 0.0359\n",
      "Epoch [5/10], Step [697/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [698/1079], Loss: 0.0028\n",
      "Epoch [5/10], Step [699/1079], Loss: 0.0075\n",
      "Epoch [5/10], Step [700/1079], Loss: 0.0309\n",
      "Epoch [5/10], Step [701/1079], Loss: 0.0187\n",
      "Epoch [5/10], Step [702/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [703/1079], Loss: 0.0119\n",
      "Epoch [5/10], Step [704/1079], Loss: 0.0077\n",
      "Epoch [5/10], Step [705/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [706/1079], Loss: 0.0021\n",
      "Epoch [5/10], Step [707/1079], Loss: 0.0097\n",
      "Epoch [5/10], Step [708/1079], Loss: 0.0032\n",
      "Epoch [5/10], Step [709/1079], Loss: 0.0391\n",
      "Epoch [5/10], Step [710/1079], Loss: 0.0010\n",
      "Epoch [5/10], Step [711/1079], Loss: 0.0049\n",
      "Epoch [5/10], Step [712/1079], Loss: 0.0040\n",
      "Epoch [5/10], Step [713/1079], Loss: 0.0091\n",
      "Epoch [5/10], Step [714/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [715/1079], Loss: 0.0044\n",
      "Epoch [5/10], Step [716/1079], Loss: 0.0022\n",
      "Epoch [5/10], Step [717/1079], Loss: 0.0430\n",
      "Epoch [5/10], Step [718/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [719/1079], Loss: 0.0021\n",
      "Epoch [5/10], Step [720/1079], Loss: 0.0016\n",
      "Epoch [5/10], Step [721/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [722/1079], Loss: 0.0066\n",
      "Epoch [5/10], Step [723/1079], Loss: 0.0101\n",
      "Epoch [5/10], Step [724/1079], Loss: 0.0034\n",
      "Epoch [5/10], Step [725/1079], Loss: 0.0240\n",
      "Epoch [5/10], Step [726/1079], Loss: 0.0353\n",
      "Epoch [5/10], Step [727/1079], Loss: 0.0002\n",
      "Epoch [5/10], Step [728/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [729/1079], Loss: 0.0036\n",
      "Epoch [5/10], Step [730/1079], Loss: 0.0108\n",
      "Epoch [5/10], Step [731/1079], Loss: 0.0082\n",
      "Epoch [5/10], Step [732/1079], Loss: 0.0627\n",
      "Epoch [5/10], Step [733/1079], Loss: 0.0100\n",
      "Epoch [5/10], Step [734/1079], Loss: 0.0092\n",
      "Epoch [5/10], Step [735/1079], Loss: 0.0002\n",
      "Epoch [5/10], Step [736/1079], Loss: 0.0243\n",
      "Epoch [5/10], Step [737/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [738/1079], Loss: 0.0087\n",
      "Epoch [5/10], Step [739/1079], Loss: 0.0545\n",
      "Epoch [5/10], Step [740/1079], Loss: 0.0011\n",
      "Epoch [5/10], Step [741/1079], Loss: 0.0089\n",
      "Epoch [5/10], Step [742/1079], Loss: 0.0837\n",
      "Epoch [5/10], Step [743/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [744/1079], Loss: 0.0168\n",
      "Epoch [5/10], Step [745/1079], Loss: 0.0133\n",
      "Epoch [5/10], Step [746/1079], Loss: 0.0098\n",
      "Epoch [5/10], Step [747/1079], Loss: 0.0034\n",
      "Epoch [5/10], Step [748/1079], Loss: 0.0034\n",
      "Epoch [5/10], Step [749/1079], Loss: 0.0163\n",
      "Epoch [5/10], Step [750/1079], Loss: 0.0254\n",
      "Epoch [5/10], Step [751/1079], Loss: 0.0027\n",
      "Epoch [5/10], Step [752/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [753/1079], Loss: 0.0381\n",
      "Epoch [5/10], Step [754/1079], Loss: 0.1062\n",
      "Epoch [5/10], Step [755/1079], Loss: 0.0043\n",
      "Epoch [5/10], Step [756/1079], Loss: 0.0177\n",
      "Epoch [5/10], Step [757/1079], Loss: 0.0064\n",
      "Epoch [5/10], Step [758/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [759/1079], Loss: 0.0130\n",
      "Epoch [5/10], Step [760/1079], Loss: 0.0977\n",
      "Epoch [5/10], Step [761/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [762/1079], Loss: 0.0100\n",
      "Epoch [5/10], Step [763/1079], Loss: 0.0249\n",
      "Epoch [5/10], Step [764/1079], Loss: 0.0021\n",
      "Epoch [5/10], Step [765/1079], Loss: 0.0422\n",
      "Epoch [5/10], Step [766/1079], Loss: 0.0047\n",
      "Epoch [5/10], Step [767/1079], Loss: 0.0029\n",
      "Epoch [5/10], Step [768/1079], Loss: 0.0050\n",
      "Epoch [5/10], Step [769/1079], Loss: 0.0293\n",
      "Epoch [5/10], Step [770/1079], Loss: 0.0023\n",
      "Epoch [5/10], Step [771/1079], Loss: 0.0040\n",
      "Epoch [5/10], Step [772/1079], Loss: 0.0174\n",
      "Epoch [5/10], Step [773/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [774/1079], Loss: 0.0055\n",
      "Epoch [5/10], Step [775/1079], Loss: 0.0173\n",
      "Epoch [5/10], Step [776/1079], Loss: 0.0077\n",
      "Epoch [5/10], Step [777/1079], Loss: 0.0155\n",
      "Epoch [5/10], Step [778/1079], Loss: 0.0046\n",
      "Epoch [5/10], Step [779/1079], Loss: 0.0069\n",
      "Epoch [5/10], Step [780/1079], Loss: 0.0131\n",
      "Epoch [5/10], Step [781/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [782/1079], Loss: 0.0018\n",
      "Epoch [5/10], Step [783/1079], Loss: 0.0590\n",
      "Epoch [5/10], Step [784/1079], Loss: 0.0238\n",
      "Epoch [5/10], Step [785/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [786/1079], Loss: 0.0046\n",
      "Epoch [5/10], Step [787/1079], Loss: 0.0346\n",
      "Epoch [5/10], Step [788/1079], Loss: 0.0076\n",
      "Epoch [5/10], Step [789/1079], Loss: 0.0057\n",
      "Epoch [5/10], Step [790/1079], Loss: 0.0042\n",
      "Epoch [5/10], Step [791/1079], Loss: 0.0297\n",
      "Epoch [5/10], Step [792/1079], Loss: 0.0094\n",
      "Epoch [5/10], Step [793/1079], Loss: 0.0108\n",
      "Epoch [5/10], Step [794/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [795/1079], Loss: 0.0072\n",
      "Epoch [5/10], Step [796/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [797/1079], Loss: 0.0228\n",
      "Epoch [5/10], Step [798/1079], Loss: 0.0006\n",
      "Epoch [5/10], Step [799/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [800/1079], Loss: 0.0099\n",
      "Epoch [5/10], Step [801/1079], Loss: 0.0268\n",
      "Epoch [5/10], Step [802/1079], Loss: 0.0020\n",
      "Epoch [5/10], Step [803/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [804/1079], Loss: 0.0042\n",
      "Epoch [5/10], Step [805/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [806/1079], Loss: 0.0020\n",
      "Epoch [5/10], Step [807/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [808/1079], Loss: 0.0250\n",
      "Epoch [5/10], Step [809/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [810/1079], Loss: 0.0691\n",
      "Epoch [5/10], Step [811/1079], Loss: 0.0093\n",
      "Epoch [5/10], Step [812/1079], Loss: 0.0716\n",
      "Epoch [5/10], Step [813/1079], Loss: 0.0153\n",
      "Epoch [5/10], Step [814/1079], Loss: 0.0209\n",
      "Epoch [5/10], Step [815/1079], Loss: 0.0703\n",
      "Epoch [5/10], Step [816/1079], Loss: 0.0020\n",
      "Epoch [5/10], Step [817/1079], Loss: 0.0150\n",
      "Epoch [5/10], Step [818/1079], Loss: 0.0373\n",
      "Epoch [5/10], Step [819/1079], Loss: 0.0572\n",
      "Epoch [5/10], Step [820/1079], Loss: 0.0028\n",
      "Epoch [5/10], Step [821/1079], Loss: 0.0044\n",
      "Epoch [5/10], Step [822/1079], Loss: 0.0338\n",
      "Epoch [5/10], Step [823/1079], Loss: 0.0225\n",
      "Epoch [5/10], Step [824/1079], Loss: 0.0334\n",
      "Epoch [5/10], Step [825/1079], Loss: 0.0113\n",
      "Epoch [5/10], Step [826/1079], Loss: 0.0392\n",
      "Epoch [5/10], Step [827/1079], Loss: 0.0433\n",
      "Epoch [5/10], Step [828/1079], Loss: 0.0011\n",
      "Epoch [5/10], Step [829/1079], Loss: 0.0120\n",
      "Epoch [5/10], Step [830/1079], Loss: 0.0010\n",
      "Epoch [5/10], Step [831/1079], Loss: 0.0068\n",
      "Epoch [5/10], Step [832/1079], Loss: 0.0108\n",
      "Epoch [5/10], Step [833/1079], Loss: 0.0058\n",
      "Epoch [5/10], Step [834/1079], Loss: 0.0021\n",
      "Epoch [5/10], Step [835/1079], Loss: 0.0008\n",
      "Epoch [5/10], Step [836/1079], Loss: 0.0052\n",
      "Epoch [5/10], Step [837/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [838/1079], Loss: 0.0043\n",
      "Epoch [5/10], Step [839/1079], Loss: 0.0185\n",
      "Epoch [5/10], Step [840/1079], Loss: 0.0114\n",
      "Epoch [5/10], Step [841/1079], Loss: 0.0382\n",
      "Epoch [5/10], Step [842/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [843/1079], Loss: 0.0022\n",
      "Epoch [5/10], Step [844/1079], Loss: 0.0014\n",
      "Epoch [5/10], Step [845/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [846/1079], Loss: 0.0204\n",
      "Epoch [5/10], Step [847/1079], Loss: 0.1164\n",
      "Epoch [5/10], Step [848/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [849/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [850/1079], Loss: 0.0032\n",
      "Epoch [5/10], Step [851/1079], Loss: 0.2489\n",
      "Epoch [5/10], Step [852/1079], Loss: 0.0074\n",
      "Epoch [5/10], Step [853/1079], Loss: 0.0018\n",
      "Epoch [5/10], Step [854/1079], Loss: 0.0073\n",
      "Epoch [5/10], Step [855/1079], Loss: 0.0036\n",
      "Epoch [5/10], Step [856/1079], Loss: 0.0270\n",
      "Epoch [5/10], Step [857/1079], Loss: 0.0322\n",
      "Epoch [5/10], Step [858/1079], Loss: 0.0060\n",
      "Epoch [5/10], Step [859/1079], Loss: 0.0053\n",
      "Epoch [5/10], Step [860/1079], Loss: 0.0010\n",
      "Epoch [5/10], Step [861/1079], Loss: 0.0018\n",
      "Epoch [5/10], Step [862/1079], Loss: 0.0076\n",
      "Epoch [5/10], Step [863/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [864/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [865/1079], Loss: 0.0511\n",
      "Epoch [5/10], Step [866/1079], Loss: 0.0126\n",
      "Epoch [5/10], Step [867/1079], Loss: 0.0204\n",
      "Epoch [5/10], Step [868/1079], Loss: 0.0021\n",
      "Epoch [5/10], Step [869/1079], Loss: 0.0076\n",
      "Epoch [5/10], Step [870/1079], Loss: 0.0137\n",
      "Epoch [5/10], Step [871/1079], Loss: 0.0077\n",
      "Epoch [5/10], Step [872/1079], Loss: 0.0037\n",
      "Epoch [5/10], Step [873/1079], Loss: 0.0013\n",
      "Epoch [5/10], Step [874/1079], Loss: 0.0024\n",
      "Epoch [5/10], Step [875/1079], Loss: 0.0016\n",
      "Epoch [5/10], Step [876/1079], Loss: 0.0117\n",
      "Epoch [5/10], Step [877/1079], Loss: 0.0013\n",
      "Epoch [5/10], Step [878/1079], Loss: 0.0293\n",
      "Epoch [5/10], Step [879/1079], Loss: 0.0824\n",
      "Epoch [5/10], Step [880/1079], Loss: 0.0959\n",
      "Epoch [5/10], Step [881/1079], Loss: 0.0046\n",
      "Epoch [5/10], Step [882/1079], Loss: 0.0126\n",
      "Epoch [5/10], Step [883/1079], Loss: 0.0016\n",
      "Epoch [5/10], Step [884/1079], Loss: 0.1045\n",
      "Epoch [5/10], Step [885/1079], Loss: 0.0006\n",
      "Epoch [5/10], Step [886/1079], Loss: 0.0744\n",
      "Epoch [5/10], Step [887/1079], Loss: 0.0447\n",
      "Epoch [5/10], Step [888/1079], Loss: 0.0240\n",
      "Epoch [5/10], Step [889/1079], Loss: 0.0081\n",
      "Epoch [5/10], Step [890/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [891/1079], Loss: 0.1084\n",
      "Epoch [5/10], Step [892/1079], Loss: 0.0311\n",
      "Epoch [5/10], Step [893/1079], Loss: 0.0258\n",
      "Epoch [5/10], Step [894/1079], Loss: 0.0943\n",
      "Epoch [5/10], Step [895/1079], Loss: 0.0016\n",
      "Epoch [5/10], Step [896/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [897/1079], Loss: 0.0653\n",
      "Epoch [5/10], Step [898/1079], Loss: 0.0035\n",
      "Epoch [5/10], Step [899/1079], Loss: 0.0463\n",
      "Epoch [5/10], Step [900/1079], Loss: 0.0134\n",
      "Epoch [5/10], Step [901/1079], Loss: 0.0159\n",
      "Epoch [5/10], Step [902/1079], Loss: 0.0173\n",
      "Epoch [5/10], Step [903/1079], Loss: 0.0272\n",
      "Epoch [5/10], Step [904/1079], Loss: 0.0210\n",
      "Epoch [5/10], Step [905/1079], Loss: 0.0034\n",
      "Epoch [5/10], Step [906/1079], Loss: 0.0495\n",
      "Epoch [5/10], Step [907/1079], Loss: 0.0144\n",
      "Epoch [5/10], Step [908/1079], Loss: 0.0173\n",
      "Epoch [5/10], Step [909/1079], Loss: 0.0111\n",
      "Epoch [5/10], Step [910/1079], Loss: 0.0006\n",
      "Epoch [5/10], Step [911/1079], Loss: 0.0325\n",
      "Epoch [5/10], Step [912/1079], Loss: 0.0002\n",
      "Epoch [5/10], Step [913/1079], Loss: 0.0797\n",
      "Epoch [5/10], Step [914/1079], Loss: 0.0020\n",
      "Epoch [5/10], Step [915/1079], Loss: 0.0046\n",
      "Epoch [5/10], Step [916/1079], Loss: 0.0162\n",
      "Epoch [5/10], Step [917/1079], Loss: 0.0044\n",
      "Epoch [5/10], Step [918/1079], Loss: 0.0120\n",
      "Epoch [5/10], Step [919/1079], Loss: 0.0026\n",
      "Epoch [5/10], Step [920/1079], Loss: 0.0023\n",
      "Epoch [5/10], Step [921/1079], Loss: 0.0272\n",
      "Epoch [5/10], Step [922/1079], Loss: 0.0103\n",
      "Epoch [5/10], Step [923/1079], Loss: 0.0171\n",
      "Epoch [5/10], Step [924/1079], Loss: 0.0055\n",
      "Epoch [5/10], Step [925/1079], Loss: 0.0034\n",
      "Epoch [5/10], Step [926/1079], Loss: 0.0051\n",
      "Epoch [5/10], Step [927/1079], Loss: 0.0157\n",
      "Epoch [5/10], Step [928/1079], Loss: 0.0036\n",
      "Epoch [5/10], Step [929/1079], Loss: 0.0018\n",
      "Epoch [5/10], Step [930/1079], Loss: 0.0100\n",
      "Epoch [5/10], Step [931/1079], Loss: 0.0044\n",
      "Epoch [5/10], Step [932/1079], Loss: 0.0606\n",
      "Epoch [5/10], Step [933/1079], Loss: 0.0011\n",
      "Epoch [5/10], Step [934/1079], Loss: 0.0018\n",
      "Epoch [5/10], Step [935/1079], Loss: 0.0063\n",
      "Epoch [5/10], Step [936/1079], Loss: 0.0496\n",
      "Epoch [5/10], Step [937/1079], Loss: 0.0004\n",
      "Epoch [5/10], Step [938/1079], Loss: 0.0432\n",
      "Epoch [5/10], Step [939/1079], Loss: 0.0027\n",
      "Epoch [5/10], Step [940/1079], Loss: 0.0059\n",
      "Epoch [5/10], Step [941/1079], Loss: 0.0010\n",
      "Epoch [5/10], Step [942/1079], Loss: 0.0055\n",
      "Epoch [5/10], Step [943/1079], Loss: 0.0045\n",
      "Epoch [5/10], Step [944/1079], Loss: 0.0115\n",
      "Epoch [5/10], Step [945/1079], Loss: 0.0029\n",
      "Epoch [5/10], Step [946/1079], Loss: 0.0023\n",
      "Epoch [5/10], Step [947/1079], Loss: 0.0114\n",
      "Epoch [5/10], Step [948/1079], Loss: 0.0104\n",
      "Epoch [5/10], Step [949/1079], Loss: 0.0238\n",
      "Epoch [5/10], Step [950/1079], Loss: 0.0001\n",
      "Epoch [5/10], Step [951/1079], Loss: 0.0043\n",
      "Epoch [5/10], Step [952/1079], Loss: 0.0242\n",
      "Epoch [5/10], Step [953/1079], Loss: 0.0026\n",
      "Epoch [5/10], Step [954/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [955/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [956/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [957/1079], Loss: 0.2173\n",
      "Epoch [5/10], Step [958/1079], Loss: 0.0252\n",
      "Epoch [5/10], Step [959/1079], Loss: 0.0006\n",
      "Epoch [5/10], Step [960/1079], Loss: 0.1044\n",
      "Epoch [5/10], Step [961/1079], Loss: 0.0066\n",
      "Epoch [5/10], Step [962/1079], Loss: 0.0148\n",
      "Epoch [5/10], Step [963/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [964/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [965/1079], Loss: 0.0010\n",
      "Epoch [5/10], Step [966/1079], Loss: 0.0073\n",
      "Epoch [5/10], Step [967/1079], Loss: 0.0028\n",
      "Epoch [5/10], Step [968/1079], Loss: 0.0088\n",
      "Epoch [5/10], Step [969/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [970/1079], Loss: 0.0599\n",
      "Epoch [5/10], Step [971/1079], Loss: 0.1156\n",
      "Epoch [5/10], Step [972/1079], Loss: 0.0001\n",
      "Epoch [5/10], Step [973/1079], Loss: 0.0059\n",
      "Epoch [5/10], Step [974/1079], Loss: 0.0560\n",
      "Epoch [5/10], Step [975/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [976/1079], Loss: 0.0128\n",
      "Epoch [5/10], Step [977/1079], Loss: 0.0103\n",
      "Epoch [5/10], Step [978/1079], Loss: 0.0086\n",
      "Epoch [5/10], Step [979/1079], Loss: 0.0030\n",
      "Epoch [5/10], Step [980/1079], Loss: 0.0226\n",
      "Epoch [5/10], Step [981/1079], Loss: 0.0131\n",
      "Epoch [5/10], Step [982/1079], Loss: 0.0412\n",
      "Epoch [5/10], Step [983/1079], Loss: 0.0065\n",
      "Epoch [5/10], Step [984/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [985/1079], Loss: 0.0142\n",
      "Epoch [5/10], Step [986/1079], Loss: 0.0011\n",
      "Epoch [5/10], Step [987/1079], Loss: 0.0627\n",
      "Epoch [5/10], Step [988/1079], Loss: 0.0044\n",
      "Epoch [5/10], Step [989/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [990/1079], Loss: 0.0294\n",
      "Epoch [5/10], Step [991/1079], Loss: 0.0183\n",
      "Epoch [5/10], Step [992/1079], Loss: 0.0512\n",
      "Epoch [5/10], Step [993/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [994/1079], Loss: 0.0018\n",
      "Epoch [5/10], Step [995/1079], Loss: 0.0089\n",
      "Epoch [5/10], Step [996/1079], Loss: 0.0046\n",
      "Epoch [5/10], Step [997/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [998/1079], Loss: 0.0445\n",
      "Epoch [5/10], Step [999/1079], Loss: 0.0479\n",
      "Epoch [5/10], Step [1000/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [1001/1079], Loss: 0.0081\n",
      "Epoch [5/10], Step [1002/1079], Loss: 0.0019\n",
      "Epoch [5/10], Step [1003/1079], Loss: 0.0021\n",
      "Epoch [5/10], Step [1004/1079], Loss: 0.0030\n",
      "Epoch [5/10], Step [1005/1079], Loss: 0.0077\n",
      "Epoch [5/10], Step [1006/1079], Loss: 0.0169\n",
      "Epoch [5/10], Step [1007/1079], Loss: 0.0052\n",
      "Epoch [5/10], Step [1008/1079], Loss: 0.0682\n",
      "Epoch [5/10], Step [1009/1079], Loss: 0.0065\n",
      "Epoch [5/10], Step [1010/1079], Loss: 0.0156\n",
      "Epoch [5/10], Step [1011/1079], Loss: 0.0120\n",
      "Epoch [5/10], Step [1012/1079], Loss: 0.0378\n",
      "Epoch [5/10], Step [1013/1079], Loss: 0.0003\n",
      "Epoch [5/10], Step [1014/1079], Loss: 0.0069\n",
      "Epoch [5/10], Step [1015/1079], Loss: 0.0081\n",
      "Epoch [5/10], Step [1016/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [1017/1079], Loss: 0.0138\n",
      "Epoch [5/10], Step [1018/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [1019/1079], Loss: 0.0134\n",
      "Epoch [5/10], Step [1020/1079], Loss: 0.0622\n",
      "Epoch [5/10], Step [1021/1079], Loss: 0.0038\n",
      "Epoch [5/10], Step [1022/1079], Loss: 0.0006\n",
      "Epoch [5/10], Step [1023/1079], Loss: 0.0156\n",
      "Epoch [5/10], Step [1024/1079], Loss: 0.0233\n",
      "Epoch [5/10], Step [1025/1079], Loss: 0.0029\n",
      "Epoch [5/10], Step [1026/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [1027/1079], Loss: 0.0084\n",
      "Epoch [5/10], Step [1028/1079], Loss: 0.0552\n",
      "Epoch [5/10], Step [1029/1079], Loss: 0.0127\n",
      "Epoch [5/10], Step [1030/1079], Loss: 0.3197\n",
      "Epoch [5/10], Step [1031/1079], Loss: 0.0034\n",
      "Epoch [5/10], Step [1032/1079], Loss: 0.0184\n",
      "Epoch [5/10], Step [1033/1079], Loss: 0.0066\n",
      "Epoch [5/10], Step [1034/1079], Loss: 0.0327\n",
      "Epoch [5/10], Step [1035/1079], Loss: 0.0005\n",
      "Epoch [5/10], Step [1036/1079], Loss: 0.0296\n",
      "Epoch [5/10], Step [1037/1079], Loss: 0.0214\n",
      "Epoch [5/10], Step [1038/1079], Loss: 0.0235\n",
      "Epoch [5/10], Step [1039/1079], Loss: 0.0289\n",
      "Epoch [5/10], Step [1040/1079], Loss: 0.0679\n",
      "Epoch [5/10], Step [1041/1079], Loss: 0.0624\n",
      "Epoch [5/10], Step [1042/1079], Loss: 0.0709\n",
      "Epoch [5/10], Step [1043/1079], Loss: 0.0051\n",
      "Epoch [5/10], Step [1044/1079], Loss: 0.0360\n",
      "Epoch [5/10], Step [1045/1079], Loss: 0.0049\n",
      "Epoch [5/10], Step [1046/1079], Loss: 0.0042\n",
      "Epoch [5/10], Step [1047/1079], Loss: 0.0002\n",
      "Epoch [5/10], Step [1048/1079], Loss: 0.0816\n",
      "Epoch [5/10], Step [1049/1079], Loss: 0.0127\n",
      "Epoch [5/10], Step [1050/1079], Loss: 0.0343\n",
      "Epoch [5/10], Step [1051/1079], Loss: 0.0038\n",
      "Epoch [5/10], Step [1052/1079], Loss: 0.0087\n",
      "Epoch [5/10], Step [1053/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [1054/1079], Loss: 0.0415\n",
      "Epoch [5/10], Step [1055/1079], Loss: 0.0913\n",
      "Epoch [5/10], Step [1056/1079], Loss: 0.0027\n",
      "Epoch [5/10], Step [1057/1079], Loss: 0.0035\n",
      "Epoch [5/10], Step [1058/1079], Loss: 0.0024\n",
      "Epoch [5/10], Step [1059/1079], Loss: 0.0046\n",
      "Epoch [5/10], Step [1060/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [1061/1079], Loss: 0.0086\n",
      "Epoch [5/10], Step [1062/1079], Loss: 0.0273\n",
      "Epoch [5/10], Step [1063/1079], Loss: 0.0012\n",
      "Epoch [5/10], Step [1064/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [1065/1079], Loss: 0.0006\n",
      "Epoch [5/10], Step [1066/1079], Loss: 0.0098\n",
      "Epoch [5/10], Step [1067/1079], Loss: 0.0031\n",
      "Epoch [5/10], Step [1068/1079], Loss: 0.0074\n",
      "Epoch [5/10], Step [1069/1079], Loss: 0.0015\n",
      "Epoch [5/10], Step [1070/1079], Loss: 0.0007\n",
      "Epoch [5/10], Step [1071/1079], Loss: 0.0019\n",
      "Epoch [5/10], Step [1072/1079], Loss: 0.0009\n",
      "Epoch [5/10], Step [1073/1079], Loss: 0.0170\n",
      "Epoch [5/10], Step [1074/1079], Loss: 0.0509\n",
      "Epoch [5/10], Step [1075/1079], Loss: 0.0017\n",
      "Epoch [5/10], Step [1076/1079], Loss: 0.0208\n",
      "Epoch [5/10], Step [1077/1079], Loss: 0.0107\n",
      "Epoch [5/10], Step [1078/1079], Loss: 0.0615\n",
      "Epoch [5/10], Step [1079/1079], Loss: 0.0000\n",
      "Epoch [6/10], Step [1/1079], Loss: 0.0013\n",
      "Epoch [6/10], Step [2/1079], Loss: 0.0143\n",
      "Epoch [6/10], Step [3/1079], Loss: 0.0075\n",
      "Epoch [6/10], Step [4/1079], Loss: 0.0254\n",
      "Epoch [6/10], Step [5/1079], Loss: 0.0057\n",
      "Epoch [6/10], Step [6/1079], Loss: 0.0051\n",
      "Epoch [6/10], Step [7/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [8/1079], Loss: 0.0484\n",
      "Epoch [6/10], Step [9/1079], Loss: 0.0171\n",
      "Epoch [6/10], Step [10/1079], Loss: 0.0081\n",
      "Epoch [6/10], Step [11/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [12/1079], Loss: 0.0026\n",
      "Epoch [6/10], Step [13/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [14/1079], Loss: 0.0377\n",
      "Epoch [6/10], Step [15/1079], Loss: 0.0014\n",
      "Epoch [6/10], Step [16/1079], Loss: 0.0480\n",
      "Epoch [6/10], Step [17/1079], Loss: 0.0641\n",
      "Epoch [6/10], Step [18/1079], Loss: 0.0359\n",
      "Epoch [6/10], Step [19/1079], Loss: 0.0026\n",
      "Epoch [6/10], Step [20/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [21/1079], Loss: 0.0025\n",
      "Epoch [6/10], Step [22/1079], Loss: 0.0026\n",
      "Epoch [6/10], Step [23/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [24/1079], Loss: 0.0076\n",
      "Epoch [6/10], Step [25/1079], Loss: 0.0265\n",
      "Epoch [6/10], Step [26/1079], Loss: 0.0016\n",
      "Epoch [6/10], Step [27/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [28/1079], Loss: 0.0756\n",
      "Epoch [6/10], Step [29/1079], Loss: 0.0150\n",
      "Epoch [6/10], Step [30/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [31/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [32/1079], Loss: 0.0124\n",
      "Epoch [6/10], Step [33/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [34/1079], Loss: 0.0107\n",
      "Epoch [6/10], Step [35/1079], Loss: 0.0081\n",
      "Epoch [6/10], Step [36/1079], Loss: 0.0041\n",
      "Epoch [6/10], Step [37/1079], Loss: 0.0029\n",
      "Epoch [6/10], Step [38/1079], Loss: 0.0032\n",
      "Epoch [6/10], Step [39/1079], Loss: 0.0044\n",
      "Epoch [6/10], Step [40/1079], Loss: 0.0015\n",
      "Epoch [6/10], Step [41/1079], Loss: 0.0174\n",
      "Epoch [6/10], Step [42/1079], Loss: 0.0037\n",
      "Epoch [6/10], Step [43/1079], Loss: 0.0404\n",
      "Epoch [6/10], Step [44/1079], Loss: 0.0080\n",
      "Epoch [6/10], Step [45/1079], Loss: 0.0099\n",
      "Epoch [6/10], Step [46/1079], Loss: 0.0033\n",
      "Epoch [6/10], Step [47/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [48/1079], Loss: 0.0033\n",
      "Epoch [6/10], Step [49/1079], Loss: 0.0048\n",
      "Epoch [6/10], Step [50/1079], Loss: 0.0781\n",
      "Epoch [6/10], Step [51/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [52/1079], Loss: 0.0048\n",
      "Epoch [6/10], Step [53/1079], Loss: 0.0045\n",
      "Epoch [6/10], Step [54/1079], Loss: 0.0078\n",
      "Epoch [6/10], Step [55/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [56/1079], Loss: 0.0654\n",
      "Epoch [6/10], Step [57/1079], Loss: 0.0006\n",
      "Epoch [6/10], Step [58/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [59/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [60/1079], Loss: 0.0131\n",
      "Epoch [6/10], Step [61/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [62/1079], Loss: 0.0077\n",
      "Epoch [6/10], Step [63/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [64/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [65/1079], Loss: 0.0016\n",
      "Epoch [6/10], Step [66/1079], Loss: 0.0273\n",
      "Epoch [6/10], Step [67/1079], Loss: 0.0037\n",
      "Epoch [6/10], Step [68/1079], Loss: 0.0096\n",
      "Epoch [6/10], Step [69/1079], Loss: 0.0006\n",
      "Epoch [6/10], Step [70/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [71/1079], Loss: 0.0696\n",
      "Epoch [6/10], Step [72/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [73/1079], Loss: 0.0023\n",
      "Epoch [6/10], Step [74/1079], Loss: 0.0036\n",
      "Epoch [6/10], Step [75/1079], Loss: 0.0064\n",
      "Epoch [6/10], Step [76/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [77/1079], Loss: 0.0229\n",
      "Epoch [6/10], Step [78/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [79/1079], Loss: 0.0417\n",
      "Epoch [6/10], Step [80/1079], Loss: 0.0020\n",
      "Epoch [6/10], Step [81/1079], Loss: 0.0287\n",
      "Epoch [6/10], Step [82/1079], Loss: 0.0098\n",
      "Epoch [6/10], Step [83/1079], Loss: 0.0189\n",
      "Epoch [6/10], Step [84/1079], Loss: 0.0027\n",
      "Epoch [6/10], Step [85/1079], Loss: 0.0014\n",
      "Epoch [6/10], Step [86/1079], Loss: 0.0100\n",
      "Epoch [6/10], Step [87/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [88/1079], Loss: 0.0464\n",
      "Epoch [6/10], Step [89/1079], Loss: 0.0117\n",
      "Epoch [6/10], Step [90/1079], Loss: 0.0052\n",
      "Epoch [6/10], Step [91/1079], Loss: 0.0165\n",
      "Epoch [6/10], Step [92/1079], Loss: 0.0144\n",
      "Epoch [6/10], Step [93/1079], Loss: 0.0034\n",
      "Epoch [6/10], Step [94/1079], Loss: 0.0035\n",
      "Epoch [6/10], Step [95/1079], Loss: 0.0046\n",
      "Epoch [6/10], Step [96/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [97/1079], Loss: 0.0034\n",
      "Epoch [6/10], Step [98/1079], Loss: 0.0031\n",
      "Epoch [6/10], Step [99/1079], Loss: 0.0122\n",
      "Epoch [6/10], Step [100/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [101/1079], Loss: 0.0073\n",
      "Epoch [6/10], Step [102/1079], Loss: 0.0036\n",
      "Epoch [6/10], Step [103/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [104/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [105/1079], Loss: 0.0488\n",
      "Epoch [6/10], Step [106/1079], Loss: 0.0634\n",
      "Epoch [6/10], Step [107/1079], Loss: 0.0015\n",
      "Epoch [6/10], Step [108/1079], Loss: 0.0031\n",
      "Epoch [6/10], Step [109/1079], Loss: 0.0161\n",
      "Epoch [6/10], Step [110/1079], Loss: 0.0025\n",
      "Epoch [6/10], Step [111/1079], Loss: 0.0119\n",
      "Epoch [6/10], Step [112/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [113/1079], Loss: 0.0549\n",
      "Epoch [6/10], Step [114/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [115/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [116/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [117/1079], Loss: 0.0233\n",
      "Epoch [6/10], Step [118/1079], Loss: 0.0006\n",
      "Epoch [6/10], Step [119/1079], Loss: 0.0093\n",
      "Epoch [6/10], Step [120/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [121/1079], Loss: 0.0040\n",
      "Epoch [6/10], Step [122/1079], Loss: 0.0038\n",
      "Epoch [6/10], Step [123/1079], Loss: 0.0036\n",
      "Epoch [6/10], Step [124/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [125/1079], Loss: 0.0289\n",
      "Epoch [6/10], Step [126/1079], Loss: 0.0157\n",
      "Epoch [6/10], Step [127/1079], Loss: 0.0082\n",
      "Epoch [6/10], Step [128/1079], Loss: 0.0012\n",
      "Epoch [6/10], Step [129/1079], Loss: 0.0462\n",
      "Epoch [6/10], Step [130/1079], Loss: 0.0067\n",
      "Epoch [6/10], Step [131/1079], Loss: 0.0021\n",
      "Epoch [6/10], Step [132/1079], Loss: 0.0044\n",
      "Epoch [6/10], Step [133/1079], Loss: 0.0064\n",
      "Epoch [6/10], Step [134/1079], Loss: 0.0311\n",
      "Epoch [6/10], Step [135/1079], Loss: 0.0182\n",
      "Epoch [6/10], Step [136/1079], Loss: 0.0041\n",
      "Epoch [6/10], Step [137/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [138/1079], Loss: 0.0272\n",
      "Epoch [6/10], Step [139/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [140/1079], Loss: 0.0308\n",
      "Epoch [6/10], Step [141/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [142/1079], Loss: 0.0317\n",
      "Epoch [6/10], Step [143/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [144/1079], Loss: 0.0102\n",
      "Epoch [6/10], Step [145/1079], Loss: 0.0638\n",
      "Epoch [6/10], Step [146/1079], Loss: 0.0150\n",
      "Epoch [6/10], Step [147/1079], Loss: 0.0197\n",
      "Epoch [6/10], Step [148/1079], Loss: 0.0013\n",
      "Epoch [6/10], Step [149/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [150/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [151/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [152/1079], Loss: 0.0121\n",
      "Epoch [6/10], Step [153/1079], Loss: 0.0028\n",
      "Epoch [6/10], Step [154/1079], Loss: 0.0013\n",
      "Epoch [6/10], Step [155/1079], Loss: 0.0084\n",
      "Epoch [6/10], Step [156/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [157/1079], Loss: 0.0014\n",
      "Epoch [6/10], Step [158/1079], Loss: 0.0037\n",
      "Epoch [6/10], Step [159/1079], Loss: 0.0020\n",
      "Epoch [6/10], Step [160/1079], Loss: 0.0014\n",
      "Epoch [6/10], Step [161/1079], Loss: 0.0020\n",
      "Epoch [6/10], Step [162/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [163/1079], Loss: 0.0051\n",
      "Epoch [6/10], Step [164/1079], Loss: 0.0046\n",
      "Epoch [6/10], Step [165/1079], Loss: 0.0113\n",
      "Epoch [6/10], Step [166/1079], Loss: 0.0107\n",
      "Epoch [6/10], Step [167/1079], Loss: 0.0162\n",
      "Epoch [6/10], Step [168/1079], Loss: 0.0159\n",
      "Epoch [6/10], Step [169/1079], Loss: 0.0081\n",
      "Epoch [6/10], Step [170/1079], Loss: 0.0100\n",
      "Epoch [6/10], Step [171/1079], Loss: 0.0231\n",
      "Epoch [6/10], Step [172/1079], Loss: 0.0015\n",
      "Epoch [6/10], Step [173/1079], Loss: 0.0087\n",
      "Epoch [6/10], Step [174/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [175/1079], Loss: 0.0068\n",
      "Epoch [6/10], Step [176/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [177/1079], Loss: 0.0036\n",
      "Epoch [6/10], Step [178/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [179/1079], Loss: 0.0061\n",
      "Epoch [6/10], Step [180/1079], Loss: 0.0035\n",
      "Epoch [6/10], Step [181/1079], Loss: 0.0128\n",
      "Epoch [6/10], Step [182/1079], Loss: 0.0029\n",
      "Epoch [6/10], Step [183/1079], Loss: 0.0256\n",
      "Epoch [6/10], Step [184/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [185/1079], Loss: 0.0030\n",
      "Epoch [6/10], Step [186/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [187/1079], Loss: 0.0015\n",
      "Epoch [6/10], Step [188/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [189/1079], Loss: 0.0377\n",
      "Epoch [6/10], Step [190/1079], Loss: 0.0158\n",
      "Epoch [6/10], Step [191/1079], Loss: 0.0013\n",
      "Epoch [6/10], Step [192/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [193/1079], Loss: 0.0112\n",
      "Epoch [6/10], Step [194/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [195/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [196/1079], Loss: 0.0070\n",
      "Epoch [6/10], Step [197/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [198/1079], Loss: 0.0012\n",
      "Epoch [6/10], Step [199/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [200/1079], Loss: 0.0028\n",
      "Epoch [6/10], Step [201/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [202/1079], Loss: 0.0036\n",
      "Epoch [6/10], Step [203/1079], Loss: 0.0162\n",
      "Epoch [6/10], Step [204/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [205/1079], Loss: 0.0061\n",
      "Epoch [6/10], Step [206/1079], Loss: 0.0431\n",
      "Epoch [6/10], Step [207/1079], Loss: 0.0033\n",
      "Epoch [6/10], Step [208/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [209/1079], Loss: 0.0074\n",
      "Epoch [6/10], Step [210/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [211/1079], Loss: 0.0014\n",
      "Epoch [6/10], Step [212/1079], Loss: 0.0458\n",
      "Epoch [6/10], Step [213/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [214/1079], Loss: 0.0292\n",
      "Epoch [6/10], Step [215/1079], Loss: 0.0025\n",
      "Epoch [6/10], Step [216/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [217/1079], Loss: 0.0012\n",
      "Epoch [6/10], Step [218/1079], Loss: 0.0038\n",
      "Epoch [6/10], Step [219/1079], Loss: 0.0053\n",
      "Epoch [6/10], Step [220/1079], Loss: 0.0060\n",
      "Epoch [6/10], Step [221/1079], Loss: 0.0021\n",
      "Epoch [6/10], Step [222/1079], Loss: 0.0172\n",
      "Epoch [6/10], Step [223/1079], Loss: 0.0057\n",
      "Epoch [6/10], Step [224/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [225/1079], Loss: 0.0070\n",
      "Epoch [6/10], Step [226/1079], Loss: 0.0152\n",
      "Epoch [6/10], Step [227/1079], Loss: 0.0100\n",
      "Epoch [6/10], Step [228/1079], Loss: 0.0060\n",
      "Epoch [6/10], Step [229/1079], Loss: 0.0366\n",
      "Epoch [6/10], Step [230/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [231/1079], Loss: 0.0015\n",
      "Epoch [6/10], Step [232/1079], Loss: 0.0013\n",
      "Epoch [6/10], Step [233/1079], Loss: 0.0006\n",
      "Epoch [6/10], Step [234/1079], Loss: 0.0064\n",
      "Epoch [6/10], Step [235/1079], Loss: 0.0070\n",
      "Epoch [6/10], Step [236/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [237/1079], Loss: 0.0049\n",
      "Epoch [6/10], Step [238/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [239/1079], Loss: 0.0100\n",
      "Epoch [6/10], Step [240/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [241/1079], Loss: 0.0039\n",
      "Epoch [6/10], Step [242/1079], Loss: 0.0058\n",
      "Epoch [6/10], Step [243/1079], Loss: 0.0107\n",
      "Epoch [6/10], Step [244/1079], Loss: 0.0085\n",
      "Epoch [6/10], Step [245/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [246/1079], Loss: 0.0119\n",
      "Epoch [6/10], Step [247/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [248/1079], Loss: 0.0120\n",
      "Epoch [6/10], Step [249/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [250/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [251/1079], Loss: 0.0006\n",
      "Epoch [6/10], Step [252/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [253/1079], Loss: 0.0205\n",
      "Epoch [6/10], Step [254/1079], Loss: 0.0000\n",
      "Epoch [6/10], Step [255/1079], Loss: 0.0029\n",
      "Epoch [6/10], Step [256/1079], Loss: 0.0113\n",
      "Epoch [6/10], Step [257/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [258/1079], Loss: 0.0071\n",
      "Epoch [6/10], Step [259/1079], Loss: 0.0056\n",
      "Epoch [6/10], Step [260/1079], Loss: 0.0502\n",
      "Epoch [6/10], Step [261/1079], Loss: 0.0055\n",
      "Epoch [6/10], Step [262/1079], Loss: 0.0197\n",
      "Epoch [6/10], Step [263/1079], Loss: 0.0078\n",
      "Epoch [6/10], Step [264/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [265/1079], Loss: 0.0162\n",
      "Epoch [6/10], Step [266/1079], Loss: 0.0111\n",
      "Epoch [6/10], Step [267/1079], Loss: 0.0015\n",
      "Epoch [6/10], Step [268/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [269/1079], Loss: 0.0406\n",
      "Epoch [6/10], Step [270/1079], Loss: 0.0041\n",
      "Epoch [6/10], Step [271/1079], Loss: 0.0035\n",
      "Epoch [6/10], Step [272/1079], Loss: 0.0877\n",
      "Epoch [6/10], Step [273/1079], Loss: 0.0429\n",
      "Epoch [6/10], Step [274/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [275/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [276/1079], Loss: 0.0042\n",
      "Epoch [6/10], Step [277/1079], Loss: 0.0028\n",
      "Epoch [6/10], Step [278/1079], Loss: 0.0061\n",
      "Epoch [6/10], Step [279/1079], Loss: 0.0164\n",
      "Epoch [6/10], Step [280/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [281/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [282/1079], Loss: 0.0059\n",
      "Epoch [6/10], Step [283/1079], Loss: 0.0049\n",
      "Epoch [6/10], Step [284/1079], Loss: 0.0019\n",
      "Epoch [6/10], Step [285/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [286/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [287/1079], Loss: 0.0836\n",
      "Epoch [6/10], Step [288/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [289/1079], Loss: 0.0020\n",
      "Epoch [6/10], Step [290/1079], Loss: 0.0020\n",
      "Epoch [6/10], Step [291/1079], Loss: 0.0229\n",
      "Epoch [6/10], Step [292/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [293/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [294/1079], Loss: 0.0029\n",
      "Epoch [6/10], Step [295/1079], Loss: 0.0088\n",
      "Epoch [6/10], Step [296/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [297/1079], Loss: 0.0079\n",
      "Epoch [6/10], Step [298/1079], Loss: 0.0493\n",
      "Epoch [6/10], Step [299/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [300/1079], Loss: 0.0473\n",
      "Epoch [6/10], Step [301/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [302/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [303/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [304/1079], Loss: 0.0036\n",
      "Epoch [6/10], Step [305/1079], Loss: 0.0032\n",
      "Epoch [6/10], Step [306/1079], Loss: 0.0085\n",
      "Epoch [6/10], Step [307/1079], Loss: 0.0048\n",
      "Epoch [6/10], Step [308/1079], Loss: 0.0146\n",
      "Epoch [6/10], Step [309/1079], Loss: 0.0019\n",
      "Epoch [6/10], Step [310/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [311/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [312/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [313/1079], Loss: 0.0127\n",
      "Epoch [6/10], Step [314/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [315/1079], Loss: 0.0519\n",
      "Epoch [6/10], Step [316/1079], Loss: 0.0019\n",
      "Epoch [6/10], Step [317/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [318/1079], Loss: 0.0255\n",
      "Epoch [6/10], Step [319/1079], Loss: 0.0028\n",
      "Epoch [6/10], Step [320/1079], Loss: 0.0198\n",
      "Epoch [6/10], Step [321/1079], Loss: 0.0089\n",
      "Epoch [6/10], Step [322/1079], Loss: 0.0038\n",
      "Epoch [6/10], Step [323/1079], Loss: 0.0016\n",
      "Epoch [6/10], Step [324/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [325/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [326/1079], Loss: 0.0180\n",
      "Epoch [6/10], Step [327/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [328/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [329/1079], Loss: 0.0050\n",
      "Epoch [6/10], Step [330/1079], Loss: 0.0407\n",
      "Epoch [6/10], Step [331/1079], Loss: 0.0030\n",
      "Epoch [6/10], Step [332/1079], Loss: 0.0868\n",
      "Epoch [6/10], Step [333/1079], Loss: 0.0029\n",
      "Epoch [6/10], Step [334/1079], Loss: 0.0028\n",
      "Epoch [6/10], Step [335/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [336/1079], Loss: 0.0044\n",
      "Epoch [6/10], Step [337/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [338/1079], Loss: 0.0021\n",
      "Epoch [6/10], Step [339/1079], Loss: 0.0070\n",
      "Epoch [6/10], Step [340/1079], Loss: 0.0065\n",
      "Epoch [6/10], Step [341/1079], Loss: 0.0057\n",
      "Epoch [6/10], Step [342/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [343/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [344/1079], Loss: 0.0015\n",
      "Epoch [6/10], Step [345/1079], Loss: 0.0170\n",
      "Epoch [6/10], Step [346/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [347/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [348/1079], Loss: 0.0028\n",
      "Epoch [6/10], Step [349/1079], Loss: 0.0046\n",
      "Epoch [6/10], Step [350/1079], Loss: 0.0052\n",
      "Epoch [6/10], Step [351/1079], Loss: 0.0182\n",
      "Epoch [6/10], Step [352/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [353/1079], Loss: 0.0081\n",
      "Epoch [6/10], Step [354/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [355/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [356/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [357/1079], Loss: 0.0068\n",
      "Epoch [6/10], Step [358/1079], Loss: 0.0197\n",
      "Epoch [6/10], Step [359/1079], Loss: 0.0126\n",
      "Epoch [6/10], Step [360/1079], Loss: 0.0416\n",
      "Epoch [6/10], Step [361/1079], Loss: 0.0026\n",
      "Epoch [6/10], Step [362/1079], Loss: 0.0034\n",
      "Epoch [6/10], Step [363/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [364/1079], Loss: 0.0078\n",
      "Epoch [6/10], Step [365/1079], Loss: 0.0061\n",
      "Epoch [6/10], Step [366/1079], Loss: 0.0023\n",
      "Epoch [6/10], Step [367/1079], Loss: 0.0623\n",
      "Epoch [6/10], Step [368/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [369/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [370/1079], Loss: 0.0295\n",
      "Epoch [6/10], Step [371/1079], Loss: 0.0024\n",
      "Epoch [6/10], Step [372/1079], Loss: 0.0026\n",
      "Epoch [6/10], Step [373/1079], Loss: 0.0071\n",
      "Epoch [6/10], Step [374/1079], Loss: 0.0519\n",
      "Epoch [6/10], Step [375/1079], Loss: 0.0915\n",
      "Epoch [6/10], Step [376/1079], Loss: 0.0036\n",
      "Epoch [6/10], Step [377/1079], Loss: 0.0012\n",
      "Epoch [6/10], Step [378/1079], Loss: 0.0382\n",
      "Epoch [6/10], Step [379/1079], Loss: 0.0557\n",
      "Epoch [6/10], Step [380/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [381/1079], Loss: 0.0023\n",
      "Epoch [6/10], Step [382/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [383/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [384/1079], Loss: 0.0006\n",
      "Epoch [6/10], Step [385/1079], Loss: 0.0128\n",
      "Epoch [6/10], Step [386/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [387/1079], Loss: 0.0124\n",
      "Epoch [6/10], Step [388/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [389/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [390/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [391/1079], Loss: 0.0939\n",
      "Epoch [6/10], Step [392/1079], Loss: 0.0034\n",
      "Epoch [6/10], Step [393/1079], Loss: 0.0394\n",
      "Epoch [6/10], Step [394/1079], Loss: 0.0328\n",
      "Epoch [6/10], Step [395/1079], Loss: 0.0770\n",
      "Epoch [6/10], Step [396/1079], Loss: 0.0322\n",
      "Epoch [6/10], Step [397/1079], Loss: 0.0262\n",
      "Epoch [6/10], Step [398/1079], Loss: 0.0556\n",
      "Epoch [6/10], Step [399/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [400/1079], Loss: 0.1126\n",
      "Epoch [6/10], Step [401/1079], Loss: 0.1486\n",
      "Epoch [6/10], Step [402/1079], Loss: 0.0125\n",
      "Epoch [6/10], Step [403/1079], Loss: 0.0021\n",
      "Epoch [6/10], Step [404/1079], Loss: 0.0297\n",
      "Epoch [6/10], Step [405/1079], Loss: 0.0032\n",
      "Epoch [6/10], Step [406/1079], Loss: 0.0214\n",
      "Epoch [6/10], Step [407/1079], Loss: 0.0182\n",
      "Epoch [6/10], Step [408/1079], Loss: 0.0160\n",
      "Epoch [6/10], Step [409/1079], Loss: 0.0260\n",
      "Epoch [6/10], Step [410/1079], Loss: 0.0201\n",
      "Epoch [6/10], Step [411/1079], Loss: 0.0264\n",
      "Epoch [6/10], Step [412/1079], Loss: 0.0046\n",
      "Epoch [6/10], Step [413/1079], Loss: 0.0133\n",
      "Epoch [6/10], Step [414/1079], Loss: 0.0028\n",
      "Epoch [6/10], Step [415/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [416/1079], Loss: 0.0604\n",
      "Epoch [6/10], Step [417/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [418/1079], Loss: 0.0014\n",
      "Epoch [6/10], Step [419/1079], Loss: 0.0185\n",
      "Epoch [6/10], Step [420/1079], Loss: 0.0423\n",
      "Epoch [6/10], Step [421/1079], Loss: 0.0027\n",
      "Epoch [6/10], Step [422/1079], Loss: 0.0705\n",
      "Epoch [6/10], Step [423/1079], Loss: 0.0013\n",
      "Epoch [6/10], Step [424/1079], Loss: 0.0135\n",
      "Epoch [6/10], Step [425/1079], Loss: 0.0137\n",
      "Epoch [6/10], Step [426/1079], Loss: 0.0033\n",
      "Epoch [6/10], Step [427/1079], Loss: 0.0042\n",
      "Epoch [6/10], Step [428/1079], Loss: 0.0066\n",
      "Epoch [6/10], Step [429/1079], Loss: 0.0301\n",
      "Epoch [6/10], Step [430/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [431/1079], Loss: 0.0012\n",
      "Epoch [6/10], Step [432/1079], Loss: 0.0093\n",
      "Epoch [6/10], Step [433/1079], Loss: 0.0553\n",
      "Epoch [6/10], Step [434/1079], Loss: 0.0019\n",
      "Epoch [6/10], Step [435/1079], Loss: 0.0026\n",
      "Epoch [6/10], Step [436/1079], Loss: 0.0035\n",
      "Epoch [6/10], Step [437/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [438/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [439/1079], Loss: 0.0025\n",
      "Epoch [6/10], Step [440/1079], Loss: 0.0031\n",
      "Epoch [6/10], Step [441/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [442/1079], Loss: 0.0338\n",
      "Epoch [6/10], Step [443/1079], Loss: 0.0039\n",
      "Epoch [6/10], Step [444/1079], Loss: 0.0059\n",
      "Epoch [6/10], Step [445/1079], Loss: 0.0131\n",
      "Epoch [6/10], Step [446/1079], Loss: 0.0277\n",
      "Epoch [6/10], Step [447/1079], Loss: 0.0122\n",
      "Epoch [6/10], Step [448/1079], Loss: 0.0042\n",
      "Epoch [6/10], Step [449/1079], Loss: 0.0056\n",
      "Epoch [6/10], Step [450/1079], Loss: 0.0030\n",
      "Epoch [6/10], Step [451/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [452/1079], Loss: 0.0298\n",
      "Epoch [6/10], Step [453/1079], Loss: 0.0068\n",
      "Epoch [6/10], Step [454/1079], Loss: 0.0094\n",
      "Epoch [6/10], Step [455/1079], Loss: 0.0360\n",
      "Epoch [6/10], Step [456/1079], Loss: 0.0170\n",
      "Epoch [6/10], Step [457/1079], Loss: 0.0104\n",
      "Epoch [6/10], Step [458/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [459/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [460/1079], Loss: 0.0147\n",
      "Epoch [6/10], Step [461/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [462/1079], Loss: 0.0025\n",
      "Epoch [6/10], Step [463/1079], Loss: 0.0330\n",
      "Epoch [6/10], Step [464/1079], Loss: 0.0911\n",
      "Epoch [6/10], Step [465/1079], Loss: 0.0128\n",
      "Epoch [6/10], Step [466/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [467/1079], Loss: 0.0050\n",
      "Epoch [6/10], Step [468/1079], Loss: 0.0340\n",
      "Epoch [6/10], Step [469/1079], Loss: 0.0152\n",
      "Epoch [6/10], Step [470/1079], Loss: 0.0897\n",
      "Epoch [6/10], Step [471/1079], Loss: 0.0023\n",
      "Epoch [6/10], Step [472/1079], Loss: 0.0014\n",
      "Epoch [6/10], Step [473/1079], Loss: 0.0012\n",
      "Epoch [6/10], Step [474/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [475/1079], Loss: 0.0098\n",
      "Epoch [6/10], Step [476/1079], Loss: 0.0428\n",
      "Epoch [6/10], Step [477/1079], Loss: 0.0298\n",
      "Epoch [6/10], Step [478/1079], Loss: 0.0072\n",
      "Epoch [6/10], Step [479/1079], Loss: 0.0051\n",
      "Epoch [6/10], Step [480/1079], Loss: 0.0049\n",
      "Epoch [6/10], Step [481/1079], Loss: 0.0015\n",
      "Epoch [6/10], Step [482/1079], Loss: 0.0277\n",
      "Epoch [6/10], Step [483/1079], Loss: 0.0058\n",
      "Epoch [6/10], Step [484/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [485/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [486/1079], Loss: 0.0089\n",
      "Epoch [6/10], Step [487/1079], Loss: 0.0104\n",
      "Epoch [6/10], Step [488/1079], Loss: 0.0071\n",
      "Epoch [6/10], Step [489/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [490/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [491/1079], Loss: 0.0961\n",
      "Epoch [6/10], Step [492/1079], Loss: 0.0236\n",
      "Epoch [6/10], Step [493/1079], Loss: 0.0054\n",
      "Epoch [6/10], Step [494/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [495/1079], Loss: 0.0044\n",
      "Epoch [6/10], Step [496/1079], Loss: 0.0299\n",
      "Epoch [6/10], Step [497/1079], Loss: 0.0208\n",
      "Epoch [6/10], Step [498/1079], Loss: 0.0119\n",
      "Epoch [6/10], Step [499/1079], Loss: 0.0052\n",
      "Epoch [6/10], Step [500/1079], Loss: 0.0130\n",
      "Epoch [6/10], Step [501/1079], Loss: 0.0115\n",
      "Epoch [6/10], Step [502/1079], Loss: 0.0133\n",
      "Epoch [6/10], Step [503/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [504/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [505/1079], Loss: 0.0089\n",
      "Epoch [6/10], Step [506/1079], Loss: 0.0020\n",
      "Epoch [6/10], Step [507/1079], Loss: 0.0034\n",
      "Epoch [6/10], Step [508/1079], Loss: 0.0038\n",
      "Epoch [6/10], Step [509/1079], Loss: 0.0198\n",
      "Epoch [6/10], Step [510/1079], Loss: 0.0078\n",
      "Epoch [6/10], Step [511/1079], Loss: 0.0025\n",
      "Epoch [6/10], Step [512/1079], Loss: 0.0020\n",
      "Epoch [6/10], Step [513/1079], Loss: 0.0024\n",
      "Epoch [6/10], Step [514/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [515/1079], Loss: 0.0088\n",
      "Epoch [6/10], Step [516/1079], Loss: 0.0113\n",
      "Epoch [6/10], Step [517/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [518/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [519/1079], Loss: 0.0098\n",
      "Epoch [6/10], Step [520/1079], Loss: 0.0177\n",
      "Epoch [6/10], Step [521/1079], Loss: 0.0735\n",
      "Epoch [6/10], Step [522/1079], Loss: 0.0013\n",
      "Epoch [6/10], Step [523/1079], Loss: 0.0131\n",
      "Epoch [6/10], Step [524/1079], Loss: 0.0032\n",
      "Epoch [6/10], Step [525/1079], Loss: 0.0176\n",
      "Epoch [6/10], Step [526/1079], Loss: 0.0058\n",
      "Epoch [6/10], Step [527/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [528/1079], Loss: 0.0371\n",
      "Epoch [6/10], Step [529/1079], Loss: 0.0718\n",
      "Epoch [6/10], Step [530/1079], Loss: 0.0177\n",
      "Epoch [6/10], Step [531/1079], Loss: 0.0566\n",
      "Epoch [6/10], Step [532/1079], Loss: 0.0053\n",
      "Epoch [6/10], Step [533/1079], Loss: 0.0049\n",
      "Epoch [6/10], Step [534/1079], Loss: 0.0532\n",
      "Epoch [6/10], Step [535/1079], Loss: 0.0055\n",
      "Epoch [6/10], Step [536/1079], Loss: 0.0147\n",
      "Epoch [6/10], Step [537/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [538/1079], Loss: 0.0042\n",
      "Epoch [6/10], Step [539/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [540/1079], Loss: 0.0273\n",
      "Epoch [6/10], Step [541/1079], Loss: 0.0085\n",
      "Epoch [6/10], Step [542/1079], Loss: 0.0050\n",
      "Epoch [6/10], Step [543/1079], Loss: 0.0056\n",
      "Epoch [6/10], Step [544/1079], Loss: 0.0301\n",
      "Epoch [6/10], Step [545/1079], Loss: 0.0021\n",
      "Epoch [6/10], Step [546/1079], Loss: 0.0020\n",
      "Epoch [6/10], Step [547/1079], Loss: 0.0168\n",
      "Epoch [6/10], Step [548/1079], Loss: 0.0103\n",
      "Epoch [6/10], Step [549/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [550/1079], Loss: 0.0249\n",
      "Epoch [6/10], Step [551/1079], Loss: 0.0230\n",
      "Epoch [6/10], Step [552/1079], Loss: 0.0027\n",
      "Epoch [6/10], Step [553/1079], Loss: 0.0080\n",
      "Epoch [6/10], Step [554/1079], Loss: 0.0030\n",
      "Epoch [6/10], Step [555/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [556/1079], Loss: 0.0047\n",
      "Epoch [6/10], Step [557/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [558/1079], Loss: 0.0029\n",
      "Epoch [6/10], Step [559/1079], Loss: 0.0045\n",
      "Epoch [6/10], Step [560/1079], Loss: 0.0027\n",
      "Epoch [6/10], Step [561/1079], Loss: 0.0300\n",
      "Epoch [6/10], Step [562/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [563/1079], Loss: 0.0526\n",
      "Epoch [6/10], Step [564/1079], Loss: 0.1413\n",
      "Epoch [6/10], Step [565/1079], Loss: 0.0119\n",
      "Epoch [6/10], Step [566/1079], Loss: 0.0221\n",
      "Epoch [6/10], Step [567/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [568/1079], Loss: 0.0050\n",
      "Epoch [6/10], Step [569/1079], Loss: 0.0770\n",
      "Epoch [6/10], Step [570/1079], Loss: 0.0075\n",
      "Epoch [6/10], Step [571/1079], Loss: 0.0015\n",
      "Epoch [6/10], Step [572/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [573/1079], Loss: 0.0025\n",
      "Epoch [6/10], Step [574/1079], Loss: 0.0222\n",
      "Epoch [6/10], Step [575/1079], Loss: 0.0275\n",
      "Epoch [6/10], Step [576/1079], Loss: 0.0006\n",
      "Epoch [6/10], Step [577/1079], Loss: 0.0095\n",
      "Epoch [6/10], Step [578/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [579/1079], Loss: 0.0088\n",
      "Epoch [6/10], Step [580/1079], Loss: 0.0237\n",
      "Epoch [6/10], Step [581/1079], Loss: 0.0200\n",
      "Epoch [6/10], Step [582/1079], Loss: 0.0449\n",
      "Epoch [6/10], Step [583/1079], Loss: 0.0049\n",
      "Epoch [6/10], Step [584/1079], Loss: 0.0060\n",
      "Epoch [6/10], Step [585/1079], Loss: 0.0209\n",
      "Epoch [6/10], Step [586/1079], Loss: 0.0465\n",
      "Epoch [6/10], Step [587/1079], Loss: 0.0027\n",
      "Epoch [6/10], Step [588/1079], Loss: 0.1019\n",
      "Epoch [6/10], Step [589/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [590/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [591/1079], Loss: 0.1109\n",
      "Epoch [6/10], Step [592/1079], Loss: 0.0236\n",
      "Epoch [6/10], Step [593/1079], Loss: 0.0053\n",
      "Epoch [6/10], Step [594/1079], Loss: 0.0826\n",
      "Epoch [6/10], Step [595/1079], Loss: 0.0463\n",
      "Epoch [6/10], Step [596/1079], Loss: 0.0800\n",
      "Epoch [6/10], Step [597/1079], Loss: 0.0209\n",
      "Epoch [6/10], Step [598/1079], Loss: 0.0495\n",
      "Epoch [6/10], Step [599/1079], Loss: 0.0041\n",
      "Epoch [6/10], Step [600/1079], Loss: 0.0045\n",
      "Epoch [6/10], Step [601/1079], Loss: 0.1218\n",
      "Epoch [6/10], Step [602/1079], Loss: 0.0068\n",
      "Epoch [6/10], Step [603/1079], Loss: 0.0404\n",
      "Epoch [6/10], Step [604/1079], Loss: 0.0871\n",
      "Epoch [6/10], Step [605/1079], Loss: 0.0273\n",
      "Epoch [6/10], Step [606/1079], Loss: 0.0038\n",
      "Epoch [6/10], Step [607/1079], Loss: 0.0093\n",
      "Epoch [6/10], Step [608/1079], Loss: 0.0253\n",
      "Epoch [6/10], Step [609/1079], Loss: 0.0184\n",
      "Epoch [6/10], Step [610/1079], Loss: 0.0228\n",
      "Epoch [6/10], Step [611/1079], Loss: 0.0079\n",
      "Epoch [6/10], Step [612/1079], Loss: 0.0155\n",
      "Epoch [6/10], Step [613/1079], Loss: 0.0024\n",
      "Epoch [6/10], Step [614/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [615/1079], Loss: 0.0506\n",
      "Epoch [6/10], Step [616/1079], Loss: 0.0373\n",
      "Epoch [6/10], Step [617/1079], Loss: 0.0100\n",
      "Epoch [6/10], Step [618/1079], Loss: 0.0300\n",
      "Epoch [6/10], Step [619/1079], Loss: 0.0052\n",
      "Epoch [6/10], Step [620/1079], Loss: 0.0012\n",
      "Epoch [6/10], Step [621/1079], Loss: 0.0120\n",
      "Epoch [6/10], Step [622/1079], Loss: 0.0322\n",
      "Epoch [6/10], Step [623/1079], Loss: 0.0162\n",
      "Epoch [6/10], Step [624/1079], Loss: 0.0238\n",
      "Epoch [6/10], Step [625/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [626/1079], Loss: 0.0044\n",
      "Epoch [6/10], Step [627/1079], Loss: 0.0058\n",
      "Epoch [6/10], Step [628/1079], Loss: 0.0256\n",
      "Epoch [6/10], Step [629/1079], Loss: 0.0162\n",
      "Epoch [6/10], Step [630/1079], Loss: 0.0436\n",
      "Epoch [6/10], Step [631/1079], Loss: 0.0524\n",
      "Epoch [6/10], Step [632/1079], Loss: 0.0069\n",
      "Epoch [6/10], Step [633/1079], Loss: 0.0051\n",
      "Epoch [6/10], Step [634/1079], Loss: 0.0796\n",
      "Epoch [6/10], Step [635/1079], Loss: 0.0780\n",
      "Epoch [6/10], Step [636/1079], Loss: 0.0210\n",
      "Epoch [6/10], Step [637/1079], Loss: 0.0771\n",
      "Epoch [6/10], Step [638/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [639/1079], Loss: 0.0033\n",
      "Epoch [6/10], Step [640/1079], Loss: 0.0048\n",
      "Epoch [6/10], Step [641/1079], Loss: 0.0019\n",
      "Epoch [6/10], Step [642/1079], Loss: 0.0185\n",
      "Epoch [6/10], Step [643/1079], Loss: 0.0099\n",
      "Epoch [6/10], Step [644/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [645/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [646/1079], Loss: 0.0426\n",
      "Epoch [6/10], Step [647/1079], Loss: 0.0152\n",
      "Epoch [6/10], Step [648/1079], Loss: 0.0953\n",
      "Epoch [6/10], Step [649/1079], Loss: 0.0305\n",
      "Epoch [6/10], Step [650/1079], Loss: 0.0204\n",
      "Epoch [6/10], Step [651/1079], Loss: 0.0808\n",
      "Epoch [6/10], Step [652/1079], Loss: 0.0285\n",
      "Epoch [6/10], Step [653/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [654/1079], Loss: 0.0115\n",
      "Epoch [6/10], Step [655/1079], Loss: 0.0193\n",
      "Epoch [6/10], Step [656/1079], Loss: 0.0145\n",
      "Epoch [6/10], Step [657/1079], Loss: 0.0102\n",
      "Epoch [6/10], Step [658/1079], Loss: 0.0026\n",
      "Epoch [6/10], Step [659/1079], Loss: 0.0236\n",
      "Epoch [6/10], Step [660/1079], Loss: 0.0586\n",
      "Epoch [6/10], Step [661/1079], Loss: 0.0650\n",
      "Epoch [6/10], Step [662/1079], Loss: 0.0504\n",
      "Epoch [6/10], Step [663/1079], Loss: 0.0044\n",
      "Epoch [6/10], Step [664/1079], Loss: 0.0027\n",
      "Epoch [6/10], Step [665/1079], Loss: 0.0039\n",
      "Epoch [6/10], Step [666/1079], Loss: 0.0408\n",
      "Epoch [6/10], Step [667/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [668/1079], Loss: 0.0070\n",
      "Epoch [6/10], Step [669/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [670/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [671/1079], Loss: 0.0038\n",
      "Epoch [6/10], Step [672/1079], Loss: 0.0034\n",
      "Epoch [6/10], Step [673/1079], Loss: 0.0016\n",
      "Epoch [6/10], Step [674/1079], Loss: 0.0029\n",
      "Epoch [6/10], Step [675/1079], Loss: 0.0228\n",
      "Epoch [6/10], Step [676/1079], Loss: 0.0271\n",
      "Epoch [6/10], Step [677/1079], Loss: 0.1022\n",
      "Epoch [6/10], Step [678/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [679/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [680/1079], Loss: 0.0074\n",
      "Epoch [6/10], Step [681/1079], Loss: 0.0609\n",
      "Epoch [6/10], Step [682/1079], Loss: 0.0030\n",
      "Epoch [6/10], Step [683/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [684/1079], Loss: 0.0023\n",
      "Epoch [6/10], Step [685/1079], Loss: 0.0198\n",
      "Epoch [6/10], Step [686/1079], Loss: 0.0352\n",
      "Epoch [6/10], Step [687/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [688/1079], Loss: 0.0140\n",
      "Epoch [6/10], Step [689/1079], Loss: 0.0427\n",
      "Epoch [6/10], Step [690/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [691/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [692/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [693/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [694/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [695/1079], Loss: 0.0233\n",
      "Epoch [6/10], Step [696/1079], Loss: 0.0014\n",
      "Epoch [6/10], Step [697/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [698/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [699/1079], Loss: 0.0026\n",
      "Epoch [6/10], Step [700/1079], Loss: 0.0292\n",
      "Epoch [6/10], Step [701/1079], Loss: 0.0040\n",
      "Epoch [6/10], Step [702/1079], Loss: 0.0040\n",
      "Epoch [6/10], Step [703/1079], Loss: 0.0181\n",
      "Epoch [6/10], Step [704/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [705/1079], Loss: 0.0013\n",
      "Epoch [6/10], Step [706/1079], Loss: 0.0220\n",
      "Epoch [6/10], Step [707/1079], Loss: 0.0272\n",
      "Epoch [6/10], Step [708/1079], Loss: 0.0120\n",
      "Epoch [6/10], Step [709/1079], Loss: 0.0031\n",
      "Epoch [6/10], Step [710/1079], Loss: 0.0030\n",
      "Epoch [6/10], Step [711/1079], Loss: 0.0025\n",
      "Epoch [6/10], Step [712/1079], Loss: 0.0096\n",
      "Epoch [6/10], Step [713/1079], Loss: 0.0073\n",
      "Epoch [6/10], Step [714/1079], Loss: 0.0255\n",
      "Epoch [6/10], Step [715/1079], Loss: 0.0019\n",
      "Epoch [6/10], Step [716/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [717/1079], Loss: 0.0019\n",
      "Epoch [6/10], Step [718/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [719/1079], Loss: 0.0021\n",
      "Epoch [6/10], Step [720/1079], Loss: 0.0067\n",
      "Epoch [6/10], Step [721/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [722/1079], Loss: 0.0075\n",
      "Epoch [6/10], Step [723/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [724/1079], Loss: 0.0088\n",
      "Epoch [6/10], Step [725/1079], Loss: 0.0238\n",
      "Epoch [6/10], Step [726/1079], Loss: 0.0336\n",
      "Epoch [6/10], Step [727/1079], Loss: 0.0237\n",
      "Epoch [6/10], Step [728/1079], Loss: 0.0055\n",
      "Epoch [6/10], Step [729/1079], Loss: 0.0070\n",
      "Epoch [6/10], Step [730/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [731/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [732/1079], Loss: 0.0156\n",
      "Epoch [6/10], Step [733/1079], Loss: 0.0576\n",
      "Epoch [6/10], Step [734/1079], Loss: 0.0164\n",
      "Epoch [6/10], Step [735/1079], Loss: 0.0026\n",
      "Epoch [6/10], Step [736/1079], Loss: 0.0218\n",
      "Epoch [6/10], Step [737/1079], Loss: 0.0324\n",
      "Epoch [6/10], Step [738/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [739/1079], Loss: 0.0457\n",
      "Epoch [6/10], Step [740/1079], Loss: 0.0110\n",
      "Epoch [6/10], Step [741/1079], Loss: 0.0610\n",
      "Epoch [6/10], Step [742/1079], Loss: 0.0669\n",
      "Epoch [6/10], Step [743/1079], Loss: 0.0020\n",
      "Epoch [6/10], Step [744/1079], Loss: 0.0015\n",
      "Epoch [6/10], Step [745/1079], Loss: 0.0249\n",
      "Epoch [6/10], Step [746/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [747/1079], Loss: 0.0371\n",
      "Epoch [6/10], Step [748/1079], Loss: 0.0875\n",
      "Epoch [6/10], Step [749/1079], Loss: 0.0329\n",
      "Epoch [6/10], Step [750/1079], Loss: 0.0016\n",
      "Epoch [6/10], Step [751/1079], Loss: 0.0101\n",
      "Epoch [6/10], Step [752/1079], Loss: 0.0452\n",
      "Epoch [6/10], Step [753/1079], Loss: 0.0013\n",
      "Epoch [6/10], Step [754/1079], Loss: 0.0034\n",
      "Epoch [6/10], Step [755/1079], Loss: 0.1960\n",
      "Epoch [6/10], Step [756/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [757/1079], Loss: 0.0458\n",
      "Epoch [6/10], Step [758/1079], Loss: 0.0122\n",
      "Epoch [6/10], Step [759/1079], Loss: 0.0024\n",
      "Epoch [6/10], Step [760/1079], Loss: 0.0409\n",
      "Epoch [6/10], Step [761/1079], Loss: 0.0019\n",
      "Epoch [6/10], Step [762/1079], Loss: 0.0052\n",
      "Epoch [6/10], Step [763/1079], Loss: 0.0093\n",
      "Epoch [6/10], Step [764/1079], Loss: 0.0352\n",
      "Epoch [6/10], Step [765/1079], Loss: 0.1778\n",
      "Epoch [6/10], Step [766/1079], Loss: 0.0108\n",
      "Epoch [6/10], Step [767/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [768/1079], Loss: 0.0221\n",
      "Epoch [6/10], Step [769/1079], Loss: 0.0191\n",
      "Epoch [6/10], Step [770/1079], Loss: 0.0031\n",
      "Epoch [6/10], Step [771/1079], Loss: 0.0066\n",
      "Epoch [6/10], Step [772/1079], Loss: 0.0013\n",
      "Epoch [6/10], Step [773/1079], Loss: 0.0069\n",
      "Epoch [6/10], Step [774/1079], Loss: 0.0740\n",
      "Epoch [6/10], Step [775/1079], Loss: 0.0032\n",
      "Epoch [6/10], Step [776/1079], Loss: 0.0062\n",
      "Epoch [6/10], Step [777/1079], Loss: 0.0293\n",
      "Epoch [6/10], Step [778/1079], Loss: 0.0013\n",
      "Epoch [6/10], Step [779/1079], Loss: 0.0121\n",
      "Epoch [6/10], Step [780/1079], Loss: 0.0216\n",
      "Epoch [6/10], Step [781/1079], Loss: 0.0249\n",
      "Epoch [6/10], Step [782/1079], Loss: 0.0462\n",
      "Epoch [6/10], Step [783/1079], Loss: 0.0398\n",
      "Epoch [6/10], Step [784/1079], Loss: 0.0016\n",
      "Epoch [6/10], Step [785/1079], Loss: 0.0401\n",
      "Epoch [6/10], Step [786/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [787/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [788/1079], Loss: 0.0385\n",
      "Epoch [6/10], Step [789/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [790/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [791/1079], Loss: 0.0049\n",
      "Epoch [6/10], Step [792/1079], Loss: 0.0082\n",
      "Epoch [6/10], Step [793/1079], Loss: 0.0055\n",
      "Epoch [6/10], Step [794/1079], Loss: 0.0051\n",
      "Epoch [6/10], Step [795/1079], Loss: 0.0041\n",
      "Epoch [6/10], Step [796/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [797/1079], Loss: 0.0363\n",
      "Epoch [6/10], Step [798/1079], Loss: 0.1362\n",
      "Epoch [6/10], Step [799/1079], Loss: 0.0707\n",
      "Epoch [6/10], Step [800/1079], Loss: 0.0015\n",
      "Epoch [6/10], Step [801/1079], Loss: 0.0261\n",
      "Epoch [6/10], Step [802/1079], Loss: 0.0165\n",
      "Epoch [6/10], Step [803/1079], Loss: 0.0410\n",
      "Epoch [6/10], Step [804/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [805/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [806/1079], Loss: 0.0012\n",
      "Epoch [6/10], Step [807/1079], Loss: 0.0034\n",
      "Epoch [6/10], Step [808/1079], Loss: 0.0029\n",
      "Epoch [6/10], Step [809/1079], Loss: 0.0012\n",
      "Epoch [6/10], Step [810/1079], Loss: 0.0299\n",
      "Epoch [6/10], Step [811/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [812/1079], Loss: 0.0079\n",
      "Epoch [6/10], Step [813/1079], Loss: 0.0228\n",
      "Epoch [6/10], Step [814/1079], Loss: 0.0243\n",
      "Epoch [6/10], Step [815/1079], Loss: 0.0016\n",
      "Epoch [6/10], Step [816/1079], Loss: 0.0046\n",
      "Epoch [6/10], Step [817/1079], Loss: 0.0125\n",
      "Epoch [6/10], Step [818/1079], Loss: 0.0155\n",
      "Epoch [6/10], Step [819/1079], Loss: 0.0526\n",
      "Epoch [6/10], Step [820/1079], Loss: 0.0126\n",
      "Epoch [6/10], Step [821/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [822/1079], Loss: 0.0180\n",
      "Epoch [6/10], Step [823/1079], Loss: 0.0113\n",
      "Epoch [6/10], Step [824/1079], Loss: 0.0061\n",
      "Epoch [6/10], Step [825/1079], Loss: 0.0047\n",
      "Epoch [6/10], Step [826/1079], Loss: 0.0030\n",
      "Epoch [6/10], Step [827/1079], Loss: 0.0104\n",
      "Epoch [6/10], Step [828/1079], Loss: 0.0046\n",
      "Epoch [6/10], Step [829/1079], Loss: 0.0069\n",
      "Epoch [6/10], Step [830/1079], Loss: 0.0019\n",
      "Epoch [6/10], Step [831/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [832/1079], Loss: 0.0021\n",
      "Epoch [6/10], Step [833/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [834/1079], Loss: 0.0112\n",
      "Epoch [6/10], Step [835/1079], Loss: 0.0045\n",
      "Epoch [6/10], Step [836/1079], Loss: 0.0046\n",
      "Epoch [6/10], Step [837/1079], Loss: 0.0215\n",
      "Epoch [6/10], Step [838/1079], Loss: 0.0144\n",
      "Epoch [6/10], Step [839/1079], Loss: 0.0045\n",
      "Epoch [6/10], Step [840/1079], Loss: 0.0398\n",
      "Epoch [6/10], Step [841/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [842/1079], Loss: 0.0832\n",
      "Epoch [6/10], Step [843/1079], Loss: 0.0044\n",
      "Epoch [6/10], Step [844/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [845/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [846/1079], Loss: 0.0041\n",
      "Epoch [6/10], Step [847/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [848/1079], Loss: 0.0156\n",
      "Epoch [6/10], Step [849/1079], Loss: 0.0365\n",
      "Epoch [6/10], Step [850/1079], Loss: 0.0218\n",
      "Epoch [6/10], Step [851/1079], Loss: 0.0025\n",
      "Epoch [6/10], Step [852/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [853/1079], Loss: 0.0073\n",
      "Epoch [6/10], Step [854/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [855/1079], Loss: 0.0443\n",
      "Epoch [6/10], Step [856/1079], Loss: 0.0084\n",
      "Epoch [6/10], Step [857/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [858/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [859/1079], Loss: 0.0321\n",
      "Epoch [6/10], Step [860/1079], Loss: 0.0060\n",
      "Epoch [6/10], Step [861/1079], Loss: 0.1157\n",
      "Epoch [6/10], Step [862/1079], Loss: 0.0032\n",
      "Epoch [6/10], Step [863/1079], Loss: 0.0234\n",
      "Epoch [6/10], Step [864/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [865/1079], Loss: 0.0073\n",
      "Epoch [6/10], Step [866/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [867/1079], Loss: 0.0077\n",
      "Epoch [6/10], Step [868/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [869/1079], Loss: 0.0675\n",
      "Epoch [6/10], Step [870/1079], Loss: 0.0065\n",
      "Epoch [6/10], Step [871/1079], Loss: 0.0046\n",
      "Epoch [6/10], Step [872/1079], Loss: 0.0012\n",
      "Epoch [6/10], Step [873/1079], Loss: 0.0123\n",
      "Epoch [6/10], Step [874/1079], Loss: 0.0407\n",
      "Epoch [6/10], Step [875/1079], Loss: 0.0144\n",
      "Epoch [6/10], Step [876/1079], Loss: 0.0047\n",
      "Epoch [6/10], Step [877/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [878/1079], Loss: 0.0159\n",
      "Epoch [6/10], Step [879/1079], Loss: 0.0021\n",
      "Epoch [6/10], Step [880/1079], Loss: 0.0006\n",
      "Epoch [6/10], Step [881/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [882/1079], Loss: 0.0114\n",
      "Epoch [6/10], Step [883/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [884/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [885/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [886/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [887/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [888/1079], Loss: 0.0649\n",
      "Epoch [6/10], Step [889/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [890/1079], Loss: 0.2123\n",
      "Epoch [6/10], Step [891/1079], Loss: 0.0030\n",
      "Epoch [6/10], Step [892/1079], Loss: 0.1458\n",
      "Epoch [6/10], Step [893/1079], Loss: 0.0038\n",
      "Epoch [6/10], Step [894/1079], Loss: 0.0031\n",
      "Epoch [6/10], Step [895/1079], Loss: 0.0047\n",
      "Epoch [6/10], Step [896/1079], Loss: 0.0041\n",
      "Epoch [6/10], Step [897/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [898/1079], Loss: 0.0051\n",
      "Epoch [6/10], Step [899/1079], Loss: 0.0095\n",
      "Epoch [6/10], Step [900/1079], Loss: 0.0137\n",
      "Epoch [6/10], Step [901/1079], Loss: 0.0066\n",
      "Epoch [6/10], Step [902/1079], Loss: 0.0404\n",
      "Epoch [6/10], Step [903/1079], Loss: 0.0098\n",
      "Epoch [6/10], Step [904/1079], Loss: 0.0014\n",
      "Epoch [6/10], Step [905/1079], Loss: 0.0016\n",
      "Epoch [6/10], Step [906/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [907/1079], Loss: 0.0092\n",
      "Epoch [6/10], Step [908/1079], Loss: 0.0046\n",
      "Epoch [6/10], Step [909/1079], Loss: 0.0293\n",
      "Epoch [6/10], Step [910/1079], Loss: 0.0175\n",
      "Epoch [6/10], Step [911/1079], Loss: 0.0082\n",
      "Epoch [6/10], Step [912/1079], Loss: 0.0127\n",
      "Epoch [6/10], Step [913/1079], Loss: 0.0365\n",
      "Epoch [6/10], Step [914/1079], Loss: 0.0227\n",
      "Epoch [6/10], Step [915/1079], Loss: 0.0126\n",
      "Epoch [6/10], Step [916/1079], Loss: 0.0548\n",
      "Epoch [6/10], Step [917/1079], Loss: 0.0290\n",
      "Epoch [6/10], Step [918/1079], Loss: 0.0039\n",
      "Epoch [6/10], Step [919/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [920/1079], Loss: 0.0130\n",
      "Epoch [6/10], Step [921/1079], Loss: 0.0048\n",
      "Epoch [6/10], Step [922/1079], Loss: 0.0057\n",
      "Epoch [6/10], Step [923/1079], Loss: 0.0060\n",
      "Epoch [6/10], Step [924/1079], Loss: 0.0282\n",
      "Epoch [6/10], Step [925/1079], Loss: 0.0545\n",
      "Epoch [6/10], Step [926/1079], Loss: 0.0184\n",
      "Epoch [6/10], Step [927/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [928/1079], Loss: 0.0020\n",
      "Epoch [6/10], Step [929/1079], Loss: 0.0023\n",
      "Epoch [6/10], Step [930/1079], Loss: 0.1586\n",
      "Epoch [6/10], Step [931/1079], Loss: 0.0498\n",
      "Epoch [6/10], Step [932/1079], Loss: 0.0044\n",
      "Epoch [6/10], Step [933/1079], Loss: 0.0016\n",
      "Epoch [6/10], Step [934/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [935/1079], Loss: 0.0446\n",
      "Epoch [6/10], Step [936/1079], Loss: 0.0090\n",
      "Epoch [6/10], Step [937/1079], Loss: 0.0083\n",
      "Epoch [6/10], Step [938/1079], Loss: 0.0060\n",
      "Epoch [6/10], Step [939/1079], Loss: 0.0068\n",
      "Epoch [6/10], Step [940/1079], Loss: 0.0033\n",
      "Epoch [6/10], Step [941/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [942/1079], Loss: 0.0414\n",
      "Epoch [6/10], Step [943/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [944/1079], Loss: 0.0074\n",
      "Epoch [6/10], Step [945/1079], Loss: 0.0014\n",
      "Epoch [6/10], Step [946/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [947/1079], Loss: 0.0160\n",
      "Epoch [6/10], Step [948/1079], Loss: 0.0021\n",
      "Epoch [6/10], Step [949/1079], Loss: 0.0257\n",
      "Epoch [6/10], Step [950/1079], Loss: 0.0065\n",
      "Epoch [6/10], Step [951/1079], Loss: 0.0038\n",
      "Epoch [6/10], Step [952/1079], Loss: 0.0393\n",
      "Epoch [6/10], Step [953/1079], Loss: 0.0126\n",
      "Epoch [6/10], Step [954/1079], Loss: 0.0074\n",
      "Epoch [6/10], Step [955/1079], Loss: 0.0019\n",
      "Epoch [6/10], Step [956/1079], Loss: 0.0046\n",
      "Epoch [6/10], Step [957/1079], Loss: 0.0071\n",
      "Epoch [6/10], Step [958/1079], Loss: 0.0116\n",
      "Epoch [6/10], Step [959/1079], Loss: 0.0456\n",
      "Epoch [6/10], Step [960/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [961/1079], Loss: 0.0445\n",
      "Epoch [6/10], Step [962/1079], Loss: 0.0061\n",
      "Epoch [6/10], Step [963/1079], Loss: 0.0093\n",
      "Epoch [6/10], Step [964/1079], Loss: 0.0208\n",
      "Epoch [6/10], Step [965/1079], Loss: 0.0009\n",
      "Epoch [6/10], Step [966/1079], Loss: 0.0398\n",
      "Epoch [6/10], Step [967/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [968/1079], Loss: 0.0043\n",
      "Epoch [6/10], Step [969/1079], Loss: 0.0057\n",
      "Epoch [6/10], Step [970/1079], Loss: 0.0059\n",
      "Epoch [6/10], Step [971/1079], Loss: 0.0048\n",
      "Epoch [6/10], Step [972/1079], Loss: 0.0027\n",
      "Epoch [6/10], Step [973/1079], Loss: 0.0049\n",
      "Epoch [6/10], Step [974/1079], Loss: 0.0021\n",
      "Epoch [6/10], Step [975/1079], Loss: 0.0082\n",
      "Epoch [6/10], Step [976/1079], Loss: 0.0189\n",
      "Epoch [6/10], Step [977/1079], Loss: 0.0055\n",
      "Epoch [6/10], Step [978/1079], Loss: 0.0873\n",
      "Epoch [6/10], Step [979/1079], Loss: 0.0051\n",
      "Epoch [6/10], Step [980/1079], Loss: 0.0070\n",
      "Epoch [6/10], Step [981/1079], Loss: 0.0728\n",
      "Epoch [6/10], Step [982/1079], Loss: 0.0026\n",
      "Epoch [6/10], Step [983/1079], Loss: 0.0023\n",
      "Epoch [6/10], Step [984/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [985/1079], Loss: 0.0112\n",
      "Epoch [6/10], Step [986/1079], Loss: 0.0006\n",
      "Epoch [6/10], Step [987/1079], Loss: 0.0273\n",
      "Epoch [6/10], Step [988/1079], Loss: 0.0006\n",
      "Epoch [6/10], Step [989/1079], Loss: 0.0229\n",
      "Epoch [6/10], Step [990/1079], Loss: 0.0251\n",
      "Epoch [6/10], Step [991/1079], Loss: 0.0039\n",
      "Epoch [6/10], Step [992/1079], Loss: 0.0016\n",
      "Epoch [6/10], Step [993/1079], Loss: 0.0178\n",
      "Epoch [6/10], Step [994/1079], Loss: 0.0005\n",
      "Epoch [6/10], Step [995/1079], Loss: 0.0683\n",
      "Epoch [6/10], Step [996/1079], Loss: 0.0281\n",
      "Epoch [6/10], Step [997/1079], Loss: 0.0006\n",
      "Epoch [6/10], Step [998/1079], Loss: 0.0057\n",
      "Epoch [6/10], Step [999/1079], Loss: 0.0160\n",
      "Epoch [6/10], Step [1000/1079], Loss: 0.0043\n",
      "Epoch [6/10], Step [1001/1079], Loss: 0.0190\n",
      "Epoch [6/10], Step [1002/1079], Loss: 0.0242\n",
      "Epoch [6/10], Step [1003/1079], Loss: 0.0276\n",
      "Epoch [6/10], Step [1004/1079], Loss: 0.0022\n",
      "Epoch [6/10], Step [1005/1079], Loss: 0.0410\n",
      "Epoch [6/10], Step [1006/1079], Loss: 0.0325\n",
      "Epoch [6/10], Step [1007/1079], Loss: 0.0027\n",
      "Epoch [6/10], Step [1008/1079], Loss: 0.0057\n",
      "Epoch [6/10], Step [1009/1079], Loss: 0.0032\n",
      "Epoch [6/10], Step [1010/1079], Loss: 0.0485\n",
      "Epoch [6/10], Step [1011/1079], Loss: 0.0006\n",
      "Epoch [6/10], Step [1012/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [1013/1079], Loss: 0.0027\n",
      "Epoch [6/10], Step [1014/1079], Loss: 0.0020\n",
      "Epoch [6/10], Step [1015/1079], Loss: 0.0216\n",
      "Epoch [6/10], Step [1016/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [1017/1079], Loss: 0.0017\n",
      "Epoch [6/10], Step [1018/1079], Loss: 0.0036\n",
      "Epoch [6/10], Step [1019/1079], Loss: 0.0028\n",
      "Epoch [6/10], Step [1020/1079], Loss: 0.0053\n",
      "Epoch [6/10], Step [1021/1079], Loss: 0.0292\n",
      "Epoch [6/10], Step [1022/1079], Loss: 0.0408\n",
      "Epoch [6/10], Step [1023/1079], Loss: 0.0131\n",
      "Epoch [6/10], Step [1024/1079], Loss: 0.0092\n",
      "Epoch [6/10], Step [1025/1079], Loss: 0.0167\n",
      "Epoch [6/10], Step [1026/1079], Loss: 0.0021\n",
      "Epoch [6/10], Step [1027/1079], Loss: 0.0189\n",
      "Epoch [6/10], Step [1028/1079], Loss: 0.0075\n",
      "Epoch [6/10], Step [1029/1079], Loss: 0.0007\n",
      "Epoch [6/10], Step [1030/1079], Loss: 0.0021\n",
      "Epoch [6/10], Step [1031/1079], Loss: 0.0070\n",
      "Epoch [6/10], Step [1032/1079], Loss: 0.0026\n",
      "Epoch [6/10], Step [1033/1079], Loss: 0.1121\n",
      "Epoch [6/10], Step [1034/1079], Loss: 0.0234\n",
      "Epoch [6/10], Step [1035/1079], Loss: 0.0180\n",
      "Epoch [6/10], Step [1036/1079], Loss: 0.0027\n",
      "Epoch [6/10], Step [1037/1079], Loss: 0.0160\n",
      "Epoch [6/10], Step [1038/1079], Loss: 0.0025\n",
      "Epoch [6/10], Step [1039/1079], Loss: 0.0018\n",
      "Epoch [6/10], Step [1040/1079], Loss: 0.0061\n",
      "Epoch [6/10], Step [1041/1079], Loss: 0.1604\n",
      "Epoch [6/10], Step [1042/1079], Loss: 0.0043\n",
      "Epoch [6/10], Step [1043/1079], Loss: 0.0010\n",
      "Epoch [6/10], Step [1044/1079], Loss: 0.0041\n",
      "Epoch [6/10], Step [1045/1079], Loss: 0.0016\n",
      "Epoch [6/10], Step [1046/1079], Loss: 0.0120\n",
      "Epoch [6/10], Step [1047/1079], Loss: 0.0001\n",
      "Epoch [6/10], Step [1048/1079], Loss: 0.0069\n",
      "Epoch [6/10], Step [1049/1079], Loss: 0.0050\n",
      "Epoch [6/10], Step [1050/1079], Loss: 0.0205\n",
      "Epoch [6/10], Step [1051/1079], Loss: 0.0169\n",
      "Epoch [6/10], Step [1052/1079], Loss: 0.0722\n",
      "Epoch [6/10], Step [1053/1079], Loss: 0.0100\n",
      "Epoch [6/10], Step [1054/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [1055/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [1056/1079], Loss: 0.0037\n",
      "Epoch [6/10], Step [1057/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [1058/1079], Loss: 0.0003\n",
      "Epoch [6/10], Step [1059/1079], Loss: 0.0161\n",
      "Epoch [6/10], Step [1060/1079], Loss: 0.0083\n",
      "Epoch [6/10], Step [1061/1079], Loss: 0.0054\n",
      "Epoch [6/10], Step [1062/1079], Loss: 0.0073\n",
      "Epoch [6/10], Step [1063/1079], Loss: 0.0044\n",
      "Epoch [6/10], Step [1064/1079], Loss: 0.0079\n",
      "Epoch [6/10], Step [1065/1079], Loss: 0.0435\n",
      "Epoch [6/10], Step [1066/1079], Loss: 0.0015\n",
      "Epoch [6/10], Step [1067/1079], Loss: 0.0044\n",
      "Epoch [6/10], Step [1068/1079], Loss: 0.0002\n",
      "Epoch [6/10], Step [1069/1079], Loss: 0.0173\n",
      "Epoch [6/10], Step [1070/1079], Loss: 0.0069\n",
      "Epoch [6/10], Step [1071/1079], Loss: 0.0004\n",
      "Epoch [6/10], Step [1072/1079], Loss: 0.0019\n",
      "Epoch [6/10], Step [1073/1079], Loss: 0.0073\n",
      "Epoch [6/10], Step [1074/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [1075/1079], Loss: 0.0028\n",
      "Epoch [6/10], Step [1076/1079], Loss: 0.0011\n",
      "Epoch [6/10], Step [1077/1079], Loss: 0.0008\n",
      "Epoch [6/10], Step [1078/1079], Loss: 0.0580\n",
      "Epoch [6/10], Step [1079/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [1/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [2/1079], Loss: 0.0026\n",
      "Epoch [7/10], Step [3/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [4/1079], Loss: 0.0215\n",
      "Epoch [7/10], Step [5/1079], Loss: 0.0024\n",
      "Epoch [7/10], Step [6/1079], Loss: 0.0018\n",
      "Epoch [7/10], Step [7/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [8/1079], Loss: 0.0028\n",
      "Epoch [7/10], Step [9/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [10/1079], Loss: 0.0189\n",
      "Epoch [7/10], Step [11/1079], Loss: 0.0181\n",
      "Epoch [7/10], Step [12/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [13/1079], Loss: 0.0027\n",
      "Epoch [7/10], Step [14/1079], Loss: 0.0058\n",
      "Epoch [7/10], Step [15/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [16/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [17/1079], Loss: 0.0250\n",
      "Epoch [7/10], Step [18/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [19/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [20/1079], Loss: 0.0189\n",
      "Epoch [7/10], Step [21/1079], Loss: 0.0037\n",
      "Epoch [7/10], Step [22/1079], Loss: 0.0124\n",
      "Epoch [7/10], Step [23/1079], Loss: 0.0012\n",
      "Epoch [7/10], Step [24/1079], Loss: 0.0048\n",
      "Epoch [7/10], Step [25/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [26/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [27/1079], Loss: 0.1314\n",
      "Epoch [7/10], Step [28/1079], Loss: 0.0048\n",
      "Epoch [7/10], Step [29/1079], Loss: 0.0020\n",
      "Epoch [7/10], Step [30/1079], Loss: 0.0024\n",
      "Epoch [7/10], Step [31/1079], Loss: 0.0280\n",
      "Epoch [7/10], Step [32/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [33/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [34/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [35/1079], Loss: 0.0229\n",
      "Epoch [7/10], Step [36/1079], Loss: 0.0046\n",
      "Epoch [7/10], Step [37/1079], Loss: 0.0015\n",
      "Epoch [7/10], Step [38/1079], Loss: 0.0234\n",
      "Epoch [7/10], Step [39/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [40/1079], Loss: 0.0210\n",
      "Epoch [7/10], Step [41/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [42/1079], Loss: 0.0128\n",
      "Epoch [7/10], Step [43/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [44/1079], Loss: 0.0053\n",
      "Epoch [7/10], Step [45/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [46/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [47/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [48/1079], Loss: 0.0347\n",
      "Epoch [7/10], Step [49/1079], Loss: 0.0020\n",
      "Epoch [7/10], Step [50/1079], Loss: 0.0076\n",
      "Epoch [7/10], Step [51/1079], Loss: 0.0184\n",
      "Epoch [7/10], Step [52/1079], Loss: 0.0142\n",
      "Epoch [7/10], Step [53/1079], Loss: 0.0905\n",
      "Epoch [7/10], Step [54/1079], Loss: 0.0020\n",
      "Epoch [7/10], Step [55/1079], Loss: 0.0069\n",
      "Epoch [7/10], Step [56/1079], Loss: 0.0038\n",
      "Epoch [7/10], Step [57/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [58/1079], Loss: 0.0125\n",
      "Epoch [7/10], Step [59/1079], Loss: 0.0477\n",
      "Epoch [7/10], Step [60/1079], Loss: 0.0029\n",
      "Epoch [7/10], Step [61/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [62/1079], Loss: 0.0000\n",
      "Epoch [7/10], Step [63/1079], Loss: 0.0131\n",
      "Epoch [7/10], Step [64/1079], Loss: 0.0038\n",
      "Epoch [7/10], Step [65/1079], Loss: 0.0308\n",
      "Epoch [7/10], Step [66/1079], Loss: 0.0253\n",
      "Epoch [7/10], Step [67/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [68/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [69/1079], Loss: 0.0044\n",
      "Epoch [7/10], Step [70/1079], Loss: 0.0032\n",
      "Epoch [7/10], Step [71/1079], Loss: 0.0025\n",
      "Epoch [7/10], Step [72/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [73/1079], Loss: 0.0240\n",
      "Epoch [7/10], Step [74/1079], Loss: 0.0023\n",
      "Epoch [7/10], Step [75/1079], Loss: 0.0032\n",
      "Epoch [7/10], Step [76/1079], Loss: 0.0025\n",
      "Epoch [7/10], Step [77/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [78/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [79/1079], Loss: 0.0060\n",
      "Epoch [7/10], Step [80/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [81/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [82/1079], Loss: 0.0914\n",
      "Epoch [7/10], Step [83/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [84/1079], Loss: 0.0048\n",
      "Epoch [7/10], Step [85/1079], Loss: 0.0107\n",
      "Epoch [7/10], Step [86/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [87/1079], Loss: 0.0037\n",
      "Epoch [7/10], Step [88/1079], Loss: 0.0033\n",
      "Epoch [7/10], Step [89/1079], Loss: 0.0018\n",
      "Epoch [7/10], Step [90/1079], Loss: 0.0012\n",
      "Epoch [7/10], Step [91/1079], Loss: 0.0102\n",
      "Epoch [7/10], Step [92/1079], Loss: 0.0044\n",
      "Epoch [7/10], Step [93/1079], Loss: 0.0015\n",
      "Epoch [7/10], Step [94/1079], Loss: 0.0058\n",
      "Epoch [7/10], Step [95/1079], Loss: 0.0258\n",
      "Epoch [7/10], Step [96/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [97/1079], Loss: 0.0057\n",
      "Epoch [7/10], Step [98/1079], Loss: 0.0180\n",
      "Epoch [7/10], Step [99/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [100/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [101/1079], Loss: 0.0023\n",
      "Epoch [7/10], Step [102/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [103/1079], Loss: 0.0090\n",
      "Epoch [7/10], Step [104/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [105/1079], Loss: 0.0038\n",
      "Epoch [7/10], Step [106/1079], Loss: 0.0150\n",
      "Epoch [7/10], Step [107/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [108/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [109/1079], Loss: 0.0038\n",
      "Epoch [7/10], Step [110/1079], Loss: 0.0134\n",
      "Epoch [7/10], Step [111/1079], Loss: 0.0446\n",
      "Epoch [7/10], Step [112/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [113/1079], Loss: 0.0256\n",
      "Epoch [7/10], Step [114/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [115/1079], Loss: 0.0221\n",
      "Epoch [7/10], Step [116/1079], Loss: 0.0216\n",
      "Epoch [7/10], Step [117/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [118/1079], Loss: 0.0078\n",
      "Epoch [7/10], Step [119/1079], Loss: 0.0048\n",
      "Epoch [7/10], Step [120/1079], Loss: 0.0259\n",
      "Epoch [7/10], Step [121/1079], Loss: 0.0022\n",
      "Epoch [7/10], Step [122/1079], Loss: 0.0148\n",
      "Epoch [7/10], Step [123/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [124/1079], Loss: 0.0061\n",
      "Epoch [7/10], Step [125/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [126/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [127/1079], Loss: 0.0283\n",
      "Epoch [7/10], Step [128/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [129/1079], Loss: 0.0121\n",
      "Epoch [7/10], Step [130/1079], Loss: 0.0678\n",
      "Epoch [7/10], Step [131/1079], Loss: 0.0074\n",
      "Epoch [7/10], Step [132/1079], Loss: 0.0067\n",
      "Epoch [7/10], Step [133/1079], Loss: 0.0162\n",
      "Epoch [7/10], Step [134/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [135/1079], Loss: 0.0048\n",
      "Epoch [7/10], Step [136/1079], Loss: 0.1406\n",
      "Epoch [7/10], Step [137/1079], Loss: 0.0108\n",
      "Epoch [7/10], Step [138/1079], Loss: 0.0042\n",
      "Epoch [7/10], Step [139/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [140/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [141/1079], Loss: 0.0082\n",
      "Epoch [7/10], Step [142/1079], Loss: 0.0163\n",
      "Epoch [7/10], Step [143/1079], Loss: 0.0544\n",
      "Epoch [7/10], Step [144/1079], Loss: 0.0044\n",
      "Epoch [7/10], Step [145/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [146/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [147/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [148/1079], Loss: 0.0583\n",
      "Epoch [7/10], Step [149/1079], Loss: 0.0013\n",
      "Epoch [7/10], Step [150/1079], Loss: 0.0085\n",
      "Epoch [7/10], Step [151/1079], Loss: 0.0126\n",
      "Epoch [7/10], Step [152/1079], Loss: 0.0020\n",
      "Epoch [7/10], Step [153/1079], Loss: 0.0152\n",
      "Epoch [7/10], Step [154/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [155/1079], Loss: 0.0023\n",
      "Epoch [7/10], Step [156/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [157/1079], Loss: 0.0071\n",
      "Epoch [7/10], Step [158/1079], Loss: 0.0021\n",
      "Epoch [7/10], Step [159/1079], Loss: 0.0168\n",
      "Epoch [7/10], Step [160/1079], Loss: 0.0020\n",
      "Epoch [7/10], Step [161/1079], Loss: 0.0026\n",
      "Epoch [7/10], Step [162/1079], Loss: 0.0564\n",
      "Epoch [7/10], Step [163/1079], Loss: 0.0204\n",
      "Epoch [7/10], Step [164/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [165/1079], Loss: 0.0079\n",
      "Epoch [7/10], Step [166/1079], Loss: 0.0291\n",
      "Epoch [7/10], Step [167/1079], Loss: 0.0225\n",
      "Epoch [7/10], Step [168/1079], Loss: 0.0281\n",
      "Epoch [7/10], Step [169/1079], Loss: 0.0024\n",
      "Epoch [7/10], Step [170/1079], Loss: 0.0015\n",
      "Epoch [7/10], Step [171/1079], Loss: 0.0025\n",
      "Epoch [7/10], Step [172/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [173/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [174/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [175/1079], Loss: 0.0038\n",
      "Epoch [7/10], Step [176/1079], Loss: 0.0107\n",
      "Epoch [7/10], Step [177/1079], Loss: 0.0671\n",
      "Epoch [7/10], Step [178/1079], Loss: 0.0072\n",
      "Epoch [7/10], Step [179/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [180/1079], Loss: 0.1805\n",
      "Epoch [7/10], Step [181/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [182/1079], Loss: 0.0168\n",
      "Epoch [7/10], Step [183/1079], Loss: 0.0357\n",
      "Epoch [7/10], Step [184/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [185/1079], Loss: 0.0023\n",
      "Epoch [7/10], Step [186/1079], Loss: 0.0315\n",
      "Epoch [7/10], Step [187/1079], Loss: 0.0183\n",
      "Epoch [7/10], Step [188/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [189/1079], Loss: 0.0188\n",
      "Epoch [7/10], Step [190/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [191/1079], Loss: 0.0261\n",
      "Epoch [7/10], Step [192/1079], Loss: 0.0747\n",
      "Epoch [7/10], Step [193/1079], Loss: 0.0120\n",
      "Epoch [7/10], Step [194/1079], Loss: 0.0201\n",
      "Epoch [7/10], Step [195/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [196/1079], Loss: 0.0041\n",
      "Epoch [7/10], Step [197/1079], Loss: 0.0079\n",
      "Epoch [7/10], Step [198/1079], Loss: 0.0508\n",
      "Epoch [7/10], Step [199/1079], Loss: 0.0107\n",
      "Epoch [7/10], Step [200/1079], Loss: 0.0577\n",
      "Epoch [7/10], Step [201/1079], Loss: 0.0313\n",
      "Epoch [7/10], Step [202/1079], Loss: 0.0159\n",
      "Epoch [7/10], Step [203/1079], Loss: 0.0088\n",
      "Epoch [7/10], Step [204/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [205/1079], Loss: 0.0016\n",
      "Epoch [7/10], Step [206/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [207/1079], Loss: 0.0041\n",
      "Epoch [7/10], Step [208/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [209/1079], Loss: 0.0055\n",
      "Epoch [7/10], Step [210/1079], Loss: 0.0035\n",
      "Epoch [7/10], Step [211/1079], Loss: 0.0057\n",
      "Epoch [7/10], Step [212/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [213/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [214/1079], Loss: 0.0062\n",
      "Epoch [7/10], Step [215/1079], Loss: 0.0157\n",
      "Epoch [7/10], Step [216/1079], Loss: 0.0022\n",
      "Epoch [7/10], Step [217/1079], Loss: 0.0032\n",
      "Epoch [7/10], Step [218/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [219/1079], Loss: 0.0102\n",
      "Epoch [7/10], Step [220/1079], Loss: 0.0045\n",
      "Epoch [7/10], Step [221/1079], Loss: 0.0081\n",
      "Epoch [7/10], Step [222/1079], Loss: 0.0028\n",
      "Epoch [7/10], Step [223/1079], Loss: 0.0572\n",
      "Epoch [7/10], Step [224/1079], Loss: 0.0069\n",
      "Epoch [7/10], Step [225/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [226/1079], Loss: 0.0041\n",
      "Epoch [7/10], Step [227/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [228/1079], Loss: 0.0052\n",
      "Epoch [7/10], Step [229/1079], Loss: 0.0138\n",
      "Epoch [7/10], Step [230/1079], Loss: 0.0085\n",
      "Epoch [7/10], Step [231/1079], Loss: 0.0019\n",
      "Epoch [7/10], Step [232/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [233/1079], Loss: 0.0054\n",
      "Epoch [7/10], Step [234/1079], Loss: 0.0051\n",
      "Epoch [7/10], Step [235/1079], Loss: 0.0021\n",
      "Epoch [7/10], Step [236/1079], Loss: 0.0040\n",
      "Epoch [7/10], Step [237/1079], Loss: 0.0064\n",
      "Epoch [7/10], Step [238/1079], Loss: 0.0060\n",
      "Epoch [7/10], Step [239/1079], Loss: 0.0053\n",
      "Epoch [7/10], Step [240/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [241/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [242/1079], Loss: 0.0031\n",
      "Epoch [7/10], Step [243/1079], Loss: 0.0212\n",
      "Epoch [7/10], Step [244/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [245/1079], Loss: 0.0088\n",
      "Epoch [7/10], Step [246/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [247/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [248/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [249/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [250/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [251/1079], Loss: 0.0064\n",
      "Epoch [7/10], Step [252/1079], Loss: 0.0115\n",
      "Epoch [7/10], Step [253/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [254/1079], Loss: 0.0015\n",
      "Epoch [7/10], Step [255/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [256/1079], Loss: 0.0028\n",
      "Epoch [7/10], Step [257/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [258/1079], Loss: 0.0054\n",
      "Epoch [7/10], Step [259/1079], Loss: 0.0012\n",
      "Epoch [7/10], Step [260/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [261/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [262/1079], Loss: 0.0128\n",
      "Epoch [7/10], Step [263/1079], Loss: 0.0015\n",
      "Epoch [7/10], Step [264/1079], Loss: 0.0021\n",
      "Epoch [7/10], Step [265/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [266/1079], Loss: 0.0023\n",
      "Epoch [7/10], Step [267/1079], Loss: 0.0240\n",
      "Epoch [7/10], Step [268/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [269/1079], Loss: 0.0237\n",
      "Epoch [7/10], Step [270/1079], Loss: 0.0036\n",
      "Epoch [7/10], Step [271/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [272/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [273/1079], Loss: 0.0031\n",
      "Epoch [7/10], Step [274/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [275/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [276/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [277/1079], Loss: 0.0117\n",
      "Epoch [7/10], Step [278/1079], Loss: 0.0012\n",
      "Epoch [7/10], Step [279/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [280/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [281/1079], Loss: 0.0067\n",
      "Epoch [7/10], Step [282/1079], Loss: 0.0436\n",
      "Epoch [7/10], Step [283/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [284/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [285/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [286/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [287/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [288/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [289/1079], Loss: 0.0013\n",
      "Epoch [7/10], Step [290/1079], Loss: 0.0026\n",
      "Epoch [7/10], Step [291/1079], Loss: 0.0027\n",
      "Epoch [7/10], Step [292/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [293/1079], Loss: 0.0022\n",
      "Epoch [7/10], Step [294/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [295/1079], Loss: 0.0078\n",
      "Epoch [7/10], Step [296/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [297/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [298/1079], Loss: 0.0036\n",
      "Epoch [7/10], Step [299/1079], Loss: 0.0042\n",
      "Epoch [7/10], Step [300/1079], Loss: 0.0059\n",
      "Epoch [7/10], Step [301/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [302/1079], Loss: 0.0061\n",
      "Epoch [7/10], Step [303/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [304/1079], Loss: 0.0037\n",
      "Epoch [7/10], Step [305/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [306/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [307/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [308/1079], Loss: 0.1290\n",
      "Epoch [7/10], Step [309/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [310/1079], Loss: 0.0107\n",
      "Epoch [7/10], Step [311/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [312/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [313/1079], Loss: 0.0159\n",
      "Epoch [7/10], Step [314/1079], Loss: 0.0028\n",
      "Epoch [7/10], Step [315/1079], Loss: 0.0183\n",
      "Epoch [7/10], Step [316/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [317/1079], Loss: 0.0044\n",
      "Epoch [7/10], Step [318/1079], Loss: 0.0095\n",
      "Epoch [7/10], Step [319/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [320/1079], Loss: 0.0040\n",
      "Epoch [7/10], Step [321/1079], Loss: 0.0356\n",
      "Epoch [7/10], Step [322/1079], Loss: 0.0064\n",
      "Epoch [7/10], Step [323/1079], Loss: 0.0035\n",
      "Epoch [7/10], Step [324/1079], Loss: 0.0388\n",
      "Epoch [7/10], Step [325/1079], Loss: 0.0145\n",
      "Epoch [7/10], Step [326/1079], Loss: 0.0396\n",
      "Epoch [7/10], Step [327/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [328/1079], Loss: 0.0056\n",
      "Epoch [7/10], Step [329/1079], Loss: 0.0038\n",
      "Epoch [7/10], Step [330/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [331/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [332/1079], Loss: 0.0095\n",
      "Epoch [7/10], Step [333/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [334/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [335/1079], Loss: 0.0143\n",
      "Epoch [7/10], Step [336/1079], Loss: 0.0095\n",
      "Epoch [7/10], Step [337/1079], Loss: 0.0031\n",
      "Epoch [7/10], Step [338/1079], Loss: 0.0203\n",
      "Epoch [7/10], Step [339/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [340/1079], Loss: 0.0065\n",
      "Epoch [7/10], Step [341/1079], Loss: 0.0246\n",
      "Epoch [7/10], Step [342/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [343/1079], Loss: 0.0087\n",
      "Epoch [7/10], Step [344/1079], Loss: 0.0141\n",
      "Epoch [7/10], Step [345/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [346/1079], Loss: 0.0025\n",
      "Epoch [7/10], Step [347/1079], Loss: 0.0107\n",
      "Epoch [7/10], Step [348/1079], Loss: 0.0318\n",
      "Epoch [7/10], Step [349/1079], Loss: 0.0060\n",
      "Epoch [7/10], Step [350/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [351/1079], Loss: 0.0040\n",
      "Epoch [7/10], Step [352/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [353/1079], Loss: 0.0181\n",
      "Epoch [7/10], Step [354/1079], Loss: 0.0012\n",
      "Epoch [7/10], Step [355/1079], Loss: 0.0059\n",
      "Epoch [7/10], Step [356/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [357/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [358/1079], Loss: 0.0214\n",
      "Epoch [7/10], Step [359/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [360/1079], Loss: 0.0176\n",
      "Epoch [7/10], Step [361/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [362/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [363/1079], Loss: 0.0360\n",
      "Epoch [7/10], Step [364/1079], Loss: 0.0418\n",
      "Epoch [7/10], Step [365/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [366/1079], Loss: 0.0044\n",
      "Epoch [7/10], Step [367/1079], Loss: 0.0018\n",
      "Epoch [7/10], Step [368/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [369/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [370/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [371/1079], Loss: 0.0018\n",
      "Epoch [7/10], Step [372/1079], Loss: 0.0106\n",
      "Epoch [7/10], Step [373/1079], Loss: 0.0206\n",
      "Epoch [7/10], Step [374/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [375/1079], Loss: 0.0225\n",
      "Epoch [7/10], Step [376/1079], Loss: 0.0089\n",
      "Epoch [7/10], Step [377/1079], Loss: 0.0118\n",
      "Epoch [7/10], Step [378/1079], Loss: 0.0086\n",
      "Epoch [7/10], Step [379/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [380/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [381/1079], Loss: 0.0029\n",
      "Epoch [7/10], Step [382/1079], Loss: 0.0019\n",
      "Epoch [7/10], Step [383/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [384/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [385/1079], Loss: 0.0050\n",
      "Epoch [7/10], Step [386/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [387/1079], Loss: 0.0056\n",
      "Epoch [7/10], Step [388/1079], Loss: 0.0331\n",
      "Epoch [7/10], Step [389/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [390/1079], Loss: 0.0288\n",
      "Epoch [7/10], Step [391/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [392/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [393/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [394/1079], Loss: 0.0565\n",
      "Epoch [7/10], Step [395/1079], Loss: 0.0029\n",
      "Epoch [7/10], Step [396/1079], Loss: 0.0565\n",
      "Epoch [7/10], Step [397/1079], Loss: 0.0270\n",
      "Epoch [7/10], Step [398/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [399/1079], Loss: 0.0052\n",
      "Epoch [7/10], Step [400/1079], Loss: 0.0265\n",
      "Epoch [7/10], Step [401/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [402/1079], Loss: 0.0081\n",
      "Epoch [7/10], Step [403/1079], Loss: 0.0071\n",
      "Epoch [7/10], Step [404/1079], Loss: 0.0077\n",
      "Epoch [7/10], Step [405/1079], Loss: 0.0015\n",
      "Epoch [7/10], Step [406/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [407/1079], Loss: 0.0392\n",
      "Epoch [7/10], Step [408/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [409/1079], Loss: 0.0052\n",
      "Epoch [7/10], Step [410/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [411/1079], Loss: 0.0538\n",
      "Epoch [7/10], Step [412/1079], Loss: 0.0012\n",
      "Epoch [7/10], Step [413/1079], Loss: 0.0067\n",
      "Epoch [7/10], Step [414/1079], Loss: 0.0196\n",
      "Epoch [7/10], Step [415/1079], Loss: 0.0022\n",
      "Epoch [7/10], Step [416/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [417/1079], Loss: 0.0021\n",
      "Epoch [7/10], Step [418/1079], Loss: 0.0076\n",
      "Epoch [7/10], Step [419/1079], Loss: 0.0029\n",
      "Epoch [7/10], Step [420/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [421/1079], Loss: 0.0028\n",
      "Epoch [7/10], Step [422/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [423/1079], Loss: 0.0098\n",
      "Epoch [7/10], Step [424/1079], Loss: 0.0042\n",
      "Epoch [7/10], Step [425/1079], Loss: 0.0075\n",
      "Epoch [7/10], Step [426/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [427/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [428/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [429/1079], Loss: 0.0336\n",
      "Epoch [7/10], Step [430/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [431/1079], Loss: 0.0018\n",
      "Epoch [7/10], Step [432/1079], Loss: 0.0051\n",
      "Epoch [7/10], Step [433/1079], Loss: 0.0023\n",
      "Epoch [7/10], Step [434/1079], Loss: 0.0138\n",
      "Epoch [7/10], Step [435/1079], Loss: 0.0374\n",
      "Epoch [7/10], Step [436/1079], Loss: 0.0012\n",
      "Epoch [7/10], Step [437/1079], Loss: 0.0483\n",
      "Epoch [7/10], Step [438/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [439/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [440/1079], Loss: 0.1092\n",
      "Epoch [7/10], Step [441/1079], Loss: 0.0147\n",
      "Epoch [7/10], Step [442/1079], Loss: 0.0038\n",
      "Epoch [7/10], Step [443/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [444/1079], Loss: 0.0025\n",
      "Epoch [7/10], Step [445/1079], Loss: 0.0019\n",
      "Epoch [7/10], Step [446/1079], Loss: 0.0057\n",
      "Epoch [7/10], Step [447/1079], Loss: 0.0078\n",
      "Epoch [7/10], Step [448/1079], Loss: 0.0107\n",
      "Epoch [7/10], Step [449/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [450/1079], Loss: 0.0052\n",
      "Epoch [7/10], Step [451/1079], Loss: 0.0141\n",
      "Epoch [7/10], Step [452/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [453/1079], Loss: 0.0015\n",
      "Epoch [7/10], Step [454/1079], Loss: 0.0160\n",
      "Epoch [7/10], Step [455/1079], Loss: 0.0040\n",
      "Epoch [7/10], Step [456/1079], Loss: 0.0059\n",
      "Epoch [7/10], Step [457/1079], Loss: 0.0156\n",
      "Epoch [7/10], Step [458/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [459/1079], Loss: 0.0078\n",
      "Epoch [7/10], Step [460/1079], Loss: 0.0033\n",
      "Epoch [7/10], Step [461/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [462/1079], Loss: 0.0325\n",
      "Epoch [7/10], Step [463/1079], Loss: 0.0057\n",
      "Epoch [7/10], Step [464/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [465/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [466/1079], Loss: 0.0022\n",
      "Epoch [7/10], Step [467/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [468/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [469/1079], Loss: 0.0420\n",
      "Epoch [7/10], Step [470/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [471/1079], Loss: 0.0013\n",
      "Epoch [7/10], Step [472/1079], Loss: 0.0024\n",
      "Epoch [7/10], Step [473/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [474/1079], Loss: 0.0094\n",
      "Epoch [7/10], Step [475/1079], Loss: 0.0109\n",
      "Epoch [7/10], Step [476/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [477/1079], Loss: 0.0406\n",
      "Epoch [7/10], Step [478/1079], Loss: 0.0000\n",
      "Epoch [7/10], Step [479/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [480/1079], Loss: 0.0119\n",
      "Epoch [7/10], Step [481/1079], Loss: 0.0050\n",
      "Epoch [7/10], Step [482/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [483/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [484/1079], Loss: 0.0251\n",
      "Epoch [7/10], Step [485/1079], Loss: 0.0019\n",
      "Epoch [7/10], Step [486/1079], Loss: 0.0551\n",
      "Epoch [7/10], Step [487/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [488/1079], Loss: 0.0069\n",
      "Epoch [7/10], Step [489/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [490/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [491/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [492/1079], Loss: 0.0114\n",
      "Epoch [7/10], Step [493/1079], Loss: 0.0176\n",
      "Epoch [7/10], Step [494/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [495/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [496/1079], Loss: 0.0312\n",
      "Epoch [7/10], Step [497/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [498/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [499/1079], Loss: 0.0021\n",
      "Epoch [7/10], Step [500/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [501/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [502/1079], Loss: 0.0598\n",
      "Epoch [7/10], Step [503/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [504/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [505/1079], Loss: 0.0028\n",
      "Epoch [7/10], Step [506/1079], Loss: 0.0031\n",
      "Epoch [7/10], Step [507/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [508/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [509/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [510/1079], Loss: 0.0026\n",
      "Epoch [7/10], Step [511/1079], Loss: 0.0031\n",
      "Epoch [7/10], Step [512/1079], Loss: 0.0209\n",
      "Epoch [7/10], Step [513/1079], Loss: 0.0289\n",
      "Epoch [7/10], Step [514/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [515/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [516/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [517/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [518/1079], Loss: 0.0013\n",
      "Epoch [7/10], Step [519/1079], Loss: 0.0018\n",
      "Epoch [7/10], Step [520/1079], Loss: 0.0038\n",
      "Epoch [7/10], Step [521/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [522/1079], Loss: 0.0059\n",
      "Epoch [7/10], Step [523/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [524/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [525/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [526/1079], Loss: 0.0064\n",
      "Epoch [7/10], Step [527/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [528/1079], Loss: 0.0028\n",
      "Epoch [7/10], Step [529/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [530/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [531/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [532/1079], Loss: 0.0050\n",
      "Epoch [7/10], Step [533/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [534/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [535/1079], Loss: 0.0132\n",
      "Epoch [7/10], Step [536/1079], Loss: 0.0480\n",
      "Epoch [7/10], Step [537/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [538/1079], Loss: 0.0063\n",
      "Epoch [7/10], Step [539/1079], Loss: 0.0130\n",
      "Epoch [7/10], Step [540/1079], Loss: 0.0024\n",
      "Epoch [7/10], Step [541/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [542/1079], Loss: 0.0012\n",
      "Epoch [7/10], Step [543/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [544/1079], Loss: 0.0507\n",
      "Epoch [7/10], Step [545/1079], Loss: 0.0053\n",
      "Epoch [7/10], Step [546/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [547/1079], Loss: 0.0023\n",
      "Epoch [7/10], Step [548/1079], Loss: 0.0861\n",
      "Epoch [7/10], Step [549/1079], Loss: 0.0020\n",
      "Epoch [7/10], Step [550/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [551/1079], Loss: 0.0013\n",
      "Epoch [7/10], Step [552/1079], Loss: 0.0042\n",
      "Epoch [7/10], Step [553/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [554/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [555/1079], Loss: 0.0932\n",
      "Epoch [7/10], Step [556/1079], Loss: 0.0306\n",
      "Epoch [7/10], Step [557/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [558/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [559/1079], Loss: 0.0086\n",
      "Epoch [7/10], Step [560/1079], Loss: 0.0044\n",
      "Epoch [7/10], Step [561/1079], Loss: 0.0064\n",
      "Epoch [7/10], Step [562/1079], Loss: 0.0612\n",
      "Epoch [7/10], Step [563/1079], Loss: 0.0080\n",
      "Epoch [7/10], Step [564/1079], Loss: 0.0225\n",
      "Epoch [7/10], Step [565/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [566/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [567/1079], Loss: 0.0415\n",
      "Epoch [7/10], Step [568/1079], Loss: 0.0075\n",
      "Epoch [7/10], Step [569/1079], Loss: 0.0040\n",
      "Epoch [7/10], Step [570/1079], Loss: 0.0047\n",
      "Epoch [7/10], Step [571/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [572/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [573/1079], Loss: 0.0159\n",
      "Epoch [7/10], Step [574/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [575/1079], Loss: 0.0022\n",
      "Epoch [7/10], Step [576/1079], Loss: 0.0016\n",
      "Epoch [7/10], Step [577/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [578/1079], Loss: 0.0113\n",
      "Epoch [7/10], Step [579/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [580/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [581/1079], Loss: 0.0094\n",
      "Epoch [7/10], Step [582/1079], Loss: 0.0052\n",
      "Epoch [7/10], Step [583/1079], Loss: 0.0048\n",
      "Epoch [7/10], Step [584/1079], Loss: 0.0012\n",
      "Epoch [7/10], Step [585/1079], Loss: 0.0129\n",
      "Epoch [7/10], Step [586/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [587/1079], Loss: 0.0077\n",
      "Epoch [7/10], Step [588/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [589/1079], Loss: 0.0056\n",
      "Epoch [7/10], Step [590/1079], Loss: 0.0048\n",
      "Epoch [7/10], Step [591/1079], Loss: 0.0755\n",
      "Epoch [7/10], Step [592/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [593/1079], Loss: 0.0043\n",
      "Epoch [7/10], Step [594/1079], Loss: 0.0031\n",
      "Epoch [7/10], Step [595/1079], Loss: 0.0019\n",
      "Epoch [7/10], Step [596/1079], Loss: 0.0080\n",
      "Epoch [7/10], Step [597/1079], Loss: 0.0472\n",
      "Epoch [7/10], Step [598/1079], Loss: 0.0045\n",
      "Epoch [7/10], Step [599/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [600/1079], Loss: 0.0218\n",
      "Epoch [7/10], Step [601/1079], Loss: 0.0248\n",
      "Epoch [7/10], Step [602/1079], Loss: 0.0015\n",
      "Epoch [7/10], Step [603/1079], Loss: 0.0297\n",
      "Epoch [7/10], Step [604/1079], Loss: 0.0020\n",
      "Epoch [7/10], Step [605/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [606/1079], Loss: 0.0015\n",
      "Epoch [7/10], Step [607/1079], Loss: 0.0019\n",
      "Epoch [7/10], Step [608/1079], Loss: 0.0022\n",
      "Epoch [7/10], Step [609/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [610/1079], Loss: 0.0018\n",
      "Epoch [7/10], Step [611/1079], Loss: 0.0016\n",
      "Epoch [7/10], Step [612/1079], Loss: 0.0043\n",
      "Epoch [7/10], Step [613/1079], Loss: 0.0333\n",
      "Epoch [7/10], Step [614/1079], Loss: 0.0021\n",
      "Epoch [7/10], Step [615/1079], Loss: 0.0040\n",
      "Epoch [7/10], Step [616/1079], Loss: 0.0035\n",
      "Epoch [7/10], Step [617/1079], Loss: 0.0018\n",
      "Epoch [7/10], Step [618/1079], Loss: 0.0022\n",
      "Epoch [7/10], Step [619/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [620/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [621/1079], Loss: 0.0021\n",
      "Epoch [7/10], Step [622/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [623/1079], Loss: 0.0029\n",
      "Epoch [7/10], Step [624/1079], Loss: 0.0029\n",
      "Epoch [7/10], Step [625/1079], Loss: 0.0296\n",
      "Epoch [7/10], Step [626/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [627/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [628/1079], Loss: 0.0026\n",
      "Epoch [7/10], Step [629/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [630/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [631/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [632/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [633/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [634/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [635/1079], Loss: 0.0012\n",
      "Epoch [7/10], Step [636/1079], Loss: 0.0160\n",
      "Epoch [7/10], Step [637/1079], Loss: 0.0489\n",
      "Epoch [7/10], Step [638/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [639/1079], Loss: 0.0200\n",
      "Epoch [7/10], Step [640/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [641/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [642/1079], Loss: 0.0049\n",
      "Epoch [7/10], Step [643/1079], Loss: 0.0051\n",
      "Epoch [7/10], Step [644/1079], Loss: 0.0029\n",
      "Epoch [7/10], Step [645/1079], Loss: 0.0038\n",
      "Epoch [7/10], Step [646/1079], Loss: 0.0333\n",
      "Epoch [7/10], Step [647/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [648/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [649/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [650/1079], Loss: 0.0088\n",
      "Epoch [7/10], Step [651/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [652/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [653/1079], Loss: 0.0200\n",
      "Epoch [7/10], Step [654/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [655/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [656/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [657/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [658/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [659/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [660/1079], Loss: 0.0043\n",
      "Epoch [7/10], Step [661/1079], Loss: 0.0238\n",
      "Epoch [7/10], Step [662/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [663/1079], Loss: 0.0098\n",
      "Epoch [7/10], Step [664/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [665/1079], Loss: 0.0033\n",
      "Epoch [7/10], Step [666/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [667/1079], Loss: 0.1715\n",
      "Epoch [7/10], Step [668/1079], Loss: 0.0156\n",
      "Epoch [7/10], Step [669/1079], Loss: 0.0047\n",
      "Epoch [7/10], Step [670/1079], Loss: 0.0035\n",
      "Epoch [7/10], Step [671/1079], Loss: 0.0043\n",
      "Epoch [7/10], Step [672/1079], Loss: 0.0703\n",
      "Epoch [7/10], Step [673/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [674/1079], Loss: 0.0027\n",
      "Epoch [7/10], Step [675/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [676/1079], Loss: 0.0237\n",
      "Epoch [7/10], Step [677/1079], Loss: 0.0127\n",
      "Epoch [7/10], Step [678/1079], Loss: 0.0024\n",
      "Epoch [7/10], Step [679/1079], Loss: 0.0567\n",
      "Epoch [7/10], Step [680/1079], Loss: 0.0995\n",
      "Epoch [7/10], Step [681/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [682/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [683/1079], Loss: 0.0044\n",
      "Epoch [7/10], Step [684/1079], Loss: 0.0141\n",
      "Epoch [7/10], Step [685/1079], Loss: 0.0093\n",
      "Epoch [7/10], Step [686/1079], Loss: 0.0126\n",
      "Epoch [7/10], Step [687/1079], Loss: 0.0029\n",
      "Epoch [7/10], Step [688/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [689/1079], Loss: 0.0038\n",
      "Epoch [7/10], Step [690/1079], Loss: 0.0054\n",
      "Epoch [7/10], Step [691/1079], Loss: 0.1043\n",
      "Epoch [7/10], Step [692/1079], Loss: 0.0069\n",
      "Epoch [7/10], Step [693/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [694/1079], Loss: 0.0020\n",
      "Epoch [7/10], Step [695/1079], Loss: 0.0432\n",
      "Epoch [7/10], Step [696/1079], Loss: 0.0013\n",
      "Epoch [7/10], Step [697/1079], Loss: 0.0129\n",
      "Epoch [7/10], Step [698/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [699/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [700/1079], Loss: 0.0087\n",
      "Epoch [7/10], Step [701/1079], Loss: 0.0104\n",
      "Epoch [7/10], Step [702/1079], Loss: 0.0033\n",
      "Epoch [7/10], Step [703/1079], Loss: 0.0166\n",
      "Epoch [7/10], Step [704/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [705/1079], Loss: 0.0032\n",
      "Epoch [7/10], Step [706/1079], Loss: 0.0190\n",
      "Epoch [7/10], Step [707/1079], Loss: 0.0383\n",
      "Epoch [7/10], Step [708/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [709/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [710/1079], Loss: 0.0515\n",
      "Epoch [7/10], Step [711/1079], Loss: 0.0093\n",
      "Epoch [7/10], Step [712/1079], Loss: 0.0044\n",
      "Epoch [7/10], Step [713/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [714/1079], Loss: 0.0026\n",
      "Epoch [7/10], Step [715/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [716/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [717/1079], Loss: 0.0208\n",
      "Epoch [7/10], Step [718/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [719/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [720/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [721/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [722/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [723/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [724/1079], Loss: 0.0067\n",
      "Epoch [7/10], Step [725/1079], Loss: 0.0159\n",
      "Epoch [7/10], Step [726/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [727/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [728/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [729/1079], Loss: 0.0185\n",
      "Epoch [7/10], Step [730/1079], Loss: 0.0638\n",
      "Epoch [7/10], Step [731/1079], Loss: 0.0289\n",
      "Epoch [7/10], Step [732/1079], Loss: 0.0016\n",
      "Epoch [7/10], Step [733/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [734/1079], Loss: 0.0122\n",
      "Epoch [7/10], Step [735/1079], Loss: 0.0173\n",
      "Epoch [7/10], Step [736/1079], Loss: 0.0067\n",
      "Epoch [7/10], Step [737/1079], Loss: 0.0321\n",
      "Epoch [7/10], Step [738/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [739/1079], Loss: 0.0049\n",
      "Epoch [7/10], Step [740/1079], Loss: 0.0366\n",
      "Epoch [7/10], Step [741/1079], Loss: 0.0091\n",
      "Epoch [7/10], Step [742/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [743/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [744/1079], Loss: 0.0031\n",
      "Epoch [7/10], Step [745/1079], Loss: 0.0233\n",
      "Epoch [7/10], Step [746/1079], Loss: 0.0036\n",
      "Epoch [7/10], Step [747/1079], Loss: 0.0057\n",
      "Epoch [7/10], Step [748/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [749/1079], Loss: 0.0080\n",
      "Epoch [7/10], Step [750/1079], Loss: 0.0584\n",
      "Epoch [7/10], Step [751/1079], Loss: 0.0016\n",
      "Epoch [7/10], Step [752/1079], Loss: 0.0020\n",
      "Epoch [7/10], Step [753/1079], Loss: 0.0215\n",
      "Epoch [7/10], Step [754/1079], Loss: 0.0142\n",
      "Epoch [7/10], Step [755/1079], Loss: 0.0375\n",
      "Epoch [7/10], Step [756/1079], Loss: 0.0024\n",
      "Epoch [7/10], Step [757/1079], Loss: 0.0130\n",
      "Epoch [7/10], Step [758/1079], Loss: 0.0537\n",
      "Epoch [7/10], Step [759/1079], Loss: 0.0079\n",
      "Epoch [7/10], Step [760/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [761/1079], Loss: 0.0897\n",
      "Epoch [7/10], Step [762/1079], Loss: 0.0290\n",
      "Epoch [7/10], Step [763/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [764/1079], Loss: 0.0117\n",
      "Epoch [7/10], Step [765/1079], Loss: 0.0151\n",
      "Epoch [7/10], Step [766/1079], Loss: 0.0402\n",
      "Epoch [7/10], Step [767/1079], Loss: 0.0115\n",
      "Epoch [7/10], Step [768/1079], Loss: 0.0038\n",
      "Epoch [7/10], Step [769/1079], Loss: 0.0095\n",
      "Epoch [7/10], Step [770/1079], Loss: 0.0101\n",
      "Epoch [7/10], Step [771/1079], Loss: 0.0258\n",
      "Epoch [7/10], Step [772/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [773/1079], Loss: 0.0218\n",
      "Epoch [7/10], Step [774/1079], Loss: 0.0035\n",
      "Epoch [7/10], Step [775/1079], Loss: 0.0324\n",
      "Epoch [7/10], Step [776/1079], Loss: 0.0694\n",
      "Epoch [7/10], Step [777/1079], Loss: 0.0419\n",
      "Epoch [7/10], Step [778/1079], Loss: 0.0649\n",
      "Epoch [7/10], Step [779/1079], Loss: 0.0022\n",
      "Epoch [7/10], Step [780/1079], Loss: 0.0095\n",
      "Epoch [7/10], Step [781/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [782/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [783/1079], Loss: 0.0346\n",
      "Epoch [7/10], Step [784/1079], Loss: 0.0049\n",
      "Epoch [7/10], Step [785/1079], Loss: 0.0652\n",
      "Epoch [7/10], Step [786/1079], Loss: 0.0024\n",
      "Epoch [7/10], Step [787/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [788/1079], Loss: 0.0013\n",
      "Epoch [7/10], Step [789/1079], Loss: 0.0123\n",
      "Epoch [7/10], Step [790/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [791/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [792/1079], Loss: 0.0012\n",
      "Epoch [7/10], Step [793/1079], Loss: 0.0016\n",
      "Epoch [7/10], Step [794/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [795/1079], Loss: 0.0084\n",
      "Epoch [7/10], Step [796/1079], Loss: 0.0138\n",
      "Epoch [7/10], Step [797/1079], Loss: 0.0025\n",
      "Epoch [7/10], Step [798/1079], Loss: 0.0223\n",
      "Epoch [7/10], Step [799/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [800/1079], Loss: 0.0042\n",
      "Epoch [7/10], Step [801/1079], Loss: 0.0390\n",
      "Epoch [7/10], Step [802/1079], Loss: 0.0659\n",
      "Epoch [7/10], Step [803/1079], Loss: 0.0135\n",
      "Epoch [7/10], Step [804/1079], Loss: 0.0192\n",
      "Epoch [7/10], Step [805/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [806/1079], Loss: 0.0058\n",
      "Epoch [7/10], Step [807/1079], Loss: 0.0143\n",
      "Epoch [7/10], Step [808/1079], Loss: 0.0317\n",
      "Epoch [7/10], Step [809/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [810/1079], Loss: 0.0122\n",
      "Epoch [7/10], Step [811/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [812/1079], Loss: 0.0080\n",
      "Epoch [7/10], Step [813/1079], Loss: 0.0085\n",
      "Epoch [7/10], Step [814/1079], Loss: 0.0058\n",
      "Epoch [7/10], Step [815/1079], Loss: 0.0577\n",
      "Epoch [7/10], Step [816/1079], Loss: 0.0090\n",
      "Epoch [7/10], Step [817/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [818/1079], Loss: 0.0045\n",
      "Epoch [7/10], Step [819/1079], Loss: 0.0026\n",
      "Epoch [7/10], Step [820/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [821/1079], Loss: 0.0600\n",
      "Epoch [7/10], Step [822/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [823/1079], Loss: 0.0089\n",
      "Epoch [7/10], Step [824/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [825/1079], Loss: 0.0255\n",
      "Epoch [7/10], Step [826/1079], Loss: 0.0282\n",
      "Epoch [7/10], Step [827/1079], Loss: 0.0029\n",
      "Epoch [7/10], Step [828/1079], Loss: 0.0036\n",
      "Epoch [7/10], Step [829/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [830/1079], Loss: 0.0055\n",
      "Epoch [7/10], Step [831/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [832/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [833/1079], Loss: 0.1062\n",
      "Epoch [7/10], Step [834/1079], Loss: 0.0096\n",
      "Epoch [7/10], Step [835/1079], Loss: 0.0694\n",
      "Epoch [7/10], Step [836/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [837/1079], Loss: 0.0172\n",
      "Epoch [7/10], Step [838/1079], Loss: 0.0269\n",
      "Epoch [7/10], Step [839/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [840/1079], Loss: 0.0228\n",
      "Epoch [7/10], Step [841/1079], Loss: 0.0318\n",
      "Epoch [7/10], Step [842/1079], Loss: 0.0071\n",
      "Epoch [7/10], Step [843/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [844/1079], Loss: 0.0254\n",
      "Epoch [7/10], Step [845/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [846/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [847/1079], Loss: 0.0061\n",
      "Epoch [7/10], Step [848/1079], Loss: 0.0033\n",
      "Epoch [7/10], Step [849/1079], Loss: 0.0115\n",
      "Epoch [7/10], Step [850/1079], Loss: 0.0340\n",
      "Epoch [7/10], Step [851/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [852/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [853/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [854/1079], Loss: 0.0085\n",
      "Epoch [7/10], Step [855/1079], Loss: 0.0047\n",
      "Epoch [7/10], Step [856/1079], Loss: 0.0021\n",
      "Epoch [7/10], Step [857/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [858/1079], Loss: 0.0131\n",
      "Epoch [7/10], Step [859/1079], Loss: 0.0130\n",
      "Epoch [7/10], Step [860/1079], Loss: 0.0051\n",
      "Epoch [7/10], Step [861/1079], Loss: 0.0062\n",
      "Epoch [7/10], Step [862/1079], Loss: 0.0021\n",
      "Epoch [7/10], Step [863/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [864/1079], Loss: 0.0342\n",
      "Epoch [7/10], Step [865/1079], Loss: 0.0067\n",
      "Epoch [7/10], Step [866/1079], Loss: 0.0101\n",
      "Epoch [7/10], Step [867/1079], Loss: 0.0085\n",
      "Epoch [7/10], Step [868/1079], Loss: 0.0950\n",
      "Epoch [7/10], Step [869/1079], Loss: 0.0106\n",
      "Epoch [7/10], Step [870/1079], Loss: 0.0120\n",
      "Epoch [7/10], Step [871/1079], Loss: 0.0231\n",
      "Epoch [7/10], Step [872/1079], Loss: 0.0161\n",
      "Epoch [7/10], Step [873/1079], Loss: 0.0024\n",
      "Epoch [7/10], Step [874/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [875/1079], Loss: 0.0016\n",
      "Epoch [7/10], Step [876/1079], Loss: 0.0049\n",
      "Epoch [7/10], Step [877/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [878/1079], Loss: 0.0046\n",
      "Epoch [7/10], Step [879/1079], Loss: 0.0063\n",
      "Epoch [7/10], Step [880/1079], Loss: 0.0134\n",
      "Epoch [7/10], Step [881/1079], Loss: 0.0173\n",
      "Epoch [7/10], Step [882/1079], Loss: 0.0070\n",
      "Epoch [7/10], Step [883/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [884/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [885/1079], Loss: 0.0182\n",
      "Epoch [7/10], Step [886/1079], Loss: 0.0021\n",
      "Epoch [7/10], Step [887/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [888/1079], Loss: 0.0088\n",
      "Epoch [7/10], Step [889/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [890/1079], Loss: 0.0074\n",
      "Epoch [7/10], Step [891/1079], Loss: 0.0045\n",
      "Epoch [7/10], Step [892/1079], Loss: 0.0033\n",
      "Epoch [7/10], Step [893/1079], Loss: 0.0021\n",
      "Epoch [7/10], Step [894/1079], Loss: 0.0320\n",
      "Epoch [7/10], Step [895/1079], Loss: 0.0452\n",
      "Epoch [7/10], Step [896/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [897/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [898/1079], Loss: 0.0019\n",
      "Epoch [7/10], Step [899/1079], Loss: 0.0035\n",
      "Epoch [7/10], Step [900/1079], Loss: 0.0083\n",
      "Epoch [7/10], Step [901/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [902/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [903/1079], Loss: 0.0255\n",
      "Epoch [7/10], Step [904/1079], Loss: 0.0405\n",
      "Epoch [7/10], Step [905/1079], Loss: 0.0112\n",
      "Epoch [7/10], Step [906/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [907/1079], Loss: 0.0027\n",
      "Epoch [7/10], Step [908/1079], Loss: 0.0023\n",
      "Epoch [7/10], Step [909/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [910/1079], Loss: 0.0018\n",
      "Epoch [7/10], Step [911/1079], Loss: 0.0019\n",
      "Epoch [7/10], Step [912/1079], Loss: 0.0304\n",
      "Epoch [7/10], Step [913/1079], Loss: 0.0091\n",
      "Epoch [7/10], Step [914/1079], Loss: 0.0137\n",
      "Epoch [7/10], Step [915/1079], Loss: 0.0164\n",
      "Epoch [7/10], Step [916/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [917/1079], Loss: 0.0055\n",
      "Epoch [7/10], Step [918/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [919/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [920/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [921/1079], Loss: 0.0022\n",
      "Epoch [7/10], Step [922/1079], Loss: 0.0013\n",
      "Epoch [7/10], Step [923/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [924/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [925/1079], Loss: 0.0116\n",
      "Epoch [7/10], Step [926/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [927/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [928/1079], Loss: 0.0018\n",
      "Epoch [7/10], Step [929/1079], Loss: 0.0151\n",
      "Epoch [7/10], Step [930/1079], Loss: 0.0013\n",
      "Epoch [7/10], Step [931/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [932/1079], Loss: 0.0026\n",
      "Epoch [7/10], Step [933/1079], Loss: 0.0173\n",
      "Epoch [7/10], Step [934/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [935/1079], Loss: 0.0000\n",
      "Epoch [7/10], Step [936/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [937/1079], Loss: 0.0095\n",
      "Epoch [7/10], Step [938/1079], Loss: 0.0092\n",
      "Epoch [7/10], Step [939/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [940/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [941/1079], Loss: 0.0021\n",
      "Epoch [7/10], Step [942/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [943/1079], Loss: 0.0131\n",
      "Epoch [7/10], Step [944/1079], Loss: 0.0199\n",
      "Epoch [7/10], Step [945/1079], Loss: 0.0022\n",
      "Epoch [7/10], Step [946/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [947/1079], Loss: 0.0054\n",
      "Epoch [7/10], Step [948/1079], Loss: 0.0234\n",
      "Epoch [7/10], Step [949/1079], Loss: 0.0292\n",
      "Epoch [7/10], Step [950/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [951/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [952/1079], Loss: 0.0032\n",
      "Epoch [7/10], Step [953/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [954/1079], Loss: 0.0027\n",
      "Epoch [7/10], Step [955/1079], Loss: 0.0038\n",
      "Epoch [7/10], Step [956/1079], Loss: 0.0013\n",
      "Epoch [7/10], Step [957/1079], Loss: 0.0006\n",
      "Epoch [7/10], Step [958/1079], Loss: 0.0041\n",
      "Epoch [7/10], Step [959/1079], Loss: 0.0044\n",
      "Epoch [7/10], Step [960/1079], Loss: 0.0415\n",
      "Epoch [7/10], Step [961/1079], Loss: 0.0015\n",
      "Epoch [7/10], Step [962/1079], Loss: 0.0082\n",
      "Epoch [7/10], Step [963/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [964/1079], Loss: 0.0097\n",
      "Epoch [7/10], Step [965/1079], Loss: 0.0082\n",
      "Epoch [7/10], Step [966/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [967/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [968/1079], Loss: 0.0189\n",
      "Epoch [7/10], Step [969/1079], Loss: 0.0145\n",
      "Epoch [7/10], Step [970/1079], Loss: 0.0938\n",
      "Epoch [7/10], Step [971/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [972/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [973/1079], Loss: 0.0543\n",
      "Epoch [7/10], Step [974/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [975/1079], Loss: 0.0032\n",
      "Epoch [7/10], Step [976/1079], Loss: 0.0040\n",
      "Epoch [7/10], Step [977/1079], Loss: 0.0026\n",
      "Epoch [7/10], Step [978/1079], Loss: 0.0575\n",
      "Epoch [7/10], Step [979/1079], Loss: 0.0285\n",
      "Epoch [7/10], Step [980/1079], Loss: 0.0228\n",
      "Epoch [7/10], Step [981/1079], Loss: 0.0122\n",
      "Epoch [7/10], Step [982/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [983/1079], Loss: 0.0072\n",
      "Epoch [7/10], Step [984/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [985/1079], Loss: 0.0361\n",
      "Epoch [7/10], Step [986/1079], Loss: 0.0013\n",
      "Epoch [7/10], Step [987/1079], Loss: 0.0169\n",
      "Epoch [7/10], Step [988/1079], Loss: 0.0373\n",
      "Epoch [7/10], Step [989/1079], Loss: 0.0238\n",
      "Epoch [7/10], Step [990/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [991/1079], Loss: 0.0051\n",
      "Epoch [7/10], Step [992/1079], Loss: 0.0384\n",
      "Epoch [7/10], Step [993/1079], Loss: 0.0041\n",
      "Epoch [7/10], Step [994/1079], Loss: 0.1345\n",
      "Epoch [7/10], Step [995/1079], Loss: 0.0030\n",
      "Epoch [7/10], Step [996/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [997/1079], Loss: 0.0036\n",
      "Epoch [7/10], Step [998/1079], Loss: 0.0020\n",
      "Epoch [7/10], Step [999/1079], Loss: 0.0014\n",
      "Epoch [7/10], Step [1000/1079], Loss: 0.0096\n",
      "Epoch [7/10], Step [1001/1079], Loss: 0.0049\n",
      "Epoch [7/10], Step [1002/1079], Loss: 0.0012\n",
      "Epoch [7/10], Step [1003/1079], Loss: 0.0438\n",
      "Epoch [7/10], Step [1004/1079], Loss: 0.0267\n",
      "Epoch [7/10], Step [1005/1079], Loss: 0.0105\n",
      "Epoch [7/10], Step [1006/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [1007/1079], Loss: 0.0004\n",
      "Epoch [7/10], Step [1008/1079], Loss: 0.0044\n",
      "Epoch [7/10], Step [1009/1079], Loss: 0.0023\n",
      "Epoch [7/10], Step [1010/1079], Loss: 0.0278\n",
      "Epoch [7/10], Step [1011/1079], Loss: 0.0059\n",
      "Epoch [7/10], Step [1012/1079], Loss: 0.0011\n",
      "Epoch [7/10], Step [1013/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [1014/1079], Loss: 0.0040\n",
      "Epoch [7/10], Step [1015/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [1016/1079], Loss: 0.0444\n",
      "Epoch [7/10], Step [1017/1079], Loss: 0.0015\n",
      "Epoch [7/10], Step [1018/1079], Loss: 0.0049\n",
      "Epoch [7/10], Step [1019/1079], Loss: 0.0153\n",
      "Epoch [7/10], Step [1020/1079], Loss: 0.0042\n",
      "Epoch [7/10], Step [1021/1079], Loss: 0.0005\n",
      "Epoch [7/10], Step [1022/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [1023/1079], Loss: 0.0261\n",
      "Epoch [7/10], Step [1024/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [1025/1079], Loss: 0.0076\n",
      "Epoch [7/10], Step [1026/1079], Loss: 0.0001\n",
      "Epoch [7/10], Step [1027/1079], Loss: 0.1156\n",
      "Epoch [7/10], Step [1028/1079], Loss: 0.0324\n",
      "Epoch [7/10], Step [1029/1079], Loss: 0.0357\n",
      "Epoch [7/10], Step [1030/1079], Loss: 0.0188\n",
      "Epoch [7/10], Step [1031/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [1032/1079], Loss: 0.0013\n",
      "Epoch [7/10], Step [1033/1079], Loss: 0.0074\n",
      "Epoch [7/10], Step [1034/1079], Loss: 0.0016\n",
      "Epoch [7/10], Step [1035/1079], Loss: 0.0336\n",
      "Epoch [7/10], Step [1036/1079], Loss: 0.0066\n",
      "Epoch [7/10], Step [1037/1079], Loss: 0.0763\n",
      "Epoch [7/10], Step [1038/1079], Loss: 0.0326\n",
      "Epoch [7/10], Step [1039/1079], Loss: 0.0047\n",
      "Epoch [7/10], Step [1040/1079], Loss: 0.0612\n",
      "Epoch [7/10], Step [1041/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [1042/1079], Loss: 0.0111\n",
      "Epoch [7/10], Step [1043/1079], Loss: 0.0186\n",
      "Epoch [7/10], Step [1044/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [1045/1079], Loss: 0.0009\n",
      "Epoch [7/10], Step [1046/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [1047/1079], Loss: 0.0044\n",
      "Epoch [7/10], Step [1048/1079], Loss: 0.0253\n",
      "Epoch [7/10], Step [1049/1079], Loss: 0.0015\n",
      "Epoch [7/10], Step [1050/1079], Loss: 0.0068\n",
      "Epoch [7/10], Step [1051/1079], Loss: 0.0023\n",
      "Epoch [7/10], Step [1052/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [1053/1079], Loss: 0.0086\n",
      "Epoch [7/10], Step [1054/1079], Loss: 0.0040\n",
      "Epoch [7/10], Step [1055/1079], Loss: 0.0834\n",
      "Epoch [7/10], Step [1056/1079], Loss: 0.0514\n",
      "Epoch [7/10], Step [1057/1079], Loss: 0.0034\n",
      "Epoch [7/10], Step [1058/1079], Loss: 0.0066\n",
      "Epoch [7/10], Step [1059/1079], Loss: 0.0146\n",
      "Epoch [7/10], Step [1060/1079], Loss: 0.0143\n",
      "Epoch [7/10], Step [1061/1079], Loss: 0.0039\n",
      "Epoch [7/10], Step [1062/1079], Loss: 0.0080\n",
      "Epoch [7/10], Step [1063/1079], Loss: 0.0174\n",
      "Epoch [7/10], Step [1064/1079], Loss: 0.0176\n",
      "Epoch [7/10], Step [1065/1079], Loss: 0.0116\n",
      "Epoch [7/10], Step [1066/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [1067/1079], Loss: 0.0027\n",
      "Epoch [7/10], Step [1068/1079], Loss: 0.0002\n",
      "Epoch [7/10], Step [1069/1079], Loss: 0.0053\n",
      "Epoch [7/10], Step [1070/1079], Loss: 0.0010\n",
      "Epoch [7/10], Step [1071/1079], Loss: 0.0008\n",
      "Epoch [7/10], Step [1072/1079], Loss: 0.0018\n",
      "Epoch [7/10], Step [1073/1079], Loss: 0.0276\n",
      "Epoch [7/10], Step [1074/1079], Loss: 0.0003\n",
      "Epoch [7/10], Step [1075/1079], Loss: 0.0017\n",
      "Epoch [7/10], Step [1076/1079], Loss: 0.0007\n",
      "Epoch [7/10], Step [1077/1079], Loss: 0.0079\n",
      "Epoch [7/10], Step [1078/1079], Loss: 0.0131\n",
      "Epoch [7/10], Step [1079/1079], Loss: 0.2651\n",
      "Epoch [8/10], Step [1/1079], Loss: 0.0032\n",
      "Epoch [8/10], Step [2/1079], Loss: 0.0224\n",
      "Epoch [8/10], Step [3/1079], Loss: 0.0128\n",
      "Epoch [8/10], Step [4/1079], Loss: 0.0020\n",
      "Epoch [8/10], Step [5/1079], Loss: 0.0330\n",
      "Epoch [8/10], Step [6/1079], Loss: 0.0113\n",
      "Epoch [8/10], Step [7/1079], Loss: 0.0962\n",
      "Epoch [8/10], Step [8/1079], Loss: 0.0127\n",
      "Epoch [8/10], Step [9/1079], Loss: 0.0945\n",
      "Epoch [8/10], Step [10/1079], Loss: 0.0098\n",
      "Epoch [8/10], Step [11/1079], Loss: 0.0035\n",
      "Epoch [8/10], Step [12/1079], Loss: 0.0893\n",
      "Epoch [8/10], Step [13/1079], Loss: 0.0045\n",
      "Epoch [8/10], Step [14/1079], Loss: 0.0323\n",
      "Epoch [8/10], Step [15/1079], Loss: 0.0023\n",
      "Epoch [8/10], Step [16/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [17/1079], Loss: 0.0072\n",
      "Epoch [8/10], Step [18/1079], Loss: 0.0651\n",
      "Epoch [8/10], Step [19/1079], Loss: 0.0224\n",
      "Epoch [8/10], Step [20/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [21/1079], Loss: 0.0050\n",
      "Epoch [8/10], Step [22/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [23/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [24/1079], Loss: 0.0095\n",
      "Epoch [8/10], Step [25/1079], Loss: 0.0559\n",
      "Epoch [8/10], Step [26/1079], Loss: 0.0088\n",
      "Epoch [8/10], Step [27/1079], Loss: 0.0010\n",
      "Epoch [8/10], Step [28/1079], Loss: 0.0227\n",
      "Epoch [8/10], Step [29/1079], Loss: 0.0372\n",
      "Epoch [8/10], Step [30/1079], Loss: 0.0038\n",
      "Epoch [8/10], Step [31/1079], Loss: 0.0552\n",
      "Epoch [8/10], Step [32/1079], Loss: 0.0031\n",
      "Epoch [8/10], Step [33/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [34/1079], Loss: 0.0518\n",
      "Epoch [8/10], Step [35/1079], Loss: 0.0059\n",
      "Epoch [8/10], Step [36/1079], Loss: 0.0047\n",
      "Epoch [8/10], Step [37/1079], Loss: 0.0050\n",
      "Epoch [8/10], Step [38/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [39/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [40/1079], Loss: 0.0241\n",
      "Epoch [8/10], Step [41/1079], Loss: 0.0311\n",
      "Epoch [8/10], Step [42/1079], Loss: 0.0107\n",
      "Epoch [8/10], Step [43/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [44/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [45/1079], Loss: 0.0053\n",
      "Epoch [8/10], Step [46/1079], Loss: 0.0050\n",
      "Epoch [8/10], Step [47/1079], Loss: 0.0147\n",
      "Epoch [8/10], Step [48/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [49/1079], Loss: 0.0054\n",
      "Epoch [8/10], Step [50/1079], Loss: 0.0089\n",
      "Epoch [8/10], Step [51/1079], Loss: 0.0131\n",
      "Epoch [8/10], Step [52/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [53/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [54/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [55/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [56/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [57/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [58/1079], Loss: 0.0126\n",
      "Epoch [8/10], Step [59/1079], Loss: 0.0028\n",
      "Epoch [8/10], Step [60/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [61/1079], Loss: 0.0294\n",
      "Epoch [8/10], Step [62/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [63/1079], Loss: 0.0050\n",
      "Epoch [8/10], Step [64/1079], Loss: 0.0117\n",
      "Epoch [8/10], Step [65/1079], Loss: 0.0216\n",
      "Epoch [8/10], Step [66/1079], Loss: 0.0124\n",
      "Epoch [8/10], Step [67/1079], Loss: 0.0307\n",
      "Epoch [8/10], Step [68/1079], Loss: 0.0430\n",
      "Epoch [8/10], Step [69/1079], Loss: 0.0050\n",
      "Epoch [8/10], Step [70/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [71/1079], Loss: 0.0077\n",
      "Epoch [8/10], Step [72/1079], Loss: 0.1765\n",
      "Epoch [8/10], Step [73/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [74/1079], Loss: 0.0020\n",
      "Epoch [8/10], Step [75/1079], Loss: 0.0020\n",
      "Epoch [8/10], Step [76/1079], Loss: 0.0614\n",
      "Epoch [8/10], Step [77/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [78/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [79/1079], Loss: 0.0213\n",
      "Epoch [8/10], Step [80/1079], Loss: 0.0044\n",
      "Epoch [8/10], Step [81/1079], Loss: 0.0159\n",
      "Epoch [8/10], Step [82/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [83/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [84/1079], Loss: 0.0064\n",
      "Epoch [8/10], Step [85/1079], Loss: 0.0120\n",
      "Epoch [8/10], Step [86/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [87/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [88/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [89/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [90/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [91/1079], Loss: 0.0122\n",
      "Epoch [8/10], Step [92/1079], Loss: 0.0023\n",
      "Epoch [8/10], Step [93/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [94/1079], Loss: 0.0441\n",
      "Epoch [8/10], Step [95/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [96/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [97/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [98/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [99/1079], Loss: 0.0059\n",
      "Epoch [8/10], Step [100/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [101/1079], Loss: 0.0041\n",
      "Epoch [8/10], Step [102/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [103/1079], Loss: 0.0025\n",
      "Epoch [8/10], Step [104/1079], Loss: 0.0027\n",
      "Epoch [8/10], Step [105/1079], Loss: 0.0854\n",
      "Epoch [8/10], Step [106/1079], Loss: 0.0183\n",
      "Epoch [8/10], Step [107/1079], Loss: 0.0031\n",
      "Epoch [8/10], Step [108/1079], Loss: 0.0479\n",
      "Epoch [8/10], Step [109/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [110/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [111/1079], Loss: 0.0093\n",
      "Epoch [8/10], Step [112/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [113/1079], Loss: 0.0568\n",
      "Epoch [8/10], Step [114/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [115/1079], Loss: 0.0053\n",
      "Epoch [8/10], Step [116/1079], Loss: 0.0052\n",
      "Epoch [8/10], Step [117/1079], Loss: 0.0193\n",
      "Epoch [8/10], Step [118/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [119/1079], Loss: 0.0047\n",
      "Epoch [8/10], Step [120/1079], Loss: 0.0022\n",
      "Epoch [8/10], Step [121/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [122/1079], Loss: 0.0072\n",
      "Epoch [8/10], Step [123/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [124/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [125/1079], Loss: 0.0365\n",
      "Epoch [8/10], Step [126/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [127/1079], Loss: 0.0087\n",
      "Epoch [8/10], Step [128/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [129/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [130/1079], Loss: 0.0035\n",
      "Epoch [8/10], Step [131/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [132/1079], Loss: 0.0047\n",
      "Epoch [8/10], Step [133/1079], Loss: 0.0407\n",
      "Epoch [8/10], Step [134/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [135/1079], Loss: 0.0060\n",
      "Epoch [8/10], Step [136/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [137/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [138/1079], Loss: 0.0030\n",
      "Epoch [8/10], Step [139/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [140/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [141/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [142/1079], Loss: 0.0056\n",
      "Epoch [8/10], Step [143/1079], Loss: 0.0049\n",
      "Epoch [8/10], Step [144/1079], Loss: 0.0334\n",
      "Epoch [8/10], Step [145/1079], Loss: 0.0023\n",
      "Epoch [8/10], Step [146/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [147/1079], Loss: 0.0112\n",
      "Epoch [8/10], Step [148/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [149/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [150/1079], Loss: 0.0027\n",
      "Epoch [8/10], Step [151/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [152/1079], Loss: 0.0050\n",
      "Epoch [8/10], Step [153/1079], Loss: 0.0044\n",
      "Epoch [8/10], Step [154/1079], Loss: 0.0168\n",
      "Epoch [8/10], Step [155/1079], Loss: 0.0069\n",
      "Epoch [8/10], Step [156/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [157/1079], Loss: 0.0113\n",
      "Epoch [8/10], Step [158/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [159/1079], Loss: 0.0182\n",
      "Epoch [8/10], Step [160/1079], Loss: 0.0118\n",
      "Epoch [8/10], Step [161/1079], Loss: 0.0125\n",
      "Epoch [8/10], Step [162/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [163/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [164/1079], Loss: 0.0032\n",
      "Epoch [8/10], Step [165/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [166/1079], Loss: 0.0233\n",
      "Epoch [8/10], Step [167/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [168/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [169/1079], Loss: 0.0518\n",
      "Epoch [8/10], Step [170/1079], Loss: 0.0029\n",
      "Epoch [8/10], Step [171/1079], Loss: 0.0016\n",
      "Epoch [8/10], Step [172/1079], Loss: 0.0088\n",
      "Epoch [8/10], Step [173/1079], Loss: 0.0026\n",
      "Epoch [8/10], Step [174/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [175/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [176/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [177/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [178/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [179/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [180/1079], Loss: 0.0714\n",
      "Epoch [8/10], Step [181/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [182/1079], Loss: 0.0637\n",
      "Epoch [8/10], Step [183/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [184/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [185/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [186/1079], Loss: 0.0638\n",
      "Epoch [8/10], Step [187/1079], Loss: 0.0024\n",
      "Epoch [8/10], Step [188/1079], Loss: 0.0027\n",
      "Epoch [8/10], Step [189/1079], Loss: 0.0032\n",
      "Epoch [8/10], Step [190/1079], Loss: 0.0025\n",
      "Epoch [8/10], Step [191/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [192/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [193/1079], Loss: 0.0194\n",
      "Epoch [8/10], Step [194/1079], Loss: 0.0262\n",
      "Epoch [8/10], Step [195/1079], Loss: 0.0211\n",
      "Epoch [8/10], Step [196/1079], Loss: 0.0013\n",
      "Epoch [8/10], Step [197/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [198/1079], Loss: 0.0072\n",
      "Epoch [8/10], Step [199/1079], Loss: 0.0536\n",
      "Epoch [8/10], Step [200/1079], Loss: 0.0375\n",
      "Epoch [8/10], Step [201/1079], Loss: 0.0044\n",
      "Epoch [8/10], Step [202/1079], Loss: 0.0269\n",
      "Epoch [8/10], Step [203/1079], Loss: 0.0685\n",
      "Epoch [8/10], Step [204/1079], Loss: 0.0170\n",
      "Epoch [8/10], Step [205/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [206/1079], Loss: 0.0029\n",
      "Epoch [8/10], Step [207/1079], Loss: 0.0829\n",
      "Epoch [8/10], Step [208/1079], Loss: 0.0045\n",
      "Epoch [8/10], Step [209/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [210/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [211/1079], Loss: 0.0198\n",
      "Epoch [8/10], Step [212/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [213/1079], Loss: 0.0092\n",
      "Epoch [8/10], Step [214/1079], Loss: 0.0736\n",
      "Epoch [8/10], Step [215/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [216/1079], Loss: 0.0238\n",
      "Epoch [8/10], Step [217/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [218/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [219/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [220/1079], Loss: 0.0718\n",
      "Epoch [8/10], Step [221/1079], Loss: 0.0089\n",
      "Epoch [8/10], Step [222/1079], Loss: 0.0067\n",
      "Epoch [8/10], Step [223/1079], Loss: 0.0062\n",
      "Epoch [8/10], Step [224/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [225/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [226/1079], Loss: 0.0070\n",
      "Epoch [8/10], Step [227/1079], Loss: 0.0034\n",
      "Epoch [8/10], Step [228/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [229/1079], Loss: 0.0263\n",
      "Epoch [8/10], Step [230/1079], Loss: 0.0013\n",
      "Epoch [8/10], Step [231/1079], Loss: 0.0022\n",
      "Epoch [8/10], Step [232/1079], Loss: 0.0102\n",
      "Epoch [8/10], Step [233/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [234/1079], Loss: 0.0035\n",
      "Epoch [8/10], Step [235/1079], Loss: 0.0041\n",
      "Epoch [8/10], Step [236/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [237/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [238/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [239/1079], Loss: 0.0078\n",
      "Epoch [8/10], Step [240/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [241/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [242/1079], Loss: 0.0031\n",
      "Epoch [8/10], Step [243/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [244/1079], Loss: 0.0112\n",
      "Epoch [8/10], Step [245/1079], Loss: 0.0464\n",
      "Epoch [8/10], Step [246/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [247/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [248/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [249/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [250/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [251/1079], Loss: 0.0053\n",
      "Epoch [8/10], Step [252/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [253/1079], Loss: 0.0124\n",
      "Epoch [8/10], Step [254/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [255/1079], Loss: 0.0013\n",
      "Epoch [8/10], Step [256/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [257/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [258/1079], Loss: 0.0013\n",
      "Epoch [8/10], Step [259/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [260/1079], Loss: 0.0144\n",
      "Epoch [8/10], Step [261/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [262/1079], Loss: 0.0039\n",
      "Epoch [8/10], Step [263/1079], Loss: 0.0788\n",
      "Epoch [8/10], Step [264/1079], Loss: 0.0093\n",
      "Epoch [8/10], Step [265/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [266/1079], Loss: 0.0287\n",
      "Epoch [8/10], Step [267/1079], Loss: 0.0040\n",
      "Epoch [8/10], Step [268/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [269/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [270/1079], Loss: 0.0023\n",
      "Epoch [8/10], Step [271/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [272/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [273/1079], Loss: 0.0040\n",
      "Epoch [8/10], Step [274/1079], Loss: 0.0947\n",
      "Epoch [8/10], Step [275/1079], Loss: 0.0647\n",
      "Epoch [8/10], Step [276/1079], Loss: 0.0086\n",
      "Epoch [8/10], Step [277/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [278/1079], Loss: 0.0132\n",
      "Epoch [8/10], Step [279/1079], Loss: 0.0197\n",
      "Epoch [8/10], Step [280/1079], Loss: 0.0048\n",
      "Epoch [8/10], Step [281/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [282/1079], Loss: 0.0035\n",
      "Epoch [8/10], Step [283/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [284/1079], Loss: 0.0109\n",
      "Epoch [8/10], Step [285/1079], Loss: 0.0251\n",
      "Epoch [8/10], Step [286/1079], Loss: 0.0077\n",
      "Epoch [8/10], Step [287/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [288/1079], Loss: 0.0032\n",
      "Epoch [8/10], Step [289/1079], Loss: 0.0026\n",
      "Epoch [8/10], Step [290/1079], Loss: 0.0399\n",
      "Epoch [8/10], Step [291/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [292/1079], Loss: 0.0058\n",
      "Epoch [8/10], Step [293/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [294/1079], Loss: 0.0040\n",
      "Epoch [8/10], Step [295/1079], Loss: 0.0022\n",
      "Epoch [8/10], Step [296/1079], Loss: 0.0393\n",
      "Epoch [8/10], Step [297/1079], Loss: 0.0051\n",
      "Epoch [8/10], Step [298/1079], Loss: 0.0031\n",
      "Epoch [8/10], Step [299/1079], Loss: 0.0174\n",
      "Epoch [8/10], Step [300/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [301/1079], Loss: 0.0032\n",
      "Epoch [8/10], Step [302/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [303/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [304/1079], Loss: 0.0117\n",
      "Epoch [8/10], Step [305/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [306/1079], Loss: 0.0157\n",
      "Epoch [8/10], Step [307/1079], Loss: 0.0662\n",
      "Epoch [8/10], Step [308/1079], Loss: 0.0106\n",
      "Epoch [8/10], Step [309/1079], Loss: 0.0263\n",
      "Epoch [8/10], Step [310/1079], Loss: 0.0102\n",
      "Epoch [8/10], Step [311/1079], Loss: 0.0052\n",
      "Epoch [8/10], Step [312/1079], Loss: 0.0052\n",
      "Epoch [8/10], Step [313/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [314/1079], Loss: 0.0024\n",
      "Epoch [8/10], Step [315/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [316/1079], Loss: 0.0027\n",
      "Epoch [8/10], Step [317/1079], Loss: 0.0160\n",
      "Epoch [8/10], Step [318/1079], Loss: 0.0093\n",
      "Epoch [8/10], Step [319/1079], Loss: 0.0055\n",
      "Epoch [8/10], Step [320/1079], Loss: 0.0053\n",
      "Epoch [8/10], Step [321/1079], Loss: 0.0097\n",
      "Epoch [8/10], Step [322/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [323/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [324/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [325/1079], Loss: 0.0033\n",
      "Epoch [8/10], Step [326/1079], Loss: 0.0052\n",
      "Epoch [8/10], Step [327/1079], Loss: 0.0184\n",
      "Epoch [8/10], Step [328/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [329/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [330/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [331/1079], Loss: 0.0212\n",
      "Epoch [8/10], Step [332/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [333/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [334/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [335/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [336/1079], Loss: 0.0031\n",
      "Epoch [8/10], Step [337/1079], Loss: 0.0021\n",
      "Epoch [8/10], Step [338/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [339/1079], Loss: 0.0399\n",
      "Epoch [8/10], Step [340/1079], Loss: 0.0099\n",
      "Epoch [8/10], Step [341/1079], Loss: 0.0013\n",
      "Epoch [8/10], Step [342/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [343/1079], Loss: 0.0042\n",
      "Epoch [8/10], Step [344/1079], Loss: 0.0052\n",
      "Epoch [8/10], Step [345/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [346/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [347/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [348/1079], Loss: 0.0032\n",
      "Epoch [8/10], Step [349/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [350/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [351/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [352/1079], Loss: 0.0079\n",
      "Epoch [8/10], Step [353/1079], Loss: 0.0023\n",
      "Epoch [8/10], Step [354/1079], Loss: 0.0021\n",
      "Epoch [8/10], Step [355/1079], Loss: 0.0062\n",
      "Epoch [8/10], Step [356/1079], Loss: 0.0010\n",
      "Epoch [8/10], Step [357/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [358/1079], Loss: 0.0090\n",
      "Epoch [8/10], Step [359/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [360/1079], Loss: 0.0131\n",
      "Epoch [8/10], Step [361/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [362/1079], Loss: 0.0176\n",
      "Epoch [8/10], Step [363/1079], Loss: 0.0047\n",
      "Epoch [8/10], Step [364/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [365/1079], Loss: 0.0163\n",
      "Epoch [8/10], Step [366/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [367/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [368/1079], Loss: 0.0059\n",
      "Epoch [8/10], Step [369/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [370/1079], Loss: 0.0021\n",
      "Epoch [8/10], Step [371/1079], Loss: 0.0066\n",
      "Epoch [8/10], Step [372/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [373/1079], Loss: 0.0366\n",
      "Epoch [8/10], Step [374/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [375/1079], Loss: 0.0227\n",
      "Epoch [8/10], Step [376/1079], Loss: 0.0022\n",
      "Epoch [8/10], Step [377/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [378/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [379/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [380/1079], Loss: 0.0049\n",
      "Epoch [8/10], Step [381/1079], Loss: 0.0956\n",
      "Epoch [8/10], Step [382/1079], Loss: 0.0534\n",
      "Epoch [8/10], Step [383/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [384/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [385/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [386/1079], Loss: 0.0026\n",
      "Epoch [8/10], Step [387/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [388/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [389/1079], Loss: 0.0033\n",
      "Epoch [8/10], Step [390/1079], Loss: 0.0023\n",
      "Epoch [8/10], Step [391/1079], Loss: 0.0129\n",
      "Epoch [8/10], Step [392/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [393/1079], Loss: 0.0147\n",
      "Epoch [8/10], Step [394/1079], Loss: 0.0071\n",
      "Epoch [8/10], Step [395/1079], Loss: 0.0016\n",
      "Epoch [8/10], Step [396/1079], Loss: 0.0103\n",
      "Epoch [8/10], Step [397/1079], Loss: 0.0231\n",
      "Epoch [8/10], Step [398/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [399/1079], Loss: 0.0013\n",
      "Epoch [8/10], Step [400/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [401/1079], Loss: 0.0041\n",
      "Epoch [8/10], Step [402/1079], Loss: 0.0271\n",
      "Epoch [8/10], Step [403/1079], Loss: 0.0069\n",
      "Epoch [8/10], Step [404/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [405/1079], Loss: 0.0118\n",
      "Epoch [8/10], Step [406/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [407/1079], Loss: 0.0087\n",
      "Epoch [8/10], Step [408/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [409/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [410/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [411/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [412/1079], Loss: 0.0172\n",
      "Epoch [8/10], Step [413/1079], Loss: 0.0202\n",
      "Epoch [8/10], Step [414/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [415/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [416/1079], Loss: 0.0016\n",
      "Epoch [8/10], Step [417/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [418/1079], Loss: 0.0087\n",
      "Epoch [8/10], Step [419/1079], Loss: 0.0153\n",
      "Epoch [8/10], Step [420/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [421/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [422/1079], Loss: 0.0734\n",
      "Epoch [8/10], Step [423/1079], Loss: 0.0027\n",
      "Epoch [8/10], Step [424/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [425/1079], Loss: 0.0263\n",
      "Epoch [8/10], Step [426/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [427/1079], Loss: 0.0159\n",
      "Epoch [8/10], Step [428/1079], Loss: 0.0339\n",
      "Epoch [8/10], Step [429/1079], Loss: 0.1071\n",
      "Epoch [8/10], Step [430/1079], Loss: 0.0034\n",
      "Epoch [8/10], Step [431/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [432/1079], Loss: 0.0010\n",
      "Epoch [8/10], Step [433/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [434/1079], Loss: 0.0039\n",
      "Epoch [8/10], Step [435/1079], Loss: 0.0060\n",
      "Epoch [8/10], Step [436/1079], Loss: 0.0037\n",
      "Epoch [8/10], Step [437/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [438/1079], Loss: 0.0107\n",
      "Epoch [8/10], Step [439/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [440/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [441/1079], Loss: 0.0059\n",
      "Epoch [8/10], Step [442/1079], Loss: 0.0036\n",
      "Epoch [8/10], Step [443/1079], Loss: 0.0047\n",
      "Epoch [8/10], Step [444/1079], Loss: 0.0072\n",
      "Epoch [8/10], Step [445/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [446/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [447/1079], Loss: 0.0183\n",
      "Epoch [8/10], Step [448/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [449/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [450/1079], Loss: 0.0309\n",
      "Epoch [8/10], Step [451/1079], Loss: 0.0038\n",
      "Epoch [8/10], Step [452/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [453/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [454/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [455/1079], Loss: 0.0202\n",
      "Epoch [8/10], Step [456/1079], Loss: 0.0185\n",
      "Epoch [8/10], Step [457/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [458/1079], Loss: 0.0246\n",
      "Epoch [8/10], Step [459/1079], Loss: 0.0047\n",
      "Epoch [8/10], Step [460/1079], Loss: 0.0016\n",
      "Epoch [8/10], Step [461/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [462/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [463/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [464/1079], Loss: 0.0222\n",
      "Epoch [8/10], Step [465/1079], Loss: 0.0094\n",
      "Epoch [8/10], Step [466/1079], Loss: 0.0010\n",
      "Epoch [8/10], Step [467/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [468/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [469/1079], Loss: 0.0033\n",
      "Epoch [8/10], Step [470/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [471/1079], Loss: 0.0016\n",
      "Epoch [8/10], Step [472/1079], Loss: 0.0076\n",
      "Epoch [8/10], Step [473/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [474/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [475/1079], Loss: 0.0032\n",
      "Epoch [8/10], Step [476/1079], Loss: 0.0228\n",
      "Epoch [8/10], Step [477/1079], Loss: 0.0287\n",
      "Epoch [8/10], Step [478/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [479/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [480/1079], Loss: 0.0199\n",
      "Epoch [8/10], Step [481/1079], Loss: 0.0788\n",
      "Epoch [8/10], Step [482/1079], Loss: 0.0026\n",
      "Epoch [8/10], Step [483/1079], Loss: 0.0022\n",
      "Epoch [8/10], Step [484/1079], Loss: 0.0027\n",
      "Epoch [8/10], Step [485/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [486/1079], Loss: 0.0184\n",
      "Epoch [8/10], Step [487/1079], Loss: 0.0298\n",
      "Epoch [8/10], Step [488/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [489/1079], Loss: 0.0037\n",
      "Epoch [8/10], Step [490/1079], Loss: 0.0010\n",
      "Epoch [8/10], Step [491/1079], Loss: 0.0029\n",
      "Epoch [8/10], Step [492/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [493/1079], Loss: 0.0016\n",
      "Epoch [8/10], Step [494/1079], Loss: 0.0086\n",
      "Epoch [8/10], Step [495/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [496/1079], Loss: 0.0034\n",
      "Epoch [8/10], Step [497/1079], Loss: 0.0029\n",
      "Epoch [8/10], Step [498/1079], Loss: 0.0010\n",
      "Epoch [8/10], Step [499/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [500/1079], Loss: 0.0066\n",
      "Epoch [8/10], Step [501/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [502/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [503/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [504/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [505/1079], Loss: 0.0022\n",
      "Epoch [8/10], Step [506/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [507/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [508/1079], Loss: 0.0023\n",
      "Epoch [8/10], Step [509/1079], Loss: 0.0016\n",
      "Epoch [8/10], Step [510/1079], Loss: 0.0030\n",
      "Epoch [8/10], Step [511/1079], Loss: 0.0010\n",
      "Epoch [8/10], Step [512/1079], Loss: 0.0032\n",
      "Epoch [8/10], Step [513/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [514/1079], Loss: 0.0021\n",
      "Epoch [8/10], Step [515/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [516/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [517/1079], Loss: 0.0264\n",
      "Epoch [8/10], Step [518/1079], Loss: 0.0055\n",
      "Epoch [8/10], Step [519/1079], Loss: 0.0048\n",
      "Epoch [8/10], Step [520/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [521/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [522/1079], Loss: 0.0033\n",
      "Epoch [8/10], Step [523/1079], Loss: 0.0032\n",
      "Epoch [8/10], Step [524/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [525/1079], Loss: 0.0026\n",
      "Epoch [8/10], Step [526/1079], Loss: 0.0114\n",
      "Epoch [8/10], Step [527/1079], Loss: 0.0155\n",
      "Epoch [8/10], Step [528/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [529/1079], Loss: 0.0033\n",
      "Epoch [8/10], Step [530/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [531/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [532/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [533/1079], Loss: 0.0110\n",
      "Epoch [8/10], Step [534/1079], Loss: 0.0022\n",
      "Epoch [8/10], Step [535/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [536/1079], Loss: 0.0023\n",
      "Epoch [8/10], Step [537/1079], Loss: 0.0026\n",
      "Epoch [8/10], Step [538/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [539/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [540/1079], Loss: 0.0141\n",
      "Epoch [8/10], Step [541/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [542/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [543/1079], Loss: 0.0089\n",
      "Epoch [8/10], Step [544/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [545/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [546/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [547/1079], Loss: 0.0132\n",
      "Epoch [8/10], Step [548/1079], Loss: 0.0154\n",
      "Epoch [8/10], Step [549/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [550/1079], Loss: 0.0052\n",
      "Epoch [8/10], Step [551/1079], Loss: 0.0665\n",
      "Epoch [8/10], Step [552/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [553/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [554/1079], Loss: 0.0021\n",
      "Epoch [8/10], Step [555/1079], Loss: 0.0079\n",
      "Epoch [8/10], Step [556/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [557/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [558/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [559/1079], Loss: 0.0040\n",
      "Epoch [8/10], Step [560/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [561/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [562/1079], Loss: 0.0046\n",
      "Epoch [8/10], Step [563/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [564/1079], Loss: 0.0262\n",
      "Epoch [8/10], Step [565/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [566/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [567/1079], Loss: 0.0122\n",
      "Epoch [8/10], Step [568/1079], Loss: 0.0030\n",
      "Epoch [8/10], Step [569/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [570/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [571/1079], Loss: 0.0020\n",
      "Epoch [8/10], Step [572/1079], Loss: 0.0047\n",
      "Epoch [8/10], Step [573/1079], Loss: 0.0062\n",
      "Epoch [8/10], Step [574/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [575/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [576/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [577/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [578/1079], Loss: 0.0198\n",
      "Epoch [8/10], Step [579/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [580/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [581/1079], Loss: 0.0020\n",
      "Epoch [8/10], Step [582/1079], Loss: 0.0053\n",
      "Epoch [8/10], Step [583/1079], Loss: 0.0042\n",
      "Epoch [8/10], Step [584/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [585/1079], Loss: 0.0188\n",
      "Epoch [8/10], Step [586/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [587/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [588/1079], Loss: 0.0040\n",
      "Epoch [8/10], Step [589/1079], Loss: 0.0422\n",
      "Epoch [8/10], Step [590/1079], Loss: 0.0087\n",
      "Epoch [8/10], Step [591/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [592/1079], Loss: 0.0010\n",
      "Epoch [8/10], Step [593/1079], Loss: 0.0022\n",
      "Epoch [8/10], Step [594/1079], Loss: 0.0155\n",
      "Epoch [8/10], Step [595/1079], Loss: 0.0010\n",
      "Epoch [8/10], Step [596/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [597/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [598/1079], Loss: 0.0061\n",
      "Epoch [8/10], Step [599/1079], Loss: 0.0044\n",
      "Epoch [8/10], Step [600/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [601/1079], Loss: 0.0050\n",
      "Epoch [8/10], Step [602/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [603/1079], Loss: 0.0318\n",
      "Epoch [8/10], Step [604/1079], Loss: 0.0489\n",
      "Epoch [8/10], Step [605/1079], Loss: 0.0490\n",
      "Epoch [8/10], Step [606/1079], Loss: 0.0036\n",
      "Epoch [8/10], Step [607/1079], Loss: 0.0021\n",
      "Epoch [8/10], Step [608/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [609/1079], Loss: 0.0053\n",
      "Epoch [8/10], Step [610/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [611/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [612/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [613/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [614/1079], Loss: 0.1087\n",
      "Epoch [8/10], Step [615/1079], Loss: 0.0255\n",
      "Epoch [8/10], Step [616/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [617/1079], Loss: 0.0048\n",
      "Epoch [8/10], Step [618/1079], Loss: 0.0205\n",
      "Epoch [8/10], Step [619/1079], Loss: 0.0264\n",
      "Epoch [8/10], Step [620/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [621/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [622/1079], Loss: 0.0115\n",
      "Epoch [8/10], Step [623/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [624/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [625/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [626/1079], Loss: 0.0054\n",
      "Epoch [8/10], Step [627/1079], Loss: 0.0063\n",
      "Epoch [8/10], Step [628/1079], Loss: 0.0107\n",
      "Epoch [8/10], Step [629/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [630/1079], Loss: 0.0022\n",
      "Epoch [8/10], Step [631/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [632/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [633/1079], Loss: 0.0633\n",
      "Epoch [8/10], Step [634/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [635/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [636/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [637/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [638/1079], Loss: 0.0013\n",
      "Epoch [8/10], Step [639/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [640/1079], Loss: 0.0053\n",
      "Epoch [8/10], Step [641/1079], Loss: 0.0354\n",
      "Epoch [8/10], Step [642/1079], Loss: 0.0022\n",
      "Epoch [8/10], Step [643/1079], Loss: 0.0016\n",
      "Epoch [8/10], Step [644/1079], Loss: 0.0046\n",
      "Epoch [8/10], Step [645/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [646/1079], Loss: 0.0052\n",
      "Epoch [8/10], Step [647/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [648/1079], Loss: 0.0068\n",
      "Epoch [8/10], Step [649/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [650/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [651/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [652/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [653/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [654/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [655/1079], Loss: 0.0135\n",
      "Epoch [8/10], Step [656/1079], Loss: 0.0073\n",
      "Epoch [8/10], Step [657/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [658/1079], Loss: 0.0051\n",
      "Epoch [8/10], Step [659/1079], Loss: 0.0081\n",
      "Epoch [8/10], Step [660/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [661/1079], Loss: 0.0050\n",
      "Epoch [8/10], Step [662/1079], Loss: 0.0013\n",
      "Epoch [8/10], Step [663/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [664/1079], Loss: 0.0021\n",
      "Epoch [8/10], Step [665/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [666/1079], Loss: 0.0136\n",
      "Epoch [8/10], Step [667/1079], Loss: 0.0098\n",
      "Epoch [8/10], Step [668/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [669/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [670/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [671/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [672/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [673/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [674/1079], Loss: 0.0013\n",
      "Epoch [8/10], Step [675/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [676/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [677/1079], Loss: 0.0315\n",
      "Epoch [8/10], Step [678/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [679/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [680/1079], Loss: 0.0102\n",
      "Epoch [8/10], Step [681/1079], Loss: 0.0960\n",
      "Epoch [8/10], Step [682/1079], Loss: 0.0026\n",
      "Epoch [8/10], Step [683/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [684/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [685/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [686/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [687/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [688/1079], Loss: 0.0030\n",
      "Epoch [8/10], Step [689/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [690/1079], Loss: 0.0026\n",
      "Epoch [8/10], Step [691/1079], Loss: 0.0045\n",
      "Epoch [8/10], Step [692/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [693/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [694/1079], Loss: 0.0038\n",
      "Epoch [8/10], Step [695/1079], Loss: 0.0675\n",
      "Epoch [8/10], Step [696/1079], Loss: 0.0793\n",
      "Epoch [8/10], Step [697/1079], Loss: 0.0013\n",
      "Epoch [8/10], Step [698/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [699/1079], Loss: 0.0153\n",
      "Epoch [8/10], Step [700/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [701/1079], Loss: 0.0025\n",
      "Epoch [8/10], Step [702/1079], Loss: 0.0296\n",
      "Epoch [8/10], Step [703/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [704/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [705/1079], Loss: 0.0030\n",
      "Epoch [8/10], Step [706/1079], Loss: 0.0299\n",
      "Epoch [8/10], Step [707/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [708/1079], Loss: 0.0063\n",
      "Epoch [8/10], Step [709/1079], Loss: 0.0022\n",
      "Epoch [8/10], Step [710/1079], Loss: 0.0093\n",
      "Epoch [8/10], Step [711/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [712/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [713/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [714/1079], Loss: 0.0124\n",
      "Epoch [8/10], Step [715/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [716/1079], Loss: 0.0105\n",
      "Epoch [8/10], Step [717/1079], Loss: 0.0056\n",
      "Epoch [8/10], Step [718/1079], Loss: 0.0063\n",
      "Epoch [8/10], Step [719/1079], Loss: 0.0067\n",
      "Epoch [8/10], Step [720/1079], Loss: 0.0021\n",
      "Epoch [8/10], Step [721/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [722/1079], Loss: 0.0046\n",
      "Epoch [8/10], Step [723/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [724/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [725/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [726/1079], Loss: 0.0198\n",
      "Epoch [8/10], Step [727/1079], Loss: 0.0052\n",
      "Epoch [8/10], Step [728/1079], Loss: 0.0091\n",
      "Epoch [8/10], Step [729/1079], Loss: 0.0295\n",
      "Epoch [8/10], Step [730/1079], Loss: 0.0086\n",
      "Epoch [8/10], Step [731/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [732/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [733/1079], Loss: 0.0167\n",
      "Epoch [8/10], Step [734/1079], Loss: 0.0120\n",
      "Epoch [8/10], Step [735/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [736/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [737/1079], Loss: 0.0050\n",
      "Epoch [8/10], Step [738/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [739/1079], Loss: 0.0020\n",
      "Epoch [8/10], Step [740/1079], Loss: 0.0033\n",
      "Epoch [8/10], Step [741/1079], Loss: 0.0037\n",
      "Epoch [8/10], Step [742/1079], Loss: 0.0024\n",
      "Epoch [8/10], Step [743/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [744/1079], Loss: 0.0620\n",
      "Epoch [8/10], Step [745/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [746/1079], Loss: 0.0559\n",
      "Epoch [8/10], Step [747/1079], Loss: 0.0023\n",
      "Epoch [8/10], Step [748/1079], Loss: 0.0016\n",
      "Epoch [8/10], Step [749/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [750/1079], Loss: 0.0134\n",
      "Epoch [8/10], Step [751/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [752/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [753/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [754/1079], Loss: 0.0034\n",
      "Epoch [8/10], Step [755/1079], Loss: 0.0010\n",
      "Epoch [8/10], Step [756/1079], Loss: 0.0744\n",
      "Epoch [8/10], Step [757/1079], Loss: 0.0090\n",
      "Epoch [8/10], Step [758/1079], Loss: 0.0039\n",
      "Epoch [8/10], Step [759/1079], Loss: 0.0010\n",
      "Epoch [8/10], Step [760/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [761/1079], Loss: 0.0074\n",
      "Epoch [8/10], Step [762/1079], Loss: 0.0035\n",
      "Epoch [8/10], Step [763/1079], Loss: 0.0079\n",
      "Epoch [8/10], Step [764/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [765/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [766/1079], Loss: 0.0037\n",
      "Epoch [8/10], Step [767/1079], Loss: 0.0055\n",
      "Epoch [8/10], Step [768/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [769/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [770/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [771/1079], Loss: 0.0142\n",
      "Epoch [8/10], Step [772/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [773/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [774/1079], Loss: 0.0054\n",
      "Epoch [8/10], Step [775/1079], Loss: 0.0125\n",
      "Epoch [8/10], Step [776/1079], Loss: 0.0350\n",
      "Epoch [8/10], Step [777/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [778/1079], Loss: 0.0020\n",
      "Epoch [8/10], Step [779/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [780/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [781/1079], Loss: 0.0131\n",
      "Epoch [8/10], Step [782/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [783/1079], Loss: 0.0021\n",
      "Epoch [8/10], Step [784/1079], Loss: 0.0110\n",
      "Epoch [8/10], Step [785/1079], Loss: 0.0037\n",
      "Epoch [8/10], Step [786/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [787/1079], Loss: 0.0021\n",
      "Epoch [8/10], Step [788/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [789/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [790/1079], Loss: 0.0282\n",
      "Epoch [8/10], Step [791/1079], Loss: 0.0021\n",
      "Epoch [8/10], Step [792/1079], Loss: 0.0527\n",
      "Epoch [8/10], Step [793/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [794/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [795/1079], Loss: 0.0124\n",
      "Epoch [8/10], Step [796/1079], Loss: 0.0027\n",
      "Epoch [8/10], Step [797/1079], Loss: 0.0068\n",
      "Epoch [8/10], Step [798/1079], Loss: 0.0041\n",
      "Epoch [8/10], Step [799/1079], Loss: 0.0164\n",
      "Epoch [8/10], Step [800/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [801/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [802/1079], Loss: 0.0062\n",
      "Epoch [8/10], Step [803/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [804/1079], Loss: 0.0102\n",
      "Epoch [8/10], Step [805/1079], Loss: 0.0438\n",
      "Epoch [8/10], Step [806/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [807/1079], Loss: 0.0023\n",
      "Epoch [8/10], Step [808/1079], Loss: 0.0040\n",
      "Epoch [8/10], Step [809/1079], Loss: 0.0025\n",
      "Epoch [8/10], Step [810/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [811/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [812/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [813/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [814/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [815/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [816/1079], Loss: 0.0126\n",
      "Epoch [8/10], Step [817/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [818/1079], Loss: 0.0025\n",
      "Epoch [8/10], Step [819/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [820/1079], Loss: 0.0077\n",
      "Epoch [8/10], Step [821/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [822/1079], Loss: 0.0168\n",
      "Epoch [8/10], Step [823/1079], Loss: 0.0156\n",
      "Epoch [8/10], Step [824/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [825/1079], Loss: 0.0030\n",
      "Epoch [8/10], Step [826/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [827/1079], Loss: 0.0091\n",
      "Epoch [8/10], Step [828/1079], Loss: 0.0313\n",
      "Epoch [8/10], Step [829/1079], Loss: 0.0022\n",
      "Epoch [8/10], Step [830/1079], Loss: 0.0013\n",
      "Epoch [8/10], Step [831/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [832/1079], Loss: 0.0191\n",
      "Epoch [8/10], Step [833/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [834/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [835/1079], Loss: 0.0016\n",
      "Epoch [8/10], Step [836/1079], Loss: 0.0182\n",
      "Epoch [8/10], Step [837/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [838/1079], Loss: 0.0056\n",
      "Epoch [8/10], Step [839/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [840/1079], Loss: 0.0383\n",
      "Epoch [8/10], Step [841/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [842/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [843/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [844/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [845/1079], Loss: 0.0198\n",
      "Epoch [8/10], Step [846/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [847/1079], Loss: 0.0156\n",
      "Epoch [8/10], Step [848/1079], Loss: 0.0211\n",
      "Epoch [8/10], Step [849/1079], Loss: 0.0149\n",
      "Epoch [8/10], Step [850/1079], Loss: 0.0085\n",
      "Epoch [8/10], Step [851/1079], Loss: 0.0120\n",
      "Epoch [8/10], Step [852/1079], Loss: 0.0023\n",
      "Epoch [8/10], Step [853/1079], Loss: 0.0075\n",
      "Epoch [8/10], Step [854/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [855/1079], Loss: 0.0038\n",
      "Epoch [8/10], Step [856/1079], Loss: 0.0650\n",
      "Epoch [8/10], Step [857/1079], Loss: 0.0021\n",
      "Epoch [8/10], Step [858/1079], Loss: 0.0039\n",
      "Epoch [8/10], Step [859/1079], Loss: 0.0115\n",
      "Epoch [8/10], Step [860/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [861/1079], Loss: 0.0031\n",
      "Epoch [8/10], Step [862/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [863/1079], Loss: 0.0044\n",
      "Epoch [8/10], Step [864/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [865/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [866/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [867/1079], Loss: 0.0046\n",
      "Epoch [8/10], Step [868/1079], Loss: 0.0338\n",
      "Epoch [8/10], Step [869/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [870/1079], Loss: 0.0053\n",
      "Epoch [8/10], Step [871/1079], Loss: 0.0039\n",
      "Epoch [8/10], Step [872/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [873/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [874/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [875/1079], Loss: 0.0116\n",
      "Epoch [8/10], Step [876/1079], Loss: 0.0260\n",
      "Epoch [8/10], Step [877/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [878/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [879/1079], Loss: 0.0067\n",
      "Epoch [8/10], Step [880/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [881/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [882/1079], Loss: 0.0167\n",
      "Epoch [8/10], Step [883/1079], Loss: 0.0047\n",
      "Epoch [8/10], Step [884/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [885/1079], Loss: 0.0485\n",
      "Epoch [8/10], Step [886/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [887/1079], Loss: 0.0196\n",
      "Epoch [8/10], Step [888/1079], Loss: 0.0065\n",
      "Epoch [8/10], Step [889/1079], Loss: 0.0047\n",
      "Epoch [8/10], Step [890/1079], Loss: 0.0173\n",
      "Epoch [8/10], Step [891/1079], Loss: 0.0033\n",
      "Epoch [8/10], Step [892/1079], Loss: 0.0074\n",
      "Epoch [8/10], Step [893/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [894/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [895/1079], Loss: 0.0058\n",
      "Epoch [8/10], Step [896/1079], Loss: 0.0422\n",
      "Epoch [8/10], Step [897/1079], Loss: 0.0031\n",
      "Epoch [8/10], Step [898/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [899/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [900/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [901/1079], Loss: 0.0339\n",
      "Epoch [8/10], Step [902/1079], Loss: 0.0120\n",
      "Epoch [8/10], Step [903/1079], Loss: 0.0010\n",
      "Epoch [8/10], Step [904/1079], Loss: 0.0078\n",
      "Epoch [8/10], Step [905/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [906/1079], Loss: 0.0495\n",
      "Epoch [8/10], Step [907/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [908/1079], Loss: 0.1437\n",
      "Epoch [8/10], Step [909/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [910/1079], Loss: 0.0388\n",
      "Epoch [8/10], Step [911/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [912/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [913/1079], Loss: 0.0236\n",
      "Epoch [8/10], Step [914/1079], Loss: 0.0724\n",
      "Epoch [8/10], Step [915/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [916/1079], Loss: 0.0103\n",
      "Epoch [8/10], Step [917/1079], Loss: 0.0012\n",
      "Epoch [8/10], Step [918/1079], Loss: 0.0025\n",
      "Epoch [8/10], Step [919/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [920/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [921/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [922/1079], Loss: 0.0282\n",
      "Epoch [8/10], Step [923/1079], Loss: 0.0122\n",
      "Epoch [8/10], Step [924/1079], Loss: 0.0038\n",
      "Epoch [8/10], Step [925/1079], Loss: 0.0031\n",
      "Epoch [8/10], Step [926/1079], Loss: 0.0036\n",
      "Epoch [8/10], Step [927/1079], Loss: 0.0043\n",
      "Epoch [8/10], Step [928/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [929/1079], Loss: 0.0025\n",
      "Epoch [8/10], Step [930/1079], Loss: 0.0033\n",
      "Epoch [8/10], Step [931/1079], Loss: 0.0037\n",
      "Epoch [8/10], Step [932/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [933/1079], Loss: 0.0349\n",
      "Epoch [8/10], Step [934/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [935/1079], Loss: 0.0017\n",
      "Epoch [8/10], Step [936/1079], Loss: 0.0055\n",
      "Epoch [8/10], Step [937/1079], Loss: 0.0029\n",
      "Epoch [8/10], Step [938/1079], Loss: 0.0110\n",
      "Epoch [8/10], Step [939/1079], Loss: 0.0034\n",
      "Epoch [8/10], Step [940/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [941/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [942/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [943/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [944/1079], Loss: 0.0080\n",
      "Epoch [8/10], Step [945/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [946/1079], Loss: 0.0226\n",
      "Epoch [8/10], Step [947/1079], Loss: 0.0026\n",
      "Epoch [8/10], Step [948/1079], Loss: 0.0036\n",
      "Epoch [8/10], Step [949/1079], Loss: 0.0034\n",
      "Epoch [8/10], Step [950/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [951/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [952/1079], Loss: 0.0180\n",
      "Epoch [8/10], Step [953/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [954/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [955/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [956/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [957/1079], Loss: 0.0067\n",
      "Epoch [8/10], Step [958/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [959/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [960/1079], Loss: 0.0024\n",
      "Epoch [8/10], Step [961/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [962/1079], Loss: 0.0038\n",
      "Epoch [8/10], Step [963/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [964/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [965/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [966/1079], Loss: 0.0063\n",
      "Epoch [8/10], Step [967/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [968/1079], Loss: 0.0044\n",
      "Epoch [8/10], Step [969/1079], Loss: 0.0151\n",
      "Epoch [8/10], Step [970/1079], Loss: 0.0104\n",
      "Epoch [8/10], Step [971/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [972/1079], Loss: 0.0223\n",
      "Epoch [8/10], Step [973/1079], Loss: 0.0032\n",
      "Epoch [8/10], Step [974/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [975/1079], Loss: 0.0096\n",
      "Epoch [8/10], Step [976/1079], Loss: 0.0167\n",
      "Epoch [8/10], Step [977/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [978/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [979/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [980/1079], Loss: 0.0068\n",
      "Epoch [8/10], Step [981/1079], Loss: 0.0030\n",
      "Epoch [8/10], Step [982/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [983/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [984/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [985/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [986/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [987/1079], Loss: 0.0024\n",
      "Epoch [8/10], Step [988/1079], Loss: 0.0054\n",
      "Epoch [8/10], Step [989/1079], Loss: 0.0023\n",
      "Epoch [8/10], Step [990/1079], Loss: 0.0072\n",
      "Epoch [8/10], Step [991/1079], Loss: 0.0621\n",
      "Epoch [8/10], Step [992/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [993/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [994/1079], Loss: 0.0219\n",
      "Epoch [8/10], Step [995/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [996/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [997/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [998/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [999/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [1000/1079], Loss: 0.0020\n",
      "Epoch [8/10], Step [1001/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [1002/1079], Loss: 0.0003\n",
      "Epoch [8/10], Step [1003/1079], Loss: 0.0147\n",
      "Epoch [8/10], Step [1004/1079], Loss: 0.0030\n",
      "Epoch [8/10], Step [1005/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [1006/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [1007/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [1008/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [1009/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [1010/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [1011/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [1012/1079], Loss: 0.0014\n",
      "Epoch [8/10], Step [1013/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [1014/1079], Loss: 0.0952\n",
      "Epoch [8/10], Step [1015/1079], Loss: 0.0019\n",
      "Epoch [8/10], Step [1016/1079], Loss: 0.0055\n",
      "Epoch [8/10], Step [1017/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [1018/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [1019/1079], Loss: 0.0064\n",
      "Epoch [8/10], Step [1020/1079], Loss: 0.0011\n",
      "Epoch [8/10], Step [1021/1079], Loss: 0.0034\n",
      "Epoch [8/10], Step [1022/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [1023/1079], Loss: 0.0034\n",
      "Epoch [8/10], Step [1024/1079], Loss: 0.0034\n",
      "Epoch [8/10], Step [1025/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [1026/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [1027/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [1028/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [1029/1079], Loss: 0.0020\n",
      "Epoch [8/10], Step [1030/1079], Loss: 0.0025\n",
      "Epoch [8/10], Step [1031/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [1032/1079], Loss: 0.0059\n",
      "Epoch [8/10], Step [1033/1079], Loss: 0.0034\n",
      "Epoch [8/10], Step [1034/1079], Loss: 0.0220\n",
      "Epoch [8/10], Step [1035/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [1036/1079], Loss: 0.0062\n",
      "Epoch [8/10], Step [1037/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [1038/1079], Loss: 0.0186\n",
      "Epoch [8/10], Step [1039/1079], Loss: 0.0298\n",
      "Epoch [8/10], Step [1040/1079], Loss: 0.0060\n",
      "Epoch [8/10], Step [1041/1079], Loss: 0.0528\n",
      "Epoch [8/10], Step [1042/1079], Loss: 0.0229\n",
      "Epoch [8/10], Step [1043/1079], Loss: 0.0024\n",
      "Epoch [8/10], Step [1044/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [1045/1079], Loss: 0.0005\n",
      "Epoch [8/10], Step [1046/1079], Loss: 0.0039\n",
      "Epoch [8/10], Step [1047/1079], Loss: 0.0020\n",
      "Epoch [8/10], Step [1048/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [1049/1079], Loss: 0.0001\n",
      "Epoch [8/10], Step [1050/1079], Loss: 0.0007\n",
      "Epoch [8/10], Step [1051/1079], Loss: 0.0075\n",
      "Epoch [8/10], Step [1052/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [1053/1079], Loss: 0.0075\n",
      "Epoch [8/10], Step [1054/1079], Loss: 0.0303\n",
      "Epoch [8/10], Step [1055/1079], Loss: 0.0240\n",
      "Epoch [8/10], Step [1056/1079], Loss: 0.0169\n",
      "Epoch [8/10], Step [1057/1079], Loss: 0.0048\n",
      "Epoch [8/10], Step [1058/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [1059/1079], Loss: 0.0205\n",
      "Epoch [8/10], Step [1060/1079], Loss: 0.0009\n",
      "Epoch [8/10], Step [1061/1079], Loss: 0.0004\n",
      "Epoch [8/10], Step [1062/1079], Loss: 0.0140\n",
      "Epoch [8/10], Step [1063/1079], Loss: 0.0008\n",
      "Epoch [8/10], Step [1064/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [1065/1079], Loss: 0.0018\n",
      "Epoch [8/10], Step [1066/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [1067/1079], Loss: 0.0027\n",
      "Epoch [8/10], Step [1068/1079], Loss: 0.0642\n",
      "Epoch [8/10], Step [1069/1079], Loss: 0.0055\n",
      "Epoch [8/10], Step [1070/1079], Loss: 0.0000\n",
      "Epoch [8/10], Step [1071/1079], Loss: 0.0006\n",
      "Epoch [8/10], Step [1072/1079], Loss: 0.0002\n",
      "Epoch [8/10], Step [1073/1079], Loss: 0.0015\n",
      "Epoch [8/10], Step [1074/1079], Loss: 0.0032\n",
      "Epoch [8/10], Step [1075/1079], Loss: 0.1059\n",
      "Epoch [8/10], Step [1076/1079], Loss: 0.1677\n",
      "Epoch [8/10], Step [1077/1079], Loss: 0.0720\n",
      "Epoch [8/10], Step [1078/1079], Loss: 0.0229\n",
      "Epoch [8/10], Step [1079/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [1/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [2/1079], Loss: 0.0171\n",
      "Epoch [9/10], Step [3/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [4/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [5/1079], Loss: 0.0094\n",
      "Epoch [9/10], Step [6/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [7/1079], Loss: 0.0018\n",
      "Epoch [9/10], Step [8/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [9/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [10/1079], Loss: 0.0126\n",
      "Epoch [9/10], Step [11/1079], Loss: 0.0215\n",
      "Epoch [9/10], Step [12/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [13/1079], Loss: 0.2014\n",
      "Epoch [9/10], Step [14/1079], Loss: 0.0034\n",
      "Epoch [9/10], Step [15/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [16/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [17/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [18/1079], Loss: 0.0540\n",
      "Epoch [9/10], Step [19/1079], Loss: 0.0059\n",
      "Epoch [9/10], Step [20/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [21/1079], Loss: 0.0042\n",
      "Epoch [9/10], Step [22/1079], Loss: 0.0012\n",
      "Epoch [9/10], Step [23/1079], Loss: 0.0034\n",
      "Epoch [9/10], Step [24/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [25/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [26/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [27/1079], Loss: 0.0082\n",
      "Epoch [9/10], Step [28/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [29/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [30/1079], Loss: 0.0065\n",
      "Epoch [9/10], Step [31/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [32/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [33/1079], Loss: 0.0309\n",
      "Epoch [9/10], Step [34/1079], Loss: 0.0051\n",
      "Epoch [9/10], Step [35/1079], Loss: 0.0075\n",
      "Epoch [9/10], Step [36/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [37/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [38/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [39/1079], Loss: 0.0368\n",
      "Epoch [9/10], Step [40/1079], Loss: 0.0159\n",
      "Epoch [9/10], Step [41/1079], Loss: 0.0017\n",
      "Epoch [9/10], Step [42/1079], Loss: 0.0311\n",
      "Epoch [9/10], Step [43/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [44/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [45/1079], Loss: 0.0043\n",
      "Epoch [9/10], Step [46/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [47/1079], Loss: 0.0062\n",
      "Epoch [9/10], Step [48/1079], Loss: 0.0143\n",
      "Epoch [9/10], Step [49/1079], Loss: 0.0456\n",
      "Epoch [9/10], Step [50/1079], Loss: 0.0164\n",
      "Epoch [9/10], Step [51/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [52/1079], Loss: 0.0058\n",
      "Epoch [9/10], Step [53/1079], Loss: 0.0072\n",
      "Epoch [9/10], Step [54/1079], Loss: 0.0027\n",
      "Epoch [9/10], Step [55/1079], Loss: 0.0031\n",
      "Epoch [9/10], Step [56/1079], Loss: 0.0094\n",
      "Epoch [9/10], Step [57/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [58/1079], Loss: 0.0109\n",
      "Epoch [9/10], Step [59/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [60/1079], Loss: 0.0052\n",
      "Epoch [9/10], Step [61/1079], Loss: 0.0776\n",
      "Epoch [9/10], Step [62/1079], Loss: 0.0015\n",
      "Epoch [9/10], Step [63/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [64/1079], Loss: 0.0024\n",
      "Epoch [9/10], Step [65/1079], Loss: 0.0028\n",
      "Epoch [9/10], Step [66/1079], Loss: 0.0084\n",
      "Epoch [9/10], Step [67/1079], Loss: 0.0148\n",
      "Epoch [9/10], Step [68/1079], Loss: 0.0035\n",
      "Epoch [9/10], Step [69/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [70/1079], Loss: 0.0015\n",
      "Epoch [9/10], Step [71/1079], Loss: 0.0098\n",
      "Epoch [9/10], Step [72/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [73/1079], Loss: 0.0233\n",
      "Epoch [9/10], Step [74/1079], Loss: 0.0183\n",
      "Epoch [9/10], Step [75/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [76/1079], Loss: 0.0029\n",
      "Epoch [9/10], Step [77/1079], Loss: 0.0103\n",
      "Epoch [9/10], Step [78/1079], Loss: 0.0030\n",
      "Epoch [9/10], Step [79/1079], Loss: 0.0019\n",
      "Epoch [9/10], Step [80/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [81/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [82/1079], Loss: 0.0041\n",
      "Epoch [9/10], Step [83/1079], Loss: 0.0086\n",
      "Epoch [9/10], Step [84/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [85/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [86/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [87/1079], Loss: 0.0023\n",
      "Epoch [9/10], Step [88/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [89/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [90/1079], Loss: 0.0024\n",
      "Epoch [9/10], Step [91/1079], Loss: 0.0013\n",
      "Epoch [9/10], Step [92/1079], Loss: 0.0015\n",
      "Epoch [9/10], Step [93/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [94/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [95/1079], Loss: 0.0012\n",
      "Epoch [9/10], Step [96/1079], Loss: 0.0078\n",
      "Epoch [9/10], Step [97/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [98/1079], Loss: 0.0052\n",
      "Epoch [9/10], Step [99/1079], Loss: 0.0015\n",
      "Epoch [9/10], Step [100/1079], Loss: 0.0133\n",
      "Epoch [9/10], Step [101/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [102/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [103/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [104/1079], Loss: 0.0021\n",
      "Epoch [9/10], Step [105/1079], Loss: 0.0155\n",
      "Epoch [9/10], Step [106/1079], Loss: 0.0454\n",
      "Epoch [9/10], Step [107/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [108/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [109/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [110/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [111/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [112/1079], Loss: 0.0103\n",
      "Epoch [9/10], Step [113/1079], Loss: 0.0042\n",
      "Epoch [9/10], Step [114/1079], Loss: 0.0106\n",
      "Epoch [9/10], Step [115/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [116/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [117/1079], Loss: 0.0070\n",
      "Epoch [9/10], Step [118/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [119/1079], Loss: 0.0020\n",
      "Epoch [9/10], Step [120/1079], Loss: 0.0097\n",
      "Epoch [9/10], Step [121/1079], Loss: 0.0296\n",
      "Epoch [9/10], Step [122/1079], Loss: 0.0252\n",
      "Epoch [9/10], Step [123/1079], Loss: 0.0340\n",
      "Epoch [9/10], Step [124/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [125/1079], Loss: 0.0022\n",
      "Epoch [9/10], Step [126/1079], Loss: 0.0217\n",
      "Epoch [9/10], Step [127/1079], Loss: 0.0326\n",
      "Epoch [9/10], Step [128/1079], Loss: 0.0020\n",
      "Epoch [9/10], Step [129/1079], Loss: 0.0024\n",
      "Epoch [9/10], Step [130/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [131/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [132/1079], Loss: 0.0081\n",
      "Epoch [9/10], Step [133/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [134/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [135/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [136/1079], Loss: 0.0039\n",
      "Epoch [9/10], Step [137/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [138/1079], Loss: 0.0026\n",
      "Epoch [9/10], Step [139/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [140/1079], Loss: 0.0094\n",
      "Epoch [9/10], Step [141/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [142/1079], Loss: 0.0163\n",
      "Epoch [9/10], Step [143/1079], Loss: 0.0273\n",
      "Epoch [9/10], Step [144/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [145/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [146/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [147/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [148/1079], Loss: 0.0033\n",
      "Epoch [9/10], Step [149/1079], Loss: 0.0013\n",
      "Epoch [9/10], Step [150/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [151/1079], Loss: 0.0290\n",
      "Epoch [9/10], Step [152/1079], Loss: 0.0031\n",
      "Epoch [9/10], Step [153/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [154/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [155/1079], Loss: 0.0023\n",
      "Epoch [9/10], Step [156/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [157/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [158/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [159/1079], Loss: 0.0083\n",
      "Epoch [9/10], Step [160/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [161/1079], Loss: 0.0138\n",
      "Epoch [9/10], Step [162/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [163/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [164/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [165/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [166/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [167/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [168/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [169/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [170/1079], Loss: 0.0034\n",
      "Epoch [9/10], Step [171/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [172/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [173/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [174/1079], Loss: 0.0127\n",
      "Epoch [9/10], Step [175/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [176/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [177/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [178/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [179/1079], Loss: 0.0143\n",
      "Epoch [9/10], Step [180/1079], Loss: 0.0065\n",
      "Epoch [9/10], Step [181/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [182/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [183/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [184/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [185/1079], Loss: 0.0170\n",
      "Epoch [9/10], Step [186/1079], Loss: 0.0039\n",
      "Epoch [9/10], Step [187/1079], Loss: 0.0060\n",
      "Epoch [9/10], Step [188/1079], Loss: 0.0022\n",
      "Epoch [9/10], Step [189/1079], Loss: 0.0175\n",
      "Epoch [9/10], Step [190/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [191/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [192/1079], Loss: 0.0104\n",
      "Epoch [9/10], Step [193/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [194/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [195/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [196/1079], Loss: 0.0032\n",
      "Epoch [9/10], Step [197/1079], Loss: 0.0024\n",
      "Epoch [9/10], Step [198/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [199/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [200/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [201/1079], Loss: 0.0052\n",
      "Epoch [9/10], Step [202/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [203/1079], Loss: 0.1225\n",
      "Epoch [9/10], Step [204/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [205/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [206/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [207/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [208/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [209/1079], Loss: 0.0593\n",
      "Epoch [9/10], Step [210/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [211/1079], Loss: 0.0070\n",
      "Epoch [9/10], Step [212/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [213/1079], Loss: 0.0021\n",
      "Epoch [9/10], Step [214/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [215/1079], Loss: 0.0179\n",
      "Epoch [9/10], Step [216/1079], Loss: 0.0091\n",
      "Epoch [9/10], Step [217/1079], Loss: 0.0019\n",
      "Epoch [9/10], Step [218/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [219/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [220/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [221/1079], Loss: 0.0057\n",
      "Epoch [9/10], Step [222/1079], Loss: 0.0199\n",
      "Epoch [9/10], Step [223/1079], Loss: 0.0091\n",
      "Epoch [9/10], Step [224/1079], Loss: 0.0069\n",
      "Epoch [9/10], Step [225/1079], Loss: 0.0150\n",
      "Epoch [9/10], Step [226/1079], Loss: 0.0012\n",
      "Epoch [9/10], Step [227/1079], Loss: 0.0276\n",
      "Epoch [9/10], Step [228/1079], Loss: 0.0042\n",
      "Epoch [9/10], Step [229/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [230/1079], Loss: 0.0053\n",
      "Epoch [9/10], Step [231/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [232/1079], Loss: 0.0088\n",
      "Epoch [9/10], Step [233/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [234/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [235/1079], Loss: 0.0064\n",
      "Epoch [9/10], Step [236/1079], Loss: 0.0061\n",
      "Epoch [9/10], Step [237/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [238/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [239/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [240/1079], Loss: 0.0096\n",
      "Epoch [9/10], Step [241/1079], Loss: 0.0067\n",
      "Epoch [9/10], Step [242/1079], Loss: 0.0193\n",
      "Epoch [9/10], Step [243/1079], Loss: 0.0058\n",
      "Epoch [9/10], Step [244/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [245/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [246/1079], Loss: 0.0015\n",
      "Epoch [9/10], Step [247/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [248/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [249/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [250/1079], Loss: 0.0106\n",
      "Epoch [9/10], Step [251/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [252/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [253/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [254/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [255/1079], Loss: 0.0015\n",
      "Epoch [9/10], Step [256/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [257/1079], Loss: 0.0149\n",
      "Epoch [9/10], Step [258/1079], Loss: 0.0374\n",
      "Epoch [9/10], Step [259/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [260/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [261/1079], Loss: 0.0013\n",
      "Epoch [9/10], Step [262/1079], Loss: 0.0125\n",
      "Epoch [9/10], Step [263/1079], Loss: 0.0031\n",
      "Epoch [9/10], Step [264/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [265/1079], Loss: 0.0264\n",
      "Epoch [9/10], Step [266/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [267/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [268/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [269/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [270/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [271/1079], Loss: 0.0037\n",
      "Epoch [9/10], Step [272/1079], Loss: 0.0024\n",
      "Epoch [9/10], Step [273/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [274/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [275/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [276/1079], Loss: 0.0561\n",
      "Epoch [9/10], Step [277/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [278/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [279/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [280/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [281/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [282/1079], Loss: 0.0032\n",
      "Epoch [9/10], Step [283/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [284/1079], Loss: 0.0067\n",
      "Epoch [9/10], Step [285/1079], Loss: 0.0069\n",
      "Epoch [9/10], Step [286/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [287/1079], Loss: 0.0024\n",
      "Epoch [9/10], Step [288/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [289/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [290/1079], Loss: 0.0023\n",
      "Epoch [9/10], Step [291/1079], Loss: 0.0063\n",
      "Epoch [9/10], Step [292/1079], Loss: 0.0019\n",
      "Epoch [9/10], Step [293/1079], Loss: 0.0040\n",
      "Epoch [9/10], Step [294/1079], Loss: 0.0360\n",
      "Epoch [9/10], Step [295/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [296/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [297/1079], Loss: 0.0033\n",
      "Epoch [9/10], Step [298/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [299/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [300/1079], Loss: 0.0017\n",
      "Epoch [9/10], Step [301/1079], Loss: 0.0025\n",
      "Epoch [9/10], Step [302/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [303/1079], Loss: 0.1364\n",
      "Epoch [9/10], Step [304/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [305/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [306/1079], Loss: 0.0061\n",
      "Epoch [9/10], Step [307/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [308/1079], Loss: 0.0290\n",
      "Epoch [9/10], Step [309/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [310/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [311/1079], Loss: 0.0033\n",
      "Epoch [9/10], Step [312/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [313/1079], Loss: 0.0023\n",
      "Epoch [9/10], Step [314/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [315/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [316/1079], Loss: 0.0456\n",
      "Epoch [9/10], Step [317/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [318/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [319/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [320/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [321/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [322/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [323/1079], Loss: 0.0303\n",
      "Epoch [9/10], Step [324/1079], Loss: 0.0403\n",
      "Epoch [9/10], Step [325/1079], Loss: 0.0024\n",
      "Epoch [9/10], Step [326/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [327/1079], Loss: 0.0024\n",
      "Epoch [9/10], Step [328/1079], Loss: 0.0016\n",
      "Epoch [9/10], Step [329/1079], Loss: 0.0058\n",
      "Epoch [9/10], Step [330/1079], Loss: 0.0048\n",
      "Epoch [9/10], Step [331/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [332/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [333/1079], Loss: 0.0038\n",
      "Epoch [9/10], Step [334/1079], Loss: 0.0049\n",
      "Epoch [9/10], Step [335/1079], Loss: 0.0053\n",
      "Epoch [9/10], Step [336/1079], Loss: 0.0085\n",
      "Epoch [9/10], Step [337/1079], Loss: 0.0013\n",
      "Epoch [9/10], Step [338/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [339/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [340/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [341/1079], Loss: 0.0410\n",
      "Epoch [9/10], Step [342/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [343/1079], Loss: 0.0085\n",
      "Epoch [9/10], Step [344/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [345/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [346/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [347/1079], Loss: 0.0046\n",
      "Epoch [9/10], Step [348/1079], Loss: 0.0111\n",
      "Epoch [9/10], Step [349/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [350/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [351/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [352/1079], Loss: 0.0276\n",
      "Epoch [9/10], Step [353/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [354/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [355/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [356/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [357/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [358/1079], Loss: 0.0030\n",
      "Epoch [9/10], Step [359/1079], Loss: 0.0210\n",
      "Epoch [9/10], Step [360/1079], Loss: 0.0029\n",
      "Epoch [9/10], Step [361/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [362/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [363/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [364/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [365/1079], Loss: 0.0052\n",
      "Epoch [9/10], Step [366/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [367/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [368/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [369/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [370/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [371/1079], Loss: 0.0097\n",
      "Epoch [9/10], Step [372/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [373/1079], Loss: 0.0026\n",
      "Epoch [9/10], Step [374/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [375/1079], Loss: 0.0099\n",
      "Epoch [9/10], Step [376/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [377/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [378/1079], Loss: 0.0245\n",
      "Epoch [9/10], Step [379/1079], Loss: 0.0174\n",
      "Epoch [9/10], Step [380/1079], Loss: 0.0072\n",
      "Epoch [9/10], Step [381/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [382/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [383/1079], Loss: 0.0016\n",
      "Epoch [9/10], Step [384/1079], Loss: 0.0057\n",
      "Epoch [9/10], Step [385/1079], Loss: 0.0031\n",
      "Epoch [9/10], Step [386/1079], Loss: 0.0119\n",
      "Epoch [9/10], Step [387/1079], Loss: 0.0100\n",
      "Epoch [9/10], Step [388/1079], Loss: 0.0070\n",
      "Epoch [9/10], Step [389/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [390/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [391/1079], Loss: 0.0142\n",
      "Epoch [9/10], Step [392/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [393/1079], Loss: 0.0385\n",
      "Epoch [9/10], Step [394/1079], Loss: 0.0041\n",
      "Epoch [9/10], Step [395/1079], Loss: 0.0052\n",
      "Epoch [9/10], Step [396/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [397/1079], Loss: 0.0578\n",
      "Epoch [9/10], Step [398/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [399/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [400/1079], Loss: 0.0169\n",
      "Epoch [9/10], Step [401/1079], Loss: 0.0028\n",
      "Epoch [9/10], Step [402/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [403/1079], Loss: 0.0020\n",
      "Epoch [9/10], Step [404/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [405/1079], Loss: 0.0107\n",
      "Epoch [9/10], Step [406/1079], Loss: 0.0130\n",
      "Epoch [9/10], Step [407/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [408/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [409/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [410/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [411/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [412/1079], Loss: 0.0027\n",
      "Epoch [9/10], Step [413/1079], Loss: 0.0265\n",
      "Epoch [9/10], Step [414/1079], Loss: 0.0046\n",
      "Epoch [9/10], Step [415/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [416/1079], Loss: 0.0023\n",
      "Epoch [9/10], Step [417/1079], Loss: 0.0160\n",
      "Epoch [9/10], Step [418/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [419/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [420/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [421/1079], Loss: 0.0039\n",
      "Epoch [9/10], Step [422/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [423/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [424/1079], Loss: 0.0032\n",
      "Epoch [9/10], Step [425/1079], Loss: 0.0040\n",
      "Epoch [9/10], Step [426/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [427/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [428/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [429/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [430/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [431/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [432/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [433/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [434/1079], Loss: 0.0195\n",
      "Epoch [9/10], Step [435/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [436/1079], Loss: 0.0359\n",
      "Epoch [9/10], Step [437/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [438/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [439/1079], Loss: 0.0105\n",
      "Epoch [9/10], Step [440/1079], Loss: 0.0064\n",
      "Epoch [9/10], Step [441/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [442/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [443/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [444/1079], Loss: 0.0114\n",
      "Epoch [9/10], Step [445/1079], Loss: 0.0067\n",
      "Epoch [9/10], Step [446/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [447/1079], Loss: 0.0031\n",
      "Epoch [9/10], Step [448/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [449/1079], Loss: 0.0302\n",
      "Epoch [9/10], Step [450/1079], Loss: 0.0027\n",
      "Epoch [9/10], Step [451/1079], Loss: 0.0021\n",
      "Epoch [9/10], Step [452/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [453/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [454/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [455/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [456/1079], Loss: 0.0015\n",
      "Epoch [9/10], Step [457/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [458/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [459/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [460/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [461/1079], Loss: 0.0048\n",
      "Epoch [9/10], Step [462/1079], Loss: 0.0307\n",
      "Epoch [9/10], Step [463/1079], Loss: 0.0099\n",
      "Epoch [9/10], Step [464/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [465/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [466/1079], Loss: 0.0020\n",
      "Epoch [9/10], Step [467/1079], Loss: 0.0023\n",
      "Epoch [9/10], Step [468/1079], Loss: 0.0167\n",
      "Epoch [9/10], Step [469/1079], Loss: 0.0278\n",
      "Epoch [9/10], Step [470/1079], Loss: 0.0157\n",
      "Epoch [9/10], Step [471/1079], Loss: 0.0012\n",
      "Epoch [9/10], Step [472/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [473/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [474/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [475/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [476/1079], Loss: 0.0342\n",
      "Epoch [9/10], Step [477/1079], Loss: 0.0016\n",
      "Epoch [9/10], Step [478/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [479/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [480/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [481/1079], Loss: 0.0023\n",
      "Epoch [9/10], Step [482/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [483/1079], Loss: 0.0035\n",
      "Epoch [9/10], Step [484/1079], Loss: 0.0389\n",
      "Epoch [9/10], Step [485/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [486/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [487/1079], Loss: 0.0083\n",
      "Epoch [9/10], Step [488/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [489/1079], Loss: 0.0023\n",
      "Epoch [9/10], Step [490/1079], Loss: 0.0025\n",
      "Epoch [9/10], Step [491/1079], Loss: 0.0286\n",
      "Epoch [9/10], Step [492/1079], Loss: 0.0029\n",
      "Epoch [9/10], Step [493/1079], Loss: 0.0017\n",
      "Epoch [9/10], Step [494/1079], Loss: 0.0037\n",
      "Epoch [9/10], Step [495/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [496/1079], Loss: 0.0147\n",
      "Epoch [9/10], Step [497/1079], Loss: 0.0319\n",
      "Epoch [9/10], Step [498/1079], Loss: 0.0019\n",
      "Epoch [9/10], Step [499/1079], Loss: 0.0243\n",
      "Epoch [9/10], Step [500/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [501/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [502/1079], Loss: 0.0027\n",
      "Epoch [9/10], Step [503/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [504/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [505/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [506/1079], Loss: 0.0853\n",
      "Epoch [9/10], Step [507/1079], Loss: 0.0086\n",
      "Epoch [9/10], Step [508/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [509/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [510/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [511/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [512/1079], Loss: 0.0105\n",
      "Epoch [9/10], Step [513/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [514/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [515/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [516/1079], Loss: 0.0720\n",
      "Epoch [9/10], Step [517/1079], Loss: 0.0098\n",
      "Epoch [9/10], Step [518/1079], Loss: 0.0126\n",
      "Epoch [9/10], Step [519/1079], Loss: 0.0017\n",
      "Epoch [9/10], Step [520/1079], Loss: 0.0154\n",
      "Epoch [9/10], Step [521/1079], Loss: 0.0018\n",
      "Epoch [9/10], Step [522/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [523/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [524/1079], Loss: 0.0021\n",
      "Epoch [9/10], Step [525/1079], Loss: 0.0094\n",
      "Epoch [9/10], Step [526/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [527/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [528/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [529/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [530/1079], Loss: 0.0404\n",
      "Epoch [9/10], Step [531/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [532/1079], Loss: 0.0612\n",
      "Epoch [9/10], Step [533/1079], Loss: 0.0070\n",
      "Epoch [9/10], Step [534/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [535/1079], Loss: 0.0095\n",
      "Epoch [9/10], Step [536/1079], Loss: 0.0612\n",
      "Epoch [9/10], Step [537/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [538/1079], Loss: 0.0013\n",
      "Epoch [9/10], Step [539/1079], Loss: 0.0028\n",
      "Epoch [9/10], Step [540/1079], Loss: 0.0109\n",
      "Epoch [9/10], Step [541/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [542/1079], Loss: 0.0040\n",
      "Epoch [9/10], Step [543/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [544/1079], Loss: 0.0153\n",
      "Epoch [9/10], Step [545/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [546/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [547/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [548/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [549/1079], Loss: 0.0016\n",
      "Epoch [9/10], Step [550/1079], Loss: 0.0012\n",
      "Epoch [9/10], Step [551/1079], Loss: 0.0442\n",
      "Epoch [9/10], Step [552/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [553/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [554/1079], Loss: 0.0073\n",
      "Epoch [9/10], Step [555/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [556/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [557/1079], Loss: 0.0275\n",
      "Epoch [9/10], Step [558/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [559/1079], Loss: 0.0040\n",
      "Epoch [9/10], Step [560/1079], Loss: 0.0044\n",
      "Epoch [9/10], Step [561/1079], Loss: 0.0215\n",
      "Epoch [9/10], Step [562/1079], Loss: 0.0105\n",
      "Epoch [9/10], Step [563/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [564/1079], Loss: 0.0045\n",
      "Epoch [9/10], Step [565/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [566/1079], Loss: 0.0015\n",
      "Epoch [9/10], Step [567/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [568/1079], Loss: 0.0152\n",
      "Epoch [9/10], Step [569/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [570/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [571/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [572/1079], Loss: 0.0046\n",
      "Epoch [9/10], Step [573/1079], Loss: 0.0370\n",
      "Epoch [9/10], Step [574/1079], Loss: 0.0120\n",
      "Epoch [9/10], Step [575/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [576/1079], Loss: 0.0083\n",
      "Epoch [9/10], Step [577/1079], Loss: 0.0034\n",
      "Epoch [9/10], Step [578/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [579/1079], Loss: 0.0173\n",
      "Epoch [9/10], Step [580/1079], Loss: 0.0017\n",
      "Epoch [9/10], Step [581/1079], Loss: 0.0340\n",
      "Epoch [9/10], Step [582/1079], Loss: 0.0100\n",
      "Epoch [9/10], Step [583/1079], Loss: 0.0092\n",
      "Epoch [9/10], Step [584/1079], Loss: 0.0155\n",
      "Epoch [9/10], Step [585/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [586/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [587/1079], Loss: 0.0073\n",
      "Epoch [9/10], Step [588/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [589/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [590/1079], Loss: 0.0044\n",
      "Epoch [9/10], Step [591/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [592/1079], Loss: 0.0224\n",
      "Epoch [9/10], Step [593/1079], Loss: 0.0020\n",
      "Epoch [9/10], Step [594/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [595/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [596/1079], Loss: 0.0206\n",
      "Epoch [9/10], Step [597/1079], Loss: 0.0016\n",
      "Epoch [9/10], Step [598/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [599/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [600/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [601/1079], Loss: 0.0094\n",
      "Epoch [9/10], Step [602/1079], Loss: 0.0026\n",
      "Epoch [9/10], Step [603/1079], Loss: 0.0028\n",
      "Epoch [9/10], Step [604/1079], Loss: 0.0051\n",
      "Epoch [9/10], Step [605/1079], Loss: 0.0035\n",
      "Epoch [9/10], Step [606/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [607/1079], Loss: 0.0040\n",
      "Epoch [9/10], Step [608/1079], Loss: 0.0137\n",
      "Epoch [9/10], Step [609/1079], Loss: 0.0044\n",
      "Epoch [9/10], Step [610/1079], Loss: 0.0298\n",
      "Epoch [9/10], Step [611/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [612/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [613/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [614/1079], Loss: 0.0073\n",
      "Epoch [9/10], Step [615/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [616/1079], Loss: 0.0015\n",
      "Epoch [9/10], Step [617/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [618/1079], Loss: 0.0085\n",
      "Epoch [9/10], Step [619/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [620/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [621/1079], Loss: 0.0021\n",
      "Epoch [9/10], Step [622/1079], Loss: 0.0064\n",
      "Epoch [9/10], Step [623/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [624/1079], Loss: 0.0942\n",
      "Epoch [9/10], Step [625/1079], Loss: 0.0550\n",
      "Epoch [9/10], Step [626/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [627/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [628/1079], Loss: 0.0405\n",
      "Epoch [9/10], Step [629/1079], Loss: 0.0042\n",
      "Epoch [9/10], Step [630/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [631/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [632/1079], Loss: 0.0018\n",
      "Epoch [9/10], Step [633/1079], Loss: 0.0587\n",
      "Epoch [9/10], Step [634/1079], Loss: 0.0031\n",
      "Epoch [9/10], Step [635/1079], Loss: 0.0093\n",
      "Epoch [9/10], Step [636/1079], Loss: 0.0171\n",
      "Epoch [9/10], Step [637/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [638/1079], Loss: 0.0047\n",
      "Epoch [9/10], Step [639/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [640/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [641/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [642/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [643/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [644/1079], Loss: 0.0018\n",
      "Epoch [9/10], Step [645/1079], Loss: 0.0021\n",
      "Epoch [9/10], Step [646/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [647/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [648/1079], Loss: 0.0020\n",
      "Epoch [9/10], Step [649/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [650/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [651/1079], Loss: 0.0081\n",
      "Epoch [9/10], Step [652/1079], Loss: 0.0017\n",
      "Epoch [9/10], Step [653/1079], Loss: 0.0177\n",
      "Epoch [9/10], Step [654/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [655/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [656/1079], Loss: 0.0037\n",
      "Epoch [9/10], Step [657/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [658/1079], Loss: 0.0073\n",
      "Epoch [9/10], Step [659/1079], Loss: 0.0012\n",
      "Epoch [9/10], Step [660/1079], Loss: 0.0041\n",
      "Epoch [9/10], Step [661/1079], Loss: 0.0183\n",
      "Epoch [9/10], Step [662/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [663/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [664/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [665/1079], Loss: 0.0068\n",
      "Epoch [9/10], Step [666/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [667/1079], Loss: 0.0032\n",
      "Epoch [9/10], Step [668/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [669/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [670/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [671/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [672/1079], Loss: 0.0015\n",
      "Epoch [9/10], Step [673/1079], Loss: 0.0046\n",
      "Epoch [9/10], Step [674/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [675/1079], Loss: 0.0048\n",
      "Epoch [9/10], Step [676/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [677/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [678/1079], Loss: 0.0801\n",
      "Epoch [9/10], Step [679/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [680/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [681/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [682/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [683/1079], Loss: 0.0020\n",
      "Epoch [9/10], Step [684/1079], Loss: 0.0025\n",
      "Epoch [9/10], Step [685/1079], Loss: 0.0024\n",
      "Epoch [9/10], Step [686/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [687/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [688/1079], Loss: 0.0147\n",
      "Epoch [9/10], Step [689/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [690/1079], Loss: 0.0094\n",
      "Epoch [9/10], Step [691/1079], Loss: 0.0027\n",
      "Epoch [9/10], Step [692/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [693/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [694/1079], Loss: 0.0154\n",
      "Epoch [9/10], Step [695/1079], Loss: 0.0323\n",
      "Epoch [9/10], Step [696/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [697/1079], Loss: 0.0058\n",
      "Epoch [9/10], Step [698/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [699/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [700/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [701/1079], Loss: 0.0893\n",
      "Epoch [9/10], Step [702/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [703/1079], Loss: 0.0076\n",
      "Epoch [9/10], Step [704/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [705/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [706/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [707/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [708/1079], Loss: 0.0256\n",
      "Epoch [9/10], Step [709/1079], Loss: 0.0046\n",
      "Epoch [9/10], Step [710/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [711/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [712/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [713/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [714/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [715/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [716/1079], Loss: 0.0137\n",
      "Epoch [9/10], Step [717/1079], Loss: 0.0013\n",
      "Epoch [9/10], Step [718/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [719/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [720/1079], Loss: 0.0110\n",
      "Epoch [9/10], Step [721/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [722/1079], Loss: 0.0401\n",
      "Epoch [9/10], Step [723/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [724/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [725/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [726/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [727/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [728/1079], Loss: 0.0037\n",
      "Epoch [9/10], Step [729/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [730/1079], Loss: 0.0067\n",
      "Epoch [9/10], Step [731/1079], Loss: 0.0319\n",
      "Epoch [9/10], Step [732/1079], Loss: 0.0079\n",
      "Epoch [9/10], Step [733/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [734/1079], Loss: 0.0390\n",
      "Epoch [9/10], Step [735/1079], Loss: 0.0071\n",
      "Epoch [9/10], Step [736/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [737/1079], Loss: 0.0043\n",
      "Epoch [9/10], Step [738/1079], Loss: 0.0153\n",
      "Epoch [9/10], Step [739/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [740/1079], Loss: 0.0027\n",
      "Epoch [9/10], Step [741/1079], Loss: 0.0076\n",
      "Epoch [9/10], Step [742/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [743/1079], Loss: 0.0027\n",
      "Epoch [9/10], Step [744/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [745/1079], Loss: 0.0182\n",
      "Epoch [9/10], Step [746/1079], Loss: 0.0573\n",
      "Epoch [9/10], Step [747/1079], Loss: 0.0017\n",
      "Epoch [9/10], Step [748/1079], Loss: 0.0785\n",
      "Epoch [9/10], Step [749/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [750/1079], Loss: 0.0039\n",
      "Epoch [9/10], Step [751/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [752/1079], Loss: 0.0040\n",
      "Epoch [9/10], Step [753/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [754/1079], Loss: 0.0020\n",
      "Epoch [9/10], Step [755/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [756/1079], Loss: 0.0023\n",
      "Epoch [9/10], Step [757/1079], Loss: 0.0195\n",
      "Epoch [9/10], Step [758/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [759/1079], Loss: 0.0146\n",
      "Epoch [9/10], Step [760/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [761/1079], Loss: 0.0059\n",
      "Epoch [9/10], Step [762/1079], Loss: 0.0028\n",
      "Epoch [9/10], Step [763/1079], Loss: 0.0181\n",
      "Epoch [9/10], Step [764/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [765/1079], Loss: 0.0212\n",
      "Epoch [9/10], Step [766/1079], Loss: 0.0047\n",
      "Epoch [9/10], Step [767/1079], Loss: 0.0039\n",
      "Epoch [9/10], Step [768/1079], Loss: 0.0040\n",
      "Epoch [9/10], Step [769/1079], Loss: 0.0064\n",
      "Epoch [9/10], Step [770/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [771/1079], Loss: 0.0013\n",
      "Epoch [9/10], Step [772/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [773/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [774/1079], Loss: 0.0314\n",
      "Epoch [9/10], Step [775/1079], Loss: 0.0447\n",
      "Epoch [9/10], Step [776/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [777/1079], Loss: 0.0377\n",
      "Epoch [9/10], Step [778/1079], Loss: 0.0123\n",
      "Epoch [9/10], Step [779/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [780/1079], Loss: 0.0015\n",
      "Epoch [9/10], Step [781/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [782/1079], Loss: 0.0019\n",
      "Epoch [9/10], Step [783/1079], Loss: 0.0027\n",
      "Epoch [9/10], Step [784/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [785/1079], Loss: 0.0083\n",
      "Epoch [9/10], Step [786/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [787/1079], Loss: 0.0275\n",
      "Epoch [9/10], Step [788/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [789/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [790/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [791/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [792/1079], Loss: 0.0059\n",
      "Epoch [9/10], Step [793/1079], Loss: 0.0105\n",
      "Epoch [9/10], Step [794/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [795/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [796/1079], Loss: 0.0315\n",
      "Epoch [9/10], Step [797/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [798/1079], Loss: 0.0254\n",
      "Epoch [9/10], Step [799/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [800/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [801/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [802/1079], Loss: 0.0386\n",
      "Epoch [9/10], Step [803/1079], Loss: 0.0437\n",
      "Epoch [9/10], Step [804/1079], Loss: 0.0018\n",
      "Epoch [9/10], Step [805/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [806/1079], Loss: 0.0025\n",
      "Epoch [9/10], Step [807/1079], Loss: 0.0046\n",
      "Epoch [9/10], Step [808/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [809/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [810/1079], Loss: 0.0336\n",
      "Epoch [9/10], Step [811/1079], Loss: 0.1417\n",
      "Epoch [9/10], Step [812/1079], Loss: 0.0013\n",
      "Epoch [9/10], Step [813/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [814/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [815/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [816/1079], Loss: 0.0021\n",
      "Epoch [9/10], Step [817/1079], Loss: 0.0320\n",
      "Epoch [9/10], Step [818/1079], Loss: 0.0043\n",
      "Epoch [9/10], Step [819/1079], Loss: 0.1055\n",
      "Epoch [9/10], Step [820/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [821/1079], Loss: 0.0050\n",
      "Epoch [9/10], Step [822/1079], Loss: 0.0526\n",
      "Epoch [9/10], Step [823/1079], Loss: 0.0020\n",
      "Epoch [9/10], Step [824/1079], Loss: 0.0082\n",
      "Epoch [9/10], Step [825/1079], Loss: 0.0012\n",
      "Epoch [9/10], Step [826/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [827/1079], Loss: 0.0198\n",
      "Epoch [9/10], Step [828/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [829/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [830/1079], Loss: 0.0020\n",
      "Epoch [9/10], Step [831/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [832/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [833/1079], Loss: 0.0246\n",
      "Epoch [9/10], Step [834/1079], Loss: 0.0056\n",
      "Epoch [9/10], Step [835/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [836/1079], Loss: 0.0066\n",
      "Epoch [9/10], Step [837/1079], Loss: 0.0022\n",
      "Epoch [9/10], Step [838/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [839/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [840/1079], Loss: 0.0297\n",
      "Epoch [9/10], Step [841/1079], Loss: 0.0051\n",
      "Epoch [9/10], Step [842/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [843/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [844/1079], Loss: 0.0070\n",
      "Epoch [9/10], Step [845/1079], Loss: 0.0075\n",
      "Epoch [9/10], Step [846/1079], Loss: 0.0096\n",
      "Epoch [9/10], Step [847/1079], Loss: 0.0477\n",
      "Epoch [9/10], Step [848/1079], Loss: 0.0022\n",
      "Epoch [9/10], Step [849/1079], Loss: 0.0095\n",
      "Epoch [9/10], Step [850/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [851/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [852/1079], Loss: 0.0063\n",
      "Epoch [9/10], Step [853/1079], Loss: 0.0025\n",
      "Epoch [9/10], Step [854/1079], Loss: 0.0159\n",
      "Epoch [9/10], Step [855/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [856/1079], Loss: 0.0102\n",
      "Epoch [9/10], Step [857/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [858/1079], Loss: 0.0137\n",
      "Epoch [9/10], Step [859/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [860/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [861/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [862/1079], Loss: 0.0026\n",
      "Epoch [9/10], Step [863/1079], Loss: 0.0024\n",
      "Epoch [9/10], Step [864/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [865/1079], Loss: 0.0080\n",
      "Epoch [9/10], Step [866/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [867/1079], Loss: 0.0013\n",
      "Epoch [9/10], Step [868/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [869/1079], Loss: 0.0027\n",
      "Epoch [9/10], Step [870/1079], Loss: 0.0258\n",
      "Epoch [9/10], Step [871/1079], Loss: 0.0012\n",
      "Epoch [9/10], Step [872/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [873/1079], Loss: 0.0021\n",
      "Epoch [9/10], Step [874/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [875/1079], Loss: 0.0028\n",
      "Epoch [9/10], Step [876/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [877/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [878/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [879/1079], Loss: 0.0032\n",
      "Epoch [9/10], Step [880/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [881/1079], Loss: 0.0063\n",
      "Epoch [9/10], Step [882/1079], Loss: 0.0481\n",
      "Epoch [9/10], Step [883/1079], Loss: 0.0030\n",
      "Epoch [9/10], Step [884/1079], Loss: 0.0021\n",
      "Epoch [9/10], Step [885/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [886/1079], Loss: 0.0032\n",
      "Epoch [9/10], Step [887/1079], Loss: 0.0017\n",
      "Epoch [9/10], Step [888/1079], Loss: 0.0020\n",
      "Epoch [9/10], Step [889/1079], Loss: 0.0013\n",
      "Epoch [9/10], Step [890/1079], Loss: 0.0052\n",
      "Epoch [9/10], Step [891/1079], Loss: 0.0016\n",
      "Epoch [9/10], Step [892/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [893/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [894/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [895/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [896/1079], Loss: 0.0013\n",
      "Epoch [9/10], Step [897/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [898/1079], Loss: 0.0044\n",
      "Epoch [9/10], Step [899/1079], Loss: 0.0050\n",
      "Epoch [9/10], Step [900/1079], Loss: 0.0151\n",
      "Epoch [9/10], Step [901/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [902/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [903/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [904/1079], Loss: 0.0047\n",
      "Epoch [9/10], Step [905/1079], Loss: 0.0023\n",
      "Epoch [9/10], Step [906/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [907/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [908/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [909/1079], Loss: 0.0125\n",
      "Epoch [9/10], Step [910/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [911/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [912/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [913/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [914/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [915/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [916/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [917/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [918/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [919/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [920/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [921/1079], Loss: 0.0149\n",
      "Epoch [9/10], Step [922/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [923/1079], Loss: 0.0041\n",
      "Epoch [9/10], Step [924/1079], Loss: 0.0019\n",
      "Epoch [9/10], Step [925/1079], Loss: 0.0154\n",
      "Epoch [9/10], Step [926/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [927/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [928/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [929/1079], Loss: 0.0067\n",
      "Epoch [9/10], Step [930/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [931/1079], Loss: 0.0189\n",
      "Epoch [9/10], Step [932/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [933/1079], Loss: 0.0048\n",
      "Epoch [9/10], Step [934/1079], Loss: 0.0094\n",
      "Epoch [9/10], Step [935/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [936/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [937/1079], Loss: 0.0025\n",
      "Epoch [9/10], Step [938/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [939/1079], Loss: 0.0699\n",
      "Epoch [9/10], Step [940/1079], Loss: 0.1119\n",
      "Epoch [9/10], Step [941/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [942/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [943/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [944/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [945/1079], Loss: 0.0767\n",
      "Epoch [9/10], Step [946/1079], Loss: 0.0056\n",
      "Epoch [9/10], Step [947/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [948/1079], Loss: 0.2149\n",
      "Epoch [9/10], Step [949/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [950/1079], Loss: 0.0176\n",
      "Epoch [9/10], Step [951/1079], Loss: 0.0211\n",
      "Epoch [9/10], Step [952/1079], Loss: 0.0135\n",
      "Epoch [9/10], Step [953/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [954/1079], Loss: 0.0012\n",
      "Epoch [9/10], Step [955/1079], Loss: 0.0018\n",
      "Epoch [9/10], Step [956/1079], Loss: 0.0120\n",
      "Epoch [9/10], Step [957/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [958/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [959/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [960/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [961/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [962/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [963/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [964/1079], Loss: 0.0064\n",
      "Epoch [9/10], Step [965/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [966/1079], Loss: 0.0170\n",
      "Epoch [9/10], Step [967/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [968/1079], Loss: 0.0015\n",
      "Epoch [9/10], Step [969/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [970/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [971/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [972/1079], Loss: 0.0069\n",
      "Epoch [9/10], Step [973/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [974/1079], Loss: 0.0113\n",
      "Epoch [9/10], Step [975/1079], Loss: 0.0004\n",
      "Epoch [9/10], Step [976/1079], Loss: 0.0035\n",
      "Epoch [9/10], Step [977/1079], Loss: 0.0329\n",
      "Epoch [9/10], Step [978/1079], Loss: 0.0035\n",
      "Epoch [9/10], Step [979/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [980/1079], Loss: 0.0120\n",
      "Epoch [9/10], Step [981/1079], Loss: 0.0179\n",
      "Epoch [9/10], Step [982/1079], Loss: 0.0028\n",
      "Epoch [9/10], Step [983/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [984/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [985/1079], Loss: 0.0171\n",
      "Epoch [9/10], Step [986/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [987/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [988/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [989/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [990/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [991/1079], Loss: 0.0039\n",
      "Epoch [9/10], Step [992/1079], Loss: 0.0017\n",
      "Epoch [9/10], Step [993/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [994/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [995/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [996/1079], Loss: 0.0068\n",
      "Epoch [9/10], Step [997/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [998/1079], Loss: 0.0035\n",
      "Epoch [9/10], Step [999/1079], Loss: 0.0126\n",
      "Epoch [9/10], Step [1000/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [1001/1079], Loss: 0.0310\n",
      "Epoch [9/10], Step [1002/1079], Loss: 0.0073\n",
      "Epoch [9/10], Step [1003/1079], Loss: 0.0070\n",
      "Epoch [9/10], Step [1004/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [1005/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [1006/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [1007/1079], Loss: 0.0024\n",
      "Epoch [9/10], Step [1008/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [1009/1079], Loss: 0.0051\n",
      "Epoch [9/10], Step [1010/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [1011/1079], Loss: 0.0071\n",
      "Epoch [9/10], Step [1012/1079], Loss: 0.0023\n",
      "Epoch [9/10], Step [1013/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [1014/1079], Loss: 0.0120\n",
      "Epoch [9/10], Step [1015/1079], Loss: 0.0101\n",
      "Epoch [9/10], Step [1016/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [1017/1079], Loss: 0.0055\n",
      "Epoch [9/10], Step [1018/1079], Loss: 0.0933\n",
      "Epoch [9/10], Step [1019/1079], Loss: 0.0084\n",
      "Epoch [9/10], Step [1020/1079], Loss: 0.0017\n",
      "Epoch [9/10], Step [1021/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [1022/1079], Loss: 0.0052\n",
      "Epoch [9/10], Step [1023/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [1024/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [1025/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [1026/1079], Loss: 0.0006\n",
      "Epoch [9/10], Step [1027/1079], Loss: 0.0870\n",
      "Epoch [9/10], Step [1028/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [1029/1079], Loss: 0.0009\n",
      "Epoch [9/10], Step [1030/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [1031/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [1032/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [1033/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [1034/1079], Loss: 0.0148\n",
      "Epoch [9/10], Step [1035/1079], Loss: 0.0000\n",
      "Epoch [9/10], Step [1036/1079], Loss: 0.0145\n",
      "Epoch [9/10], Step [1037/1079], Loss: 0.0029\n",
      "Epoch [9/10], Step [1038/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [1039/1079], Loss: 0.0087\n",
      "Epoch [9/10], Step [1040/1079], Loss: 0.0017\n",
      "Epoch [9/10], Step [1041/1079], Loss: 0.1183\n",
      "Epoch [9/10], Step [1042/1079], Loss: 0.0037\n",
      "Epoch [9/10], Step [1043/1079], Loss: 0.0005\n",
      "Epoch [9/10], Step [1044/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [1045/1079], Loss: 0.0012\n",
      "Epoch [9/10], Step [1046/1079], Loss: 0.0003\n",
      "Epoch [9/10], Step [1047/1079], Loss: 0.0010\n",
      "Epoch [9/10], Step [1048/1079], Loss: 0.0293\n",
      "Epoch [9/10], Step [1049/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [1050/1079], Loss: 0.0017\n",
      "Epoch [9/10], Step [1051/1079], Loss: 0.0226\n",
      "Epoch [9/10], Step [1052/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [1053/1079], Loss: 0.0213\n",
      "Epoch [9/10], Step [1054/1079], Loss: 0.0088\n",
      "Epoch [9/10], Step [1055/1079], Loss: 0.0620\n",
      "Epoch [9/10], Step [1056/1079], Loss: 0.0008\n",
      "Epoch [9/10], Step [1057/1079], Loss: 0.0220\n",
      "Epoch [9/10], Step [1058/1079], Loss: 0.0215\n",
      "Epoch [9/10], Step [1059/1079], Loss: 0.0186\n",
      "Epoch [9/10], Step [1060/1079], Loss: 0.1098\n",
      "Epoch [9/10], Step [1061/1079], Loss: 0.0014\n",
      "Epoch [9/10], Step [1062/1079], Loss: 0.0876\n",
      "Epoch [9/10], Step [1063/1079], Loss: 0.0298\n",
      "Epoch [9/10], Step [1064/1079], Loss: 0.0389\n",
      "Epoch [9/10], Step [1065/1079], Loss: 0.0007\n",
      "Epoch [9/10], Step [1066/1079], Loss: 0.0031\n",
      "Epoch [9/10], Step [1067/1079], Loss: 0.0136\n",
      "Epoch [9/10], Step [1068/1079], Loss: 0.0019\n",
      "Epoch [9/10], Step [1069/1079], Loss: 0.0011\n",
      "Epoch [9/10], Step [1070/1079], Loss: 0.0145\n",
      "Epoch [9/10], Step [1071/1079], Loss: 0.0019\n",
      "Epoch [9/10], Step [1072/1079], Loss: 0.0019\n",
      "Epoch [9/10], Step [1073/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [1074/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [1075/1079], Loss: 0.0018\n",
      "Epoch [9/10], Step [1076/1079], Loss: 0.0001\n",
      "Epoch [9/10], Step [1077/1079], Loss: 0.0561\n",
      "Epoch [9/10], Step [1078/1079], Loss: 0.0002\n",
      "Epoch [9/10], Step [1079/1079], Loss: 0.0102\n",
      "Epoch [10/10], Step [1/1079], Loss: 0.0045\n",
      "Epoch [10/10], Step [2/1079], Loss: 0.0076\n",
      "Epoch [10/10], Step [3/1079], Loss: 0.0032\n",
      "Epoch [10/10], Step [4/1079], Loss: 0.0220\n",
      "Epoch [10/10], Step [5/1079], Loss: 0.0020\n",
      "Epoch [10/10], Step [6/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [7/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [8/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [9/1079], Loss: 0.0359\n",
      "Epoch [10/10], Step [10/1079], Loss: 0.0604\n",
      "Epoch [10/10], Step [11/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [12/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [13/1079], Loss: 0.0022\n",
      "Epoch [10/10], Step [14/1079], Loss: 0.0088\n",
      "Epoch [10/10], Step [15/1079], Loss: 0.0034\n",
      "Epoch [10/10], Step [16/1079], Loss: 0.0021\n",
      "Epoch [10/10], Step [17/1079], Loss: 0.0099\n",
      "Epoch [10/10], Step [18/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [19/1079], Loss: 0.0023\n",
      "Epoch [10/10], Step [20/1079], Loss: 0.0091\n",
      "Epoch [10/10], Step [21/1079], Loss: 0.0014\n",
      "Epoch [10/10], Step [22/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [23/1079], Loss: 0.0025\n",
      "Epoch [10/10], Step [24/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [25/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [26/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [27/1079], Loss: 0.0153\n",
      "Epoch [10/10], Step [28/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [29/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [30/1079], Loss: 0.0030\n",
      "Epoch [10/10], Step [31/1079], Loss: 0.0017\n",
      "Epoch [10/10], Step [32/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [33/1079], Loss: 0.0385\n",
      "Epoch [10/10], Step [34/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [35/1079], Loss: 0.0035\n",
      "Epoch [10/10], Step [36/1079], Loss: 0.0100\n",
      "Epoch [10/10], Step [37/1079], Loss: 0.0067\n",
      "Epoch [10/10], Step [38/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [39/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [40/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [41/1079], Loss: 0.0150\n",
      "Epoch [10/10], Step [42/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [43/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [44/1079], Loss: 0.0027\n",
      "Epoch [10/10], Step [45/1079], Loss: 0.0037\n",
      "Epoch [10/10], Step [46/1079], Loss: 0.0047\n",
      "Epoch [10/10], Step [47/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [48/1079], Loss: 0.0035\n",
      "Epoch [10/10], Step [49/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [50/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [51/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [52/1079], Loss: 0.0058\n",
      "Epoch [10/10], Step [53/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [54/1079], Loss: 0.0029\n",
      "Epoch [10/10], Step [55/1079], Loss: 0.0014\n",
      "Epoch [10/10], Step [56/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [57/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [58/1079], Loss: 0.0416\n",
      "Epoch [10/10], Step [59/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [60/1079], Loss: 0.0145\n",
      "Epoch [10/10], Step [61/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [62/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [63/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [64/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [65/1079], Loss: 0.0086\n",
      "Epoch [10/10], Step [66/1079], Loss: 0.0064\n",
      "Epoch [10/10], Step [67/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [68/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [69/1079], Loss: 0.0047\n",
      "Epoch [10/10], Step [70/1079], Loss: 0.0119\n",
      "Epoch [10/10], Step [71/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [72/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [73/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [74/1079], Loss: 0.0175\n",
      "Epoch [10/10], Step [75/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [76/1079], Loss: 0.0029\n",
      "Epoch [10/10], Step [77/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [78/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [79/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [80/1079], Loss: 0.0180\n",
      "Epoch [10/10], Step [81/1079], Loss: 0.0196\n",
      "Epoch [10/10], Step [82/1079], Loss: 0.0163\n",
      "Epoch [10/10], Step [83/1079], Loss: 0.0104\n",
      "Epoch [10/10], Step [84/1079], Loss: 0.0040\n",
      "Epoch [10/10], Step [85/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [86/1079], Loss: 0.0157\n",
      "Epoch [10/10], Step [87/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [88/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [89/1079], Loss: 0.0024\n",
      "Epoch [10/10], Step [90/1079], Loss: 0.0042\n",
      "Epoch [10/10], Step [91/1079], Loss: 0.0066\n",
      "Epoch [10/10], Step [92/1079], Loss: 0.0036\n",
      "Epoch [10/10], Step [93/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [94/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [95/1079], Loss: 0.0027\n",
      "Epoch [10/10], Step [96/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [97/1079], Loss: 0.0014\n",
      "Epoch [10/10], Step [98/1079], Loss: 0.0020\n",
      "Epoch [10/10], Step [99/1079], Loss: 0.0031\n",
      "Epoch [10/10], Step [100/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [101/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [102/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [103/1079], Loss: 0.0028\n",
      "Epoch [10/10], Step [104/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [105/1079], Loss: 0.0058\n",
      "Epoch [10/10], Step [106/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [107/1079], Loss: 0.0369\n",
      "Epoch [10/10], Step [108/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [109/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [110/1079], Loss: 0.0089\n",
      "Epoch [10/10], Step [111/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [112/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [113/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [114/1079], Loss: 0.0022\n",
      "Epoch [10/10], Step [115/1079], Loss: 0.0044\n",
      "Epoch [10/10], Step [116/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [117/1079], Loss: 0.0032\n",
      "Epoch [10/10], Step [118/1079], Loss: 0.0133\n",
      "Epoch [10/10], Step [119/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [120/1079], Loss: 0.0025\n",
      "Epoch [10/10], Step [121/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [122/1079], Loss: 0.0432\n",
      "Epoch [10/10], Step [123/1079], Loss: 0.0105\n",
      "Epoch [10/10], Step [124/1079], Loss: 0.0041\n",
      "Epoch [10/10], Step [125/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [126/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [127/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [128/1079], Loss: 0.0467\n",
      "Epoch [10/10], Step [129/1079], Loss: 0.0051\n",
      "Epoch [10/10], Step [130/1079], Loss: 0.0076\n",
      "Epoch [10/10], Step [131/1079], Loss: 0.0022\n",
      "Epoch [10/10], Step [132/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [133/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [134/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [135/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [136/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [137/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [138/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [139/1079], Loss: 0.0212\n",
      "Epoch [10/10], Step [140/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [141/1079], Loss: 0.0048\n",
      "Epoch [10/10], Step [142/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [143/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [144/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [145/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [146/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [147/1079], Loss: 0.0040\n",
      "Epoch [10/10], Step [148/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [149/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [150/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [151/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [152/1079], Loss: 0.0025\n",
      "Epoch [10/10], Step [153/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [154/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [155/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [156/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [157/1079], Loss: 0.0037\n",
      "Epoch [10/10], Step [158/1079], Loss: 0.0033\n",
      "Epoch [10/10], Step [159/1079], Loss: 0.0030\n",
      "Epoch [10/10], Step [160/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [161/1079], Loss: 0.0021\n",
      "Epoch [10/10], Step [162/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [163/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [164/1079], Loss: 0.1305\n",
      "Epoch [10/10], Step [165/1079], Loss: 0.0580\n",
      "Epoch [10/10], Step [166/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [167/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [168/1079], Loss: 0.0027\n",
      "Epoch [10/10], Step [169/1079], Loss: 0.0177\n",
      "Epoch [10/10], Step [170/1079], Loss: 0.0036\n",
      "Epoch [10/10], Step [171/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [172/1079], Loss: 0.0040\n",
      "Epoch [10/10], Step [173/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [174/1079], Loss: 0.0033\n",
      "Epoch [10/10], Step [175/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [176/1079], Loss: 0.0406\n",
      "Epoch [10/10], Step [177/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [178/1079], Loss: 0.0184\n",
      "Epoch [10/10], Step [179/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [180/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [181/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [182/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [183/1079], Loss: 0.0092\n",
      "Epoch [10/10], Step [184/1079], Loss: 0.0144\n",
      "Epoch [10/10], Step [185/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [186/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [187/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [188/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [189/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [190/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [191/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [192/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [193/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [194/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [195/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [196/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [197/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [198/1079], Loss: 0.0106\n",
      "Epoch [10/10], Step [199/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [200/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [201/1079], Loss: 0.0033\n",
      "Epoch [10/10], Step [202/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [203/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [204/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [205/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [206/1079], Loss: 0.0031\n",
      "Epoch [10/10], Step [207/1079], Loss: 0.0439\n",
      "Epoch [10/10], Step [208/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [209/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [210/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [211/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [212/1079], Loss: 0.0025\n",
      "Epoch [10/10], Step [213/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [214/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [215/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [216/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [217/1079], Loss: 0.1453\n",
      "Epoch [10/10], Step [218/1079], Loss: 0.0020\n",
      "Epoch [10/10], Step [219/1079], Loss: 0.0098\n",
      "Epoch [10/10], Step [220/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [221/1079], Loss: 0.0024\n",
      "Epoch [10/10], Step [222/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [223/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [224/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [225/1079], Loss: 0.0024\n",
      "Epoch [10/10], Step [226/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [227/1079], Loss: 0.0042\n",
      "Epoch [10/10], Step [228/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [229/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [230/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [231/1079], Loss: 0.0175\n",
      "Epoch [10/10], Step [232/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [233/1079], Loss: 0.0415\n",
      "Epoch [10/10], Step [234/1079], Loss: 0.0047\n",
      "Epoch [10/10], Step [235/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [236/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [237/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [238/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [239/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [240/1079], Loss: 0.0034\n",
      "Epoch [10/10], Step [241/1079], Loss: 0.0084\n",
      "Epoch [10/10], Step [242/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [243/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [244/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [245/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [246/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [247/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [248/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [249/1079], Loss: 0.0078\n",
      "Epoch [10/10], Step [250/1079], Loss: 0.0059\n",
      "Epoch [10/10], Step [251/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [252/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [253/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [254/1079], Loss: 0.0014\n",
      "Epoch [10/10], Step [255/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [256/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [257/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [258/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [259/1079], Loss: 0.0017\n",
      "Epoch [10/10], Step [260/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [261/1079], Loss: 0.0317\n",
      "Epoch [10/10], Step [262/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [263/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [264/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [265/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [266/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [267/1079], Loss: 0.0043\n",
      "Epoch [10/10], Step [268/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [269/1079], Loss: 0.0023\n",
      "Epoch [10/10], Step [270/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [271/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [272/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [273/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [274/1079], Loss: 0.0163\n",
      "Epoch [10/10], Step [275/1079], Loss: 0.0047\n",
      "Epoch [10/10], Step [276/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [277/1079], Loss: 0.0378\n",
      "Epoch [10/10], Step [278/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [279/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [280/1079], Loss: 0.0021\n",
      "Epoch [10/10], Step [281/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [282/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [283/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [284/1079], Loss: 0.0025\n",
      "Epoch [10/10], Step [285/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [286/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [287/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [288/1079], Loss: 0.0054\n",
      "Epoch [10/10], Step [289/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [290/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [291/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [292/1079], Loss: 0.0022\n",
      "Epoch [10/10], Step [293/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [294/1079], Loss: 0.0043\n",
      "Epoch [10/10], Step [295/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [296/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [297/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [298/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [299/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [300/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [301/1079], Loss: 0.0624\n",
      "Epoch [10/10], Step [302/1079], Loss: 0.0042\n",
      "Epoch [10/10], Step [303/1079], Loss: 0.0053\n",
      "Epoch [10/10], Step [304/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [305/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [306/1079], Loss: 0.0017\n",
      "Epoch [10/10], Step [307/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [308/1079], Loss: 0.0047\n",
      "Epoch [10/10], Step [309/1079], Loss: 0.0014\n",
      "Epoch [10/10], Step [310/1079], Loss: 0.0057\n",
      "Epoch [10/10], Step [311/1079], Loss: 0.0026\n",
      "Epoch [10/10], Step [312/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [313/1079], Loss: 0.0288\n",
      "Epoch [10/10], Step [314/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [315/1079], Loss: 0.0016\n",
      "Epoch [10/10], Step [316/1079], Loss: 0.0017\n",
      "Epoch [10/10], Step [317/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [318/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [319/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [320/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [321/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [322/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [323/1079], Loss: 0.0023\n",
      "Epoch [10/10], Step [324/1079], Loss: 0.0156\n",
      "Epoch [10/10], Step [325/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [326/1079], Loss: 0.0061\n",
      "Epoch [10/10], Step [327/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [328/1079], Loss: 0.0347\n",
      "Epoch [10/10], Step [329/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [330/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [331/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [332/1079], Loss: 0.0155\n",
      "Epoch [10/10], Step [333/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [334/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [335/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [336/1079], Loss: 0.0035\n",
      "Epoch [10/10], Step [337/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [338/1079], Loss: 0.0027\n",
      "Epoch [10/10], Step [339/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [340/1079], Loss: 0.0022\n",
      "Epoch [10/10], Step [341/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [342/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [343/1079], Loss: 0.0014\n",
      "Epoch [10/10], Step [344/1079], Loss: 0.0098\n",
      "Epoch [10/10], Step [345/1079], Loss: 0.0040\n",
      "Epoch [10/10], Step [346/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [347/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [348/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [349/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [350/1079], Loss: 0.0067\n",
      "Epoch [10/10], Step [351/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [352/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [353/1079], Loss: 0.0098\n",
      "Epoch [10/10], Step [354/1079], Loss: 0.0017\n",
      "Epoch [10/10], Step [355/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [356/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [357/1079], Loss: 0.0053\n",
      "Epoch [10/10], Step [358/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [359/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [360/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [361/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [362/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [363/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [364/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [365/1079], Loss: 0.0138\n",
      "Epoch [10/10], Step [366/1079], Loss: 0.0705\n",
      "Epoch [10/10], Step [367/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [368/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [369/1079], Loss: 0.0028\n",
      "Epoch [10/10], Step [370/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [371/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [372/1079], Loss: 0.0021\n",
      "Epoch [10/10], Step [373/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [374/1079], Loss: 0.0016\n",
      "Epoch [10/10], Step [375/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [376/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [377/1079], Loss: 0.0422\n",
      "Epoch [10/10], Step [378/1079], Loss: 0.0027\n",
      "Epoch [10/10], Step [379/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [380/1079], Loss: 0.0042\n",
      "Epoch [10/10], Step [381/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [382/1079], Loss: 0.0114\n",
      "Epoch [10/10], Step [383/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [384/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [385/1079], Loss: 0.0060\n",
      "Epoch [10/10], Step [386/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [387/1079], Loss: 0.0044\n",
      "Epoch [10/10], Step [388/1079], Loss: 0.0080\n",
      "Epoch [10/10], Step [389/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [390/1079], Loss: 0.0049\n",
      "Epoch [10/10], Step [391/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [392/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [393/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [394/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [395/1079], Loss: 0.0020\n",
      "Epoch [10/10], Step [396/1079], Loss: 0.0017\n",
      "Epoch [10/10], Step [397/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [398/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [399/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [400/1079], Loss: 0.0467\n",
      "Epoch [10/10], Step [401/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [402/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [403/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [404/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [405/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [406/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [407/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [408/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [409/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [410/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [411/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [412/1079], Loss: 0.0064\n",
      "Epoch [10/10], Step [413/1079], Loss: 0.0100\n",
      "Epoch [10/10], Step [414/1079], Loss: 0.0377\n",
      "Epoch [10/10], Step [415/1079], Loss: 0.0042\n",
      "Epoch [10/10], Step [416/1079], Loss: 0.0325\n",
      "Epoch [10/10], Step [417/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [418/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [419/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [420/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [421/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [422/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [423/1079], Loss: 0.0016\n",
      "Epoch [10/10], Step [424/1079], Loss: 0.0425\n",
      "Epoch [10/10], Step [425/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [426/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [427/1079], Loss: 0.0040\n",
      "Epoch [10/10], Step [428/1079], Loss: 0.0124\n",
      "Epoch [10/10], Step [429/1079], Loss: 0.0246\n",
      "Epoch [10/10], Step [430/1079], Loss: 0.0224\n",
      "Epoch [10/10], Step [431/1079], Loss: 0.0482\n",
      "Epoch [10/10], Step [432/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [433/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [434/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [435/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [436/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [437/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [438/1079], Loss: 0.0023\n",
      "Epoch [10/10], Step [439/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [440/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [441/1079], Loss: 0.0042\n",
      "Epoch [10/10], Step [442/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [443/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [444/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [445/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [446/1079], Loss: 0.0058\n",
      "Epoch [10/10], Step [447/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [448/1079], Loss: 0.0203\n",
      "Epoch [10/10], Step [449/1079], Loss: 0.0085\n",
      "Epoch [10/10], Step [450/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [451/1079], Loss: 0.0033\n",
      "Epoch [10/10], Step [452/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [453/1079], Loss: 0.0025\n",
      "Epoch [10/10], Step [454/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [455/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [456/1079], Loss: 0.0178\n",
      "Epoch [10/10], Step [457/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [458/1079], Loss: 0.0017\n",
      "Epoch [10/10], Step [459/1079], Loss: 0.0410\n",
      "Epoch [10/10], Step [460/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [461/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [462/1079], Loss: 0.0020\n",
      "Epoch [10/10], Step [463/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [464/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [465/1079], Loss: 0.0216\n",
      "Epoch [10/10], Step [466/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [467/1079], Loss: 0.0021\n",
      "Epoch [10/10], Step [468/1079], Loss: 0.0029\n",
      "Epoch [10/10], Step [469/1079], Loss: 0.0148\n",
      "Epoch [10/10], Step [470/1079], Loss: 0.0326\n",
      "Epoch [10/10], Step [471/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [472/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [473/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [474/1079], Loss: 0.0033\n",
      "Epoch [10/10], Step [475/1079], Loss: 0.0102\n",
      "Epoch [10/10], Step [476/1079], Loss: 0.0090\n",
      "Epoch [10/10], Step [477/1079], Loss: 0.0208\n",
      "Epoch [10/10], Step [478/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [479/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [480/1079], Loss: 0.0041\n",
      "Epoch [10/10], Step [481/1079], Loss: 0.0098\n",
      "Epoch [10/10], Step [482/1079], Loss: 0.0021\n",
      "Epoch [10/10], Step [483/1079], Loss: 0.0087\n",
      "Epoch [10/10], Step [484/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [485/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [486/1079], Loss: 0.0493\n",
      "Epoch [10/10], Step [487/1079], Loss: 0.0040\n",
      "Epoch [10/10], Step [488/1079], Loss: 0.0539\n",
      "Epoch [10/10], Step [489/1079], Loss: 0.0027\n",
      "Epoch [10/10], Step [490/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [491/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [492/1079], Loss: 0.0131\n",
      "Epoch [10/10], Step [493/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [494/1079], Loss: 0.0055\n",
      "Epoch [10/10], Step [495/1079], Loss: 0.0053\n",
      "Epoch [10/10], Step [496/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [497/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [498/1079], Loss: 0.0021\n",
      "Epoch [10/10], Step [499/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [500/1079], Loss: 0.0096\n",
      "Epoch [10/10], Step [501/1079], Loss: 0.0061\n",
      "Epoch [10/10], Step [502/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [503/1079], Loss: 0.0068\n",
      "Epoch [10/10], Step [504/1079], Loss: 0.0220\n",
      "Epoch [10/10], Step [505/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [506/1079], Loss: 0.0581\n",
      "Epoch [10/10], Step [507/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [508/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [509/1079], Loss: 0.0027\n",
      "Epoch [10/10], Step [510/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [511/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [512/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [513/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [514/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [515/1079], Loss: 0.0181\n",
      "Epoch [10/10], Step [516/1079], Loss: 0.0038\n",
      "Epoch [10/10], Step [517/1079], Loss: 0.0210\n",
      "Epoch [10/10], Step [518/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [519/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [520/1079], Loss: 0.0182\n",
      "Epoch [10/10], Step [521/1079], Loss: 0.0083\n",
      "Epoch [10/10], Step [522/1079], Loss: 0.0108\n",
      "Epoch [10/10], Step [523/1079], Loss: 0.0087\n",
      "Epoch [10/10], Step [524/1079], Loss: 0.0204\n",
      "Epoch [10/10], Step [525/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [526/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [527/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [528/1079], Loss: 0.0162\n",
      "Epoch [10/10], Step [529/1079], Loss: 0.0419\n",
      "Epoch [10/10], Step [530/1079], Loss: 0.0024\n",
      "Epoch [10/10], Step [531/1079], Loss: 0.0034\n",
      "Epoch [10/10], Step [532/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [533/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [534/1079], Loss: 0.0442\n",
      "Epoch [10/10], Step [535/1079], Loss: 0.0079\n",
      "Epoch [10/10], Step [536/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [537/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [538/1079], Loss: 0.0196\n",
      "Epoch [10/10], Step [539/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [540/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [541/1079], Loss: 0.0125\n",
      "Epoch [10/10], Step [542/1079], Loss: 0.0042\n",
      "Epoch [10/10], Step [543/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [544/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [545/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [546/1079], Loss: 0.0046\n",
      "Epoch [10/10], Step [547/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [548/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [549/1079], Loss: 0.0274\n",
      "Epoch [10/10], Step [550/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [551/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [552/1079], Loss: 0.0210\n",
      "Epoch [10/10], Step [553/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [554/1079], Loss: 0.0076\n",
      "Epoch [10/10], Step [555/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [556/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [557/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [558/1079], Loss: 0.0027\n",
      "Epoch [10/10], Step [559/1079], Loss: 0.0176\n",
      "Epoch [10/10], Step [560/1079], Loss: 0.0378\n",
      "Epoch [10/10], Step [561/1079], Loss: 0.0168\n",
      "Epoch [10/10], Step [562/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [563/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [564/1079], Loss: 0.0044\n",
      "Epoch [10/10], Step [565/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [566/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [567/1079], Loss: 0.0205\n",
      "Epoch [10/10], Step [568/1079], Loss: 0.0223\n",
      "Epoch [10/10], Step [569/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [570/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [571/1079], Loss: 0.0126\n",
      "Epoch [10/10], Step [572/1079], Loss: 0.0112\n",
      "Epoch [10/10], Step [573/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [574/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [575/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [576/1079], Loss: 0.0059\n",
      "Epoch [10/10], Step [577/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [578/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [579/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [580/1079], Loss: 0.0329\n",
      "Epoch [10/10], Step [581/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [582/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [583/1079], Loss: 0.0034\n",
      "Epoch [10/10], Step [584/1079], Loss: 0.0377\n",
      "Epoch [10/10], Step [585/1079], Loss: 0.0426\n",
      "Epoch [10/10], Step [586/1079], Loss: 0.0046\n",
      "Epoch [10/10], Step [587/1079], Loss: 0.0149\n",
      "Epoch [10/10], Step [588/1079], Loss: 0.0195\n",
      "Epoch [10/10], Step [589/1079], Loss: 0.0073\n",
      "Epoch [10/10], Step [590/1079], Loss: 0.0035\n",
      "Epoch [10/10], Step [591/1079], Loss: 0.0133\n",
      "Epoch [10/10], Step [592/1079], Loss: 0.0017\n",
      "Epoch [10/10], Step [593/1079], Loss: 0.0043\n",
      "Epoch [10/10], Step [594/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [595/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [596/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [597/1079], Loss: 0.0630\n",
      "Epoch [10/10], Step [598/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [599/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [600/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [601/1079], Loss: 0.0039\n",
      "Epoch [10/10], Step [602/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [603/1079], Loss: 0.0023\n",
      "Epoch [10/10], Step [604/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [605/1079], Loss: 0.0789\n",
      "Epoch [10/10], Step [606/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [607/1079], Loss: 0.0017\n",
      "Epoch [10/10], Step [608/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [609/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [610/1079], Loss: 0.0375\n",
      "Epoch [10/10], Step [611/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [612/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [613/1079], Loss: 0.0077\n",
      "Epoch [10/10], Step [614/1079], Loss: 0.0048\n",
      "Epoch [10/10], Step [615/1079], Loss: 0.0265\n",
      "Epoch [10/10], Step [616/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [617/1079], Loss: 0.0045\n",
      "Epoch [10/10], Step [618/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [619/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [620/1079], Loss: 0.0022\n",
      "Epoch [10/10], Step [621/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [622/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [623/1079], Loss: 0.0038\n",
      "Epoch [10/10], Step [624/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [625/1079], Loss: 0.0042\n",
      "Epoch [10/10], Step [626/1079], Loss: 0.0038\n",
      "Epoch [10/10], Step [627/1079], Loss: 0.0198\n",
      "Epoch [10/10], Step [628/1079], Loss: 0.0063\n",
      "Epoch [10/10], Step [629/1079], Loss: 0.0078\n",
      "Epoch [10/10], Step [630/1079], Loss: 0.0290\n",
      "Epoch [10/10], Step [631/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [632/1079], Loss: 0.0032\n",
      "Epoch [10/10], Step [633/1079], Loss: 0.0030\n",
      "Epoch [10/10], Step [634/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [635/1079], Loss: 0.0070\n",
      "Epoch [10/10], Step [636/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [637/1079], Loss: 0.0059\n",
      "Epoch [10/10], Step [638/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [639/1079], Loss: 0.0036\n",
      "Epoch [10/10], Step [640/1079], Loss: 0.0038\n",
      "Epoch [10/10], Step [641/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [642/1079], Loss: 0.0020\n",
      "Epoch [10/10], Step [643/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [644/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [645/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [646/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [647/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [648/1079], Loss: 0.0160\n",
      "Epoch [10/10], Step [649/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [650/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [651/1079], Loss: 0.0037\n",
      "Epoch [10/10], Step [652/1079], Loss: 0.0017\n",
      "Epoch [10/10], Step [653/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [654/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [655/1079], Loss: 0.0491\n",
      "Epoch [10/10], Step [656/1079], Loss: 0.0433\n",
      "Epoch [10/10], Step [657/1079], Loss: 0.0025\n",
      "Epoch [10/10], Step [658/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [659/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [660/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [661/1079], Loss: 0.0191\n",
      "Epoch [10/10], Step [662/1079], Loss: 0.0192\n",
      "Epoch [10/10], Step [663/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [664/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [665/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [666/1079], Loss: 0.0241\n",
      "Epoch [10/10], Step [667/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [668/1079], Loss: 0.0083\n",
      "Epoch [10/10], Step [669/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [670/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [671/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [672/1079], Loss: 0.0255\n",
      "Epoch [10/10], Step [673/1079], Loss: 0.0022\n",
      "Epoch [10/10], Step [674/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [675/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [676/1079], Loss: 0.0068\n",
      "Epoch [10/10], Step [677/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [678/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [679/1079], Loss: 0.0088\n",
      "Epoch [10/10], Step [680/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [681/1079], Loss: 0.0028\n",
      "Epoch [10/10], Step [682/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [683/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [684/1079], Loss: 0.0393\n",
      "Epoch [10/10], Step [685/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [686/1079], Loss: 0.0032\n",
      "Epoch [10/10], Step [687/1079], Loss: 0.0017\n",
      "Epoch [10/10], Step [688/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [689/1079], Loss: 0.0020\n",
      "Epoch [10/10], Step [690/1079], Loss: 0.0035\n",
      "Epoch [10/10], Step [691/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [692/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [693/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [694/1079], Loss: 0.1634\n",
      "Epoch [10/10], Step [695/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [696/1079], Loss: 0.0095\n",
      "Epoch [10/10], Step [697/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [698/1079], Loss: 0.0098\n",
      "Epoch [10/10], Step [699/1079], Loss: 0.0032\n",
      "Epoch [10/10], Step [700/1079], Loss: 0.0036\n",
      "Epoch [10/10], Step [701/1079], Loss: 0.0208\n",
      "Epoch [10/10], Step [702/1079], Loss: 0.0024\n",
      "Epoch [10/10], Step [703/1079], Loss: 0.0459\n",
      "Epoch [10/10], Step [704/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [705/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [706/1079], Loss: 0.0050\n",
      "Epoch [10/10], Step [707/1079], Loss: 0.0090\n",
      "Epoch [10/10], Step [708/1079], Loss: 0.0088\n",
      "Epoch [10/10], Step [709/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [710/1079], Loss: 0.0030\n",
      "Epoch [10/10], Step [711/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [712/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [713/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [714/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [715/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [716/1079], Loss: 0.0055\n",
      "Epoch [10/10], Step [717/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [718/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [719/1079], Loss: 0.0021\n",
      "Epoch [10/10], Step [720/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [721/1079], Loss: 0.0023\n",
      "Epoch [10/10], Step [722/1079], Loss: 0.0504\n",
      "Epoch [10/10], Step [723/1079], Loss: 0.0046\n",
      "Epoch [10/10], Step [724/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [725/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [726/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [727/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [728/1079], Loss: 0.0022\n",
      "Epoch [10/10], Step [729/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [730/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [731/1079], Loss: 0.0130\n",
      "Epoch [10/10], Step [732/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [733/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [734/1079], Loss: 0.0024\n",
      "Epoch [10/10], Step [735/1079], Loss: 0.0108\n",
      "Epoch [10/10], Step [736/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [737/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [738/1079], Loss: 0.0118\n",
      "Epoch [10/10], Step [739/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [740/1079], Loss: 0.0022\n",
      "Epoch [10/10], Step [741/1079], Loss: 0.0028\n",
      "Epoch [10/10], Step [742/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [743/1079], Loss: 0.0157\n",
      "Epoch [10/10], Step [744/1079], Loss: 0.0061\n",
      "Epoch [10/10], Step [745/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [746/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [747/1079], Loss: 0.0214\n",
      "Epoch [10/10], Step [748/1079], Loss: 0.0016\n",
      "Epoch [10/10], Step [749/1079], Loss: 0.0211\n",
      "Epoch [10/10], Step [750/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [751/1079], Loss: 0.0214\n",
      "Epoch [10/10], Step [752/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [753/1079], Loss: 0.0014\n",
      "Epoch [10/10], Step [754/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [755/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [756/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [757/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [758/1079], Loss: 0.0084\n",
      "Epoch [10/10], Step [759/1079], Loss: 0.0347\n",
      "Epoch [10/10], Step [760/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [761/1079], Loss: 0.0020\n",
      "Epoch [10/10], Step [762/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [763/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [764/1079], Loss: 0.0137\n",
      "Epoch [10/10], Step [765/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [766/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [767/1079], Loss: 0.0016\n",
      "Epoch [10/10], Step [768/1079], Loss: 0.0099\n",
      "Epoch [10/10], Step [769/1079], Loss: 0.0099\n",
      "Epoch [10/10], Step [770/1079], Loss: 0.0087\n",
      "Epoch [10/10], Step [771/1079], Loss: 0.0083\n",
      "Epoch [10/10], Step [772/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [773/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [774/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [775/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [776/1079], Loss: 0.0118\n",
      "Epoch [10/10], Step [777/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [778/1079], Loss: 0.0067\n",
      "Epoch [10/10], Step [779/1079], Loss: 0.0249\n",
      "Epoch [10/10], Step [780/1079], Loss: 0.0126\n",
      "Epoch [10/10], Step [781/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [782/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [783/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [784/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [785/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [786/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [787/1079], Loss: 0.0359\n",
      "Epoch [10/10], Step [788/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [789/1079], Loss: 0.0040\n",
      "Epoch [10/10], Step [790/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [791/1079], Loss: 0.0020\n",
      "Epoch [10/10], Step [792/1079], Loss: 0.0064\n",
      "Epoch [10/10], Step [793/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [794/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [795/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [796/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [797/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [798/1079], Loss: 0.0098\n",
      "Epoch [10/10], Step [799/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [800/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [801/1079], Loss: 0.0026\n",
      "Epoch [10/10], Step [802/1079], Loss: 0.0724\n",
      "Epoch [10/10], Step [803/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [804/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [805/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [806/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [807/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [808/1079], Loss: 0.0090\n",
      "Epoch [10/10], Step [809/1079], Loss: 0.0027\n",
      "Epoch [10/10], Step [810/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [811/1079], Loss: 0.0060\n",
      "Epoch [10/10], Step [812/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [813/1079], Loss: 0.0029\n",
      "Epoch [10/10], Step [814/1079], Loss: 0.0023\n",
      "Epoch [10/10], Step [815/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [816/1079], Loss: 0.0016\n",
      "Epoch [10/10], Step [817/1079], Loss: 0.0131\n",
      "Epoch [10/10], Step [818/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [819/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [820/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [821/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [822/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [823/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [824/1079], Loss: 0.0016\n",
      "Epoch [10/10], Step [825/1079], Loss: 0.0074\n",
      "Epoch [10/10], Step [826/1079], Loss: 0.0036\n",
      "Epoch [10/10], Step [827/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [828/1079], Loss: 0.0311\n",
      "Epoch [10/10], Step [829/1079], Loss: 0.0265\n",
      "Epoch [10/10], Step [830/1079], Loss: 0.0187\n",
      "Epoch [10/10], Step [831/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [832/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [833/1079], Loss: 0.0376\n",
      "Epoch [10/10], Step [834/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [835/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [836/1079], Loss: 0.0044\n",
      "Epoch [10/10], Step [837/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [838/1079], Loss: 0.0031\n",
      "Epoch [10/10], Step [839/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [840/1079], Loss: 0.0326\n",
      "Epoch [10/10], Step [841/1079], Loss: 0.0024\n",
      "Epoch [10/10], Step [842/1079], Loss: 0.0842\n",
      "Epoch [10/10], Step [843/1079], Loss: 0.0656\n",
      "Epoch [10/10], Step [844/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [845/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [846/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [847/1079], Loss: 0.0058\n",
      "Epoch [10/10], Step [848/1079], Loss: 0.0194\n",
      "Epoch [10/10], Step [849/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [850/1079], Loss: 0.0416\n",
      "Epoch [10/10], Step [851/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [852/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [853/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [854/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [855/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [856/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [857/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [858/1079], Loss: 0.0059\n",
      "Epoch [10/10], Step [859/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [860/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [861/1079], Loss: 0.0028\n",
      "Epoch [10/10], Step [862/1079], Loss: 0.0122\n",
      "Epoch [10/10], Step [863/1079], Loss: 0.0061\n",
      "Epoch [10/10], Step [864/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [865/1079], Loss: 0.0659\n",
      "Epoch [10/10], Step [866/1079], Loss: 0.0134\n",
      "Epoch [10/10], Step [867/1079], Loss: 0.0055\n",
      "Epoch [10/10], Step [868/1079], Loss: 0.0194\n",
      "Epoch [10/10], Step [869/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [870/1079], Loss: 0.0049\n",
      "Epoch [10/10], Step [871/1079], Loss: 0.0527\n",
      "Epoch [10/10], Step [872/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [873/1079], Loss: 0.0368\n",
      "Epoch [10/10], Step [874/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [875/1079], Loss: 0.0164\n",
      "Epoch [10/10], Step [876/1079], Loss: 0.0109\n",
      "Epoch [10/10], Step [877/1079], Loss: 0.0017\n",
      "Epoch [10/10], Step [878/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [879/1079], Loss: 0.0637\n",
      "Epoch [10/10], Step [880/1079], Loss: 0.0020\n",
      "Epoch [10/10], Step [881/1079], Loss: 0.0029\n",
      "Epoch [10/10], Step [882/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [883/1079], Loss: 0.0319\n",
      "Epoch [10/10], Step [884/1079], Loss: 0.0013\n",
      "Epoch [10/10], Step [885/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [886/1079], Loss: 0.0088\n",
      "Epoch [10/10], Step [887/1079], Loss: 0.0154\n",
      "Epoch [10/10], Step [888/1079], Loss: 0.0184\n",
      "Epoch [10/10], Step [889/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [890/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [891/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [892/1079], Loss: 0.0032\n",
      "Epoch [10/10], Step [893/1079], Loss: 0.0035\n",
      "Epoch [10/10], Step [894/1079], Loss: 0.0031\n",
      "Epoch [10/10], Step [895/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [896/1079], Loss: 0.0066\n",
      "Epoch [10/10], Step [897/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [898/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [899/1079], Loss: 0.0063\n",
      "Epoch [10/10], Step [900/1079], Loss: 0.0016\n",
      "Epoch [10/10], Step [901/1079], Loss: 0.0085\n",
      "Epoch [10/10], Step [902/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [903/1079], Loss: 0.0014\n",
      "Epoch [10/10], Step [904/1079], Loss: 0.0048\n",
      "Epoch [10/10], Step [905/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [906/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [907/1079], Loss: 0.0578\n",
      "Epoch [10/10], Step [908/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [909/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [910/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [911/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [912/1079], Loss: 0.0996\n",
      "Epoch [10/10], Step [913/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [914/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [915/1079], Loss: 0.0263\n",
      "Epoch [10/10], Step [916/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [917/1079], Loss: 0.0023\n",
      "Epoch [10/10], Step [918/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [919/1079], Loss: 0.0276\n",
      "Epoch [10/10], Step [920/1079], Loss: 0.0390\n",
      "Epoch [10/10], Step [921/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [922/1079], Loss: 0.0011\n",
      "Epoch [10/10], Step [923/1079], Loss: 0.0045\n",
      "Epoch [10/10], Step [924/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [925/1079], Loss: 0.0281\n",
      "Epoch [10/10], Step [926/1079], Loss: 0.0077\n",
      "Epoch [10/10], Step [927/1079], Loss: 0.0029\n",
      "Epoch [10/10], Step [928/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [929/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [930/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [931/1079], Loss: 0.0048\n",
      "Epoch [10/10], Step [932/1079], Loss: 0.0008\n",
      "Epoch [10/10], Step [933/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [934/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [935/1079], Loss: 0.0014\n",
      "Epoch [10/10], Step [936/1079], Loss: 0.0151\n",
      "Epoch [10/10], Step [937/1079], Loss: 0.0085\n",
      "Epoch [10/10], Step [938/1079], Loss: 0.0487\n",
      "Epoch [10/10], Step [939/1079], Loss: 0.0059\n",
      "Epoch [10/10], Step [940/1079], Loss: 0.0043\n",
      "Epoch [10/10], Step [941/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [942/1079], Loss: 0.0136\n",
      "Epoch [10/10], Step [943/1079], Loss: 0.0420\n",
      "Epoch [10/10], Step [944/1079], Loss: 0.0318\n",
      "Epoch [10/10], Step [945/1079], Loss: 0.0315\n",
      "Epoch [10/10], Step [946/1079], Loss: 0.0041\n",
      "Epoch [10/10], Step [947/1079], Loss: 0.0069\n",
      "Epoch [10/10], Step [948/1079], Loss: 0.0028\n",
      "Epoch [10/10], Step [949/1079], Loss: 0.0024\n",
      "Epoch [10/10], Step [950/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [951/1079], Loss: 0.0007\n",
      "Epoch [10/10], Step [952/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [953/1079], Loss: 0.0951\n",
      "Epoch [10/10], Step [954/1079], Loss: 0.0025\n",
      "Epoch [10/10], Step [955/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [956/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [957/1079], Loss: 0.0075\n",
      "Epoch [10/10], Step [958/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [959/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [960/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [961/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [962/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [963/1079], Loss: 0.0014\n",
      "Epoch [10/10], Step [964/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [965/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [966/1079], Loss: 0.0093\n",
      "Epoch [10/10], Step [967/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [968/1079], Loss: 0.0096\n",
      "Epoch [10/10], Step [969/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [970/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [971/1079], Loss: 0.0036\n",
      "Epoch [10/10], Step [972/1079], Loss: 0.0082\n",
      "Epoch [10/10], Step [973/1079], Loss: 0.0043\n",
      "Epoch [10/10], Step [974/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [975/1079], Loss: 0.0039\n",
      "Epoch [10/10], Step [976/1079], Loss: 0.0151\n",
      "Epoch [10/10], Step [977/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [978/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [979/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [980/1079], Loss: 0.0034\n",
      "Epoch [10/10], Step [981/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [982/1079], Loss: 0.0014\n",
      "Epoch [10/10], Step [983/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [984/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [985/1079], Loss: 0.0015\n",
      "Epoch [10/10], Step [986/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [987/1079], Loss: 0.0046\n",
      "Epoch [10/10], Step [988/1079], Loss: 0.0037\n",
      "Epoch [10/10], Step [989/1079], Loss: 0.0037\n",
      "Epoch [10/10], Step [990/1079], Loss: 0.0093\n",
      "Epoch [10/10], Step [991/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [992/1079], Loss: 0.0050\n",
      "Epoch [10/10], Step [993/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [994/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [995/1079], Loss: 0.0157\n",
      "Epoch [10/10], Step [996/1079], Loss: 0.0019\n",
      "Epoch [10/10], Step [997/1079], Loss: 0.0014\n",
      "Epoch [10/10], Step [998/1079], Loss: 0.0540\n",
      "Epoch [10/10], Step [999/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [1000/1079], Loss: 0.0041\n",
      "Epoch [10/10], Step [1001/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [1002/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [1003/1079], Loss: 0.0009\n",
      "Epoch [10/10], Step [1004/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [1005/1079], Loss: 0.0037\n",
      "Epoch [10/10], Step [1006/1079], Loss: 0.0139\n",
      "Epoch [10/10], Step [1007/1079], Loss: 0.0041\n",
      "Epoch [10/10], Step [1008/1079], Loss: 0.0565\n",
      "Epoch [10/10], Step [1009/1079], Loss: 0.0038\n",
      "Epoch [10/10], Step [1010/1079], Loss: 0.1289\n",
      "Epoch [10/10], Step [1011/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [1012/1079], Loss: 0.0111\n",
      "Epoch [10/10], Step [1013/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [1014/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [1015/1079], Loss: 0.0018\n",
      "Epoch [10/10], Step [1016/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [1017/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [1018/1079], Loss: 0.0047\n",
      "Epoch [10/10], Step [1019/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [1020/1079], Loss: 0.0071\n",
      "Epoch [10/10], Step [1021/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [1022/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [1023/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [1024/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [1025/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [1026/1079], Loss: 0.0059\n",
      "Epoch [10/10], Step [1027/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [1028/1079], Loss: 0.0004\n",
      "Epoch [10/10], Step [1029/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [1030/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [1031/1079], Loss: 0.0010\n",
      "Epoch [10/10], Step [1032/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [1033/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [1034/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [1035/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [1036/1079], Loss: 0.0407\n",
      "Epoch [10/10], Step [1037/1079], Loss: 0.0057\n",
      "Epoch [10/10], Step [1038/1079], Loss: 0.0012\n",
      "Epoch [10/10], Step [1039/1079], Loss: 0.0101\n",
      "Epoch [10/10], Step [1040/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [1041/1079], Loss: 0.0021\n",
      "Epoch [10/10], Step [1042/1079], Loss: 0.0048\n",
      "Epoch [10/10], Step [1043/1079], Loss: 0.1334\n",
      "Epoch [10/10], Step [1044/1079], Loss: 0.0016\n",
      "Epoch [10/10], Step [1045/1079], Loss: 0.0057\n",
      "Epoch [10/10], Step [1046/1079], Loss: 0.0027\n",
      "Epoch [10/10], Step [1047/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [1048/1079], Loss: 0.0093\n",
      "Epoch [10/10], Step [1049/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [1050/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [1051/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [1052/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [1053/1079], Loss: 0.0003\n",
      "Epoch [10/10], Step [1054/1079], Loss: 0.0895\n",
      "Epoch [10/10], Step [1055/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [1056/1079], Loss: 0.0036\n",
      "Epoch [10/10], Step [1057/1079], Loss: 0.0062\n",
      "Epoch [10/10], Step [1058/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [1059/1079], Loss: 0.0006\n",
      "Epoch [10/10], Step [1060/1079], Loss: 0.0312\n",
      "Epoch [10/10], Step [1061/1079], Loss: 0.0053\n",
      "Epoch [10/10], Step [1062/1079], Loss: 0.0016\n",
      "Epoch [10/10], Step [1063/1079], Loss: 0.0029\n",
      "Epoch [10/10], Step [1064/1079], Loss: 0.0046\n",
      "Epoch [10/10], Step [1065/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [1066/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [1067/1079], Loss: 0.0025\n",
      "Epoch [10/10], Step [1068/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [1069/1079], Loss: 0.0104\n",
      "Epoch [10/10], Step [1070/1079], Loss: 0.0016\n",
      "Epoch [10/10], Step [1071/1079], Loss: 0.0002\n",
      "Epoch [10/10], Step [1072/1079], Loss: 0.0275\n",
      "Epoch [10/10], Step [1073/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [1074/1079], Loss: 0.0000\n",
      "Epoch [10/10], Step [1075/1079], Loss: 0.0001\n",
      "Epoch [10/10], Step [1076/1079], Loss: 0.0005\n",
      "Epoch [10/10], Step [1077/1079], Loss: 0.0081\n",
      "Epoch [10/10], Step [1078/1079], Loss: 0.0134\n",
      "Epoch [10/10], Step [1079/1079], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "\n",
    "# Prefer CUDA > metal > CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "start_time = time.time()\n",
    "\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    val_losses.append(val_loss / len(validation_loader))\n",
    "    \n",
    "    ax.clear()\n",
    "    ax.plot(range(1, epoch+2), train_losses, label='Train Loss')\n",
    "    ax.plot(range(1, epoch+2), val_losses, label='Validation Loss')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    ax.set_title('Training and Validation Loss')\n",
    "    plt.pause(0.1)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 251.51 seconds\n",
      "Train Accuracy: 0.999\n",
      "Validation Accuracy: 1.000\n",
      "Test Accuracy: 0.994\n"
     ]
    }
   ],
   "source": [
    "# Plot training and validation loss\n",
    "plt.plot(range(1, EPOCHS+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, EPOCHS+1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "train_acc = evaluate(train_loader)\n",
    "val_acc = evaluate(validation_loader)\n",
    "test_acc = evaluate(test_loader)\n",
    "\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(f\"Train Accuracy: {train_acc:.3f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.3f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments_JF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
